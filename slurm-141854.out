wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240222_032648-wsu78eti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scintillating-noodles-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/wsu78eti
Using cpu device
-----------------------------------
| avg_speed          | 1.1        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.1        |
| reward             | -0.7893295 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.33e+03  |
| time/              |            |
|    fps             | 81         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2048       |
-----------------------------------
-------------------------------------------
| avg_speed                | 1.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.28         |
| reward                   | -0.99038064  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0037101777 |
|    clip_fraction         | 0.0619       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.127        |
|    cost_value_loss       | 0.00984      |
|    cost_values           | 0.162        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.000306    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 193          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.000179    |
|    std                   | 1.01         |
|    value_loss            | 437          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.9          |
| reward                   | -1.4174099   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0029681204 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.185        |
|    cost_value_loss       | 0.687        |
|    cost_values           | 0.162        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 227          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 1.01         |
|    value_loss            | 475          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.173        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.173        |
| reward                   | -1.166182    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.43e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0059584873 |
|    clip_fraction         | 0.0539       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.195        |
|    cost_value_loss       | 0.228        |
|    cost_values           | 0.181        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 346          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 1.01         |
|    value_loss            | 714          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.08        |
| reward                   | -0.5691006  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.37e+03   |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 10240       |
| train/                   |             |
|    approx_kl             | 0.004785875 |
|    clip_fraction         | 0.0428      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.157       |
|    cost_value_loss       | 0.000417    |
|    cost_values           | 0.159       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 272         |
|    n_updates             | 40          |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 1           |
|    value_loss            | 569         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.75         |
| reward                   | -1.418833    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0039074146 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.497        |
|    cost_value_loss       | 1.43         |
|    cost_values           | 0.471        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 175          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.999        |
|    value_loss            | 345          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3469167   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0028183707 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.858        |
|    cost_value_loss       | 2.61         |
|    cost_values           | 0.815        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 145          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.994        |
|    value_loss            | 294          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.44         |
| reward                   | -1.0635716   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0036396286 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.692        |
|    cost_value_loss       | 0.008        |
|    cost_values           | 0.709        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 229          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.994        |
|    value_loss            | 468          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -1.6135249  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.34e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 299         |
|    total_timesteps       | 18432       |
| train/                   |             |
|    approx_kl             | 0.005473659 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.695       |
|    cost_value_loss       | 0.351       |
|    cost_values           | 0.698       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 223         |
|    n_updates             | 80          |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.993       |
|    value_loss            | 466         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.5114822   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0027436635 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.651        |
|    cost_value_loss       | 0.312        |
|    cost_values           | 0.658        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 338          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.000124    |
|    std                   | 0.996        |
|    value_loss            | 671          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -1.7810568  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.43e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 367         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.004198662 |
|    clip_fraction         | 0.0382      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.745       |
|    cost_value_loss       | 0.533       |
|    cost_values           | 0.733       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 318         |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.996       |
|    value_loss            | 636         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -1.1156057  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.43e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 12          |
|    time_elapsed          | 401         |
|    total_timesteps       | 24576       |
| train/                   |             |
|    approx_kl             | 0.003138301 |
|    clip_fraction         | 0.00288     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.65        |
|    cost_value_loss       | 0.131       |
|    cost_values           | 0.666       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 535         |
|    n_updates             | 110         |
|    policy_gradient_loss  | -0.000195   |
|    std                   | 0.996       |
|    value_loss            | 1.05e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.2175769   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 435          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0042584287 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.748        |
|    cost_value_loss       | 0.426        |
|    cost_values           | 0.739        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 205          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.992        |
|    value_loss            | 418          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.0757294   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 469          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0026245606 |
|    clip_fraction         | 0.00713      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.607        |
|    cost_value_loss       | 0.00623      |
|    cost_values           | 0.619        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 228          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.000536    |
|    std                   | 0.988        |
|    value_loss            | 472          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.119001    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 503          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0017978027 |
|    clip_fraction         | 0.00293      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.529        |
|    cost_value_loss       | 0.024        |
|    cost_values           | 0.538        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 179          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.000192    |
|    std                   | 0.986        |
|    value_loss            | 380          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.71008855 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 16          |
|    time_elapsed          | 536         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.004935734 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.564       |
|    cost_value_loss       | 0.209       |
|    cost_values           | 0.562       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 179         |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.982       |
|    value_loss            | 372         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.4315815   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 570          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0057996307 |
|    clip_fraction         | 0.0425       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.671        |
|    cost_value_loss       | 0.442        |
|    cost_values           | 0.662        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 128          |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.978        |
|    value_loss            | 259          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.0896714   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 604          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0028380847 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.734        |
|    cost_value_loss       | 0.954        |
|    cost_values           | 0.729        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 185          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.000879    |
|    std                   | 0.976        |
|    value_loss            | 384          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -3.1922426  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 638         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.002708584 |
|    clip_fraction         | 0.00537     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.84        |
|    cost_value_loss       | 1.04        |
|    cost_values           | 0.828       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 357         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.000295   |
|    std                   | 0.974       |
|    value_loss            | 717         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.623031    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 672          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0037103435 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.776        |
|    cost_value_loss       | 0.322        |
|    cost_values           | 0.78         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 355          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.969        |
|    value_loss            | 717          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.6551585   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 705          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0052047796 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.943        |
|    cost_value_loss       | 0.669        |
|    cost_values           | 0.93         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 232          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.969        |
|    value_loss            | 448          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 1.38       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.38       |
| reward                   | -0.634291  |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -1.42e+03  |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 22         |
|    time_elapsed          | 739        |
|    total_timesteps       | 45056      |
| train/                   |            |
|    approx_kl             | 0.00503887 |
|    clip_fraction         | 0.0514     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.759      |
|    cost_value_loss       | 0.00958    |
|    cost_values           | 0.773      |
|    entropy               | -2.78      |
|    entropy_loss          | -2.78      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 163        |
|    n_updates             | 210        |
|    policy_gradient_loss  | -0.00357   |
|    std                   | 0.971      |
|    value_loss            | 339        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 6            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6            |
| reward                   | -1.1147515   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.43e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 773          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0032748226 |
|    clip_fraction         | 0.00845      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.633        |
|    cost_value_loss       | 0.00883      |
|    cost_values           | 0.648        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 405          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.000646    |
|    std                   | 0.974        |
|    value_loss            | 816          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.8808584  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 807         |
|    total_timesteps       | 49152       |
| train/                   |             |
|    approx_kl             | 0.004506639 |
|    clip_fraction         | 0.0329      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.63        |
|    cost_value_loss       | 0.235       |
|    cost_values           | 0.634       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 329         |
|    n_updates             | 230         |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 0.969       |
|    value_loss            | 686         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2296631   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 841          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0034268168 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.715        |
|    cost_value_loss       | 0.58         |
|    cost_values           | 0.709        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 123          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.969        |
|    value_loss            | 253          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.69004625 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.41e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 875         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.004388114 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.593       |
|    cost_value_loss       | 0.00967     |
|    cost_values           | 0.604       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 219         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.961       |
|    value_loss            | 454         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.91556674 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 909         |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.008198807 |
|    clip_fraction         | 0.0659      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.597       |
|    cost_value_loss       | 0.244       |
|    cost_values           | 0.598       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 174         |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.95        |
|    value_loss            | 342         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.125306   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 942         |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.002428951 |
|    clip_fraction         | 0.00547     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.541       |
|    cost_value_loss       | 0.124       |
|    cost_values           | 0.546       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 235         |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.000491   |
|    std                   | 0.947       |
|    value_loss            | 488         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9295245   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 976          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0037178346 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.463        |
|    cost_value_loss       | 0.019        |
|    cost_values           | 0.47         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 229          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.943        |
|    value_loss            | 453          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.07         |
| reward                   | -1.0551445   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1010         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0043566055 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.396        |
|    cost_value_loss       | 0.00642      |
|    cost_values           | 0.402        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 175          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.942        |
|    value_loss            | 340          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.7641531   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1043         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0029650833 |
|    clip_fraction         | 0.00547      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.327        |
|    cost_value_loss       | 0.00167      |
|    cost_values           | 0.332        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 198          |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.000226    |
|    std                   | 0.941        |
|    value_loss            | 415          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.7763982   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1077         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0031051517 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.56         |
|    cost_value_loss       | 0.814        |
|    cost_values           | 0.543        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 107          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.938        |
|    value_loss            | 224          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3526055  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.4e+03    |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1112        |
|    total_timesteps       | 67584       |
| train/                   |             |
|    approx_kl             | 0.003870614 |
|    clip_fraction         | 0.0085      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.7         |
|    cost_value_loss       | 0.807       |
|    cost_values           | 0.693       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 95.5        |
|    n_updates             | 320         |
|    policy_gradient_loss  | -0.000343   |
|    std                   | 0.938       |
|    value_loss            | 192         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5626085   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1146         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0032787009 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.674        |
|    cost_value_loss       | 0.274        |
|    cost_values           | 0.679        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.71        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 206          |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.000902    |
|    std                   | 0.934        |
|    value_loss            | 432          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.097522   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1180        |
|    total_timesteps       | 71680       |
| train/                   |             |
|    approx_kl             | 0.004336584 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.825       |
|    cost_value_loss       | 1           |
|    cost_values           | 0.813       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 2.38e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 190         |
|    n_updates             | 340         |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.937       |
|    value_loss            | 386         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4711672   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1214         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0036863904 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.949        |
|    cost_value_loss       | 1.61         |
|    cost_values           | 0.86         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.939        |
|    value_loss            | 225          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.3603833   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1247         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0032232436 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.866        |
|    cost_value_loss       | 0.265        |
|    cost_values           | 0.895        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.000675    |
|    std                   | 0.936        |
|    value_loss            | 228          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.88314754 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.35e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 38          |
|    time_elapsed          | 1281        |
|    total_timesteps       | 77824       |
| train/                   |             |
|    approx_kl             | 0.002272428 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.962       |
|    cost_value_loss       | 0.961       |
|    cost_values           | 0.952       |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 83.4        |
|    n_updates             | 370         |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.928       |
|    value_loss            | 167         |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.0359694 |
| rollout/                 |            |
|    ep_len_mean           | 990        |
|    ep_rew_mean           | -1.35e+03  |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 39         |
|    time_elapsed          | 1315       |
|    total_timesteps       | 79872      |
| train/                   |            |
|    approx_kl             | 0.0043794  |
|    clip_fraction         | 0.0302     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.06       |
|    cost_value_loss       | 0.775      |
|    cost_values           | 0.837      |
|    entropy               | -2.67      |
|    entropy_loss          | -2.68      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 54.1       |
|    n_updates             | 380        |
|    policy_gradient_loss  | -0.00148   |
|    std                   | 0.921      |
|    value_loss            | 123        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2410295   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1349         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0061330562 |
|    clip_fraction         | 0.0511       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.812        |
|    cost_value_loss       | 0.242        |
|    cost_values           | 0.93         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 119          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.922        |
|    value_loss            | 255          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7067577   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1384         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0054189735 |
|    clip_fraction         | 0.0422       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.709        |
|    cost_value_loss       | 0.0117       |
|    cost_values           | 0.782        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 97.7         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.917        |
|    value_loss            | 209          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -1.325096    |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1417         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0046476303 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.99         |
|    cost_values           | 0.862        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 131          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.914        |
|    value_loss            | 294          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8700566   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1451         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0024790908 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.895        |
|    cost_value_loss       | 0.396        |
|    cost_values           | 0.804        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.4         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.916        |
|    value_loss            | 131          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.8245946  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 44          |
|    time_elapsed          | 1485        |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.005749439 |
|    clip_fraction         | 0.0497      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.911       |
|    cost_value_loss       | 0.78        |
|    cost_values           | 0.885       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 122         |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.914       |
|    value_loss            | 263         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2566562  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 45          |
|    time_elapsed          | 1519        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.003607493 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.769       |
|    cost_value_loss       | 0.0436      |
|    cost_values           | 0.863       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 136         |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.914       |
|    value_loss            | 293         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8685097   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1552         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0039987196 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.727        |
|    cost_value_loss       | 0.104        |
|    cost_values           | 0.768        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 124          |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.908        |
|    value_loss            | 253          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.7124042   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1586         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0041485825 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.687        |
|    cost_value_loss       | 0.238        |
|    cost_values           | 0.713        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 83.3         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.901        |
|    value_loss            | 176          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3324494   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1620         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0036787796 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.78         |
|    cost_value_loss       | 0.547        |
|    cost_values           | 0.734        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.3         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.894        |
|    value_loss            | 128          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.5706172  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 49          |
|    time_elapsed          | 1655        |
|    total_timesteps       | 100352      |
| train/                   |             |
|    approx_kl             | 0.004999062 |
|    clip_fraction         | 0.0367      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.808       |
|    cost_value_loss       | 0.5         |
|    cost_values           | 0.795       |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 80.4        |
|    n_updates             | 480         |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.894       |
|    value_loss            | 169         |
------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.88388854 |
| rollout/           |             |
|    ep_len_mean     | 975         |
|    ep_rew_mean     | -1.29e+03   |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 102400      |
------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.4742846   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0029154383 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.806        |
|    cost_value_loss       | 0.111        |
|    cost_values           | 0.917        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 95.3         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.891        |
|    value_loss            | 208          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.51        |
| reward                   | -0.61547744 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 91          |
|    total_timesteps       | 106496      |
| train/                   |             |
|    approx_kl             | 0.003524008 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.856       |
|    cost_value_loss       | 0.55        |
|    cost_values           | 0.848       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 75.2        |
|    n_updates             | 510         |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.888       |
|    value_loss            | 151         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.03         |
| reward                   | -0.57590544  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 4            |
|    time_elapsed          | 125          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0036458946 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.691        |
|    cost_value_loss       | 0.0191       |
|    cost_values           | 0.799        |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.886        |
|    value_loss            | 258          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.9842916   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 160          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0020227053 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.828        |
|    cost_value_loss       | 0.475        |
|    cost_values           | 0.766        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.7         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.878        |
|    value_loss            | 141          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.86839896 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 195         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.006381069 |
|    clip_fraction         | 0.02        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.769       |
|    cost_value_loss       | 0.317       |
|    cost_values           | 0.804       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 144         |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.000766   |
|    std                   | 0.873       |
|    value_loss            | 293         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5645633   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 229          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0035892234 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.719        |
|    cost_value_loss       | 0.153        |
|    cost_values           | 0.763        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.87         |
|    value_loss            | 318          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.2556806   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 264          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0023010182 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.744        |
|    cost_value_loss       | 0.368        |
|    cost_values           | 0.737        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.7         |
|    n_updates             | 560          |
|    policy_gradient_loss  | 7.44e-05     |
|    std                   | 0.868        |
|    value_loss            | 109          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.5308896   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 299          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0050408705 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.64         |
|    cost_value_loss       | 0.0698       |
|    cost_values           | 0.699        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.7         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.000365    |
|    std                   | 0.864        |
|    value_loss            | 142          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.4387074   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0019439028 |
|    clip_fraction         | 0.00894      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.535        |
|    cost_value_loss       | 0.00826      |
|    cost_values           | 0.605        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.000198    |
|    std                   | 0.866        |
|    value_loss            | 257          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7766282  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 122880      |
| train/                   |             |
|    approx_kl             | 0.004070236 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.525       |
|    cost_value_loss       | 0.14        |
|    cost_values           | 0.543       |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 228         |
|    n_updates             | 590         |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.865       |
|    value_loss            | 470         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.8443469   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0026315036 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.575        |
|    cost_value_loss       | 0.494        |
|    cost_values           | 0.542        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 238          |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00075     |
|    std                   | 0.864        |
|    value_loss            | 544          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.443113    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0065729357 |
|    clip_fraction         | 0.0647       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.537        |
|    cost_value_loss       | 0.209        |
|    cost_values           | 0.554        |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 183          |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 0.862        |
|    value_loss            | 382          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.7402248   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0034586159 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.448        |
|    cost_value_loss       | 0.00685      |
|    cost_values           | 0.517        |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 255          |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.000781    |
|    std                   | 0.862        |
|    value_loss            | 505          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.9432507   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 509          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0036813896 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.469        |
|    cost_value_loss       | 0.0967       |
|    cost_values           | 0.472        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 138          |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.859        |
|    value_loss            | 291          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1314895  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 543         |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.004853749 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.383       |
|    cost_value_loss       | 0.00455     |
|    cost_values           | 0.436       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 126         |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.854       |
|    value_loss            | 255         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.2611548   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0030121084 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.386        |
|    cost_value_loss       | 0.1          |
|    cost_values           | 0.39         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 145          |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.851        |
|    value_loss            | 287          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9005119   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0065608285 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.471        |
|    cost_value_loss       | 0.462        |
|    cost_values           | 0.431        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.4         |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.848        |
|    value_loss            | 117          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6724276   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0057161814 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.533        |
|    cost_value_loss       | 0.429        |
|    cost_values           | 0.503        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 117          |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.000949    |
|    std                   | 0.848        |
|    value_loss            | 238          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1491468  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 679         |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.004111409 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.458       |
|    cost_value_loss       | 0.0342      |
|    cost_values           | 0.507       |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 231         |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.849       |
|    value_loss            | 460         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9585775   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 712          |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0056088865 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.478        |
|    cost_value_loss       | 0.324        |
|    cost_values           | 0.474        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 138          |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.000983    |
|    std                   | 0.855        |
|    value_loss            | 284          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1612082   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 746          |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0034893053 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.775        |
|    cost_value_loss       | 1.11         |
|    cost_values           | 0.687        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.8         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.000634    |
|    std                   | 0.856        |
|    value_loss            | 81.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -1.1758889 |
| rollout/                 |            |
|    ep_len_mean           | 975        |
|    ep_rew_mean           | -1.26e+03  |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 23         |
|    time_elapsed          | 780        |
|    total_timesteps       | 147456     |
| train/                   |            |
|    approx_kl             | 0.00321808 |
|    clip_fraction         | 0.00981    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.823      |
|    cost_value_loss       | 0.529      |
|    cost_values           | 0.815      |
|    entropy               | -2.52      |
|    entropy_loss          | -2.53      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 98.4       |
|    n_updates             | 710        |
|    policy_gradient_loss  | -0.000537  |
|    std                   | 0.855      |
|    value_loss            | 216        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -2.3934014  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 814         |
|    total_timesteps       | 149504      |
| train/                   |             |
|    approx_kl             | 0.002661166 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 1.33        |
|    cost_values           | 0.932       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.4        |
|    n_updates             | 720         |
|    policy_gradient_loss  | -0.000809   |
|    std                   | 0.852       |
|    value_loss            | 40.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.64         |
| reward                   | -1.0072801   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 848          |
|    total_timesteps       | 151552       |
| train/                   |              |
|    approx_kl             | 0.0033576274 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.829        |
|    cost_value_loss       | 0.06         |
|    cost_values           | 0.837        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 98           |
|    n_updates             | 730          |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.85         |
|    value_loss            | 214          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.94         |
| reward                   | -0.7359636   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 882          |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0038309656 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.82         |
|    cost_values           | 0.945        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.1         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.853        |
|    value_loss            | 163          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.37         |
| reward                   | -0.91028076  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 917          |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0024076314 |
|    clip_fraction         | 0.00649      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.88         |
|    cost_value_loss       | 0.349        |
|    cost_values           | 0.913        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 102          |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.000476    |
|    std                   | 0.852        |
|    value_loss            | 214          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9687333   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 951          |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0023421068 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.639        |
|    cost_values           | 0.95         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.000234    |
|    std                   | 0.85         |
|    value_loss            | 45.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.8330269   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 986          |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0035629463 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.898        |
|    cost_value_loss       | 0.247        |
|    cost_values           | 0.905        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.7         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.85         |
|    value_loss            | 78.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8349515  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 161792      |
| train/                   |             |
|    approx_kl             | 0.003583341 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.842       |
|    cost_value_loss       | 0.22        |
|    cost_values           | 0.875       |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 76          |
|    n_updates             | 780         |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.849       |
|    value_loss            | 163         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -1.0136286  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1054        |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.005183969 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.881       |
|    cost_value_loss       | 0.635       |
|    cost_values           | 0.861       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 112         |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.844       |
|    value_loss            | 223         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -1.2651135   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1088         |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0038563393 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.785        |
|    cost_value_loss       | 0.13         |
|    cost_values           | 0.831        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.5         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.842        |
|    value_loss            | 72.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -1.646044   |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1122        |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.002973523 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.886       |
|    cost_value_loss       | 1.06        |
|    cost_values           | 0.819       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 58.9        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.000651   |
|    std                   | 0.846       |
|    value_loss            | 126         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -1.5075158   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1156         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0071248906 |
|    clip_fraction         | 0.0623       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.728        |
|    cost_value_loss       | 0.0419       |
|    cost_values           | 0.825        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 70.9         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 0.846        |
|    value_loss            | 149          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8907913  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1190        |
|    total_timesteps       | 172032      |
| train/                   |             |
|    approx_kl             | 0.002478269 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.635       |
|    cost_value_loss       | 0.0118      |
|    cost_values           | 0.72        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 85.9        |
|    n_updates             | 830         |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.846       |
|    value_loss            | 188         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9996495  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 36          |
|    time_elapsed          | 1224        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.003704256 |
|    clip_fraction         | 0.0197      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.574       |
|    cost_value_loss       | 0.0421      |
|    cost_values           | 0.63        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 73.4        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.843       |
|    value_loss            | 160         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.93956184  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1258         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0049226107 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.487        |
|    cost_value_loss       | 0.00616      |
|    cost_values           | 0.543        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.1         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.845        |
|    value_loss            | 80           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2970924   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1292         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0037175198 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.489        |
|    cost_value_loss       | 0.203        |
|    cost_values           | 0.488        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.848        |
|    value_loss            | 41.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.8201787  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 39          |
|    time_elapsed          | 1326        |
|    total_timesteps       | 180224      |
| train/                   |             |
|    approx_kl             | 0.004593839 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.416       |
|    cost_value_loss       | 0.0117      |
|    cost_values           | 0.454       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.5        |
|    n_updates             | 870         |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.846       |
|    value_loss            | 62.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.232414    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1360         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0027867744 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.573        |
|    cost_value_loss       | 0.745        |
|    cost_values           | 0.468        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.9         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.847        |
|    value_loss            | 187          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.597388   |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 41          |
|    time_elapsed          | 1394        |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.005011416 |
|    clip_fraction         | 0.0567      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.431       |
|    cost_value_loss       | 0.00911     |
|    cost_values           | 0.51        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 138         |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.844       |
|    value_loss            | 265         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -1.245007   |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 42          |
|    time_elapsed          | 1428        |
|    total_timesteps       | 186368      |
| train/                   |             |
|    approx_kl             | 0.004805051 |
|    clip_fraction         | 0.0562      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.886       |
|    cost_value_loss       | 1.29        |
|    cost_values           | 0.808       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.43        |
|    n_updates             | 900         |
|    policy_gradient_loss  | -0.000953   |
|    std                   | 0.842       |
|    value_loss            | 14.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.9251571   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1462         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0013875051 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.774        |
|    cost_value_loss       | 0.148        |
|    cost_values           | 0.865        |
|    entropy               | -2.48        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.2         |
|    n_updates             | 910          |
|    policy_gradient_loss  | 0.000414     |
|    std                   | 0.838        |
|    value_loss            | 60.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -1.0367571   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1496         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0033426182 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.664        |
|    cost_value_loss       | 0.026        |
|    cost_values           | 0.735        |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77.1         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.838        |
|    value_loss            | 155          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.7632052   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1531         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0021058207 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.771        |
|    cost_value_loss       | 0.861        |
|    cost_values           | 0.715        |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.5         |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.000692    |
|    std                   | 0.836        |
|    value_loss            | 134          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.8517977   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1565         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0044880128 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.927        |
|    cost_value_loss       | 0.94         |
|    cost_values           | 0.838        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.2         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.833        |
|    value_loss            | 95.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.5271456  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 47          |
|    time_elapsed          | 1599        |
|    total_timesteps       | 196608      |
| train/                   |             |
|    approx_kl             | 0.003947814 |
|    clip_fraction         | 0.0218      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.85        |
|    cost_value_loss       | 0.207       |
|    cost_values           | 0.908       |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 96.7        |
|    n_updates             | 950         |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.834       |
|    value_loss            | 202         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0197775   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1634         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0048279674 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.796        |
|    cost_value_loss       | 0.123        |
|    cost_values           | 0.84         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.3         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.832        |
|    value_loss            | 108          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.85         |
| reward                   | -0.7808223   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1667         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0036581303 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.716        |
|    cost_value_loss       | 0.117        |
|    cost_values           | 0.747        |
|    entropy               | -2.48        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.835        |
|    value_loss            | 29.7         |
-------------------------------------------
------------------------------------
| avg_speed          | 6.55        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 6.55        |
| reward             | -0.87159616 |
| rollout/           |             |
|    ep_len_mean     | 992         |
|    ep_rew_mean     | -1.29e+03   |
| time/              |             |
|    fps             | 82          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 202752      |
------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0090351   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0034655863 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.581        |
|    cost_value_loss       | 0.201        |
|    cost_values           | 0.57         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.834        |
|    value_loss            | 231          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.99398464 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.004149667 |
|    clip_fraction         | 0.0281      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.573       |
|    cost_value_loss       | 0.173       |
|    cost_values           | 0.575       |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.6        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.834       |
|    value_loss            | 59.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8551806   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0050097737 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.47         |
|    cost_value_loss       | 0.00577      |
|    cost_values           | 0.523        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.1         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.833        |
|    value_loss            | 69.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -1.3337386  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 161         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.008246735 |
|    clip_fraction         | 0.0873      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.684       |
|    cost_value_loss       | 0.569       |
|    cost_values           | 0.673       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.6        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.841       |
|    value_loss            | 42.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.0932333   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 195          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0035622856 |
|    clip_fraction         | 0.379        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.628        |
|    cost_value_loss       | 0.151        |
|    cost_values           | 0.74         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.3         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | 0.043        |
|    std                   | 0.845        |
|    value_loss            | 114          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -1.4905508   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 229          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0037095195 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.56         |
|    cost_value_loss       | 0.00663      |
|    cost_values           | 0.609        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.5         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.844        |
|    value_loss            | 76.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.9622014   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 263          |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0037968415 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.457        |
|    cost_value_loss       | 0.00437      |
|    cost_values           | 0.49         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.1         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.844        |
|    value_loss            | 46.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.366        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.366        |
| reward                   | -0.738943    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 9            |
|    time_elapsed          | 296          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0037209084 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.365        |
|    cost_value_loss       | 0.00371      |
|    cost_values           | 0.41         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.9         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.843        |
|    value_loss            | 98.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.11         |
| reward                   | -0.5860412   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 330          |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0059662173 |
|    clip_fraction         | 0.0405       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.361        |
|    cost_value_loss       | 0.0653       |
|    cost_values           | 0.362        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.842        |
|    value_loss            | 30.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0105726   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 364          |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0037165778 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.763        |
|    cost_value_loss       | 1.57         |
|    cost_values           | 0.721        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.49        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00323     |
|    std                   | 0.843        |
|    value_loss            | 25.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.59092635  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 398          |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0051041073 |
|    clip_fraction         | 0.00767      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.786        |
|    cost_value_loss       | 0.559        |
|    cost_values           | 0.76         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.8         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.000484    |
|    std                   | 0.843        |
|    value_loss            | 82.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0928851  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 433         |
|    total_timesteps       | 227328      |
| train/                   |             |
|    approx_kl             | 0.003322748 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.687       |
|    cost_value_loss       | 0.0734      |
|    cost_values           | 0.706       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 1100        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.844       |
|    value_loss            | 26.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1474863  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 14          |
|    time_elapsed          | 467         |
|    total_timesteps       | 229376      |
| train/                   |             |
|    approx_kl             | 0.004592651 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.886       |
|    cost_value_loss       | 1.18        |
|    cost_values           | 0.82        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.1        |
|    n_updates             | 1110        |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.844       |
|    value_loss            | 65          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.93181115  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 501          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0031371296 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.868        |
|    cost_value_loss       | 0.27         |
|    cost_values           | 0.886        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.3         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.843        |
|    value_loss            | 71.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.78675467  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 16           |
|    time_elapsed          | 535          |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0048156683 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.792        |
|    cost_value_loss       | 0.166        |
|    cost_values           | 0.802        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.84         |
|    value_loss            | 23.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5612773   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 17           |
|    time_elapsed          | 569          |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0033270144 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.73         |
|    cost_values           | 1.01         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.56         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | 0.00039      |
|    std                   | 0.843        |
|    value_loss            | 20           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1393118   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 18           |
|    time_elapsed          | 603          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0013403569 |
|    clip_fraction         | 0.0755       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 5.62         |
|    cost_values           | 1.11         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | 0.00242      |
|    std                   | 0.844        |
|    value_loss            | 22.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.09381    |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 19          |
|    time_elapsed          | 637         |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.007820092 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 1.23        |
|    cost_values           | 1.27        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | 4.2e-05     |
|    std                   | 0.837       |
|    value_loss            | 7.79        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.7871457 |
| rollout/                 |            |
|    ep_len_mean           | 986        |
|    ep_rew_mean           | -1.16e+03  |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 20         |
|    time_elapsed          | 670        |
|    total_timesteps       | 241664     |
| train/                   |            |
|    approx_kl             | 0.00565943 |
|    clip_fraction         | 0.0984     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.34       |
|    cost_value_loss       | 0.946      |
|    cost_values           | 1.15       |
|    entropy               | -2.48      |
|    entropy_loss          | -2.48      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 12.1       |
|    n_updates             | 1170       |
|    policy_gradient_loss  | 0.000304   |
|    std                   | 0.836      |
|    value_loss            | 24.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.82735586  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 21           |
|    time_elapsed          | 704          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0027131282 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.59         |
|    cost_values           | 1.07         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.836        |
|    value_loss            | 31.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8753345  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 738         |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.005397437 |
|    clip_fraction         | 0.0456      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.85        |
|    cost_value_loss       | 0.0524      |
|    cost_values           | 0.939       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50          |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.838       |
|    value_loss            | 100         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.9584265  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 773         |
|    total_timesteps       | 247808      |
| train/                   |             |
|    approx_kl             | 0.004803026 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 5.17        |
|    cost_values           | 1.32        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 1200        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.835       |
|    value_loss            | 19.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.8220762   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 807          |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0043471255 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 2.72         |
|    cost_values           | 1.73         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.48        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.98         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.000433    |
|    std                   | 0.834        |
|    value_loss            | 12.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -1.8409601    |
| rollout/                 |               |
|    ep_len_mean           | 986           |
|    ep_rew_mean           | -1.14e+03     |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 25            |
|    time_elapsed          | 841           |
|    total_timesteps       | 251904        |
| train/                   |               |
|    approx_kl             | 0.00014888553 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.93          |
|    cost_value_loss       | 2.62          |
|    cost_values           | 1.57          |
|    entropy               | -2.47         |
|    entropy_loss          | -2.47         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 27.9          |
|    n_updates             | 1220          |
|    policy_gradient_loss  | 0.000511      |
|    std                   | 0.833         |
|    value_loss            | 58.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0797907   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 875          |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0030098727 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 1.12         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.3         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.000432    |
|    std                   | 0.833        |
|    value_loss            | 48           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.1253974   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 909          |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0037078124 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.883        |
|    cost_value_loss       | 0.16         |
|    cost_values           | 0.969        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.834        |
|    value_loss            | 50.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -1.3225359   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 943          |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0013441399 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 1            |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.000338    |
|    std                   | 0.834        |
|    value_loss            | 30           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3581243   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 977          |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0037023951 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.891        |
|    cost_value_loss       | 0.208        |
|    cost_values           | 0.918        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | 0.000664     |
|    std                   | 0.829        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -2.0380316   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1011         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0014232195 |
|    clip_fraction         | 0.0787       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.37         |
|    cost_values           | 1.16         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.2         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | 0.0011       |
|    std                   | 0.825        |
|    value_loss            | 73.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.96799785  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1045         |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0027867341 |
|    clip_fraction         | 0.084        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 1.48         |
|    cost_values           | 1.26         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.2         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | 0.00455      |
|    std                   | 0.825        |
|    value_loss            | 140          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5982607   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1079         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0051202253 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.511        |
|    cost_values           | 0.954        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.5         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.823        |
|    value_loss            | 83.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4653548  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1114        |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.001904514 |
|    clip_fraction         | 0.0137      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 1.45        |
|    cost_values           | 1.09        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.000846   |
|    std                   | 0.824       |
|    value_loss            | 24.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.0655936   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1148         |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0028370696 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 3.3          |
|    cost_values           | 1.07         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.0003      |
|    std                   | 0.824        |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91220635  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1182         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0031949356 |
|    clip_fraction         | 0.0556       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 1.62         |
|    cost_values           | 1.19         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.22         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | 0.000745     |
|    std                   | 0.825        |
|    value_loss            | 12.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.688559    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1216         |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0040590046 |
|    clip_fraction         | 0.0562       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 3.27         |
|    cost_values           | 1.24         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.35         |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.00081     |
|    std                   | 0.822        |
|    value_loss            | 12.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.77085614 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1250        |
|    total_timesteps       | 276480      |
| train/                   |             |
|    approx_kl             | 0.005196323 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 0.673       |
|    cost_values           | 1.29        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.4        |
|    n_updates             | 1340        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.821       |
|    value_loss            | 76.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.8455976   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1283         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0006060556 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 3.35         |
|    cost_values           | 1.13         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.63         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.000115    |
|    std                   | 0.821        |
|    value_loss            | 9.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.95        |
| reward                   | -0.77027744 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 39          |
|    time_elapsed          | 1317        |
|    total_timesteps       | 280576      |
| train/                   |             |
|    approx_kl             | 0.004665548 |
|    clip_fraction         | 0.0135      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 1.31        |
|    cost_values           | 1.24        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 1360        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.821       |
|    value_loss            | 36.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.78         |
| reward                   | -0.75785846  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1352         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0016120215 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 2.49         |
|    cost_values           | 1.02         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.1         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.000597    |
|    std                   | 0.821        |
|    value_loss            | 44.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.38        |
| reward                   | -0.82073927 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 41          |
|    time_elapsed          | 1387        |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.000825563 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.938       |
|    cost_values           | 0.982       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 103         |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.000432   |
|    std                   | 0.821       |
|    value_loss            | 205         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.71074927  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1421         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0055263503 |
|    clip_fraction         | 0.00659      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 1.04         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.64         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.000189    |
|    std                   | 0.82         |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.612168   |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 43          |
|    time_elapsed          | 1456        |
|    total_timesteps       | 288768      |
| train/                   |             |
|    approx_kl             | 0.004943859 |
|    clip_fraction         | 0.0367      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.939       |
|    cost_value_loss       | 0.112       |
|    cost_values           | 0.984       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 1400        |
|    policy_gradient_loss  | -0.002      |
|    std                   | 0.818       |
|    value_loss            | 44          |
------------------------------------------
--------------------------------------------
| avg_speed                | 1.75          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.75          |
| reward                   | -0.8002922    |
| rollout/                 |               |
|    ep_len_mean           | 961           |
|    ep_rew_mean           | -1.02e+03     |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 44            |
|    time_elapsed          | 1490          |
|    total_timesteps       | 290816        |
| train/                   |               |
|    approx_kl             | 0.00015178995 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.25          |
|    cost_value_loss       | 2.32          |
|    cost_values           | 0.997         |
|    entropy               | -2.44         |
|    entropy_loss          | -2.44         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 16.1          |
|    n_updates             | 1410          |
|    policy_gradient_loss  | -9.2e-06      |
|    std                   | 0.818         |
|    value_loss            | 31            |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.17        |
| reward                   | -0.73865736 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 45          |
|    time_elapsed          | 1524        |
|    total_timesteps       | 292864      |
| train/                   |             |
|    approx_kl             | 0.006788805 |
|    clip_fraction         | 0.0685      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 2.43        |
|    cost_values           | 1.07        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.5        |
|    n_updates             | 1420        |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.818       |
|    value_loss            | 63.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6508932  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 46          |
|    time_elapsed          | 1558        |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.002293215 |
|    clip_fraction         | 0.0157      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 2.56        |
|    cost_values           | 1.35        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.4        |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.000406   |
|    std                   | 0.818       |
|    value_loss            | 27.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9976885   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -993         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1592         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0030353381 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 1.04         |
|    cost_values           | 1.56         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.01         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.000296    |
|    std                   | 0.812        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5099145   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -987         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1626         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0040233545 |
|    clip_fraction         | 0.0488       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 3.21         |
|    cost_values           | 1.52         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.000106    |
|    std                   | 0.81         |
|    value_loss            | 60.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4029406   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -981         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1660         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0046095075 |
|    clip_fraction         | 0.00767      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 0.674        |
|    cost_values           | 1.36         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.81         |
|    value_loss            | 31           |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
------------------------------------
| avg_speed          | 4.74        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 4.74        |
| reward             | -0.82750046 |
| rollout/           |             |
|    ep_len_mean     | 959         |
|    ep_rew_mean     | -987        |
| time/              |             |
|    fps             | 85          |
|    iterations      | 1           |
|    time_elapsed    | 23          |
|    total_timesteps | 303104      |
------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.54080695  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -993         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 2            |
|    time_elapsed          | 57           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0016158584 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.85         |
|    cost_value_loss       | 0.0244       |
|    cost_values           | 0.974        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.3         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | 0.000664     |
|    std                   | 0.812        |
|    value_loss            | 43.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.88636804  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -991         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 3            |
|    time_elapsed          | 91           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0033288805 |
|    clip_fraction         | 0.00234      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.759        |
|    cost_value_loss       | 0.0211       |
|    cost_values           | 0.882        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.000498    |
|    std                   | 0.812        |
|    value_loss            | 29           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.77          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.77          |
| reward                   | -0.70338064   |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -989          |
| time/                    |               |
|    fps                   | 65            |
|    iterations            | 4             |
|    time_elapsed          | 125           |
|    total_timesteps       | 309248        |
| train/                   |               |
|    approx_kl             | 0.00037201005 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.731         |
|    cost_value_loss       | 0.132         |
|    cost_values           | 0.807         |
|    entropy               | -2.42         |
|    entropy_loss          | -2.42         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 33            |
|    n_updates             | 1500          |
|    policy_gradient_loss  | -0.000204     |
|    std                   | 0.812         |
|    value_loss            | 70.5          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -0.55285513   |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -988          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 5             |
|    time_elapsed          | 160           |
|    total_timesteps       | 311296        |
| train/                   |               |
|    approx_kl             | 1.3284385e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.72          |
|    cost_value_loss       | 0.161         |
|    cost_values           | 0.775         |
|    entropy               | -2.42         |
|    entropy_loss          | -2.42         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.7          |
|    n_updates             | 1510          |
|    policy_gradient_loss  | 2.79e-05      |
|    std                   | 0.812         |
|    value_loss            | 26.1          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2456068  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -981        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 6           |
|    time_elapsed          | 194         |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.004083044 |
|    clip_fraction         | 0.00776     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.956       |
|    cost_value_loss       | 1.73        |
|    cost_values           | 0.886       |
|    entropy               | -2.41       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.6        |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.000611   |
|    std                   | 0.808       |
|    value_loss            | 41.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.8786166   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -982         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 229          |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0036557796 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 2.69         |
|    cost_values           | 1.1          |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.3         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.000424    |
|    std                   | 0.805        |
|    value_loss            | 55.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1355417  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -982        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 8           |
|    time_elapsed          | 263         |
|    total_timesteps       | 317440      |
| train/                   |             |
|    approx_kl             | 0.005581021 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 1.33        |
|    cost_values           | 1.17        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 1540        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.805       |
|    value_loss            | 24          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0942156   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -976         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 297          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0031933663 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.914        |
|    cost_value_loss       | 0.0162       |
|    cost_values           | 0.96         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.28         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.803        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8462181   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -970         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 332          |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0036668265 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.766        |
|    cost_value_loss       | 0.0101       |
|    cost_values           | 0.791        |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.000245    |
|    std                   | 0.802        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.9151573  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -965        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 366         |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.005734839 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 1.85        |
|    cost_values           | 0.819       |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.9        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | 0.00967     |
|    std                   | 0.803       |
|    value_loss            | 34.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.0070426   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -958         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 400          |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0012958609 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 6.88         |
|    cost_values           | 1.08         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.000118    |
|    std                   | 0.802        |
|    value_loss            | 24           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6798056  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -956        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 434         |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.002035535 |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 1.24        |
|    cost_values           | 1.11        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.4        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.22        |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.000422   |
|    std                   | 0.802       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67835414  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -951         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 468          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0051789028 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 3.48         |
|    cost_values           | 1.05         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.801        |
|    value_loss            | 19.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0659505   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -951         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 502          |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0028148706 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.4          |
|    cost_values           | 1.11         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.6         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.801        |
|    value_loss            | 76.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.77361953  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -953         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 16           |
|    time_elapsed          | 536          |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0065487907 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 1.03         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.801        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.72736394  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -954         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 17           |
|    time_elapsed          | 570          |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0029789591 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.42         |
|    cost_values           | 1.06         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.000985    |
|    std                   | 0.8          |
|    value_loss            | 21.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3170526  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -948        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 18          |
|    time_elapsed          | 604         |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.005160425 |
|    clip_fraction         | 0.0489      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.645       |
|    cost_values           | 1.03        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 1640        |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 0.793       |
|    value_loss            | 19.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8793001   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -959         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 638          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0036943755 |
|    clip_fraction         | 0.00752      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.974        |
|    cost_value_loss       | 0.634        |
|    cost_values           | 0.965        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.000779    |
|    std                   | 0.792        |
|    value_loss            | 31.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.0898383   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -956         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 672          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0006369245 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 2.77         |
|    cost_values           | 0.986        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.6         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.000261    |
|    std                   | 0.791        |
|    value_loss            | 55.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.657282    |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -958         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 706          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0010470976 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.25         |
|    cost_values           | 1            |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.99         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.000285    |
|    std                   | 0.792        |
|    value_loss            | 14.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.851875    |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -954         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 740          |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0028382759 |
|    clip_fraction         | 0.00234      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 1.94         |
|    cost_values           | 1.07         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.000383    |
|    std                   | 0.788        |
|    value_loss            | 22.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.96028715  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -947         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 774          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0055074785 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.938        |
|    cost_value_loss       | 0.0219       |
|    cost_values           | 1.01         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.32         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.785        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.1119655   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -947         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 808          |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0016134784 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.92         |
|    cost_values           | 0.956        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.000555    |
|    std                   | 0.785        |
|    value_loss            | 21.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.265323   |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -951        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 842         |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.004578001 |
|    clip_fraction         | 0.0339      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 1.95        |
|    cost_values           | 1.1         |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.784       |
|    value_loss            | 9.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2399011   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -952         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 876          |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0020719843 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.989        |
|    cost_value_loss       | 0.0273       |
|    cost_values           | 1.08         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | 0.00181      |
|    std                   | 0.783        |
|    value_loss            | 25.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6245297   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -957         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 910          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0057810824 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.842        |
|    cost_value_loss       | 0.353        |
|    cost_values           | 0.85         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.35        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.09         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.781        |
|    value_loss            | 12.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.82          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.82          |
| reward                   | -1.4802761    |
| rollout/                 |               |
|    ep_len_mean           | 961           |
|    ep_rew_mean           | -955          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 28            |
|    time_elapsed          | 943           |
|    total_timesteps       | 358400        |
| train/                   |               |
|    approx_kl             | 0.00023864306 |
|    clip_fraction         | 0.000586      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.11          |
|    cost_value_loss       | 1.97          |
|    cost_values           | 0.921         |
|    entropy               | -2.34         |
|    entropy_loss          | -2.34         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.43          |
|    n_updates             | 1740          |
|    policy_gradient_loss  | 0.00121       |
|    std                   | 0.781         |
|    value_loss            | 17.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 3.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.42        |
| reward                   | -0.83267945 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -964        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 977         |
|    total_timesteps       | 360448      |
| train/                   |             |
|    approx_kl             | 0.005473302 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.851       |
|    cost_value_loss       | 0.0513      |
|    cost_values           | 0.967       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.5        |
|    n_updates             | 1750        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.781       |
|    value_loss            | 57          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.87751824  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -968         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1011         |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0039749416 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.3          |
|    cost_values           | 1.09         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.5         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 0.777        |
|    value_loss            | 44.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1985214   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -969         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1045         |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0006919529 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.0856       |
|    cost_values           | 1.03         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | 0.000437     |
|    std                   | 0.776        |
|    value_loss            | 54.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6523785   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -975         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1079         |
|    total_timesteps       | 366592       |
| train/                   |              |
|    approx_kl             | 0.0045015826 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.91         |
|    cost_values           | 0.96         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.31         |
|    n_updates             | 1780         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.775        |
|    value_loss            | 17.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.43328837 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -977        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1113        |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.004652048 |
|    clip_fraction         | 0.00889     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 2.43        |
|    cost_values           | 1           |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.775       |
|    value_loss            | 29.8        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.7621906 |
| rollout/                 |            |
|    ep_len_mean           | 969        |
|    ep_rew_mean           | -970       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 34         |
|    time_elapsed          | 1147       |
|    total_timesteps       | 370688     |
| train/                   |            |
|    approx_kl             | 0.00574841 |
|    clip_fraction         | 0.0195     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.27       |
|    cost_value_loss       | 2.21       |
|    cost_values           | 1.14       |
|    entropy               | -2.33      |
|    entropy_loss          | -2.33      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 13.3       |
|    n_updates             | 1800       |
|    policy_gradient_loss  | -0.00109   |
|    std                   | 0.778      |
|    value_loss            | 25.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -1.0132138  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -972        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1181        |
|    total_timesteps       | 372736      |
| train/                   |             |
|    approx_kl             | 0.004613088 |
|    clip_fraction         | 0.0372      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 4.38        |
|    cost_values           | 1.18        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 1810        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.779       |
|    value_loss            | 18.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.4728124  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -976        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 36          |
|    time_elapsed          | 1214        |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.006723178 |
|    clip_fraction         | 0.0262      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.44        |
|    cost_values           | 1.04        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.779       |
|    value_loss            | 29.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.2035717   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -980         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1248         |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0060222936 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.857        |
|    cost_value_loss       | 0.0903       |
|    cost_values           | 0.961        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.87         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.779        |
|    value_loss            | 20.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.0231762    |
| rollout/                 |               |
|    ep_len_mean           | 969           |
|    ep_rew_mean           | -976          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 38            |
|    time_elapsed          | 1282          |
|    total_timesteps       | 378880        |
| train/                   |               |
|    approx_kl             | 0.00016681346 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.748         |
|    cost_value_loss       | 0.0241        |
|    cost_values           | 0.886         |
|    entropy               | -2.34         |
|    entropy_loss          | -2.34         |
|    explained_variance    | -2.38e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 38.2          |
|    n_updates             | 1840          |
|    policy_gradient_loss  | 0.000192      |
|    std                   | 0.779         |
|    value_loss            | 84.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8111984   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -979         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1316         |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0011264242 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.766        |
|    cost_value_loss       | 0.0894       |
|    cost_values           | 0.777        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.34        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.33         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.000777    |
|    std                   | 0.784        |
|    value_loss            | 15.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.03139     |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -978         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1350         |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0007172099 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.821        |
|    cost_value_loss       | 0.879        |
|    cost_values           | 0.816        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.34         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.000713    |
|    std                   | 0.789        |
|    value_loss            | 8.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0894711   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -971         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1384         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0054306597 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 3.61         |
|    cost_values           | 0.933        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00348     |
|    std                   | 0.79         |
|    value_loss            | 25           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.58487684  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -968         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1419         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0006491289 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.51         |
|    cost_values           | 1.01         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -2.96e-05    |
|    std                   | 0.792        |
|    value_loss            | 21.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1645192   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -975         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1452         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0036356314 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 2.82         |
|    cost_values           | 1            |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.792        |
|    value_loss            | 25.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -1.0095451   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -967         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1487         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0016802154 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 3.2          |
|    cost_values           | 1            |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.63         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.000595    |
|    std                   | 0.792        |
|    value_loss            | 17.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.839645    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -966         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1521         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0033127426 |
|    clip_fraction         | 0.00562      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 3.88         |
|    cost_values           | 1.22         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.000561    |
|    std                   | 0.793        |
|    value_loss            | 72.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7897839   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -976         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1555         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0034594927 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 0.318        |
|    cost_values           | 1.4          |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.83         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.000326    |
|    std                   | 0.792        |
|    value_loss            | 14.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.276178    |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -973         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1589         |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0044277897 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.48         |
|    cost_values           | 1.34         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.792        |
|    value_loss            | 9.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.0311346   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -977         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1624         |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0019802367 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 0.0378       |
|    cost_values           | 1.34         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.65         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | 0.000636     |
|    std                   | 0.792        |
|    value_loss            | 21.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3042555   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -971         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1658         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0036144834 |
|    clip_fraction         | 0.00581      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 3.34         |
|    cost_values           | 1.17         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.000458    |
|    std                   | 0.793        |
|    value_loss            | 23.3         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.58       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.58       |
| reward             | -0.8020066 |
| rollout/           |            |
|    ep_len_mean     | 988        |
|    ep_rew_mean     | -966       |
| time/              |            |
|    fps             | 84         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 403456     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3108728   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -958         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0006704312 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.991        |
|    cost_value_loss       | 0.355        |
|    cost_values           | 0.969        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -5.85e-05    |
|    std                   | 0.792        |
|    value_loss            | 26.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.1713996   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -952         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0051473575 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 4.6          |
|    cost_values           | 1.08         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.86         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.791        |
|    value_loss            | 17.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -1.0133803   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -949         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0009372133 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 0.396        |
|    cost_values           | 1.08         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.25         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | 5.24e-06     |
|    std                   | 0.791        |
|    value_loss            | 17.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.28         |
| reward                   | -0.8961891   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -943         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0020969063 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.979        |
|    cost_value_loss       | 0.431        |
|    cost_values           | 0.984        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.12         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.000286    |
|    std                   | 0.79         |
|    value_loss            | 8.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7579497   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -939         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0035487728 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.85         |
|    cost_value_loss       | 0.0934       |
|    cost_values           | 0.929        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.79         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.000558    |
|    std                   | 0.789        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.678        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.678        |
| reward                   | -0.8216197   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0029707705 |
|    clip_fraction         | 0.002        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 5            |
|    cost_values           | 0.964        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.58         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.789        |
|    value_loss            | 15.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.912       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.912       |
| reward                   | -0.8095553  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -928        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 417792      |
| train/                   |             |
|    approx_kl             | 0.003156609 |
|    clip_fraction         | 0.002       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 0.914       |
|    cost_values           | 0.995       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.5        |
|    n_updates             | 2030        |
|    policy_gradient_loss  | -0.000598   |
|    std                   | 0.789       |
|    value_loss            | 56.9        |
------------------------------------------
--------------------------------------------
| avg_speed                | 1.89          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.89          |
| reward                   | -0.69474673   |
| rollout/                 |               |
|    ep_len_mean           | 986           |
|    ep_rew_mean           | -928          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 9             |
|    time_elapsed          | 300           |
|    total_timesteps       | 419840        |
| train/                   |               |
|    approx_kl             | 0.00031458074 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.36          |
|    cost_value_loss       | 3.09          |
|    cost_values           | 1             |
|    entropy               | -2.36         |
|    entropy_loss          | -2.36         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.86          |
|    n_updates             | 2040          |
|    policy_gradient_loss  | -6.88e-05     |
|    std                   | 0.79          |
|    value_loss            | 9             |
--------------------------------------------
------------------------------------------
| avg_speed                | 6.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.85        |
| reward                   | -0.94641286 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -926        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 421888      |
| train/                   |             |
|    approx_kl             | 0.003179627 |
|    clip_fraction         | 0.0022      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.997       |
|    cost_value_loss       | 0.464       |
|    cost_values           | 0.992       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.72        |
|    n_updates             | 2050        |
|    policy_gradient_loss  | -0.000817   |
|    std                   | 0.79        |
|    value_loss            | 10.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.03         |
| reward                   | -0.91482294  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0023400628 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.96         |
|    cost_values           | 1.04         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.56         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.000501    |
|    std                   | 0.79         |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.86332905  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0011122774 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 1.26         |
|    cost_values           | 1.05         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.01         |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.000221    |
|    std                   | 0.79         |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.76681083 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -934        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 438         |
|    total_timesteps       | 428032      |
| train/                   |             |
|    approx_kl             | 0.004345226 |
|    clip_fraction         | 0.014       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.824       |
|    cost_value_loss       | 0.0168      |
|    cost_values           | 0.905       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 2080        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.79        |
|    value_loss            | 23.8        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.66          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.66          |
| reward                   | -0.96417254   |
| rollout/                 |               |
|    ep_len_mean           | 993           |
|    ep_rew_mean           | -933          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 14            |
|    time_elapsed          | 472           |
|    total_timesteps       | 430080        |
| train/                   |               |
|    approx_kl             | 0.00037001245 |
|    clip_fraction         | 0.016         |
|    clip_range            | 0.2           |
|    cost_returns          | 0.813         |
|    cost_value_loss       | 0.45          |
|    cost_values           | 0.812         |
|    entropy               | -2.37         |
|    entropy_loss          | -2.37         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.78          |
|    n_updates             | 2090          |
|    policy_gradient_loss  | 0.000238      |
|    std                   | 0.793         |
|    value_loss            | 12.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.9274811   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -931         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0007864211 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.804        |
|    cost_value_loss       | 0.348        |
|    cost_values           | 0.806        |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.62         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | 3.84e-05     |
|    std                   | 0.797        |
|    value_loss            | 12.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.99461645 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -932        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 540         |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.002219102 |
|    clip_fraction         | 0.00684     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.72        |
|    cost_value_loss       | 0.0789      |
|    cost_values           | 0.726       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.000294   |
|    std                   | 0.785       |
|    value_loss            | 4.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.49        |
| reward                   | -0.6542704  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -928        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.003340448 |
|    clip_fraction         | 0.0291      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.622       |
|    cost_value_loss       | 0.0566      |
|    cost_values           | 0.629       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | -0.000818   |
|    std                   | 0.777       |
|    value_loss            | 7.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.0991902  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -920        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 608         |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.004628508 |
|    clip_fraction         | 0.0174      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.674       |
|    cost_value_loss       | 0.517       |
|    cost_values           | 0.628       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.49        |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -0.000939   |
|    std                   | 0.777       |
|    value_loss            | 14.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0095698   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -916         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 643          |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0051019816 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.54         |
|    cost_value_loss       | 0.0085       |
|    cost_values           | 0.605        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.000969    |
|    std                   | 0.778        |
|    value_loss            | 6.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.52         |
| reward                   | -0.6831796   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -907         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 677          |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0038496414 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.83         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 0.684        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.6          |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.778        |
|    value_loss            | 13.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.84        |
| reward                   | -0.9234773  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -904        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 711         |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.004099248 |
|    clip_fraction         | 0.0253      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 1.5         |
|    cost_values           | 0.974       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.2        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.778       |
|    value_loss            | 46.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.99906653  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 745          |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0014732344 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.863        |
|    cost_value_loss       | 0.0203       |
|    cost_values           | 0.908        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.000162    |
|    std                   | 0.776        |
|    value_loss            | 6.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.9075849   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 779          |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0032277755 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.81         |
|    cost_values           | 0.951        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.1         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.000353    |
|    std                   | 0.776        |
|    value_loss            | 46.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2795675   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 812          |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0038136095 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 4.16         |
|    cost_values           | 1.09         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.98         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 0.775        |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1275203   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -892         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 846          |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0031958525 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.0439       |
|    cost_values           | 1.16         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.68         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.000146    |
|    std                   | 0.773        |
|    value_loss            | 12.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.57         |
| reward                   | -0.80292946  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 880          |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0003394913 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.862        |
|    cost_value_loss       | 0.175        |
|    cost_values           | 0.953        |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.75         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | 0.000367     |
|    std                   | 0.772        |
|    value_loss            | 13.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.15        |
| reward                   | -0.7833399  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -886        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 914         |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.005653229 |
|    clip_fraction         | 0.0403      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 1.18        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.769       |
|    value_loss            | 21.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.12         |
| reward                   | -0.85761917  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -884         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 948          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0038533295 |
|    clip_fraction         | 0.00815      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 0.0336       |
|    cost_values           | 1.29         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.767        |
|    value_loss            | 8.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.54        |
| reward                   | -0.7185835  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -878        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 983         |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.006071198 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 8.43        |
|    cost_values           | 1.25        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.767       |
|    value_loss            | 12.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.6848314   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -880         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1017         |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0038248072 |
|    clip_fraction         | 0.00386      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.64         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 1.96         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.31        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.7         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.000684    |
|    std                   | 0.766        |
|    value_loss            | 30.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.3989288  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -871        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1051        |
|    total_timesteps       | 464896      |
| train/                   |             |
|    approx_kl             | 0.003918012 |
|    clip_fraction         | 0.0198      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.3         |
|    cost_value_loss       | 2.44        |
|    cost_values           | 2.29        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.43        |
|    n_updates             | 2260        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.77        |
|    value_loss            | 4.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2788163   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -866         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0023611244 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.32         |
|    cost_value_loss       | 9.37         |
|    cost_values           | 2.35         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.6         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.000677    |
|    std                   | 0.771        |
|    value_loss            | 56.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.86         |
| reward                   | -0.73988867  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -861         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1120         |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0008644002 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 2.9          |
|    cost_values           | 2.5          |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.000632    |
|    std                   | 0.769        |
|    value_loss            | 7.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.44568828  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -853         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1154         |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0014460798 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.86         |
|    cost_value_loss       | 9.25         |
|    cost_values           | 2.41         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.000475    |
|    std                   | 0.769        |
|    value_loss            | 41.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6859682   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1188         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0012163147 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 1.07         |
|    cost_values           | 2.37         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.5          |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00092     |
|    std                   | 0.767        |
|    value_loss            | 9.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.690281    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1221         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0040788585 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 0.468        |
|    cost_values           | 2.12         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.55         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00092     |
|    std                   | 0.766        |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.43141097  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -836         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1255         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0038179532 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 0.192        |
|    cost_values           | 1.71         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.31        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.000622    |
|    std                   | 0.766        |
|    value_loss            | 8.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.9815575   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -834         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1289         |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0016430303 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.111        |
|    cost_values           | 1.39         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.81         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.765        |
|    value_loss            | 18.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.7797016   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -833         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1323         |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0016106018 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.99         |
|    cost_value_loss       | 0.02         |
|    cost_values           | 1.05         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.000893    |
|    std                   | 0.764        |
|    value_loss            | 6.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.7355252   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1358         |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0025386703 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.803        |
|    cost_value_loss       | 0.0216       |
|    cost_values           | 0.892        |
|    entropy               | -2.29        |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.29         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.76         |
|    value_loss            | 2.71         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 5.87          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.87          |
| reward                   | -0.7475146    |
| rollout/                 |               |
|    ep_len_mean           | 969           |
|    ep_rew_mean           | -826          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 41            |
|    time_elapsed          | 1392          |
|    total_timesteps       | 485376        |
| train/                   |               |
|    approx_kl             | 0.00040266768 |
|    clip_fraction         | 0.00703       |
|    clip_range            | 0.2           |
|    cost_returns          | 1.1           |
|    cost_value_loss       | 1.67          |
|    cost_values           | 0.874         |
|    entropy               | -2.28         |
|    entropy_loss          | -2.29         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.41          |
|    n_updates             | 2360          |
|    policy_gradient_loss  | 0.000293      |
|    std                   | 0.758         |
|    value_loss            | 6.26          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9395827  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -826        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 42          |
|    time_elapsed          | 1427        |
|    total_timesteps       | 487424      |
| train/                   |             |
|    approx_kl             | 0.006720669 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 4.67        |
|    cost_values           | 1.04        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.1        |
|    n_updates             | 2370        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.758       |
|    value_loss            | 42.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8338929   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -830         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1461         |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0059858067 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.906        |
|    cost_value_loss       | 0.0404       |
|    cost_values           | 1.01         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.01         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.759        |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.79657316  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -828         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1496         |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0041362243 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 1.03         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.757        |
|    value_loss            | 18.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5650276  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -827        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 45          |
|    time_elapsed          | 1530        |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.006694197 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 5.31        |
|    cost_values           | 1.16        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.755       |
|    value_loss            | 5.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.68071496 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -816        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 46          |
|    time_elapsed          | 1565        |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.00415834  |
|    clip_fraction         | 0.0101      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 2.12        |
|    cost_values           | 1.41        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.000415   |
|    std                   | 0.754       |
|    value_loss            | 8.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.92974246  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1599         |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0056175683 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 7.65         |
|    cost_values           | 1.48         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.754        |
|    value_loss            | 11           |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.3743363 |
| rollout/                 |            |
|    ep_len_mean           | 975        |
|    ep_rew_mean           | -817       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 48         |
|    time_elapsed          | 1633       |
|    total_timesteps       | 499712     |
| train/                   |            |
|    approx_kl             | 0.00492586 |
|    clip_fraction         | 0.00571    |
|    clip_range            | 0.2        |
|    cost_returns          | 2.26       |
|    cost_value_loss       | 6.95       |
|    cost_values           | 1.58       |
|    entropy               | -2.27      |
|    entropy_loss          | -2.27      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 12.9       |
|    n_updates             | 2430       |
|    policy_gradient_loss  | -0.00147   |
|    std                   | 0.754      |
|    value_loss            | 20.9       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.66069806  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1668         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0026645456 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 1.82         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.76         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.756        |
|    value_loss            | 10.6         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.45150614 |
| rollout/           |             |
|    ep_len_mean     | 975         |
|    ep_rew_mean     | -813        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.6051667   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -811         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0011599831 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 2.41         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.25         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00046     |
|    std                   | 0.757        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.66877294 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -801        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 92          |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.004828154 |
|    clip_fraction         | 0.0118      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.32        |
|    cost_value_loss       | 7.47        |
|    cost_values           | 2.75        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 2470        |
|    policy_gradient_loss  | -0.000808   |
|    std                   | 0.757       |
|    value_loss            | 13.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0483884  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -788        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 509952      |
| train/                   |             |
|    approx_kl             | 0.007159112 |
|    clip_fraction         | 0.0133      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.56        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.99        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0.00346     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 2480        |
|    policy_gradient_loss  | -0.000769   |
|    std                   | 0.756       |
|    value_loss            | 41.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.323384    |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 160          |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0061740517 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.53         |
|    cost_value_loss       | 4.84         |
|    cost_values           | 2.9          |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.5         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.756        |
|    value_loss            | 67.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.690207   |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -794        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 6           |
|    time_elapsed          | 194         |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.003534759 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 1.55        |
|    cost_values           | 2.81        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.000516   |
|    std                   | 0.755       |
|    value_loss            | 32.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.5620943   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 229          |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0029966175 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.16         |
|    cost_value_loss       | 4.89         |
|    cost_values           | 2.64         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.8         |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.754        |
|    value_loss            | 31.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.32192335 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -793        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 8           |
|    time_elapsed          | 262         |
|    total_timesteps       | 518144      |
| train/                   |             |
|    approx_kl             | 0.010115154 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.75        |
|    cost_value_loss       | 1.44        |
|    cost_values           | 2.74        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.3         |
|    n_updates             | 2520        |
|    policy_gradient_loss  | -0.000466   |
|    std                   | 0.751       |
|    value_loss            | 5.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72574264  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 9            |
|    time_elapsed          | 296          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0038932883 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 0.314        |
|    cost_values           | 2.49         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.11         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | 5.71e-06     |
|    std                   | 0.752        |
|    value_loss            | 7.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4179392   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -797         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 330          |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0019498913 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.0697       |
|    cost_values           | 1.91         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.82         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.752        |
|    value_loss            | 3.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.324117   |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -803        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 364         |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.008355499 |
|    clip_fraction         | 0.0935      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 0.234       |
|    cost_values           | 1.63        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.7        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | 0.00346     |
|    std                   | 0.753       |
|    value_loss            | 76.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1704721   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 398          |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 7.714375e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 1.19         |
|    cost_values           | 1.33         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -3.2e-05     |
|    std                   | 0.753        |
|    value_loss            | 33           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.9665705    |
| rollout/                 |               |
|    ep_len_mean           | 958           |
|    ep_rew_mean           | -808          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 13            |
|    time_elapsed          | 432           |
|    total_timesteps       | 528384        |
| train/                   |               |
|    approx_kl             | 0.00012604118 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.976         |
|    cost_value_loss       | 0.0199        |
|    cost_values           | 1.05          |
|    entropy               | -2.27         |
|    entropy_loss          | -2.27         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.19          |
|    n_updates             | 2570          |
|    policy_gradient_loss  | -1.41e-05     |
|    std                   | 0.753         |
|    value_loss            | 19.8          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.97          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.97          |
| reward                   | -1.0824441    |
| rollout/                 |               |
|    ep_len_mean           | 958           |
|    ep_rew_mean           | -813          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 14            |
|    time_elapsed          | 466           |
|    total_timesteps       | 530432        |
| train/                   |               |
|    approx_kl             | 0.00029515717 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.882         |
|    cost_value_loss       | 0.189         |
|    cost_values           | 0.934         |
|    entropy               | -2.27         |
|    entropy_loss          | -2.27         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 32.8          |
|    n_updates             | 2580          |
|    policy_gradient_loss  | -0.000165     |
|    std                   | 0.752         |
|    value_loss            | 68.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.95645833  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 500          |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0056879693 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.791        |
|    cost_value_loss       | 0.0331       |
|    cost_values           | 0.813        |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.6         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.000872    |
|    std                   | 0.749        |
|    value_loss            | 49.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.7580205   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -812         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 16           |
|    time_elapsed          | 534          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0061390605 |
|    clip_fraction         | 0.0418       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 2.98         |
|    cost_values           | 0.992        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.53         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.747        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9756681   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 17           |
|    time_elapsed          | 568          |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0004277122 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.417        |
|    cost_values           | 1.15         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56           |
|    n_updates             | 2610         |
|    policy_gradient_loss  | 0.000238     |
|    std                   | 0.746        |
|    value_loss            | 84.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3523859   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 18           |
|    time_elapsed          | 602          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0040491256 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.727        |
|    cost_values           | 1.01         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.8         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.745        |
|    value_loss            | 35.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1906649   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -829         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 19           |
|    time_elapsed          | 636          |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0035829581 |
|    clip_fraction         | 0.00654      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.953        |
|    cost_value_loss       | 0.274        |
|    cost_values           | 0.972        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.745        |
|    value_loss            | 33.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8428544   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -842         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 20           |
|    time_elapsed          | 670          |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0061763166 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.914        |
|    cost_values           | 0.965        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.745        |
|    value_loss            | 23.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7719086  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -844        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 21          |
|    time_elapsed          | 704         |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.008022706 |
|    clip_fraction         | 0.0365      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.958       |
|    cost_value_loss       | 0.537       |
|    cost_values           | 0.986       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.3        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.00464    |
|    std                   | 0.745       |
|    value_loss            | 47.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2697175  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -843        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 22          |
|    time_elapsed          | 738         |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.002221917 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.748       |
|    cost_values           | 0.998       |
|    entropy               | -2.22       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.733       |
|    value_loss            | 22          |
------------------------------------------
------------------------------------------
| avg_speed                | 2.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.96        |
| reward                   | -0.7309035  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -842        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 772         |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.004084342 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.98        |
|    cost_value_loss       | 0.73        |
|    cost_values           | 0.978       |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.26        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | 0.000195    |
|    std                   | 0.729       |
|    value_loss            | 16.7        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.6749773    |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -839          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 24            |
|    time_elapsed          | 806           |
|    total_timesteps       | 550912        |
| train/                   |               |
|    approx_kl             | 0.00037473417 |
|    clip_fraction         | 0.00957       |
|    clip_range            | 0.2           |
|    cost_returns          | 0.802         |
|    cost_value_loss       | 0.0272        |
|    cost_values           | 0.934         |
|    entropy               | -2.2          |
|    entropy_loss          | -2.21         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.39          |
|    n_updates             | 2680          |
|    policy_gradient_loss  | 0.000926      |
|    std                   | 0.729         |
|    value_loss            | 18.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0959797   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 841          |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0012162897 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 9.75         |
|    cost_values           | 1.02         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.00056     |
|    std                   | 0.728        |
|    value_loss            | 19.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.8958514    |
| rollout/                 |               |
|    ep_len_mean           | 951           |
|    ep_rew_mean           | -822          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 26            |
|    time_elapsed          | 874           |
|    total_timesteps       | 555008        |
| train/                   |               |
|    approx_kl             | 0.00016371519 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.45          |
|    cost_value_loss       | 13.2          |
|    cost_values           | 1.24          |
|    entropy               | -2.2          |
|    entropy_loss          | -2.2          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 44.8          |
|    n_updates             | 2700          |
|    policy_gradient_loss  | -4.73e-05     |
|    std                   | 0.728         |
|    value_loss            | 72            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3912695   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 908          |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0017059207 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 0.246        |
|    cost_values           | 1.23         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44           |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.000798    |
|    std                   | 0.728        |
|    value_loss            | 56.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -1.1619799  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -820        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 942         |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.004766689 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.893       |
|    cost_value_loss       | 0.0212      |
|    cost_values           | 0.934       |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.000845   |
|    std                   | 0.726       |
|    value_loss            | 8.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0120608   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 976          |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0033242167 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.42         |
|    cost_values           | 0.955        |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.46         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.000787    |
|    std                   | 0.725        |
|    value_loss            | 18.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2295613   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -836         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1010         |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0021850145 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.829        |
|    cost_value_loss       | 0.0259       |
|    cost_values           | 0.969        |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.7         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.724        |
|    value_loss            | 50.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.87298596  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -845         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1044         |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0038102872 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 2.99         |
|    cost_values           | 1.09         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.86         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.724        |
|    value_loss            | 14.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0302228  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -843        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 32          |
|    time_elapsed          | 1078        |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.001806037 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 2.63        |
|    cost_values           | 1.19        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.08        |
|    n_updates             | 2760        |
|    policy_gradient_loss  | 4.51e-05    |
|    std                   | 0.724       |
|    value_loss            | 8.91        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.153654     |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -843          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 33            |
|    time_elapsed          | 1112          |
|    total_timesteps       | 569344        |
| train/                   |               |
|    approx_kl             | 0.00050019234 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.43          |
|    cost_value_loss       | 2.06          |
|    cost_values           | 1.04          |
|    entropy               | -2.19         |
|    entropy_loss          | -2.19         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.55          |
|    n_updates             | 2770          |
|    policy_gradient_loss  | -0.000198     |
|    std                   | 0.724         |
|    value_loss            | 15.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0386395   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1145         |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0034363507 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.907        |
|    cost_value_loss       | 0.209        |
|    cost_values           | 0.95         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.88         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.724        |
|    value_loss            | 17.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7896391  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -848        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1179        |
|    total_timesteps       | 573440      |
| train/                   |             |
|    approx_kl             | 0.005322228 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.887       |
|    cost_value_loss       | 0.507       |
|    cost_values           | 0.894       |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 2790        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.722       |
|    value_loss            | 5.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6551259   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1213         |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0021965404 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.725        |
|    cost_value_loss       | 0.00957      |
|    cost_values           | 0.758        |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.44         |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.000878    |
|    std                   | 0.72         |
|    value_loss            | 8.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1862303   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -846         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1247         |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0023635307 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.944        |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.772        |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | 0.000445     |
|    std                   | 0.719        |
|    value_loss            | 29.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.1393769    |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -851          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 38            |
|    time_elapsed          | 1281          |
|    total_timesteps       | 579584        |
| train/                   |               |
|    approx_kl             | 0.00048582233 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.08          |
|    cost_value_loss       | 2.02          |
|    cost_values           | 0.966         |
|    entropy               | -2.17         |
|    entropy_loss          | -2.18         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9             |
|    n_updates             | 2820          |
|    policy_gradient_loss  | -0.000164     |
|    std                   | 0.717         |
|    value_loss            | 14.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8684849   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -855         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1315         |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0046076532 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 2.2          |
|    cost_values           | 0.99         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.52         |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.715        |
|    value_loss            | 18.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.22417      |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -860          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 40            |
|    time_elapsed          | 1349          |
|    total_timesteps       | 583680        |
| train/                   |               |
|    approx_kl             | 0.00085342536 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.47          |
|    cost_value_loss       | 2.99          |
|    cost_values           | 1.01          |
|    entropy               | -2.17         |
|    entropy_loss          | -2.17         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.38          |
|    n_updates             | 2840          |
|    policy_gradient_loss  | -0.000249     |
|    std                   | 0.715         |
|    value_loss            | 14.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.43468392  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -859         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1383         |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0040617576 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 3.07         |
|    cost_values           | 1.07         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.715        |
|    value_loss            | 7.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7853427   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -857         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1417         |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0016338158 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 8.15         |
|    cost_values           | 1.16         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | 7.01e-05     |
|    std                   | 0.716        |
|    value_loss            | 20.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 6.91          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.91          |
| reward                   | -0.82423806   |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -851          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 43            |
|    time_elapsed          | 1452          |
|    total_timesteps       | 589824        |
| train/                   |               |
|    approx_kl             | 0.00097487425 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.12          |
|    cost_value_loss       | 0.55          |
|    cost_values           | 1.05          |
|    entropy               | -2.17         |
|    entropy_loss          | -2.17         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.16          |
|    n_updates             | 2870          |
|    policy_gradient_loss  | -0.000405     |
|    std                   | 0.716         |
|    value_loss            | 10.7          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.97913086 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -854        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 44          |
|    time_elapsed          | 1487        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.001868176 |
|    clip_fraction         | 0.000195    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 6.1         |
|    cost_values           | 1.02        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.58        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.000927   |
|    std                   | 0.716       |
|    value_loss            | 15.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.7816141   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -852         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1522         |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0034466481 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.968        |
|    cost_value_loss       | 0.474        |
|    cost_values           | 0.972        |
|    entropy               | -2.18        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.45         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.000711    |
|    std                   | 0.719        |
|    value_loss            | 3.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.64462966  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -849         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1556         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0047356095 |
|    clip_fraction         | 0.0327       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.7          |
|    cost_values           | 1.04         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.36         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.719        |
|    value_loss            | 5.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9447127   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -854         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1590         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0040818388 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.967        |
|    cost_value_loss       | 0.0725       |
|    cost_values           | 1            |
|    entropy               | -2.17        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.41         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.718        |
|    value_loss            | 8.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8818875   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -857         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1625         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0009322339 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.9          |
|    cost_value_loss       | 0.483        |
|    cost_values           | 0.925        |
|    entropy               | -2.18        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.33         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | 0.000243     |
|    std                   | 0.718        |
|    value_loss            | 14.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9361018   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -862         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1659         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0021481973 |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 1.2          |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.9         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.000384    |
|    std                   | 0.718        |
|    value_loss            | 31           |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.5967074 |
| rollout/           |            |
|    ep_len_mean     | 965        |
|    ep_rew_mean     | -868       |
| time/              |            |
|    fps             | 85         |
|    iterations      | 1          |
|    time_elapsed    | 23         |
|    total_timesteps | 604160     |
-----------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.7288106    |
| rollout/                 |               |
|    ep_len_mean           | 978           |
|    ep_rew_mean           | -878          |
| time/                    |               |
|    fps                   | 70            |
|    iterations            | 2             |
|    time_elapsed          | 58            |
|    total_timesteps       | 606208        |
| train/                   |               |
|    approx_kl             | 0.00024666573 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.27          |
|    cost_value_loss       | 0.128         |
|    cost_values           | 1.31          |
|    entropy               | -2.17         |
|    entropy_loss          | -2.17         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.57          |
|    n_updates             | 2950          |
|    policy_gradient_loss  | 3.52e-05      |
|    std                   | 0.718         |
|    value_loss            | 14.7          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.8577315    |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -882          |
| time/                    |               |
|    fps                   | 66            |
|    iterations            | 3             |
|    time_elapsed          | 92            |
|    total_timesteps       | 608256        |
| train/                   |               |
|    approx_kl             | 0.00046888247 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.34          |
|    cost_value_loss       | 8.3           |
|    cost_values           | 1.08          |
|    entropy               | -2.17         |
|    entropy_loss          | -2.17         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 18.9          |
|    n_updates             | 2960          |
|    policy_gradient_loss  | -0.000159     |
|    std                   | 0.717         |
|    value_loss            | 30.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6627291   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -880         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0034537083 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.272        |
|    cost_values           | 1.02         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.59         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.000834    |
|    std                   | 0.717        |
|    value_loss            | 13.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.6411003    |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -875          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 5             |
|    time_elapsed          | 161           |
|    total_timesteps       | 612352        |
| train/                   |               |
|    approx_kl             | 5.8068836e-06 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.18          |
|    cost_value_loss       | 1.43          |
|    cost_values           | 0.989         |
|    entropy               | -2.17         |
|    entropy_loss          | -2.17         |
|    explained_variance    | 1.79e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 14.4          |
|    n_updates             | 2980          |
|    policy_gradient_loss  | 1.23e-06      |
|    std                   | 0.716         |
|    value_loss            | 48.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.62642384  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -876         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 195          |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0044379313 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 3.24         |
|    cost_values           | 1.06         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.000583    |
|    std                   | 0.717        |
|    value_loss            | 5.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.34677     |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -880         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 229          |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0048198737 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.0825       |
|    cost_values           | 1.09         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.84         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.719        |
|    value_loss            | 7.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7276386   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -882         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 263          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0029152955 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 2.54         |
|    cost_values           | 1.01         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.000293    |
|    std                   | 0.718        |
|    value_loss            | 24.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78024775  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0016571359 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.932        |
|    cost_values           | 1.06         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.01         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.000111    |
|    std                   | 0.719        |
|    value_loss            | 14.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.0743599 |
| rollout/                 |            |
|    ep_len_mean           | 982        |
|    ep_rew_mean           | -871       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 10         |
|    time_elapsed          | 332        |
|    total_timesteps       | 622592     |
| train/                   |            |
|    approx_kl             | 0.00408163 |
|    clip_fraction         | 0.0181     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.19       |
|    cost_value_loss       | 1.37       |
|    cost_values           | 1.13       |
|    entropy               | -2.18      |
|    entropy_loss          | -2.18      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.86       |
|    n_updates             | 3030       |
|    policy_gradient_loss  | 0.000243   |
|    std                   | 0.719      |
|    value_loss            | 13.8       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1451787   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 366          |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0027631847 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.997        |
|    cost_value_loss       | 0.101        |
|    cost_values           | 1            |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.61         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.718        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0581464   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -872         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 400          |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0047058617 |
|    clip_fraction         | 0.0295       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.884        |
|    cost_value_loss       | 0.159        |
|    cost_values           | 0.975        |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.718        |
|    value_loss            | 33           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.056427    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -865         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 434          |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0030225287 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 2.33         |
|    cost_values           | 1.06         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.000208    |
|    std                   | 0.717        |
|    value_loss            | 23.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.9814723   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -864         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 468          |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0029553487 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.751        |
|    cost_values           | 1.12         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.74         |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.000255    |
|    std                   | 0.715        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.96         |
| reward                   | -0.74221146  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -865         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 503          |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0011889391 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 0.0211       |
|    cost_values           | 1.01         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.24         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | 0.0012       |
|    std                   | 0.715        |
|    value_loss            | 8.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.9245185   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -864         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 537          |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0044694925 |
|    clip_fraction         | 0.00923      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 5.13         |
|    cost_values           | 0.981        |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.715        |
|    value_loss            | 24.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6659734  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -863        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 572         |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.005448613 |
|    clip_fraction         | 0.0133      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 3.4         |
|    cost_values           | 1           |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.715       |
|    value_loss            | 28.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.99471134  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -858         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 606          |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0023932324 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.825        |
|    cost_value_loss       | 0.0119       |
|    cost_values           | 0.853        |
|    entropy               | -2.15        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.53         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.000153    |
|    std                   | 0.709        |
|    value_loss            | 5.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.717998   |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -846        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 641         |
|    total_timesteps       | 641024      |
| train/                   |             |
|    approx_kl             | 0.004596051 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 4.95        |
|    cost_values           | 1.06        |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 3120        |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.708       |
|    value_loss            | 25.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.03        |
| reward                   | -0.7395149  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -844        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 676         |
|    total_timesteps       | 643072      |
| train/                   |             |
|    approx_kl             | 0.004563736 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 1.66        |
|    cost_values           | 1.3         |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.2        |
|    n_updates             | 3130        |
|    policy_gradient_loss  | -0.000625   |
|    std                   | 0.707       |
|    value_loss            | 57.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.59707856 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -845        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 710         |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.004566718 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 4.5         |
|    cost_values           | 1.56        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.53        |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.705       |
|    value_loss            | 12.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.9343136   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -846         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 744          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0014124068 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 1.55         |
|    cost_values           | 1.73         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.45         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.000665    |
|    std                   | 0.709        |
|    value_loss            | 5.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9202102   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -843         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 779          |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0018732991 |
|    clip_fraction         | 0.00986      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 0.803        |
|    cost_values           | 1.53         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | 0.00229      |
|    std                   | 0.711        |
|    value_loss            | 22.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.63         |
| reward                   | -0.65876275  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -856         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 813          |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0036528076 |
|    clip_fraction         | 0.0452       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 3.02         |
|    cost_values           | 1.45         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.711        |
|    value_loss            | 55.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.80199426  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -861         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 847          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0010622811 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.387        |
|    cost_values           | 1.52         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.000371    |
|    std                   | 0.712        |
|    value_loss            | 27.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.757511    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -860         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 881          |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0016233707 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 2.7          |
|    cost_values           | 1.28         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.92         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.000184    |
|    std                   | 0.711        |
|    value_loss            | 13.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.71089745  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -860         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 915          |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0004583185 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 1.38         |
|    cost_values           | 1.22         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.54         |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.00016     |
|    std                   | 0.711        |
|    value_loss            | 9.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -1.1734931   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -854         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 949          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0029849843 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 2.49         |
|    cost_values           | 1.29         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.000441    |
|    std                   | 0.711        |
|    value_loss            | 57.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.377321    |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -853         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 983          |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0038985908 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 2.31         |
|    cost_values           | 1.67         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.79         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -6.27e-05    |
|    std                   | 0.711        |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.2936953   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -851         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1017         |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0025129626 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 1.73         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.711        |
|    value_loss            | 24.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.4176227   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -853         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1051         |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0037042347 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.0468       |
|    cost_values           | 1.48         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.15        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.96         |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.709        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3093592  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -858        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 32          |
|    time_elapsed          | 1085        |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.003934504 |
|    clip_fraction         | 0.0137      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 1.66        |
|    cost_values           | 1.32        |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.5        |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.000477   |
|    std                   | 0.708       |
|    value_loss            | 36.3        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.1624869    |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -863          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 33            |
|    time_elapsed          | 1119          |
|    total_timesteps       | 669696        |
| train/                   |               |
|    approx_kl             | 0.00046563777 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.07          |
|    cost_value_loss       | 0.046         |
|    cost_values           | 1.15          |
|    entropy               | -2.14         |
|    entropy_loss          | -2.14         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 18.1          |
|    n_updates             | 3260          |
|    policy_gradient_loss  | 0.000148      |
|    std                   | 0.707         |
|    value_loss            | 39.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72573274  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -864         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1153         |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0019222716 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.807        |
|    cost_value_loss       | 0.0187       |
|    cost_values           | 0.917        |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.000777    |
|    std                   | 0.707        |
|    value_loss            | 23.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.07        |
| reward                   | -0.8689362  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -866        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1188        |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.004481432 |
|    clip_fraction         | 0.00522     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 1.22        |
|    cost_values           | 0.929       |
|    entropy               | -2.15       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.71        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00022    |
|    std                   | 0.708       |
|    value_loss            | 17.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.6107662  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -859        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 36          |
|    time_elapsed          | 1222        |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.009116383 |
|    clip_fraction         | 0.0589      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 1.14        |
|    cost_values           | 1.03        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.92        |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.704       |
|    value_loss            | 15.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6694046  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -852        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1256        |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.007617123 |
|    clip_fraction         | 0.0981      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 1.01        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.6        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.704       |
|    value_loss            | 57.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7522007   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -851         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1290         |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0011084144 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.916        |
|    cost_value_loss       | 0.155        |
|    cost_values           | 0.99         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.000539    |
|    std                   | 0.703        |
|    value_loss            | 28           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4828957  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -848        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 39          |
|    time_elapsed          | 1324        |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.003179802 |
|    clip_fraction         | 0.00142     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.806       |
|    cost_value_loss       | 0.0262      |
|    cost_values           | 0.931       |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.000695   |
|    std                   | 0.703       |
|    value_loss            | 9.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0962011  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -851        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 40          |
|    time_elapsed          | 1358        |
|    total_timesteps       | 684032      |
| train/                   |             |
|    approx_kl             | 0.005642525 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.971       |
|    cost_value_loss       | 1.13        |
|    cost_values           | 0.914       |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 3330        |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.702       |
|    value_loss            | 8.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6963379   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -856         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1392         |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0038714395 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.882        |
|    cost_value_loss       | 0.221        |
|    cost_values           | 0.941        |
|    entropy               | -2.12        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.7          |
|    value_loss            | 8.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4055269   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -858         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1426         |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0035778598 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 2.21         |
|    cost_values           | 1.02         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.54         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.000545    |
|    std                   | 0.7          |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.8897548   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -857         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1460         |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0048137847 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 5.16         |
|    cost_values           | 1.25         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.7         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.7          |
|    value_loss            | 122          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.94471776  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -859         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1495         |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0009262903 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 1.15         |
|    cost_values           | 1.25         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.6          |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.000261    |
|    std                   | 0.699        |
|    value_loss            | 18.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.97783196 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -864        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 45          |
|    time_elapsed          | 1529        |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.004311377 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 0.868       |
|    cost_values           | 1.06        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.71        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.697       |
|    value_loss            | 8.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.0772628  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -862        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 46          |
|    time_elapsed          | 1564        |
|    total_timesteps       | 696320      |
| train/                   |             |
|    approx_kl             | 0.002977855 |
|    clip_fraction         | 0.00122     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.835       |
|    cost_value_loss       | 0.0243      |
|    cost_values           | 0.967       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.96        |
|    n_updates             | 3390        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.696       |
|    value_loss            | 16.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5477435  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -870        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 47          |
|    time_elapsed          | 1598        |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.004450365 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.96        |
|    cost_value_loss       | 5.81        |
|    cost_values           | 1.16        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.6        |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.696       |
|    value_loss            | 62.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1601609   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -866         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1632         |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0005963567 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.278        |
|    cost_values           | 1.38         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.000149    |
|    std                   | 0.696        |
|    value_loss            | 41.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.4420235  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -866        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 49          |
|    time_elapsed          | 1666        |
|    total_timesteps       | 702464      |
| train/                   |             |
|    approx_kl             | 0.001723513 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 1.54        |
|    cost_values           | 1.11        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 3420        |
|    policy_gradient_loss  | -0.00037    |
|    std                   | 0.696       |
|    value_loss            | 25.1        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
-----------------------------------
| avg_speed          | 7.83       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.83       |
| reward             | -0.9264558 |
| rollout/           |            |
|    ep_len_mean     | 972        |
|    ep_rew_mean     | -873       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 704512     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.81162     |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -873         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0008132653 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.994        |
|    cost_values           | 1.44         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | 2.02e-05     |
|    std                   | 0.694        |
|    value_loss            | 29.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.5482559    |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -886          |
| time/                    |               |
|    fps                   | 66            |
|    iterations            | 3             |
|    time_elapsed          | 92            |
|    total_timesteps       | 708608        |
| train/                   |               |
|    approx_kl             | 0.00053486484 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.54          |
|    cost_value_loss       | 1.57          |
|    cost_values           | 1.19          |
|    entropy               | -2.1          |
|    entropy_loss          | -2.11         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.6          |
|    n_updates             | 3450          |
|    policy_gradient_loss  | -0.000144     |
|    std                   | 0.693         |
|    value_loss            | 29.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2090803   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 126          |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0010350025 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.958        |
|    cost_value_loss       | 0.1          |
|    cost_values           | 1.02         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.3         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.000642    |
|    std                   | 0.693        |
|    value_loss            | 78.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.6774528   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -906         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 160          |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0072836694 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.912        |
|    cost_values           | 0.944        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.2         |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 0.693        |
|    value_loss            | 70           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.620296     |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -908          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 6             |
|    time_elapsed          | 194           |
|    total_timesteps       | 714752        |
| train/                   |               |
|    approx_kl             | 0.00025238417 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.784         |
|    cost_value_loss       | 0.033         |
|    cost_values           | 0.95          |
|    entropy               | -2.1          |
|    entropy_loss          | -2.1          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 27.5          |
|    n_updates             | 3480          |
|    policy_gradient_loss  | -0.000153     |
|    std                   | 0.693         |
|    value_loss            | 61.9          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.68743277   |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -918          |
| time/                    |               |
|    fps                   | 62            |
|    iterations            | 7             |
|    time_elapsed          | 228           |
|    total_timesteps       | 716800        |
| train/                   |               |
|    approx_kl             | 0.00072224997 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.775         |
|    cost_value_loss       | 0.028         |
|    cost_values           | 0.91          |
|    entropy               | -2.1          |
|    entropy_loss          | -2.1          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 22.1          |
|    n_updates             | 3490          |
|    policy_gradient_loss  | -0.000248     |
|    std                   | 0.693         |
|    value_loss            | 48.7          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9310285  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -917        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 8           |
|    time_elapsed          | 263         |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.004293202 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 2.79        |
|    cost_values           | 0.987       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.5        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.694       |
|    value_loss            | 58          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.79957515  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 9            |
|    time_elapsed          | 297          |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0043697604 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.45         |
|    cost_values           | 1.01         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.694        |
|    value_loss            | 9.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.226619    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -912         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 331          |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0034746453 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 1.06         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.34         |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.693        |
|    value_loss            | 12.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.15         |
| reward                   | -0.6271444   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 365          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0036798487 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 0.603        |
|    cost_values           | 1.08         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.9          |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.000675    |
|    std                   | 0.693        |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.55         |
| reward                   | -0.8110269   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 400          |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0015991721 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 0.992        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.44         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.000269    |
|    std                   | 0.693        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.8879009   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 434          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0028761318 |
|    clip_fraction         | 0.00874      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 1.69         |
|    cost_values           | 1.03         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.1         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.22         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.000222    |
|    std                   | 0.694        |
|    value_loss            | 16.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.6196854    |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -920          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 14            |
|    time_elapsed          | 468           |
|    total_timesteps       | 731136        |
| train/                   |               |
|    approx_kl             | 0.00023080155 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.934         |
|    cost_value_loss       | 0.0623        |
|    cost_values           | 1.01          |
|    entropy               | -2.11         |
|    entropy_loss          | -2.11         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 18.5          |
|    n_updates             | 3560          |
|    policy_gradient_loss  | 0.000197      |
|    std                   | 0.694         |
|    value_loss            | 39.4          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -1.8336784  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -910        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 15          |
|    time_elapsed          | 503         |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.008274037 |
|    clip_fraction         | 0.056       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 1.22        |
|    cost_values           | 0.977       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 42.2        |
|    n_updates             | 3570        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.695       |
|    value_loss            | 79.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9446627   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -918         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 537          |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0020196284 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.726        |
|    cost_values           | 0.999        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.1         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | 0.000384     |
|    std                   | 0.693        |
|    value_loss            | 103          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1765987   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 571          |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0015753796 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.855        |
|    cost_value_loss       | 0.107        |
|    cost_values           | 0.978        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.2         |
|    n_updates             | 3590         |
|    policy_gradient_loss  | 0.00123      |
|    std                   | 0.693        |
|    value_loss            | 48.6         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.5855112 |
| rollout/                 |            |
|    ep_len_mean           | 965        |
|    ep_rew_mean           | -925       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 18         |
|    time_elapsed          | 606        |
|    total_timesteps       | 739328     |
| train/                   |            |
|    approx_kl             | 0.00395598 |
|    clip_fraction         | 0.012      |
|    clip_range            | 0.2        |
|    cost_returns          | 1.31       |
|    cost_value_loss       | 1.82       |
|    cost_values           | 0.992      |
|    entropy               | -2.1       |
|    entropy_loss          | -2.1       |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.29       |
|    n_updates             | 3600       |
|    policy_gradient_loss  | -0.00127   |
|    std                   | 0.692      |
|    value_loss            | 9.84       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0284331   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -927         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 641          |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0067800432 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 6.22         |
|    cost_values           | 1.05         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.691        |
|    value_loss            | 24.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48781016  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 676          |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0011006176 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.348        |
|    cost_values           | 1.02         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.6         |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.000253    |
|    std                   | 0.69         |
|    value_loss            | 47.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85885525  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 710          |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0032720927 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.781        |
|    cost_value_loss       | 0.0197       |
|    cost_values           | 0.869        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.09         |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.000546    |
|    std                   | 0.69         |
|    value_loss            | 6.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.84909797 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -926        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 745         |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.006351959 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 1.92        |
|    cost_values           | 0.837       |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.69        |
|    value_loss            | 24.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.99803513  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -921         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 780          |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0057715704 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.965        |
|    cost_value_loss       | 0.511        |
|    cost_values           | 0.961        |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.69         |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.86         |
| reward                   | -0.61454314  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 815          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0032605957 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 2.59         |
|    cost_values           | 1.03         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.39         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.69         |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.56         |
| reward                   | -0.74545926  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -927         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 849          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0060869413 |
|    clip_fraction         | 0.0529       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.905        |
|    cost_value_loss       | 0.0475       |
|    cost_values           | 0.978        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.69         |
|    value_loss            | 8.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.75546366  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 883          |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0049214945 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.39         |
|    cost_values           | 0.94         |
|    entropy               | -2.09        |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.26         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.69         |
|    value_loss            | 14.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6400491  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -921        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 917         |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.003939385 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.77        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 1.15        |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.93        |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.688       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.99256843 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -920        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 952         |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.004717377 |
|    clip_fraction         | 0.00952     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 8.19        |
|    cost_values           | 1.49        |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.2        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.688       |
|    value_loss            | 27.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1553383  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -925        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 986         |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.004886246 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.39        |
|    cost_value_loss       | 4.37        |
|    cost_values           | 1.78        |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.688       |
|    value_loss            | 30.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.758946    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1021         |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0048668887 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 0.153        |
|    cost_values           | 2.07         |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.688        |
|    value_loss            | 31.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.905195    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -913         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 765952       |
| train/                   |              |
|    approx_kl             | 0.0050005675 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 0.284        |
|    cost_values           | 1.66         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 3730         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.686        |
|    value_loss            | 7.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7541771   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -908         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1090         |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0012417424 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 5.34         |
|    cost_values           | 1.4          |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.33         |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -3.71e-05    |
|    std                   | 0.686        |
|    value_loss            | 16.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45391732  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -909         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1124         |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0042917007 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 4.23         |
|    cost_values           | 1.42         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.0009      |
|    std                   | 0.685        |
|    value_loss            | 19.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.9244265   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -903         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1158         |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0026622103 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 0.0933       |
|    cost_values           | 1.58         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.684        |
|    value_loss            | 27.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.38522506  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -909         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1192         |
|    total_timesteps       | 774144       |
| train/                   |              |
|    approx_kl             | 0.0049872934 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 4.22         |
|    cost_values           | 1.21         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 3770         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.684        |
|    value_loss            | 21           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2524858   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -908         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1226         |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0074423836 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 2.1          |
|    cost_values           | 1.14         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.2          |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.685        |
|    value_loss            | 16           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -1.2173785   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -911         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1260         |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0045283823 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 1.03         |
|    cost_values           | 1.23         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.22         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | 0.000226     |
|    std                   | 0.685        |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.5217522   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -906         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1295         |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0008373766 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.174        |
|    cost_values           | 1.04         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 0.682        |
|    value_loss            | 13.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.1279444  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -905        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 39          |
|    time_elapsed          | 1329        |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.007991997 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 2.02        |
|    cost_values           | 1.01        |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22          |
|    n_updates             | 3810        |
|    policy_gradient_loss  | 0.00398     |
|    std                   | 0.681       |
|    value_loss            | 53.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.1576208   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -907         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1364         |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0047614435 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.983        |
|    cost_value_loss       | 0.299        |
|    cost_values           | 0.999        |
|    entropy               | -2.06        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | 4.95e-05     |
|    std                   | 0.678        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.848418   |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -893        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 41          |
|    time_elapsed          | 1398        |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.004788882 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 1.26        |
|    cost_values           | 1.02        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.56        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.000824   |
|    std                   | 0.675       |
|    value_loss            | 14.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0261492  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -895        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 42          |
|    time_elapsed          | 1432        |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.005103762 |
|    clip_fraction         | 0.0248      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 3.8         |
|    cost_values           | 1.01        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 40.1        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.673       |
|    value_loss            | 76.3        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.8513295    |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -893          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 43            |
|    time_elapsed          | 1466          |
|    total_timesteps       | 790528        |
| train/                   |               |
|    approx_kl             | 0.00043739495 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.1           |
|    cost_value_loss       | 0.88          |
|    cost_values           | 1.04          |
|    entropy               | -2.05         |
|    entropy_loss          | -2.05         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.17          |
|    n_updates             | 3850          |
|    policy_gradient_loss  | 0.000362      |
|    std                   | 0.675         |
|    value_loss            | 17.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8050378   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1500         |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0036266467 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.824        |
|    cost_value_loss       | 0.0179       |
|    cost_values           | 0.89         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.3          |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.000138    |
|    std                   | 0.675        |
|    value_loss            | 14.5         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.9956322 |
| rollout/                 |            |
|    ep_len_mean           | 963        |
|    ep_rew_mean           | -890       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 45         |
|    time_elapsed          | 1534       |
|    total_timesteps       | 794624     |
| train/                   |            |
|    approx_kl             | 0.00494396 |
|    clip_fraction         | 0.0194     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.664      |
|    cost_value_loss       | 0.0326     |
|    cost_values           | 0.833      |
|    entropy               | -2.05      |
|    entropy_loss          | -2.05      |
|    explained_variance    | 1.79e-07   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 17.8       |
|    n_updates             | 3870       |
|    policy_gradient_loss  | -0.0021    |
|    std                   | 0.675      |
|    value_loss            | 39.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.76022965  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -891         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1568         |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0034645363 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.729        |
|    cost_value_loss       | 0.0983       |
|    cost_values           | 0.77         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.83         |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.675        |
|    value_loss            | 5.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.1410631   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -890         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1602         |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0033153896 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 2.79         |
|    cost_values           | 0.947        |
|    entropy               | -2.04        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.7          |
|    n_updates             | 3890         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.671        |
|    value_loss            | 9.69         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.46804902 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -884        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 48          |
|    time_elapsed          | 1637        |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.0066481   |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.94        |
|    cost_value_loss       | 0.11        |
|    cost_values           | 0.952       |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.671       |
|    value_loss            | 9.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.4820921   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -885         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1673         |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0016965177 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 1.08         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19           |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.000513    |
|    std                   | 0.672        |
|    value_loss            | 30.3         |
-------------------------------------------
----------------------------------
| avg_speed          | 7.99      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 7.99      |
| reward             | -0.801246 |
| rollout/           |           |
|    ep_len_mean     | 963       |
|    ep_rew_mean     | -873      |
| time/              |           |
|    fps             | 82        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 804864    |
----------------------------------
------------------------------------------
| avg_speed                | 6.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.96        |
| reward                   | -0.60833335 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -864        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.005229391 |
|    clip_fraction         | 0.00952     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.336       |
|    cost_values           | 1.06        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.94        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.000208   |
|    std                   | 0.671       |
|    value_loss            | 15.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -1.0701456   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -854         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0047734766 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.966        |
|    cost_value_loss       | 0.442        |
|    cost_values           | 0.974        |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.87         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | 0.00105      |
|    std                   | 0.671        |
|    value_loss            | 12.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.0887002 |
| rollout/                 |            |
|    ep_len_mean           | 963        |
|    ep_rew_mean           | -846       |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 4          |
|    time_elapsed          | 127        |
|    total_timesteps       | 811008     |
| train/                   |            |
|    approx_kl             | 0.00104955 |
|    clip_fraction         | 0.00381    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.39       |
|    cost_value_loss       | 2.59       |
|    cost_values           | 1.18       |
|    entropy               | -2.04      |
|    entropy_loss          | -2.04      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.04       |
|    n_updates             | 3950       |
|    policy_gradient_loss  | 0.00027    |
|    std                   | 0.67       |
|    value_loss            | 10         |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.3613533  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -841        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 161         |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.001255552 |
|    clip_fraction         | 0.00884     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 0.068       |
|    cost_values           | 1.14        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.54        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.000255   |
|    std                   | 0.666       |
|    value_loss            | 12.9        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5179078    |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -844          |
| time/                    |               |
|    fps                   | 62            |
|    iterations            | 6             |
|    time_elapsed          | 195           |
|    total_timesteps       | 815104        |
| train/                   |               |
|    approx_kl             | 0.00043662413 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.831         |
|    cost_value_loss       | 0.0304        |
|    cost_values           | 0.986         |
|    entropy               | -2.03         |
|    entropy_loss          | -2.03         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.05          |
|    n_updates             | 3970          |
|    policy_gradient_loss  | -0.0001       |
|    std                   | 0.666         |
|    value_loss            | 18.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.99707156 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -841        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 229         |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.00325307  |
|    clip_fraction         | 0.00171     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.07        |
|    cost_value_loss       | 5.83        |
|    cost_values           | 1.07        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 3980        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.666       |
|    value_loss            | 25          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0563803  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 8           |
|    time_elapsed          | 263         |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.005560475 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.963       |
|    cost_value_loss       | 0.025       |
|    cost_values           | 1.05        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 0.665       |
|    value_loss            | 9.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8427641   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -830         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0007824452 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 1.06         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.000255    |
|    std                   | 0.665        |
|    value_loss            | 11.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0163        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0163        |
| reward                   | -0.74479294   |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -827          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 10            |
|    time_elapsed          | 332           |
|    total_timesteps       | 823296        |
| train/                   |               |
|    approx_kl             | 5.9612503e-06 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.28          |
|    cost_value_loss       | 6.74          |
|    cost_values           | 1.42          |
|    entropy               | -2.02         |
|    entropy_loss          | -2.02         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.99          |
|    n_updates             | 4010          |
|    policy_gradient_loss  | 2.75e-05      |
|    std                   | 0.666         |
|    value_loss            | 8.82          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.49034217  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -816         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 366          |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0038228482 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 0.0726       |
|    cost_values           | 1.46         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.33         |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.666        |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.83111644 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -819        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 12          |
|    time_elapsed          | 400         |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.005747669 |
|    clip_fraction         | 0.0165      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.961       |
|    cost_value_loss       | 0.0178      |
|    cost_values           | 0.995       |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 0.667       |
|    value_loss            | 43.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.58        |
| reward                   | -0.78736126 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -818        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 434         |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.004631626 |
|    clip_fraction         | 0.00444     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 4.85        |
|    cost_values           | 1.12        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.1        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.000616   |
|    std                   | 0.666       |
|    value_loss            | 44.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.73132384 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -811        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 14          |
|    time_elapsed          | 468         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.003271711 |
|    clip_fraction         | 0.00176     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.32        |
|    cost_value_loss       | 6.09        |
|    cost_values           | 1.32        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.5        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.666       |
|    value_loss            | 34.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2824606   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 502          |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0040405435 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.72         |
|    cost_values           | 1.47         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.000427    |
|    std                   | 0.665        |
|    value_loss            | 32.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.64806134 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -811        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 16          |
|    time_elapsed          | 537         |
|    total_timesteps       | 835584      |
| train/                   |             |
|    approx_kl             | 0.00179681  |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 1.96        |
|    cost_values           | 1.5         |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 4070        |
|    policy_gradient_loss  | -0.000278   |
|    std                   | 0.665       |
|    value_loss            | 21.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.531081    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 571          |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0033581834 |
|    clip_fraction         | 0.00762      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 15           |
|    cost_values           | 1.41         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.665        |
|    value_loss            | 13.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.39324543 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -803        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 605         |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.003750099 |
|    clip_fraction         | 0.00381     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 7.2         |
|    cost_values           | 1.89        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.44        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.000442   |
|    std                   | 0.666       |
|    value_loss            | 6.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.63         |
| reward                   | -0.87091976  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 639          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0058010938 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.34         |
|    cost_value_loss       | 8.8          |
|    cost_values           | 2.45         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.666        |
|    value_loss            | 15           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.6384249    |
| rollout/                 |               |
|    ep_len_mean           | 961           |
|    ep_rew_mean           | -796          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 20            |
|    time_elapsed          | 673           |
|    total_timesteps       | 843776        |
| train/                   |               |
|    approx_kl             | 0.00093384157 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.13          |
|    cost_value_loss       | 5.32          |
|    cost_values           | 2.74          |
|    entropy               | -2.02         |
|    entropy_loss          | -2.02         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 30.2          |
|    n_updates             | 4110          |
|    policy_gradient_loss  | -0.000186     |
|    std                   | 0.666         |
|    value_loss            | 38.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.6388308   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 707          |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0013970715 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 0.612        |
|    cost_values           | 2.56         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.08         |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -0.000509    |
|    std                   | 0.668        |
|    value_loss            | 5.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.1087463  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -791        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 741         |
|    total_timesteps       | 847872      |
| train/                   |             |
|    approx_kl             | 0.006637113 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.01        |
|    cost_value_loss       | 0.4         |
|    cost_values           | 2.09        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.97        |
|    n_updates             | 4130        |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.667       |
|    value_loss            | 7.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.63037795 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -798        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 775         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.005463981 |
|    clip_fraction         | 0.0173      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.45        |
|    cost_value_loss       | 5.22        |
|    cost_values           | 2.02        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.57        |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.000623   |
|    std                   | 0.668       |
|    value_loss            | 8.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.63047826  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -793         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 810          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0026993607 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.176        |
|    cost_values           | 2.21         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.4         |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.000375    |
|    std                   | 0.668        |
|    value_loss            | 46.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.8961034   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 844          |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 9.216883e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 1.78         |
|    cost_values           | 1.92         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.19         |
|    n_updates             | 4160         |
|    policy_gradient_loss  | -9.53e-07    |
|    std                   | 0.668        |
|    value_loss            | 12.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.98811936  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 878          |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0033216293 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 3.65         |
|    cost_values           | 1.84         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.04         |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.000545    |
|    std                   | 0.668        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.8141023  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -788        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 913         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.002833568 |
|    clip_fraction         | 0.00474     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 0.136       |
|    cost_values           | 1.88        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.000314   |
|    std                   | 0.669       |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.89759445  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -789         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 947          |
|    total_timesteps       | 860160       |
| train/                   |              |
|    approx_kl             | 0.0013461988 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 1.61         |
|    cost_values           | 1.47         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.33         |
|    n_updates             | 4190         |
|    policy_gradient_loss  | 8.4e-05      |
|    std                   | 0.669        |
|    value_loss            | 9.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1871475  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -795        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 982         |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.002147797 |
|    clip_fraction         | 0.000635    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 0.0453      |
|    cost_values           | 1.35        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 4200        |
|    policy_gradient_loss  | 3.22e-05    |
|    std                   | 0.669       |
|    value_loss            | 12.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.8232767   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -801         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1016         |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0037894268 |
|    clip_fraction         | 0.0534       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.133        |
|    cost_values           | 1.05         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.94         |
|    n_updates             | 4210         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.669        |
|    value_loss            | 4.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.38278648  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1050         |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0031092623 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 6.5          |
|    cost_values           | 1.05         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | 0.00133      |
|    std                   | 0.669        |
|    value_loss            | 29.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0739559   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -802         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1084         |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0061673326 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 3.26         |
|    cost_values           | 1.04         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.668        |
|    value_loss            | 17.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8399492   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1119         |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0054854495 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.888        |
|    cost_value_loss       | 0.0876       |
|    cost_values           | 0.957        |
|    entropy               | -2.02        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.666        |
|    value_loss            | 6.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2170793   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1152         |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0052553373 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 3.19         |
|    cost_values           | 1.08         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.61         |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.000366    |
|    std                   | 0.664        |
|    value_loss            | 8.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7313053  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -809        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1186        |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.004476168 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 0.986       |
|    cost_values           | 1.33        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -2.82e-05   |
|    std                   | 0.665       |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0109531   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1221         |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0022159922 |
|    clip_fraction         | 0.00259      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 0.0665       |
|    cost_values           | 1.25         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.18         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | 0.000916     |
|    std                   | 0.666        |
|    value_loss            | 21.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8879983   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1256         |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0016126747 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 8            |
|    cost_values           | 1.11         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.17         |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.00071     |
|    std                   | 0.666        |
|    value_loss            | 10.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45177722 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -815        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 38          |
|    time_elapsed          | 1291        |
|    total_timesteps       | 880640      |
| train/                   |             |
|    approx_kl             | 0.005017557 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 2.14        |
|    cost_values           | 1.22        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.45        |
|    n_updates             | 4290        |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 0.666       |
|    value_loss            | 9.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.621        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.621        |
| reward                   | -0.6237147   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1326         |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0063874116 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 5.41         |
|    cost_values           | 1.3          |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.666        |
|    value_loss            | 30.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.879482   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -820        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 40          |
|    time_elapsed          | 1361        |
|    total_timesteps       | 884736      |
| train/                   |             |
|    approx_kl             | 0.000514387 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 1.44        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 4310        |
|    policy_gradient_loss  | -9.49e-05   |
|    std                   | 0.666       |
|    value_loss            | 20.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.6042976   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1395         |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0011141669 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.4          |
|    cost_value_loss       | 11.1         |
|    cost_values           | 1.59         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.000715    |
|    std                   | 0.665        |
|    value_loss            | 52.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8370175  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -812        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 42          |
|    time_elapsed          | 1429        |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.004538173 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 2.66        |
|    cost_values           | 1.65        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.62        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.664       |
|    value_loss            | 9.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.070449   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -806        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 43          |
|    time_elapsed          | 1464        |
|    total_timesteps       | 890880      |
| train/                   |             |
|    approx_kl             | 0.005982818 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.0515      |
|    cost_values           | 1.49        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.99        |
|    n_updates             | 4340        |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.66        |
|    value_loss            | 2.01        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.3505561    |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -809          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 44            |
|    time_elapsed          | 1498          |
|    total_timesteps       | 892928        |
| train/                   |               |
|    approx_kl             | 0.00081031054 |
|    clip_fraction         | 0.00498       |
|    clip_range            | 0.2           |
|    cost_returns          | 1.11          |
|    cost_value_loss       | 0.215         |
|    cost_values           | 1.1           |
|    entropy               | -2            |
|    entropy_loss          | -2            |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 2.41          |
|    n_updates             | 4350          |
|    policy_gradient_loss  | -0.000639     |
|    std                   | 0.659         |
|    value_loss            | 4.21          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0664448   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1532         |
|    total_timesteps       | 894976       |
| train/                   |              |
|    approx_kl             | 0.0023740302 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.849        |
|    cost_value_loss       | 0.0299       |
|    cost_values           | 0.998        |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.14         |
|    n_updates             | 4360         |
|    policy_gradient_loss  | 0.00127      |
|    std                   | 0.659        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0472946   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1566         |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0010905728 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 3.7          |
|    cost_values           | 1.15         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.8         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | -0.000306    |
|    std                   | 0.659        |
|    value_loss            | 55.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.48829302 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -815        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 47          |
|    time_elapsed          | 1600        |
|    total_timesteps       | 899072      |
| train/                   |             |
|    approx_kl             | 0.004524397 |
|    clip_fraction         | 0.00396     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 5.17        |
|    cost_values           | 1.49        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 4380        |
|    policy_gradient_loss  | -0.000176   |
|    std                   | 0.659       |
|    value_loss            | 16.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.1882672  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -814        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 48          |
|    time_elapsed          | 1635        |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.003535871 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.241       |
|    cost_values           | 1.52        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 4390        |
|    policy_gradient_loss  | 0.000241    |
|    std                   | 0.659       |
|    value_loss            | 26.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.8446246  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -819        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 49          |
|    time_elapsed          | 1669        |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.001114071 |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 0.0254      |
|    cost_values           | 1.12        |
|    entropy               | -1.99       |
|    entropy_loss          | -2          |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | -0.000371   |
|    std                   | 0.654       |
|    value_loss            | 5.05        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
------------------------------------
| avg_speed          | 7.98        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.98        |
| reward             | -0.68559927 |
| rollout/           |             |
|    ep_len_mean     | 975         |
|    ep_rew_mean     | -818        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 905216      |
------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.9609417  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -823        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 907264      |
| train/                   |             |
|    approx_kl             | 0.002559448 |
|    clip_fraction         | 0.000879    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.24        |
|    cost_value_loss       | 8.46        |
|    cost_values           | 1.04        |
|    entropy               | -1.99       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.65        |
|    n_updates             | 4420        |
|    policy_gradient_loss  | -0.000809   |
|    std                   | 0.653       |
|    value_loss            | 12.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.9741148   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -821         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0009855371 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.997        |
|    cost_value_loss       | 0.148        |
|    cost_values           | 1.07         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.2         |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.000393    |
|    std                   | 0.653        |
|    value_loss            | 59.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.5141476   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -816         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 911360       |
| train/                   |              |
|    approx_kl             | 0.0038176682 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 3.99         |
|    cost_values           | 1.03         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 4440         |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.653        |
|    value_loss            | 22.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.953481   |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -822        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 913408      |
| train/                   |             |
|    approx_kl             | 0.005530015 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 1.69        |
|    cost_values           | 1.07        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 4450        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.652       |
|    value_loss            | 20.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.9611508  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -823        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 915456      |
| train/                   |             |
|    approx_kl             | 0.005996076 |
|    clip_fraction         | 0.0187      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.73        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 1.17        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.7        |
|    n_updates             | 4460        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.652       |
|    value_loss            | 51.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.64682686 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.005876148 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 0.0843      |
|    cost_values           | 1.26        |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.647       |
|    value_loss            | 3.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.43734822 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -834        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.004686626 |
|    clip_fraction         | 0.0194      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.49        |
|    cost_values           | 1.07        |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.646       |
|    value_loss            | 28.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.68081295  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0051241075 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.933        |
|    cost_value_loss       | 0.325        |
|    cost_values           | 0.96         |
|    entropy               | -1.96        |
|    entropy_loss          | -1.96        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 4490         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.644        |
|    value_loss            | 9.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.9881      |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -834         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0036471912 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.52         |
|    cost_values           | 1.11         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.639        |
|    value_loss            | 27.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.4142932  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 925696      |
| train/                   |             |
|    approx_kl             | 0.005021313 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 6.95        |
|    cost_values           | 1.24        |
|    entropy               | -1.94       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.77        |
|    n_updates             | 4510        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.638       |
|    value_loss            | 9.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0398964  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -839        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 404         |
|    total_timesteps       | 927744      |
| train/                   |             |
|    approx_kl             | 0.005996183 |
|    clip_fraction         | 0.0404      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 0.354       |
|    cost_values           | 1.18        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.33        |
|    n_updates             | 4520        |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.636       |
|    value_loss            | 11.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.80617595  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -833         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 929792       |
| train/                   |              |
|    approx_kl             | 0.0024305955 |
|    clip_fraction         | 0.00464      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 4.38         |
|    cost_values           | 1.14         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 4530         |
|    policy_gradient_loss  | 0.0002       |
|    std                   | 0.636        |
|    value_loss            | 18.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -1.2237072   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -832         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0042621624 |
|    clip_fraction         | 0.0433       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 3.06         |
|    cost_values           | 1.19         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.4         |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.634        |
|    value_loss            | 44.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0537728  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 508         |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.005261124 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 0.435       |
|    cost_values           | 1.29        |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00238    |
|    std                   | 0.634       |
|    value_loss            | 13          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3407799   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -829         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 935936       |
| train/                   |              |
|    approx_kl             | 0.0029015406 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 6.86         |
|    cost_values           | 1.17         |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.3         |
|    n_updates             | 4560         |
|    policy_gradient_loss  | -0.000526    |
|    std                   | 0.634        |
|    value_loss            | 29.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9973128   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 576          |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0024255537 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 0.608        |
|    cost_values           | 1.2          |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.4         |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.000205    |
|    std                   | 0.633        |
|    value_loss            | 48.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9195092   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -837         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 611          |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0032190979 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 1.63         |
|    cost_values           | 1.1          |
|    entropy               | -1.93        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.89         |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.000651    |
|    std                   | 0.634        |
|    value_loss            | 17.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.025758    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0028833319 |
|    clip_fraction         | 0.00122      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 2.45         |
|    cost_values           | 1.24         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.000344    |
|    std                   | 0.635        |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.86880577  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -844         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0025633038 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 2.98         |
|    cost_values           | 1.33         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.000441    |
|    std                   | 0.635        |
|    value_loss            | 5.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.117877    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -844         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 714          |
|    total_timesteps       | 946176       |
| train/                   |              |
|    approx_kl             | 0.0003399852 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.058        |
|    cost_values           | 1.35         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 4610         |
|    policy_gradient_loss  | 0.000474     |
|    std                   | 0.636        |
|    value_loss            | 37.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.67417616  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 948224       |
| train/                   |              |
|    approx_kl             | 0.0031527202 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.998        |
|    cost_value_loss       | 0.0181       |
|    cost_values           | 1.04         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.06         |
|    n_updates             | 4620         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.629        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0597551   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -843         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 783          |
|    total_timesteps       | 950272       |
| train/                   |              |
|    approx_kl             | 0.0038108865 |
|    clip_fraction         | 0.00679      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.78         |
|    cost_values           | 1            |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.03         |
|    n_updates             | 4630         |
|    policy_gradient_loss  | -0.000409    |
|    std                   | 0.627        |
|    value_loss            | 5.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.81032634  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -846         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 819          |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0042914394 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.821        |
|    cost_value_loss       | 0.0228       |
|    cost_values           | 0.947        |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.43         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.627        |
|    value_loss            | 7.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.57         |
| reward                   | -0.732876    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 853          |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0054129763 |
|    clip_fraction         | 0.0481       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.989        |
|    cost_value_loss       | 0.878        |
|    cost_values           | 0.957        |
|    entropy               | -1.89        |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.34         |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.624        |
|    value_loss            | 7.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6463498  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -850        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 888         |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.005493229 |
|    clip_fraction         | 0.0338      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 1.48        |
|    cost_values           | 1.04        |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.95        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.622       |
|    value_loss            | 11.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.56823194  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -842         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 923          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0021898288 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 1.13         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.4         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.000457    |
|    std                   | 0.621        |
|    value_loss            | 41.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.88          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.88          |
| reward                   | -0.25306386   |
| rollout/                 |               |
|    ep_len_mean           | 977           |
|    ep_rew_mean           | -837          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 28            |
|    time_elapsed          | 957           |
|    total_timesteps       | 960512        |
| train/                   |               |
|    approx_kl             | 0.00027279137 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.64          |
|    cost_value_loss       | 3.59          |
|    cost_values           | 1.07          |
|    entropy               | -1.88         |
|    entropy_loss          | -1.88         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.56          |
|    n_updates             | 4680          |
|    policy_gradient_loss  | -1.9e-05      |
|    std                   | 0.621         |
|    value_loss            | 15.2          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.41147697 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -833        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 992         |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.005852083 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.969       |
|    cost_value_loss       | 0.467       |
|    cost_values           | 0.968       |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.621       |
|    value_loss            | 5.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0003521   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -828         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1026         |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0037730802 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 6.49         |
|    cost_values           | 1.2          |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.000707    |
|    std                   | 0.62         |
|    value_loss            | 34.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.97121143  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -828         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1060         |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0063838707 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 4.36         |
|    cost_values           | 1.56         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.27         |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.62         |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0453097   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -833         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1094         |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0069723674 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.312        |
|    cost_values           | 1.44         |
|    entropy               | -1.87        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.618        |
|    value_loss            | 6.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.97275615  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1129         |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0025359178 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 0.0352       |
|    cost_values           | 1.23         |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.21         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | 0.00167      |
|    std                   | 0.618        |
|    value_loss            | 20           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47654295  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -832         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1163         |
|    total_timesteps       | 972800       |
| train/                   |              |
|    approx_kl             | 0.0054875165 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.887        |
|    cost_value_loss       | 0.0177       |
|    cost_values           | 0.945        |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.05         |
|    n_updates             | 4740         |
|    policy_gradient_loss  | -0.000881    |
|    std                   | 0.616        |
|    value_loss            | 9.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.43841186  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1198         |
|    total_timesteps       | 974848       |
| train/                   |              |
|    approx_kl             | 0.0061753676 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.763        |
|    cost_value_loss       | 0.0629       |
|    cost_values           | 0.802        |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.9          |
|    n_updates             | 4750         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.614        |
|    value_loss            | 5.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1907933  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -838        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1232        |
|    total_timesteps       | 976896      |
| train/                   |             |
|    approx_kl             | 0.003915376 |
|    clip_fraction         | 0.013       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.652       |
|    cost_value_loss       | 0.0552      |
|    cost_values           | 0.711       |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 4760        |
|    policy_gradient_loss  | -0.000558   |
|    std                   | 0.613       |
|    value_loss            | 11.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.678488    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0006951301 |
|    clip_fraction         | 0.00679      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.526        |
|    cost_value_loss       | 0.00899      |
|    cost_values           | 0.603        |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.47         |
|    n_updates             | 4770         |
|    policy_gradient_loss  | 0.000444     |
|    std                   | 0.613        |
|    value_loss            | 7.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7671821   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -844         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1301         |
|    total_timesteps       | 980992       |
| train/                   |              |
|    approx_kl             | 0.0049439594 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.666        |
|    cost_value_loss       | 0.779        |
|    cost_values           | 0.59         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 4780         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.612        |
|    value_loss            | 30.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8492411   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -850         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1335         |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0027877793 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.719        |
|    cost_value_loss       | 0.579        |
|    cost_values           | 0.689        |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.51         |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.000537    |
|    std                   | 0.61         |
|    value_loss            | 19.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.6933547    |
| rollout/                 |               |
|    ep_len_mean           | 980           |
|    ep_rew_mean           | -851          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 40            |
|    time_elapsed          | 1370          |
|    total_timesteps       | 985088        |
| train/                   |               |
|    approx_kl             | 0.00073215854 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.29          |
|    cost_value_loss       | 3.39          |
|    cost_values           | 0.84          |
|    entropy               | -1.84         |
|    entropy_loss          | -1.85         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.13          |
|    n_updates             | 4800          |
|    policy_gradient_loss  | -0.000197     |
|    std                   | 0.61          |
|    value_loss            | 15.8          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0992346  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -843        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1404        |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.001735499 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.822       |
|    cost_value_loss       | 0.0159      |
|    cost_values           | 0.884       |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.607       |
|    value_loss            | 9.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.830632    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -844         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1438         |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0045461776 |
|    clip_fraction         | 0.0487       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.774        |
|    cost_value_loss       | 0.215        |
|    cost_values           | 0.823        |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | 0.0011       |
|    std                   | 0.607        |
|    value_loss            | 51           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.573288   |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -839        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1473        |
|    total_timesteps       | 991232      |
| train/                   |             |
|    approx_kl             | 0.001930136 |
|    clip_fraction         | 0.00889     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 2.12        |
|    cost_values           | 0.932       |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.68        |
|    n_updates             | 4830        |
|    policy_gradient_loss  | -0.000858   |
|    std                   | 0.607       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3154497  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -847        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1507        |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.005034924 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 1.18        |
|    cost_values           | 1           |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 4840        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.606       |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81165904  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -849         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1542         |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0039090663 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.823        |
|    cost_value_loss       | 0.0257       |
|    cost_values           | 0.962        |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.41         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.606        |
|    value_loss            | 21.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8023074   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -842         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1577         |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0029471735 |
|    clip_fraction         | 0.00937      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.761        |
|    cost_value_loss       | 0.0174       |
|    cost_values           | 0.832        |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.605        |
|    value_loss            | 11.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91153127  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -845         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1611         |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0029690405 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 5.48         |
|    cost_values           | 0.856        |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.8         |
|    n_updates             | 4870         |
|    policy_gradient_loss  | -0.000265    |
|    std                   | 0.605        |
|    value_loss            | 30.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.8435445  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -838        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1646        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.004533409 |
|    clip_fraction         | 0.00601     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.832       |
|    cost_value_loss       | 0.0233      |
|    cost_values           | 0.956       |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.79        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.604       |
|    value_loss            | 18.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1271003   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -843         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1681         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0009059944 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 9.93         |
|    cost_values           | 1.02         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.000462    |
|    std                   | 0.604        |
|    value_loss            | 24.4         |
-------------------------------------------
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.36685374 |
| rollout/           |             |
|    ep_len_mean     | 979         |
|    ep_rew_mean     | -841        |
| time/              |             |
|    fps             | 81          |
|    iterations      | 1           |
|    time_elapsed    | 25          |
|    total_timesteps | 1005568     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.79626715  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0031534757 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.998        |
|    cost_value_loss       | 0.854        |
|    cost_values           | 0.961        |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.88         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | 1.27e-05     |
|    std                   | 0.602        |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8981973  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -833        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 3           |
|    time_elapsed          | 95          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.002735665 |
|    clip_fraction         | 0.002       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 9.26        |
|    cost_values           | 1.15        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 4920        |
|    policy_gradient_loss  | 0.000879    |
|    std                   | 0.601       |
|    value_loss            | 34.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6445881   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 1011712      |
| train/                   |              |
|    approx_kl             | 0.0011057465 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 0.179        |
|    cost_values           | 1.26         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.4         |
|    n_updates             | 4930         |
|    policy_gradient_loss  | -0.000521    |
|    std                   | 0.601        |
|    value_loss            | 64.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0732403  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -829        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 164         |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.004286896 |
|    clip_fraction         | 0.00615     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.314       |
|    cost_values           | 0.974       |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.92        |
|    n_updates             | 4940        |
|    policy_gradient_loss  | -0.000575   |
|    std                   | 0.602       |
|    value_loss            | 6.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5442239   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -830         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1015808      |
| train/                   |              |
|    approx_kl             | 0.0023106285 |
|    clip_fraction         | 0.00122      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 6.95         |
|    cost_values           | 1.03         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.2         |
|    n_updates             | 4950         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.603        |
|    value_loss            | 55           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.037759   |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -829        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 233         |
|    total_timesteps       | 1017856     |
| train/                   |             |
|    approx_kl             | 0.003851796 |
|    clip_fraction         | 0.00381     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 2.36        |
|    cost_values           | 1.02        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 4960        |
|    policy_gradient_loss  | -0.000595   |
|    std                   | 0.602       |
|    value_loss            | 29.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.40320224  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 1019904      |
| train/                   |              |
|    approx_kl             | 0.0026756776 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.48         |
|    cost_values           | 0.997        |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.83         |
|    n_updates             | 4970         |
|    policy_gradient_loss  | -0.000683    |
|    std                   | 0.602        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6850544   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -829         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0005420146 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 4.13         |
|    cost_values           | 1.05         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.87         |
|    n_updates             | 4980         |
|    policy_gradient_loss  | 0.000108     |
|    std                   | 0.603        |
|    value_loss            | 14.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78383726  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -827         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 1024000      |
| train/                   |              |
|    approx_kl             | 8.427611e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 5.97         |
|    cost_values           | 1.06         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 4990         |
|    policy_gradient_loss  | 9.16e-06     |
|    std                   | 0.604        |
|    value_loss            | 30.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.99          |
| reward                   | -0.9401891    |
| rollout/                 |               |
|    ep_len_mean           | 977           |
|    ep_rew_mean           | -827          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 11            |
|    time_elapsed          | 373           |
|    total_timesteps       | 1026048       |
| train/                   |               |
|    approx_kl             | 0.00025091594 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.11          |
|    cost_value_loss       | 7.94          |
|    cost_values           | 1.05          |
|    entropy               | -1.82         |
|    entropy_loss          | -1.82         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.25          |
|    n_updates             | 5000          |
|    policy_gradient_loss  | -4.64e-05     |
|    std                   | 0.603         |
|    value_loss            | 10.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1012787   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -832         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 408          |
|    total_timesteps       | 1028096      |
| train/                   |              |
|    approx_kl             | 0.0004886699 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 1.08         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.02         |
|    n_updates             | 5010         |
|    policy_gradient_loss  | -0.00023     |
|    std                   | 0.603        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0734229   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -833         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 1030144      |
| train/                   |              |
|    approx_kl             | 0.0052224277 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.9          |
|    cost_value_loss       | 0.256        |
|    cost_values           | 0.909        |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.1          |
|    n_updates             | 5020         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.605        |
|    value_loss            | 5.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.278714    |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -836         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 1032192      |
| train/                   |              |
|    approx_kl             | 0.0017350035 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.33         |
|    cost_values           | 1.04         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.83        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 5030         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.608        |
|    value_loss            | 7.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3010608   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 1034240      |
| train/                   |              |
|    approx_kl             | 0.0016859637 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.901        |
|    cost_value_loss       | 0.19         |
|    cost_values           | 0.959        |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.29         |
|    n_updates             | 5040         |
|    policy_gradient_loss  | -0.000362    |
|    std                   | 0.608        |
|    value_loss            | 20.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8412715   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -846         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 546          |
|    total_timesteps       | 1036288      |
| train/                   |              |
|    approx_kl             | 0.0042230813 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.759        |
|    cost_value_loss       | 0.0189       |
|    cost_values           | 0.871        |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.32         |
|    n_updates             | 5050         |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 0.608        |
|    value_loss            | 18.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8168359  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -847        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 17          |
|    time_elapsed          | 580         |
|    total_timesteps       | 1038336     |
| train/                   |             |
|    approx_kl             | 0.003742483 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 1.86        |
|    cost_values           | 0.918       |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.1         |
|    n_updates             | 5060        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.608       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2241957  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -848        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 615         |
|    total_timesteps       | 1040384     |
| train/                   |             |
|    approx_kl             | 0.004843795 |
|    clip_fraction         | 0.0305      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.62        |
|    cost_values           | 1.03        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.91        |
|    n_updates             | 5070        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.606       |
|    value_loss            | 10.7        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.0696563 |
| rollout/                 |            |
|    ep_len_mean           | 991        |
|    ep_rew_mean           | -846       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 19         |
|    time_elapsed          | 649        |
|    total_timesteps       | 1042432    |
| train/                   |            |
|    approx_kl             | 0.00673703 |
|    clip_fraction         | 0.0423     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.45       |
|    cost_value_loss       | 4.05       |
|    cost_values           | 1.25       |
|    entropy               | -1.82      |
|    entropy_loss          | -1.83      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.26       |
|    n_updates             | 5080       |
|    policy_gradient_loss  | -0.00237   |
|    std                   | 0.603      |
|    value_loss            | 13.7       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 6.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.13         |
| reward                   | -0.71535677  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -845         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 684          |
|    total_timesteps       | 1044480      |
| train/                   |              |
|    approx_kl             | 0.0068572806 |
|    clip_fraction         | 0.0611       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 0.442        |
|    cost_values           | 1.31         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.02         |
|    n_updates             | 5090         |
|    policy_gradient_loss  | -0.00483     |
|    std                   | 0.602        |
|    value_loss            | 18.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65464413  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 1046528      |
| train/                   |              |
|    approx_kl             | 0.0034647014 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.2          |
|    cost_values           | 1.18         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.31         |
|    n_updates             | 5100         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.601        |
|    value_loss            | 8.47         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.84600556   |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -841          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 22            |
|    time_elapsed          | 752           |
|    total_timesteps       | 1048576       |
| train/                   |               |
|    approx_kl             | 0.00023625279 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.01          |
|    cost_value_loss       | 4.3           |
|    cost_values           | 1.28          |
|    entropy               | -1.81         |
|    entropy_loss          | -1.81         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12            |
|    n_updates             | 5110          |
|    policy_gradient_loss  | 0.00027       |
|    std                   | 0.601         |
|    value_loss            | 22.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7383472   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -836         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 1050624      |
| train/                   |              |
|    approx_kl             | 0.0045474665 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.0684       |
|    cost_values           | 1.04         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 5120         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.603        |
|    value_loss            | 8.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.82276773 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 822         |
|    total_timesteps       | 1052672     |
| train/                   |             |
|    approx_kl             | 0.003933264 |
|    clip_fraction         | 0.00737     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 1.04        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 5130        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.603       |
|    value_loss            | 20.4        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.44353542   |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -826          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 25            |
|    time_elapsed          | 856           |
|    total_timesteps       | 1054720       |
| train/                   |               |
|    approx_kl             | 0.00055218354 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.52          |
|    cost_value_loss       | 2.92          |
|    cost_values           | 1.07          |
|    entropy               | -1.82         |
|    entropy_loss          | -1.82         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.82          |
|    n_updates             | 5140          |
|    policy_gradient_loss  | -0.000136     |
|    std                   | 0.603         |
|    value_loss            | 16.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0844157   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 891          |
|    total_timesteps       | 1056768      |
| train/                   |              |
|    approx_kl             | 0.0035931584 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 5.5          |
|    cost_values           | 1.07         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 5150         |
|    policy_gradient_loss  | -0.000957    |
|    std                   | 0.603        |
|    value_loss            | 20.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.55967414 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -827        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 925         |
|    total_timesteps       | 1058816     |
| train/                   |             |
|    approx_kl             | 0.005628332 |
|    clip_fraction         | 0.0432      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 5.84        |
|    cost_values           | 1.36        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.9        |
|    n_updates             | 5160        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.603       |
|    value_loss            | 44.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1348753   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -829         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 960          |
|    total_timesteps       | 1060864      |
| train/                   |              |
|    approx_kl             | 0.0012695888 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 4.69         |
|    cost_values           | 1.65         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 5170         |
|    policy_gradient_loss  | 3.52e-05     |
|    std                   | 0.604        |
|    value_loss            | 6.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7846642  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -831        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1062912     |
| train/                   |             |
|    approx_kl             | 0.006218856 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 1.41        |
|    cost_values           | 1.79        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.02        |
|    n_updates             | 5180        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.605       |
|    value_loss            | 7.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.84301615  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -832         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1029         |
|    total_timesteps       | 1064960      |
| train/                   |              |
|    approx_kl             | 0.0034315144 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 5.68         |
|    cost_values           | 1.78         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.12         |
|    n_updates             | 5190         |
|    policy_gradient_loss  | -0.000908    |
|    std                   | 0.605        |
|    value_loss            | 9.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.71822333 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 1067008     |
| train/                   |             |
|    approx_kl             | 0.006725548 |
|    clip_fraction         | 0.011       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 0.161       |
|    cost_values           | 1.89        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.12        |
|    n_updates             | 5200        |
|    policy_gradient_loss  | -0.00056    |
|    std                   | 0.605       |
|    value_loss            | 7.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.25658116  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -823         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1099         |
|    total_timesteps       | 1069056      |
| train/                   |              |
|    approx_kl             | 0.0015328255 |
|    clip_fraction         | 0.00752      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.55         |
|    cost_value_loss       | 5.98         |
|    cost_values           | 1.61         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.12         |
|    n_updates             | 5210         |
|    policy_gradient_loss  | 0.00103      |
|    std                   | 0.604        |
|    value_loss            | 6.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7121916   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1133         |
|    total_timesteps       | 1071104      |
| train/                   |              |
|    approx_kl             | 0.0018172769 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 1.88         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 5220         |
|    policy_gradient_loss  | -6.63e-05    |
|    std                   | 0.603        |
|    value_loss            | 16.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.1101297   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -821         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1168         |
|    total_timesteps       | 1073152      |
| train/                   |              |
|    approx_kl             | 0.0038701305 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 1.43         |
|    cost_values           | 1.89         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.08         |
|    n_updates             | 5230         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.603        |
|    value_loss            | 14.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.283       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.283       |
| reward                   | -0.71388793 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -817        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1203        |
|    total_timesteps       | 1075200     |
| train/                   |             |
|    approx_kl             | 0.001726335 |
|    clip_fraction         | 0.00513     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 0.0652      |
|    cost_values           | 1.65        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 5240        |
|    policy_gradient_loss  | -0.000478   |
|    std                   | 0.602       |
|    value_loss            | 6.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.65         |
| reward                   | -0.75072676  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1238         |
|    total_timesteps       | 1077248      |
| train/                   |              |
|    approx_kl             | 0.0045670504 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 3.61         |
|    cost_values           | 1.37         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.14         |
|    n_updates             | 5250         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.601        |
|    value_loss            | 7.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5164825   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1273         |
|    total_timesteps       | 1079296      |
| train/                   |              |
|    approx_kl             | 0.0019157879 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.61         |
|    cost_value_loss       | 23.5         |
|    cost_values           | 1.63         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 5260         |
|    policy_gradient_loss  | -0.000537    |
|    std                   | 0.601        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.7203789   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1307         |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 0.0023389165 |
|    clip_fraction         | 0.00679      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 2.77         |
|    cost_values           | 2            |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.38         |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -0.000758    |
|    std                   | 0.598        |
|    value_loss            | 3.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5492462   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1342         |
|    total_timesteps       | 1083392      |
| train/                   |              |
|    approx_kl             | 0.0065017873 |
|    clip_fraction         | 0.0585       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 0.214        |
|    cost_values           | 1.89         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.21         |
|    n_updates             | 5280         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 0.599        |
|    value_loss            | 4.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5150286   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1376         |
|    total_timesteps       | 1085440      |
| train/                   |              |
|    approx_kl             | 0.0007780505 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 1.36         |
|    cost_values           | 1.69         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.12         |
|    n_updates             | 5290         |
|    policy_gradient_loss  | -0.000224    |
|    std                   | 0.599        |
|    value_loss            | 2.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6818107   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1411         |
|    total_timesteps       | 1087488      |
| train/                   |              |
|    approx_kl             | 0.0022380818 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 3.21         |
|    cost_values           | 1.64         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 5300         |
|    policy_gradient_loss  | -0.000679    |
|    std                   | 0.6          |
|    value_loss            | 39.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.9504504   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -809         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1446         |
|    total_timesteps       | 1089536      |
| train/                   |              |
|    approx_kl             | 0.0036175428 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 1.57         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 5310         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.599        |
|    value_loss            | 19.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6028267   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1480         |
|    total_timesteps       | 1091584      |
| train/                   |              |
|    approx_kl             | 0.0025193437 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 0.0835       |
|    cost_values           | 1.46         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 5320         |
|    policy_gradient_loss  | 0.000495     |
|    std                   | 0.598        |
|    value_loss            | 37.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.87675965   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -796          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 44            |
|    time_elapsed          | 1515          |
|    total_timesteps       | 1093632       |
| train/                   |               |
|    approx_kl             | 0.00025487161 |
|    clip_fraction         | 0.0389        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.21          |
|    cost_value_loss       | 0.319         |
|    cost_values           | 1.19          |
|    entropy               | -1.81         |
|    entropy_loss          | -1.81         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.6          |
|    n_updates             | 5330          |
|    policy_gradient_loss  | -0.000714     |
|    std                   | 0.599         |
|    value_loss            | 26            |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.7375325    |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -797          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1550          |
|    total_timesteps       | 1095680       |
| train/                   |               |
|    approx_kl             | 0.00013158258 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2             |
|    cost_value_loss       | 5.71          |
|    cost_values           | 1.08          |
|    entropy               | -1.81         |
|    entropy_loss          | -1.81         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.9          |
|    n_updates             | 5340          |
|    policy_gradient_loss  | 0.000119      |
|    std                   | 0.599         |
|    value_loss            | 39.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0453401   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -793         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1584         |
|    total_timesteps       | 1097728      |
| train/                   |              |
|    approx_kl             | 0.0039501255 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 4.53         |
|    cost_values           | 1.33         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.62         |
|    n_updates             | 5350         |
|    policy_gradient_loss  | -0.000498    |
|    std                   | 0.6          |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8532366  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -788        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1619        |
|    total_timesteps       | 1099776     |
| train/                   |             |
|    approx_kl             | 0.008079781 |
|    clip_fraction         | 0.0414      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.24        |
|    cost_value_loss       | 0.046       |
|    cost_values           | 1.36        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 5360        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.603       |
|    value_loss            | 8.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7962403   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1654         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0025016929 |
|    clip_fraction         | 0.00562      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 2.32         |
|    cost_values           | 1.05         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.4         |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.000964    |
|    std                   | 0.603        |
|    value_loss            | 47.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7432034  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -779        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1688        |
|    total_timesteps       | 1103872     |
| train/                   |             |
|    approx_kl             | 0.002105262 |
|    clip_fraction         | 0.000391    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 9.49        |
|    cost_values           | 1.08        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.7        |
|    n_updates             | 5380        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.603       |
|    value_loss            | 30.4        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.4064035 |
| rollout/           |            |
|    ep_len_mean     | 966        |
|    ep_rew_mean     | -771       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1105920    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6184194   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1107968      |
| train/                   |              |
|    approx_kl             | 0.0025260039 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 8.5          |
|    cost_values           | 1.54         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.9         |
|    n_updates             | 5400         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.603        |
|    value_loss            | 40.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2366548  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1110016     |
| train/                   |             |
|    approx_kl             | 0.002534137 |
|    clip_fraction         | 0.000732    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.56        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 1.86        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.98        |
|    n_updates             | 5410        |
|    policy_gradient_loss  | -0.000949   |
|    std                   | 0.603       |
|    value_loss            | 8.35        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -0.5952466    |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -773          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 4             |
|    time_elapsed          | 128           |
|    total_timesteps       | 1112064       |
| train/                   |               |
|    approx_kl             | 0.00033307102 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.03          |
|    cost_value_loss       | 1.63          |
|    cost_values           | 1.91          |
|    entropy               | -1.82         |
|    entropy_loss          | -1.82         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.6          |
|    n_updates             | 5420          |
|    policy_gradient_loss  | -0.000157     |
|    std                   | 0.603         |
|    value_loss            | 29.2          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.97977877 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -771        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 1114112     |
| train/                   |             |
|    approx_kl             | 0.002614862 |
|    clip_fraction         | 0.00112     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.72        |
|    cost_value_loss       | 5.59        |
|    cost_values           | 1.91        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 5430        |
|    policy_gradient_loss  | -0.000344   |
|    std                   | 0.603       |
|    value_loss            | 15.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.58837414  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1116160      |
| train/                   |              |
|    approx_kl             | 0.0027454812 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 1.32         |
|    cost_values           | 2.09         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.01         |
|    n_updates             | 5440         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.602        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.9152316   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1118208      |
| train/                   |              |
|    approx_kl             | 0.0017781944 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 3.25         |
|    cost_values           | 1.93         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.87         |
|    n_updates             | 5450         |
|    policy_gradient_loss  | -5.98e-05    |
|    std                   | 0.602        |
|    value_loss            | 15.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.51        |
| reward                   | -0.8013346  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -784        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 267         |
|    total_timesteps       | 1120256     |
| train/                   |             |
|    approx_kl             | 0.002418065 |
|    clip_fraction         | 0.0193      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 0.801       |
|    cost_values           | 1.91        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 5460        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.601       |
|    value_loss            | 9.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.1          |
| reward                   | -0.8178765   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 1122304      |
| train/                   |              |
|    approx_kl             | 0.0044516344 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 0.155        |
|    cost_values           | 1.66         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 5470         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.6          |
|    value_loss            | 32.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7600793   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 1124352      |
| train/                   |              |
|    approx_kl             | 0.0054688505 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 5.02         |
|    cost_values           | 1.54         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 5480         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.6          |
|    value_loss            | 22.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6026898   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 1126400      |
| train/                   |              |
|    approx_kl             | 0.0037343232 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 6.32         |
|    cost_values           | 1.87         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.92         |
|    n_updates             | 5490         |
|    policy_gradient_loss  | -0.000285    |
|    std                   | 0.6          |
|    value_loss            | 7.94         |
-------------------------------------------
---------------------------------------------
| avg_speed                | 8              |
| cost                     | 1              |
| is_success               | 0              |
| max_speed                | 8              |
| reward                   | -0.70811146    |
| rollout/                 |                |
|    ep_len_mean           | 968            |
|    ep_rew_mean           | -776           |
| time/                    |                |
|    fps                   | 60             |
|    iterations            | 12             |
|    time_elapsed          | 406            |
|    total_timesteps       | 1128448        |
| train/                   |                |
|    approx_kl             | 0.000107160566 |
|    clip_fraction         | 0.0175         |
|    clip_range            | 0.2            |
|    cost_returns          | 2.36           |
|    cost_value_loss       | 3.42           |
|    cost_values           | 2.16           |
|    entropy               | -1.81          |
|    entropy_loss          | -1.81          |
|    explained_variance    | 1.19e-07       |
|    lagrangian_multiplier | 0              |
|    learning_rate         | 0.0003         |
|    loss                  | 5.79           |
|    n_updates             | 5500           |
|    policy_gradient_loss  | -0.000568      |
|    std                   | 0.598          |
|    value_loss            | 9.18           |
---------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72733456  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1130496      |
| train/                   |              |
|    approx_kl             | 0.0034761094 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.66         |
|    cost_value_loss       | 8.75         |
|    cost_values           | 2.27         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.81        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.5          |
|    n_updates             | 5510         |
|    policy_gradient_loss  | 0.000661     |
|    std                   | 0.598        |
|    value_loss            | 15.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.7399696   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 1132544      |
| train/                   |              |
|    approx_kl             | 0.0038081547 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 2.07         |
|    cost_values           | 2.17         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.15         |
|    n_updates             | 5520         |
|    policy_gradient_loss  | -0.000438    |
|    std                   | 0.597        |
|    value_loss            | 6.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2932194   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 510          |
|    total_timesteps       | 1134592      |
| train/                   |              |
|    approx_kl             | 0.0015256769 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 1.99         |
|    cost_values           | 1.99         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 5530         |
|    policy_gradient_loss  | 0.000696     |
|    std                   | 0.596        |
|    value_loss            | 33.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9567125  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -776        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 544         |
|    total_timesteps       | 1136640     |
| train/                   |             |
|    approx_kl             | 0.004596308 |
|    clip_fraction         | 0.0435      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 1.51        |
|    cost_values           | 1.84        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.45        |
|    n_updates             | 5540        |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 0.595       |
|    value_loss            | 17          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7917808  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -781        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 578         |
|    total_timesteps       | 1138688     |
| train/                   |             |
|    approx_kl             | 0.008926675 |
|    clip_fraction         | 0.0382      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 1.05        |
|    cost_values           | 1.76        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 5550        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.595       |
|    value_loss            | 18.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.91464347 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -784        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 612         |
|    total_timesteps       | 1140736     |
| train/                   |             |
|    approx_kl             | 0.005454955 |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.53        |
|    cost_value_loss       | 0.755       |
|    cost_values           | 1.51        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 5560        |
|    policy_gradient_loss  | -3.77e-06   |
|    std                   | 0.594       |
|    value_loss            | 40.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9347023  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 647         |
|    total_timesteps       | 1142784     |
| train/                   |             |
|    approx_kl             | 0.003927923 |
|    clip_fraction         | 0.00342     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 0.0275      |
|    cost_values           | 1.2         |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.27        |
|    n_updates             | 5570        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.594       |
|    value_loss            | 9.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1339532   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -793         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 1144832      |
| train/                   |              |
|    approx_kl             | 0.0028754978 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 2.89         |
|    cost_values           | 1            |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 5580         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.594        |
|    value_loss            | 40           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5663771   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -802         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 716          |
|    total_timesteps       | 1146880      |
| train/                   |              |
|    approx_kl             | 0.0038286312 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 4.13         |
|    cost_values           | 1.14         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.92         |
|    n_updates             | 5590         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.594        |
|    value_loss            | 9.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.24         |
| reward                   | -0.7906419   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 751          |
|    total_timesteps       | 1148928      |
| train/                   |              |
|    approx_kl             | 0.0015148342 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.152        |
|    cost_values           | 1.31         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 5600         |
|    policy_gradient_loss  | -0.00058     |
|    std                   | 0.594        |
|    value_loss            | 34.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5372592   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 785          |
|    total_timesteps       | 1150976      |
| train/                   |              |
|    approx_kl             | 0.0012725103 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 7.01         |
|    cost_values           | 1.1          |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.6         |
|    n_updates             | 5610         |
|    policy_gradient_loss  | -0.000768    |
|    std                   | 0.594        |
|    value_loss            | 59.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.3394554 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -802       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 24         |
|    time_elapsed          | 819        |
|    total_timesteps       | 1153024    |
| train/                   |            |
|    approx_kl             | 0.00288291 |
|    clip_fraction         | 0.00127    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.884      |
|    cost_value_loss       | 0.0205     |
|    cost_values           | 0.987      |
|    entropy               | -1.79      |
|    entropy_loss          | -1.79      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.36       |
|    n_updates             | 5620       |
|    policy_gradient_loss  | -0.000561  |
|    std                   | 0.594      |
|    value_loss            | 15.9       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.69910735 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -805        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 853         |
|    total_timesteps       | 1155072     |
| train/                   |             |
|    approx_kl             | 0.003976833 |
|    clip_fraction         | 0.0041      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 1.43        |
|    cost_values           | 0.933       |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.6        |
|    n_updates             | 5630        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.594       |
|    value_loss            | 56.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.73060805 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -808        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 888         |
|    total_timesteps       | 1157120     |
| train/                   |             |
|    approx_kl             | 0.002064052 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 2.16        |
|    cost_values           | 1.14        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.79       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 5640        |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.596       |
|    value_loss            | 20.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.83867484  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 923          |
|    total_timesteps       | 1159168      |
| train/                   |              |
|    approx_kl             | 0.0027824775 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 0.853        |
|    cost_values           | 1.23         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 5650         |
|    policy_gradient_loss  | 0.000134     |
|    std                   | 0.597        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.94368076  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 1161216      |
| train/                   |              |
|    approx_kl             | 0.0012590913 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 1.17         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.34         |
|    n_updates             | 5660         |
|    policy_gradient_loss  | 0.000447     |
|    std                   | 0.597        |
|    value_loss            | 14.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.9330803    |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -807          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 29            |
|    time_elapsed          | 992           |
|    total_timesteps       | 1163264       |
| train/                   |               |
|    approx_kl             | 0.00088129897 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.05          |
|    cost_value_loss       | 0.516         |
|    cost_values           | 1.02          |
|    entropy               | -1.8          |
|    entropy_loss          | -1.8          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.27          |
|    n_updates             | 5670          |
|    policy_gradient_loss  | -9.4e-05      |
|    std                   | 0.597         |
|    value_loss            | 8.3           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.95239663  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -811         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 1165312      |
| train/                   |              |
|    approx_kl             | 0.0044007446 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.987        |
|    cost_values           | 0.999        |
|    entropy               | -1.79        |
|    entropy_loss          | -1.8         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 5680         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.594        |
|    value_loss            | 16.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.69388175  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 1167360      |
| train/                   |              |
|    approx_kl             | 0.0057143522 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.963        |
|    cost_values           | 1            |
|    entropy               | -1.78        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.61         |
|    n_updates             | 5690         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.592        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.7255798  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -812        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1097        |
|    total_timesteps       | 1169408     |
| train/                   |             |
|    approx_kl             | 0.007339925 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.934       |
|    cost_value_loss       | 0.352       |
|    cost_values           | 0.949       |
|    entropy               | -1.79       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.39        |
|    n_updates             | 5700        |
|    policy_gradient_loss  | -0.00043    |
|    std                   | 0.593       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.98         |
| reward                   | -0.95332444  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -812         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1132         |
|    total_timesteps       | 1171456      |
| train/                   |              |
|    approx_kl             | 0.0022449917 |
|    clip_fraction         | 0.0706       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.998        |
|    cost_value_loss       | 1.25         |
|    cost_values           | 0.958        |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.26         |
|    n_updates             | 5710         |
|    policy_gradient_loss  | -0.000228    |
|    std                   | 0.593        |
|    value_loss            | 8.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.2          |
| reward                   | -0.6974047   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1166         |
|    total_timesteps       | 1173504      |
| train/                   |              |
|    approx_kl             | 0.0012626501 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 4.01         |
|    cost_values           | 1.19         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 5720         |
|    policy_gradient_loss  | -0.000597    |
|    std                   | 0.592        |
|    value_loss            | 21.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.8687626   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1201         |
|    total_timesteps       | 1175552      |
| train/                   |              |
|    approx_kl             | 0.0035731697 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 0.0625       |
|    cost_values           | 1.39         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.79        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.57         |
|    n_updates             | 5730         |
|    policy_gradient_loss  | -0.00067     |
|    std                   | 0.592        |
|    value_loss            | 17.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6290817   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1235         |
|    total_timesteps       | 1177600      |
| train/                   |              |
|    approx_kl             | 0.0047407905 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 1.78         |
|    cost_values           | 1.07         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.57         |
|    n_updates             | 5740         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.592        |
|    value_loss            | 13.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.99500674   |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -821          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 37            |
|    time_elapsed          | 1269          |
|    total_timesteps       | 1179648       |
| train/                   |               |
|    approx_kl             | 0.00049311016 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.886         |
|    cost_value_loss       | 0.244         |
|    cost_values           | 0.976         |
|    entropy               | -1.79         |
|    entropy_loss          | -1.78         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.94          |
|    n_updates             | 5750          |
|    policy_gradient_loss  | -9.5e-05      |
|    std                   | 0.592         |
|    value_loss            | 15.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.9867219  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -828        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1304        |
|    total_timesteps       | 1181696     |
| train/                   |             |
|    approx_kl             | 0.002517996 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 2.06        |
|    cost_values           | 1.16        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.5         |
|    n_updates             | 5760        |
|    policy_gradient_loss  | -0.000501   |
|    std                   | 0.592       |
|    value_loss            | 12.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.30297214 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -827        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1338        |
|    total_timesteps       | 1183744     |
| train/                   |             |
|    approx_kl             | 0.003797636 |
|    clip_fraction         | 0.0205      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 1.73        |
|    cost_values           | 1.39        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 5770        |
|    policy_gradient_loss  | 0.000305    |
|    std                   | 0.593       |
|    value_loss            | 6.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0538847   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -826         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1373         |
|    total_timesteps       | 1185792      |
| train/                   |              |
|    approx_kl             | 0.0027259206 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 1.36         |
|    cost_values           | 1.56         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.84         |
|    n_updates             | 5780         |
|    policy_gradient_loss  | -0.000622    |
|    std                   | 0.593        |
|    value_loss            | 11.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.05          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.05          |
| reward                   | -0.7063586    |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -825          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1407          |
|    total_timesteps       | 1187840       |
| train/                   |               |
|    approx_kl             | 0.00073007005 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.57          |
|    cost_value_loss       | 1.76          |
|    cost_values           | 1.37          |
|    entropy               | -1.79         |
|    entropy_loss          | -1.79         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.7          |
|    n_updates             | 5790          |
|    policy_gradient_loss  | -0.000227     |
|    std                   | 0.593         |
|    value_loss            | 25.9          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.2135597  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -828        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1441        |
|    total_timesteps       | 1189888     |
| train/                   |             |
|    approx_kl             | 0.003357891 |
|    clip_fraction         | 0.00913     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.024       |
|    cost_values           | 1.07        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.91        |
|    n_updates             | 5800        |
|    policy_gradient_loss  | -0.000473   |
|    std                   | 0.591       |
|    value_loss            | 7.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.60096425  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1476         |
|    total_timesteps       | 1191936      |
| train/                   |              |
|    approx_kl             | 0.0034226698 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 3.44         |
|    cost_values           | 1.18         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 5810         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.589        |
|    value_loss            | 20           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.679026   |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -844        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1511        |
|    total_timesteps       | 1193984     |
| train/                   |             |
|    approx_kl             | 0.004873121 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 0.0682      |
|    cost_values           | 1.28        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.08        |
|    n_updates             | 5820        |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.588       |
|    value_loss            | 14.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1585604   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -843         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1546         |
|    total_timesteps       | 1196032      |
| train/                   |              |
|    approx_kl             | 0.0015341365 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 1.02         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 5830         |
|    policy_gradient_loss  | 0.000984     |
|    std                   | 0.588        |
|    value_loss            | 52           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.639268    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -860         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1581         |
|    total_timesteps       | 1198080      |
| train/                   |              |
|    approx_kl             | 0.0042593945 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 4.4          |
|    cost_values           | 1.18         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 5840         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.587        |
|    value_loss            | 16.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.9099168   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -860         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1616         |
|    total_timesteps       | 1200128      |
| train/                   |              |
|    approx_kl             | 0.0029467351 |
|    clip_fraction         | 0.00337      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.0728       |
|    cost_values           | 1.41         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.3         |
|    n_updates             | 5850         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.587        |
|    value_loss            | 54.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.93891853  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -869         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1651         |
|    total_timesteps       | 1202176      |
| train/                   |              |
|    approx_kl             | 0.0028255759 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.455        |
|    cost_values           | 1.11         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.5         |
|    n_updates             | 5860         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.587        |
|    value_loss            | 86.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -1.0623183   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -873         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1686         |
|    total_timesteps       | 1204224      |
| train/                   |              |
|    approx_kl             | 0.0019175352 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 3.09         |
|    cost_values           | 1.12         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 5870         |
|    policy_gradient_loss  | 8.27e-07     |
|    std                   | 0.586        |
|    value_loss            | 25.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.83       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.83       |
| reward             | -0.8732887 |
| rollout/           |            |
|    ep_len_mean     | 985        |
|    ep_rew_mean     | -880       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1206272    |
-----------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.22418176 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -873        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 1208320     |
| train/                   |             |
|    approx_kl             | 0.003818199 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 1.23        |
|    cost_values           | 1.52        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.56        |
|    n_updates             | 5890        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.583       |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.855721    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -872         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1210368      |
| train/                   |              |
|    approx_kl             | 0.0045542843 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 3.55         |
|    cost_values           | 1.48         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.6         |
|    n_updates             | 5900         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.582        |
|    value_loss            | 54.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.968513   |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -880        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 1212416     |
| train/                   |             |
|    approx_kl             | 0.004128419 |
|    clip_fraction         | 0.00532     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.65        |
|    cost_value_loss       | 8.13        |
|    cost_values           | 1.49        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 5910        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.582       |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.63495094  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 1214464      |
| train/                   |              |
|    approx_kl             | 0.0004024798 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 0.54         |
|    cost_values           | 1.46         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.2         |
|    n_updates             | 5920         |
|    policy_gradient_loss  | -0.000324    |
|    std                   | 0.582        |
|    value_loss            | 64.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.332814    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1216512      |
| train/                   |              |
|    approx_kl             | 0.0058254534 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.0328       |
|    cost_values           | 1.13         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.3         |
|    n_updates             | 5930         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.582        |
|    value_loss            | 70.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.87892234  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1218560      |
| train/                   |              |
|    approx_kl             | 0.0056049363 |
|    clip_fraction         | 0.074        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.871        |
|    cost_value_loss       | 0.108        |
|    cost_values           | 0.882        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 5940         |
|    policy_gradient_loss  | -0.00569     |
|    std                   | 0.576        |
|    value_loss            | 23.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.12398     |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 1220608      |
| train/                   |              |
|    approx_kl             | 0.0038188559 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.718        |
|    cost_value_loss       | 0.0101       |
|    cost_values           | 0.745        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 5950         |
|    policy_gradient_loss  | -0.000678    |
|    std                   | 0.575        |
|    value_loss            | 11.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.9188469  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -883        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 301         |
|    total_timesteps       | 1222656     |
| train/                   |             |
|    approx_kl             | 0.003741957 |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.649       |
|    cost_value_loss       | 0.0789      |
|    cost_values           | 0.667       |
|    entropy               | -1.72       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 5960        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.574       |
|    value_loss            | 9.98        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.74          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.74          |
| reward                   | -0.77217823   |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -885          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 10            |
|    time_elapsed          | 336           |
|    total_timesteps       | 1224704       |
| train/                   |               |
|    approx_kl             | 0.00072883273 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.542         |
|    cost_value_loss       | 0.0205        |
|    cost_values           | 0.66          |
|    entropy               | -1.72         |
|    entropy_loss          | -1.72         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 32.9          |
|    n_updates             | 5970          |
|    policy_gradient_loss  | -0.000497     |
|    std                   | 0.574         |
|    value_loss            | 73            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54756284  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 1226752      |
| train/                   |              |
|    approx_kl             | 0.0057797194 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 0.74         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.6          |
|    n_updates             | 5980         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.574        |
|    value_loss            | 19.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.1804848    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -899          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 12            |
|    time_elapsed          | 405           |
|    total_timesteps       | 1228800       |
| train/                   |               |
|    approx_kl             | 0.00033518494 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.07          |
|    cost_value_loss       | 1.82          |
|    cost_values           | 0.921         |
|    entropy               | -1.72         |
|    entropy_loss          | -1.72         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 43.1          |
|    n_updates             | 5990          |
|    policy_gradient_loss  | -0.000238     |
|    std                   | 0.574         |
|    value_loss            | 88.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9080518   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1230848      |
| train/                   |              |
|    approx_kl             | 0.0013461255 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 3.38         |
|    cost_values           | 1.03         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.4          |
|    n_updates             | 6000         |
|    policy_gradient_loss  | -0.00045     |
|    std                   | 0.574        |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5795136   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1232896      |
| train/                   |              |
|    approx_kl             | 0.0015216945 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.11         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 6010         |
|    policy_gradient_loss  | -0.00026     |
|    std                   | 0.574        |
|    value_loss            | 26           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.003367    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1234944      |
| train/                   |              |
|    approx_kl             | 0.0042870976 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 2.45         |
|    cost_values           | 1.2          |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 6020         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.573        |
|    value_loss            | 22.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78937745  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -898         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 1236992      |
| train/                   |              |
|    approx_kl             | 0.0034997775 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.171        |
|    cost_values           | 1.07         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.82         |
|    n_updates             | 6030         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.569        |
|    value_loss            | 9.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6960312   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -898         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 1239040      |
| train/                   |              |
|    approx_kl             | 0.0020835847 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.619        |
|    cost_values           | 1            |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 6040         |
|    policy_gradient_loss  | -0.000439    |
|    std                   | 0.566        |
|    value_loss            | 28.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.0424542  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -892        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 611         |
|    total_timesteps       | 1241088     |
| train/                   |             |
|    approx_kl             | 0.001369661 |
|    clip_fraction         | 0.0165      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 2.25        |
|    cost_values           | 1.15        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 6050        |
|    policy_gradient_loss  | -0.000403   |
|    std                   | 0.566       |
|    value_loss            | 20.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.9963386   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -889         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 1243136      |
| train/                   |              |
|    approx_kl             | 0.0050757118 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.0276       |
|    cost_values           | 1.12         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.69         |
|    n_updates             | 6060         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.565        |
|    value_loss            | 3.93         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.86          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.86          |
| reward                   | -1.4033372    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -887          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 20            |
|    time_elapsed          | 680           |
|    total_timesteps       | 1245184       |
| train/                   |               |
|    approx_kl             | 0.00079332537 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.03          |
|    cost_value_loss       | 5.1           |
|    cost_values           | 1.04          |
|    entropy               | -1.69         |
|    entropy_loss          | -1.69         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.1          |
|    n_updates             | 6070          |
|    policy_gradient_loss  | -0.000422     |
|    std                   | 0.565         |
|    value_loss            | 27.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1856333  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -885        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 715         |
|    total_timesteps       | 1247232     |
| train/                   |             |
|    approx_kl             | 0.005900724 |
|    clip_fraction         | 0.0145      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 3.26        |
|    cost_values           | 1.09        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 6080        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.565       |
|    value_loss            | 21.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.76021254  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -894         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 1249280      |
| train/                   |              |
|    approx_kl             | 0.0012013366 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 2.3          |
|    cost_values           | 1.14         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.4         |
|    n_updates             | 6090         |
|    policy_gradient_loss  | -2.45e-05    |
|    std                   | 0.565        |
|    value_loss            | 64           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -1.3234895    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -896          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 23            |
|    time_elapsed          | 783           |
|    total_timesteps       | 1251328       |
| train/                   |               |
|    approx_kl             | 0.00051833177 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.03          |
|    cost_value_loss       | 0.0588        |
|    cost_values           | 1.11          |
|    entropy               | -1.69         |
|    entropy_loss          | -1.69         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 16.7          |
|    n_updates             | 6100          |
|    policy_gradient_loss  | -3.14e-05     |
|    std                   | 0.565         |
|    value_loss            | 35            |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.6174599  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -899        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 818         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.005275664 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.786       |
|    cost_value_loss       | 0.0114      |
|    cost_values           | 0.842       |
|    entropy               | -1.7        |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.22        |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.566       |
|    value_loss            | 8.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.6477794   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -898         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 1255424      |
| train/                   |              |
|    approx_kl             | 0.0041733244 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 4.08         |
|    cost_values           | 0.942        |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 6120         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.566        |
|    value_loss            | 17.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.98268896 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -899        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 887         |
|    total_timesteps       | 1257472     |
| train/                   |             |
|    approx_kl             | 0.004202923 |
|    clip_fraction         | 0.00483     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.08        |
|    cost_values           | 1.03        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.28        |
|    n_updates             | 6130        |
|    policy_gradient_loss  | -0.000885   |
|    std                   | 0.566       |
|    value_loss            | 14.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.441        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.441        |
| reward                   | -0.68391454  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -896         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 922          |
|    total_timesteps       | 1259520      |
| train/                   |              |
|    approx_kl             | 0.0002081421 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 7.08         |
|    cost_values           | 1.17         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.15         |
|    n_updates             | 6140         |
|    policy_gradient_loss  | -0.000133    |
|    std                   | 0.566        |
|    value_loss            | 7.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.59         |
| reward                   | -0.6855423   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1261568      |
| train/                   |              |
|    approx_kl             | 0.0021922817 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 4.08         |
|    cost_values           | 1.59         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 6150         |
|    policy_gradient_loss  | -0.000431    |
|    std                   | 0.566        |
|    value_loss            | 34.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8008883  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 990         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.005571735 |
|    clip_fraction         | 0.0197      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 3.93        |
|    cost_values           | 2.07        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 0.568       |
|    value_loss            | 25.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.90756977  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 1265664      |
| train/                   |              |
|    approx_kl             | 0.0042435583 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 0.751        |
|    cost_values           | 2.21         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.11         |
|    n_updates             | 6170         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.567        |
|    value_loss            | 7.87         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.9513837 |
| rollout/                 |            |
|    ep_len_mean           | 971        |
|    ep_rew_mean           | -899       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 31         |
|    time_elapsed          | 1059       |
|    total_timesteps       | 1267712    |
| train/                   |            |
|    approx_kl             | 0.00280238 |
|    clip_fraction         | 0.00439    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.96       |
|    cost_value_loss       | 1.3        |
|    cost_values           | 1.88       |
|    entropy               | -1.7       |
|    entropy_loss          | -1.7       |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.22       |
|    n_updates             | 6180       |
|    policy_gradient_loss  | -0.000606  |
|    std                   | 0.567      |
|    value_loss            | 16.2       |
-----------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -0.66835177   |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -900          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 32            |
|    time_elapsed          | 1094          |
|    total_timesteps       | 1269760       |
| train/                   |               |
|    approx_kl             | 0.00013485368 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.63          |
|    cost_value_loss       | 0.584         |
|    cost_values           | 1.61          |
|    entropy               | -1.7          |
|    entropy_loss          | -1.7          |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.06          |
|    n_updates             | 6190          |
|    policy_gradient_loss  | -1.93e-05     |
|    std                   | 0.567         |
|    value_loss            | 15.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.63589305  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -896         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1128         |
|    total_timesteps       | 1271808      |
| train/                   |              |
|    approx_kl             | 0.0068544587 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 2.72         |
|    cost_values           | 1.42         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.14         |
|    n_updates             | 6200         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.566        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73231816  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1163         |
|    total_timesteps       | 1273856      |
| train/                   |              |
|    approx_kl             | 0.0003384385 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 5.52         |
|    cost_values           | 1.39         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 6210         |
|    policy_gradient_loss  | -9.85e-05    |
|    std                   | 0.566        |
|    value_loss            | 18.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -1.2828414    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -896          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 35            |
|    time_elapsed          | 1197          |
|    total_timesteps       | 1275904       |
| train/                   |               |
|    approx_kl             | 0.00032000383 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.63          |
|    cost_value_loss       | 2.2           |
|    cost_values           | 1.39          |
|    entropy               | -1.69         |
|    entropy_loss          | -1.7          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.52          |
|    n_updates             | 6220          |
|    policy_gradient_loss  | 0.000269      |
|    std                   | 0.566         |
|    value_loss            | 15.4          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.072488   |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 1277952     |
| train/                   |             |
|    approx_kl             | 0.004373361 |
|    clip_fraction         | 0.00361     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 2.72        |
|    cost_values           | 1.52        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.69       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.61        |
|    n_updates             | 6230        |
|    policy_gradient_loss  | -0.000413   |
|    std                   | 0.566       |
|    value_loss            | 8.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.331155    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -903         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1265         |
|    total_timesteps       | 1280000      |
| train/                   |              |
|    approx_kl             | 0.0010746127 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 0.0377       |
|    cost_values           | 1.29         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.6         |
|    n_updates             | 6240         |
|    policy_gradient_loss  | 3.93e-05     |
|    std                   | 0.565        |
|    value_loss            | 44.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.6182382    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -905          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1300          |
|    total_timesteps       | 1282048       |
| train/                   |               |
|    approx_kl             | 6.6120934e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.905         |
|    cost_value_loss       | 0.0179        |
|    cost_values           | 0.991         |
|    entropy               | -1.69         |
|    entropy_loss          | -1.69         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 14.3          |
|    n_updates             | 6250          |
|    policy_gradient_loss  | 9.24e-05      |
|    std                   | 0.565         |
|    value_loss            | 33.2          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.44879487 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -898        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1334        |
|    total_timesteps       | 1284096     |
| train/                   |             |
|    approx_kl             | 0.004603448 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.981       |
|    cost_value_loss       | 1.09        |
|    cost_values           | 0.937       |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 6260        |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 0.564       |
|    value_loss            | 26          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4297589  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1369        |
|    total_timesteps       | 1286144     |
| train/                   |             |
|    approx_kl             | 0.002697221 |
|    clip_fraction         | 0.000635    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.98        |
|    cost_values           | 0.973       |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.51        |
|    n_updates             | 6270        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.564       |
|    value_loss            | 18.7        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.2834071    |
| rollout/                 |               |
|    ep_len_mean           | 969           |
|    ep_rew_mean           | -889          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1403          |
|    total_timesteps       | 1288192       |
| train/                   |               |
|    approx_kl             | 0.00040107823 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.32          |
|    cost_value_loss       | 7.39          |
|    cost_values           | 1.08          |
|    entropy               | -1.69         |
|    entropy_loss          | -1.69         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.7          |
|    n_updates             | 6280          |
|    policy_gradient_loss  | -4.06e-05     |
|    std                   | 0.563         |
|    value_loss            | 17.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.74510664  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1437         |
|    total_timesteps       | 1290240      |
| train/                   |              |
|    approx_kl             | 0.0038975594 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 1.39         |
|    cost_values           | 1.23         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.2         |
|    n_updates             | 6290         |
|    policy_gradient_loss  | -0.000227    |
|    std                   | 0.563        |
|    value_loss            | 65.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.85148454  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -890         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1472         |
|    total_timesteps       | 1292288      |
| train/                   |              |
|    approx_kl             | 0.0076975888 |
|    clip_fraction         | 0.0703       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 1.45         |
|    cost_values           | 1.31         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.65         |
|    n_updates             | 6300         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.563        |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.76602507  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -887         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1507         |
|    total_timesteps       | 1294336      |
| train/                   |              |
|    approx_kl             | 0.0014216625 |
|    clip_fraction         | 0.0571       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.78         |
|    cost_value_loss       | 8.78         |
|    cost_values           | 1.56         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.14         |
|    n_updates             | 6310         |
|    policy_gradient_loss  | 0.000568     |
|    std                   | 0.563        |
|    value_loss            | 6.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.3263676   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -868         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1541         |
|    total_timesteps       | 1296384      |
| train/                   |              |
|    approx_kl             | 0.0026982087 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 0.39         |
|    cost_values           | 1.76         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 6320         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.563        |
|    value_loss            | 10.7         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.9599547 |
| rollout/                 |            |
|    ep_len_mean           | 966        |
|    ep_rew_mean           | -871       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 46         |
|    time_elapsed          | 1576       |
|    total_timesteps       | 1298432    |
| train/                   |            |
|    approx_kl             | 0.00525335 |
|    clip_fraction         | 0.0147     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.37       |
|    cost_value_loss       | 0.236      |
|    cost_values           | 1.42       |
|    entropy               | -1.68      |
|    entropy_loss          | -1.68      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 33.1       |
|    n_updates             | 6330       |
|    policy_gradient_loss  | -0.00172   |
|    std                   | 0.562      |
|    value_loss            | 60.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5599256  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -875        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1611        |
|    total_timesteps       | 1300480     |
| train/                   |             |
|    approx_kl             | 0.003129474 |
|    clip_fraction         | 0.0294      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 3.63        |
|    cost_values           | 1.33        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 36.6        |
|    n_updates             | 6340        |
|    policy_gradient_loss  | -0.000971   |
|    std                   | 0.561       |
|    value_loss            | 68.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1796755   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -870         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1645         |
|    total_timesteps       | 1302528      |
| train/                   |              |
|    approx_kl             | 0.0016143935 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 0.93         |
|    cost_values           | 1.44         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 6350         |
|    policy_gradient_loss  | -0.000217    |
|    std                   | 0.561        |
|    value_loss            | 24.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -1.0217298   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -876         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1679         |
|    total_timesteps       | 1304576      |
| train/                   |              |
|    approx_kl             | 0.0035515497 |
|    clip_fraction         | 0.00264      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 1.63         |
|    cost_values           | 1.21         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.9          |
|    n_updates             | 6360         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.56         |
|    value_loss            | 18.6         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.98529273 |
| rollout/           |             |
|    ep_len_mean     | 971         |
|    ep_rew_mean     | -882        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1306624     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7056345  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -879        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 1308672     |
| train/                   |             |
|    approx_kl             | 0.005091125 |
|    clip_fraction         | 0.0205      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 1.05        |
|    cost_values           | 0.949       |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 6380        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.56        |
|    value_loss            | 11.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.48092532  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -868         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0073588495 |
|    clip_fraction         | 0.0395       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.976        |
|    cost_value_loss       | 0.981        |
|    cost_values           | 0.984        |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 6390         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.558        |
|    value_loss            | 11.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.7377758  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -871        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 1312768     |
| train/                   |             |
|    approx_kl             | 0.000953563 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.77        |
|    cost_value_loss       | 4.73        |
|    cost_values           | 1.07        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 6400        |
|    policy_gradient_loss  | 1.47e-05    |
|    std                   | 0.559       |
|    value_loss            | 21.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9524718   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -870         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 1314816      |
| train/                   |              |
|    approx_kl             | 0.0043877973 |
|    clip_fraction         | 0.00381      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 2.38         |
|    cost_values           | 1.23         |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 6410         |
|    policy_gradient_loss  | -0.000225    |
|    std                   | 0.559        |
|    value_loss            | 7.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.83758044 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -872        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 196         |
|    total_timesteps       | 1316864     |
| train/                   |             |
|    approx_kl             | 0.004638195 |
|    clip_fraction         | 0.0384      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 1.22        |
|    cost_values           | 1.21        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 6420        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.558       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.4246529   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -873         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 1318912      |
| train/                   |              |
|    approx_kl             | 0.0022435347 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.0575       |
|    cost_values           | 1.23         |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 6430         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.558        |
|    value_loss            | 35.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3762276   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -866         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1320960      |
| train/                   |              |
|    approx_kl             | 0.0038294853 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.02         |
|    cost_values           | 1.04         |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.76         |
|    n_updates             | 6440         |
|    policy_gradient_loss  | -0.000639    |
|    std                   | 0.558        |
|    value_loss            | 17.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.62355775   |
| rollout/                 |               |
|    ep_len_mean           | 979           |
|    ep_rew_mean           | -872          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 9             |
|    time_elapsed          | 299           |
|    total_timesteps       | 1323008       |
| train/                   |               |
|    approx_kl             | 7.0259324e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.19          |
|    cost_value_loss       | 1.36          |
|    cost_values           | 1.03          |
|    entropy               | -1.67         |
|    entropy_loss          | -1.67         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.1          |
|    n_updates             | 6450          |
|    policy_gradient_loss  | 0.000194      |
|    std                   | 0.558         |
|    value_loss            | 35.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.5433146   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -866         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 1325056      |
| train/                   |              |
|    approx_kl             | 0.0028730673 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.793        |
|    cost_value_loss       | 0.0317       |
|    cost_values           | 0.954        |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.73         |
|    n_updates             | 6460         |
|    policy_gradient_loss  | -0.000912    |
|    std                   | 0.558        |
|    value_loss            | 22.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1242778  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -871        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 368         |
|    total_timesteps       | 1327104     |
| train/                   |             |
|    approx_kl             | 0.004887173 |
|    clip_fraction         | 0.0281      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.755       |
|    cost_values           | 0.969       |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 6470        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.558       |
|    value_loss            | 25.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.021095    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -868         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 1329152      |
| train/                   |              |
|    approx_kl             | 0.0032715285 |
|    clip_fraction         | 0.0415       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 1.86         |
|    cost_values           | 1.11         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 6480         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.557        |
|    value_loss            | 30.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.0830739   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -868         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 1331200      |
| train/                   |              |
|    approx_kl             | 0.0031844836 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 2.13         |
|    cost_values           | 1.3          |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.69         |
|    n_updates             | 6490         |
|    policy_gradient_loss  | -0.000876    |
|    std                   | 0.557        |
|    value_loss            | 7.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75525707  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -870         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 471          |
|    total_timesteps       | 1333248      |
| train/                   |              |
|    approx_kl             | 0.0044070324 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 0.7          |
|    cost_values           | 1.32         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 6500         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.556        |
|    value_loss            | 23.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1600837   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -862         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 1335296      |
| train/                   |              |
|    approx_kl             | 0.0030673689 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.986        |
|    cost_value_loss       | 0.027        |
|    cost_values           | 1.02         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.71         |
|    n_updates             | 6510         |
|    policy_gradient_loss  | -0.000341    |
|    std                   | 0.555        |
|    value_loss            | 5.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8363673   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -864         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 540          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0017968452 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 5.57         |
|    cost_values           | 1.04         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.9         |
|    n_updates             | 6520         |
|    policy_gradient_loss  | 0.00072      |
|    std                   | 0.554        |
|    value_loss            | 58           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1317716  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -864        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 1339392     |
| train/                   |             |
|    approx_kl             | 0.004311446 |
|    clip_fraction         | 0.00562     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.981       |
|    cost_value_loss       | 0.277       |
|    cost_values           | 0.984       |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 6530        |
|    policy_gradient_loss  | -0.000681   |
|    std                   | 0.554       |
|    value_loss            | 9.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42210644  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -870         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 609          |
|    total_timesteps       | 1341440      |
| train/                   |              |
|    approx_kl             | 0.0036428836 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.831        |
|    cost_value_loss       | 0.103        |
|    cost_values           | 0.919        |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 6540         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.555        |
|    value_loss            | 15.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.378491   |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -871        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 643         |
|    total_timesteps       | 1343488     |
| train/                   |             |
|    approx_kl             | 0.007239606 |
|    clip_fraction         | 0.0506      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 3.08        |
|    cost_values           | 1.12        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.66       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.3        |
|    n_updates             | 6550        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.554       |
|    value_loss            | 53.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.94617164  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -883         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 678          |
|    total_timesteps       | 1345536      |
| train/                   |              |
|    approx_kl             | 0.0023451971 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.107        |
|    cost_values           | 1.31         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 6560         |
|    policy_gradient_loss  | -0.000795    |
|    std                   | 0.553        |
|    value_loss            | 43.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0131865   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -883         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 713          |
|    total_timesteps       | 1347584      |
| train/                   |              |
|    approx_kl             | 0.0053914785 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.122        |
|    cost_values           | 1.01         |
|    entropy               | -1.64        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.44         |
|    n_updates             | 6570         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.549        |
|    value_loss            | 9.6          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.7643538 |
| rollout/                 |            |
|    ep_len_mean           | 986        |
|    ep_rew_mean           | -888       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 22         |
|    time_elapsed          | 747        |
|    total_timesteps       | 1349632    |
| train/                   |            |
|    approx_kl             | 0.00205514 |
|    clip_fraction         | 0.00635    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.884      |
|    cost_value_loss       | 0.128      |
|    cost_values           | 0.978      |
|    entropy               | -1.63      |
|    entropy_loss          | -1.63      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 22.3       |
|    n_updates             | 6580       |
|    policy_gradient_loss  | 0.00131    |
|    std                   | 0.548      |
|    value_loss            | 46.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3842905  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -892        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 782         |
|    total_timesteps       | 1351680     |
| train/                   |             |
|    approx_kl             | 0.002104205 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.835       |
|    cost_value_loss       | 0.171       |
|    cost_values           | 0.927       |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 6590        |
|    policy_gradient_loss  | -0.000561   |
|    std                   | 0.547       |
|    value_loss            | 27.5        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.3072003 |
| rollout/                 |            |
|    ep_len_mean           | 986        |
|    ep_rew_mean           | -896       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 24         |
|    time_elapsed          | 817        |
|    total_timesteps       | 1353728    |
| train/                   |            |
|    approx_kl             | 0.00538092 |
|    clip_fraction         | 0.0179     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.961      |
|    cost_value_loss       | 0.776      |
|    cost_values           | 0.904      |
|    entropy               | -1.63      |
|    entropy_loss          | -1.63      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 15.9       |
|    n_updates             | 6600       |
|    policy_gradient_loss  | -0.00208   |
|    std                   | 0.546      |
|    value_loss            | 34.8       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.6026407   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 1355776      |
| train/                   |              |
|    approx_kl             | 0.0056788586 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.933        |
|    cost_value_loss       | 0.495        |
|    cost_values           | 0.93         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.61        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 6610         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.538        |
|    value_loss            | 25.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.8614026   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 886          |
|    total_timesteps       | 1357824      |
| train/                   |              |
|    approx_kl             | 0.0005755437 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.68         |
|    cost_values           | 1.15         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 6620         |
|    policy_gradient_loss  | 0.000167     |
|    std                   | 0.535        |
|    value_loss            | 26.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -1.0288279  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -904        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 921         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.002372284 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 1.45        |
|    cost_values           | 1.2         |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.3        |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -5.88e-05   |
|    std                   | 0.534       |
|    value_loss            | 36.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1709619   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -908         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 955          |
|    total_timesteps       | 1361920      |
| train/                   |              |
|    approx_kl             | 0.0014231805 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.92         |
|    cost_value_loss       | 0.0192       |
|    cost_values           | 1            |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 6640         |
|    policy_gradient_loss  | -0.000486    |
|    std                   | 0.534        |
|    value_loss            | 54.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3719828   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -908         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 990          |
|    total_timesteps       | 1363968      |
| train/                   |              |
|    approx_kl             | 0.0025294533 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.854        |
|    cost_value_loss       | 0.217        |
|    cost_values           | 0.889        |
|    entropy               | -1.57        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.4         |
|    n_updates             | 6650         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.532        |
|    value_loss            | 34.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.86324906  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -916         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1024         |
|    total_timesteps       | 1366016      |
| train/                   |              |
|    approx_kl             | 0.0048563303 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.986        |
|    cost_value_loss       | 0.876        |
|    cost_values           | 0.928        |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 6660         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.53         |
|    value_loss            | 24.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.2965064   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -913         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1058         |
|    total_timesteps       | 1368064      |
| train/                   |              |
|    approx_kl             | 0.0017436771 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.834        |
|    cost_value_loss       | 0.0551       |
|    cost_values           | 0.946        |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 6670         |
|    policy_gradient_loss  | -7.05e-05    |
|    std                   | 0.53         |
|    value_loss            | 22.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.87        |
| reward                   | -0.9223073  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -920        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1094        |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.003635019 |
|    clip_fraction         | 0.0136      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.729       |
|    cost_value_loss       | 0.00917     |
|    cost_values           | 0.759       |
|    entropy               | -1.56       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.8         |
|    n_updates             | 6680        |
|    policy_gradient_loss  | -0.000989   |
|    std                   | 0.53        |
|    value_loss            | 15.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.08        |
| reward                   | -0.7784975  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -923        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 1372160     |
| train/                   |             |
|    approx_kl             | 0.007285366 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.872       |
|    cost_value_loss       | 0.909       |
|    cost_values           | 0.779       |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 6690        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.529       |
|    value_loss            | 20.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.12         |
| reward                   | -0.7899302   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1163         |
|    total_timesteps       | 1374208      |
| train/                   |              |
|    approx_kl             | 0.0069522075 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 4.37         |
|    cost_values           | 0.97         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 6700         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.529        |
|    value_loss            | 20           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8916238  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -924        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1197        |
|    total_timesteps       | 1376256     |
| train/                   |             |
|    approx_kl             | 0.005899952 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.885       |
|    cost_value_loss       | 0.0172      |
|    cost_values           | 0.966       |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 6710        |
|    policy_gradient_loss  | -0.00197    |
|    std                   | 0.528       |
|    value_loss            | 9.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -1.0419399   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1231         |
|    total_timesteps       | 1378304      |
| train/                   |              |
|    approx_kl             | 0.0045879213 |
|    clip_fraction         | 0.00596      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.736        |
|    cost_value_loss       | 0.0209       |
|    cost_values           | 0.841        |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.32         |
|    n_updates             | 6720         |
|    policy_gradient_loss  | -0.000842    |
|    std                   | 0.528        |
|    value_loss            | 9.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.63663405  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 1380352      |
| train/                   |              |
|    approx_kl             | 0.0037921676 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.687        |
|    cost_value_loss       | 0.0663       |
|    cost_values           | 0.697        |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.43         |
|    n_updates             | 6730         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.525        |
|    value_loss            | 4.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.59        |
| reward                   | -0.7541038  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -919        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1300        |
|    total_timesteps       | 1382400     |
| train/                   |             |
|    approx_kl             | 0.001082777 |
|    clip_fraction         | 0.00713     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 7.37        |
|    cost_values           | 1.07        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.4        |
|    n_updates             | 6740        |
|    policy_gradient_loss  | 0.00031     |
|    std                   | 0.524       |
|    value_loss            | 27.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.78128576  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -921         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1335         |
|    total_timesteps       | 1384448      |
| train/                   |              |
|    approx_kl             | 0.0013346929 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 1.09         |
|    cost_values           | 1.48         |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.3         |
|    n_updates             | 6750         |
|    policy_gradient_loss  | -0.000715    |
|    std                   | 0.524        |
|    value_loss            | 59.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.68          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.68          |
| reward                   | -0.94028914   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -923          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 40            |
|    time_elapsed          | 1369          |
|    total_timesteps       | 1386496       |
| train/                   |               |
|    approx_kl             | 0.00023999932 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.21          |
|    cost_value_loss       | 5.95          |
|    cost_values           | 1.26          |
|    entropy               | -1.54         |
|    entropy_loss          | -1.54         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.52          |
|    n_updates             | 6760          |
|    policy_gradient_loss  | 0.000138      |
|    std                   | 0.524         |
|    value_loss            | 11.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0325617   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1404         |
|    total_timesteps       | 1388544      |
| train/                   |              |
|    approx_kl             | 0.0044045793 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.0386       |
|    cost_values           | 1.08         |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.05         |
|    n_updates             | 6770         |
|    policy_gradient_loss  | -0.000991    |
|    std                   | 0.524        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.9256457   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1438         |
|    total_timesteps       | 1390592      |
| train/                   |              |
|    approx_kl             | 0.0039997296 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 2.05         |
|    cost_values           | 0.982        |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.92         |
|    n_updates             | 6780         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.524        |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.55566216  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1473         |
|    total_timesteps       | 1392640      |
| train/                   |              |
|    approx_kl             | 0.0048389565 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.81         |
|    cost_value_loss       | 0.0117       |
|    cost_values           | 0.847        |
|    entropy               | -1.53        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.28         |
|    n_updates             | 6790         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.521        |
|    value_loss            | 4.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2246954   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1509         |
|    total_timesteps       | 1394688      |
| train/                   |              |
|    approx_kl             | 0.0026505108 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.923        |
|    cost_value_loss       | 0.679        |
|    cost_values           | 0.889        |
|    entropy               | -1.52        |
|    entropy_loss          | -1.53        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 6800         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.517        |
|    value_loss            | 25.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -1.4210377   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1544         |
|    total_timesteps       | 1396736      |
| train/                   |              |
|    approx_kl             | 0.0062602125 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 3.07         |
|    cost_values           | 0.983        |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 6810         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.515        |
|    value_loss            | 55.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.315        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.315        |
| reward                   | -0.7765701   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -931         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1578         |
|    total_timesteps       | 1398784      |
| train/                   |              |
|    approx_kl             | 0.0041002147 |
|    clip_fraction         | 0.00503      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 7.64         |
|    cost_values           | 1.29         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 6820         |
|    policy_gradient_loss  | -0.000504    |
|    std                   | 0.515        |
|    value_loss            | 20.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.52         |
| reward                   | -0.83883953  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -930         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1613         |
|    total_timesteps       | 1400832      |
| train/                   |              |
|    approx_kl             | 0.0015473226 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 0.0977       |
|    cost_values           | 1.61         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 6830         |
|    policy_gradient_loss  | -0.000565    |
|    std                   | 0.514        |
|    value_loss            | 12.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 5.64          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.64          |
| reward                   | -0.81239206   |
| rollout/                 |               |
|    ep_len_mean           | 995           |
|    ep_rew_mean           | -927          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 48            |
|    time_elapsed          | 1648          |
|    total_timesteps       | 1402880       |
| train/                   |               |
|    approx_kl             | 0.00053394784 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.06          |
|    cost_value_loss       | 3.82          |
|    cost_values           | 1.28          |
|    entropy               | -1.51         |
|    entropy_loss          | -1.51         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.43          |
|    n_updates             | 6840          |
|    policy_gradient_loss  | -0.000167     |
|    std                   | 0.514         |
|    value_loss            | 15.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.98         |
| reward                   | -0.9901115   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -921         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1683         |
|    total_timesteps       | 1404928      |
| train/                   |              |
|    approx_kl             | 0.0022683642 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 9.94         |
|    cost_values           | 1.26         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.5          |
|    n_updates             | 6850         |
|    policy_gradient_loss  | -0.000907    |
|    std                   | 0.514        |
|    value_loss            | 11.3         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.59       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.59       |
| reward             | -0.7865751 |
| rollout/           |            |
|    ep_len_mean     | 995        |
|    ep_rew_mean     | -921       |
| time/              |            |
|    fps             | 81         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 1406976    |
-----------------------------------
-------------------------------------------
| avg_speed                | 2.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.45         |
| reward                   | -0.8711473   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -920         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 1409024      |
| train/                   |              |
|    approx_kl             | 0.0009843932 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 5.5          |
|    cost_values           | 1.1          |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.15         |
|    n_updates             | 6870         |
|    policy_gradient_loss  | -0.000404    |
|    std                   | 0.514        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.79         |
| reward                   | -0.8672974   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 1411072      |
| train/                   |              |
|    approx_kl             | 0.0039608153 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.16         |
|    cost_values           | 1.02         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.12         |
|    n_updates             | 6880         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.511        |
|    value_loss            | 11.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0713      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0713      |
| reward                   | -0.7736473  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -924        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 129         |
|    total_timesteps       | 1413120     |
| train/                   |             |
|    approx_kl             | 0.004889273 |
|    clip_fraction         | 0.0193      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 1.05        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.8        |
|    n_updates             | 6890        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.51        |
|    value_loss            | 21.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.73         |
| reward                   | -0.8007149   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1415168      |
| train/                   |              |
|    approx_kl             | 0.0050445935 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 0.791        |
|    cost_values           | 1.12         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.68         |
|    n_updates             | 6900         |
|    policy_gradient_loss  | -0.000138    |
|    std                   | 0.51         |
|    value_loss            | 4.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -1.0809656   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -915         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 1417216      |
| train/                   |              |
|    approx_kl             | 0.0038227122 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.957        |
|    cost_value_loss       | 0.0502       |
|    cost_values           | 1.02         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.88         |
|    n_updates             | 6910         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.51         |
|    value_loss            | 5.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.0256587   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 234          |
|    total_timesteps       | 1419264      |
| train/                   |              |
|    approx_kl             | 0.0025077225 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 1.07         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.67         |
|    n_updates             | 6920         |
|    policy_gradient_loss  | 0.00112      |
|    std                   | 0.51         |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.24079476  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -910         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 8            |
|    time_elapsed          | 268          |
|    total_timesteps       | 1421312      |
| train/                   |              |
|    approx_kl             | 0.0042622704 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.0619       |
|    cost_values           | 1.19         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.77         |
|    n_updates             | 6930         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.51         |
|    value_loss            | 3.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.50409025  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 1423360      |
| train/                   |              |
|    approx_kl             | 0.0031531618 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.1          |
|    cost_values           | 0.997        |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.52         |
|    n_updates             | 6940         |
|    policy_gradient_loss  | -0.000715    |
|    std                   | 0.511        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.45         |
| reward                   | -0.88339394  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 1425408      |
| train/                   |              |
|    approx_kl             | 0.0052422965 |
|    clip_fraction         | 0.0558       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.863        |
|    cost_value_loss       | 0.136        |
|    cost_values           | 0.913        |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 6950         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.511        |
|    value_loss            | 39           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.66         |
| reward                   | -0.8326637   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 1427456      |
| train/                   |              |
|    approx_kl             | 0.0023408388 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 3            |
|    cost_values           | 1            |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.51         |
|    n_updates             | 6960         |
|    policy_gradient_loss  | -0.000585    |
|    std                   | 0.509        |
|    value_loss            | 9.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.74         |
| reward                   | -0.8170743   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -891         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 407          |
|    total_timesteps       | 1429504      |
| train/                   |              |
|    approx_kl             | 0.0021842383 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 3.84         |
|    cost_values           | 1.22         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.58         |
|    n_updates             | 6970         |
|    policy_gradient_loss  | -0.000398    |
|    std                   | 0.509        |
|    value_loss            | 8.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.59         |
| reward                   | -0.83526456  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -889         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 441          |
|    total_timesteps       | 1431552      |
| train/                   |              |
|    approx_kl             | 0.0029687933 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 2.64         |
|    cost_values           | 1.67         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.47         |
|    n_updates             | 6980         |
|    policy_gradient_loss  | -0.000169    |
|    std                   | 0.509        |
|    value_loss            | 8.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.16         |
| reward                   | -0.8456288   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -890         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 1433600      |
| train/                   |              |
|    approx_kl             | 0.0066504185 |
|    clip_fraction         | 0.0513       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 3.41         |
|    cost_values           | 1.99         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.54         |
|    n_updates             | 6990         |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.511        |
|    value_loss            | 2            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.93023556  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -894         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 1435648      |
| train/                   |              |
|    approx_kl             | 0.0033709374 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 0.0879       |
|    cost_values           | 1.92         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.84         |
|    n_updates             | 7000         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.51         |
|    value_loss            | 6.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8811014  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -892        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 546         |
|    total_timesteps       | 1437696     |
| train/                   |             |
|    approx_kl             | 0.007654427 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 0.396       |
|    cost_values           | 1.45        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 7010        |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.509       |
|    value_loss            | 10          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -0.9491966   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -884         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 580          |
|    total_timesteps       | 1439744      |
| train/                   |              |
|    approx_kl             | 0.0031620688 |
|    clip_fraction         | 0.0061       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 5.02         |
|    cost_values           | 1.45         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 7020         |
|    policy_gradient_loss  | -0.000545    |
|    std                   | 0.509        |
|    value_loss            | 19.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.62817955  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -885         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 614          |
|    total_timesteps       | 1441792      |
| train/                   |              |
|    approx_kl             | 0.0022459957 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 1.72         |
|    cost_values           | 1.72         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 7030         |
|    policy_gradient_loss  | 7.52e-06     |
|    std                   | 0.508        |
|    value_loss            | 6.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -1.0400636  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -874        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 649         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.005051175 |
|    clip_fraction         | 0.0257      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.83        |
|    cost_value_loss       | 1.04        |
|    cost_values           | 1.72        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 7040        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.508       |
|    value_loss            | 7.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.9632639  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -876        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 684         |
|    total_timesteps       | 1445888     |
| train/                   |             |
|    approx_kl             | 0.005618724 |
|    clip_fraction         | 0.00811     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 3.95        |
|    cost_values           | 1.72        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.85        |
|    n_updates             | 7050        |
|    policy_gradient_loss  | -0.000688   |
|    std                   | 0.508       |
|    value_loss            | 15.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.91          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 7.91          |
| reward                   | -0.51808167   |
| rollout/                 |               |
|    ep_len_mean           | 993           |
|    ep_rew_mean           | -868          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 21            |
|    time_elapsed          | 718           |
|    total_timesteps       | 1447936       |
| train/                   |               |
|    approx_kl             | 0.00055745745 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.55          |
|    cost_value_loss       | 0.234         |
|    cost_values           | 1.73          |
|    entropy               | -1.48         |
|    entropy_loss          | -1.48         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.06          |
|    n_updates             | 7060          |
|    policy_gradient_loss  | -0.000601     |
|    std                   | 0.508         |
|    value_loss            | 25.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7745051  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -860        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 752         |
|    total_timesteps       | 1449984     |
| train/                   |             |
|    approx_kl             | 0.008642167 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 1.14        |
|    cost_values           | 1.45        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.33        |
|    n_updates             | 7070        |
|    policy_gradient_loss  | -0.00241    |
|    std                   | 0.508       |
|    value_loss            | 7.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7802868  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -851        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 787         |
|    total_timesteps       | 1452032     |
| train/                   |             |
|    approx_kl             | 0.005232039 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 0.613       |
|    cost_values           | 1.31        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.21        |
|    n_updates             | 7080        |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.508       |
|    value_loss            | 16.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.754462   |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -849        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 821         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.004170725 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.65        |
|    cost_value_loss       | 7.82        |
|    cost_values           | 1.26        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.9         |
|    n_updates             | 7090        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.508       |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.8656707   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -844         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 856          |
|    total_timesteps       | 1456128      |
| train/                   |              |
|    approx_kl             | 0.0037410485 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 2.25         |
|    cost_values           | 1.53         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 7100         |
|    policy_gradient_loss  | -0.000793    |
|    std                   | 0.508        |
|    value_loss            | 15.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3803681   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -846         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 890          |
|    total_timesteps       | 1458176      |
| train/                   |              |
|    approx_kl             | 0.0031786081 |
|    clip_fraction         | 0.00332      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 1.67         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.06         |
|    n_updates             | 7110         |
|    policy_gradient_loss  | -0.000858    |
|    std                   | 0.509        |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -1.4284956  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -841        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 924         |
|    total_timesteps       | 1460224     |
| train/                   |             |
|    approx_kl             | 0.004345527 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.07        |
|    cost_value_loss       | 3.43        |
|    cost_values           | 1.56        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 7120        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.508       |
|    value_loss            | 30.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.97          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.97          |
| reward                   | -1.1032203    |
| rollout/                 |               |
|    ep_len_mean           | 993           |
|    ep_rew_mean           | -839          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 28            |
|    time_elapsed          | 959           |
|    total_timesteps       | 1462272       |
| train/                   |               |
|    approx_kl             | 0.00039956413 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.51          |
|    cost_value_loss       | 0.567         |
|    cost_values           | 1.52          |
|    entropy               | -1.48         |
|    entropy_loss          | -1.48         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.1          |
|    n_updates             | 7130          |
|    policy_gradient_loss  | 1.83e-05      |
|    std                   | 0.508         |
|    value_loss            | 33.5          |
--------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -1.0573939 |
| rollout/                 |            |
|    ep_len_mean           | 993        |
|    ep_rew_mean           | -839       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 29         |
|    time_elapsed          | 993        |
|    total_timesteps       | 1464320    |
| train/                   |            |
|    approx_kl             | 0.00401282 |
|    clip_fraction         | 0.0109     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.8        |
|    cost_value_loss       | 2.29       |
|    cost_values           | 1.43       |
|    entropy               | -1.48      |
|    entropy_loss          | -1.48      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.97       |
|    n_updates             | 7140       |
|    policy_gradient_loss  | -0.000682  |
|    std                   | 0.508      |
|    value_loss            | 14.1       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.81418824  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -836         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 1466368      |
| train/                   |              |
|    approx_kl             | 0.0050676093 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 0.065        |
|    cost_values           | 1.49         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.83         |
|    n_updates             | 7150         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.508        |
|    value_loss            | 7.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.796       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.796       |
| reward                   | -0.7789413  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -839        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 1468416     |
| train/                   |             |
|    approx_kl             | 0.004321811 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 5.62        |
|    cost_values           | 1.18        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.36        |
|    n_updates             | 7160        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.508       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.85         |
| reward                   | -0.71922135  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -840         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1098         |
|    total_timesteps       | 1470464      |
| train/                   |              |
|    approx_kl             | 0.0011586007 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.141        |
|    cost_values           | 1.14         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.9         |
|    n_updates             | 7170         |
|    policy_gradient_loss  | -0.0005      |
|    std                   | 0.508        |
|    value_loss            | 40.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.37        |
| reward                   | -0.58249027 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -836        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1132        |
|    total_timesteps       | 1472512     |
| train/                   |             |
|    approx_kl             | 0.00433488  |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.814       |
|    cost_value_loss       | 0.018       |
|    cost_values           | 0.886       |
|    entropy               | -1.47       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 2.38e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.6        |
|    n_updates             | 7180        |
|    policy_gradient_loss  | -0.000806   |
|    std                   | 0.505       |
|    value_loss            | 27.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.54        |
| reward                   | -0.9521815  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1167        |
|    total_timesteps       | 1474560     |
| train/                   |             |
|    approx_kl             | 0.002077282 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.869       |
|    cost_value_loss       | 0.511       |
|    cost_values           | 0.818       |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.59        |
|    n_updates             | 7190        |
|    policy_gradient_loss  | -0.000554   |
|    std                   | 0.504       |
|    value_loss            | 12.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.93         |
| reward                   | -0.7932814   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -830         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1202         |
|    total_timesteps       | 1476608      |
| train/                   |              |
|    approx_kl             | 0.0029539238 |
|    clip_fraction         | 0.0526       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 3.32         |
|    cost_values           | 0.94         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.3         |
|    n_updates             | 7200         |
|    policy_gradient_loss  | 0.00279      |
|    std                   | 0.504        |
|    value_loss            | 44.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5767333   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 1478656      |
| train/                   |              |
|    approx_kl             | 0.0044738157 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 3.79         |
|    cost_values           | 1.11         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.1          |
|    n_updates             | 7210         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.505        |
|    value_loss            | 7.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.5          |
| reward                   | -0.5915034   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -823         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1271         |
|    total_timesteps       | 1480704      |
| train/                   |              |
|    approx_kl             | 0.0009848474 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 2.47         |
|    cost_values           | 1.33         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.71         |
|    n_updates             | 7220         |
|    policy_gradient_loss  | -0.000136    |
|    std                   | 0.506        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.43331566 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -823        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1306        |
|    total_timesteps       | 1482752     |
| train/                   |             |
|    approx_kl             | 0.005245057 |
|    clip_fraction         | 0.00898     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 3.79        |
|    cost_values           | 1.35        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.53        |
|    n_updates             | 7230        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.506       |
|    value_loss            | 16.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.06        |
| reward                   | -0.5865351  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -820        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1341        |
|    total_timesteps       | 1484800     |
| train/                   |             |
|    approx_kl             | 0.004216193 |
|    clip_fraction         | 0.00684     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 3.39        |
|    cost_values           | 1.3         |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 7240        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.505       |
|    value_loss            | 6.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.68807507 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -821        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1377        |
|    total_timesteps       | 1486848     |
| train/                   |             |
|    approx_kl             | 0.003453524 |
|    clip_fraction         | 0.00322     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 1.42        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.4         |
|    n_updates             | 7250        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.505       |
|    value_loss            | 8.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.96722883  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1411         |
|    total_timesteps       | 1488896      |
| train/                   |              |
|    approx_kl             | 0.0019113922 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 2.56         |
|    cost_values           | 1.85         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.65         |
|    n_updates             | 7260         |
|    policy_gradient_loss  | -0.000169    |
|    std                   | 0.505        |
|    value_loss            | 4.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.47         |
| reward                   | -0.6549567   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 1490944      |
| train/                   |              |
|    approx_kl             | 0.0027682655 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 0.14         |
|    cost_values           | 1.66         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.64         |
|    n_updates             | 7270         |
|    policy_gradient_loss  | -0.00042     |
|    std                   | 0.504        |
|    value_loss            | 7.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.05        |
| reward                   | -0.47238022 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -818        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1480        |
|    total_timesteps       | 1492992     |
| train/                   |             |
|    approx_kl             | 0.005237242 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 0.0498      |
|    cost_values           | 1.37        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.64        |
|    n_updates             | 7280        |
|    policy_gradient_loss  | 0.00108     |
|    std                   | 0.505       |
|    value_loss            | 4.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.679931   |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -818        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1515        |
|    total_timesteps       | 1495040     |
| train/                   |             |
|    approx_kl             | 0.004937991 |
|    clip_fraction         | 0.0466      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 2.12        |
|    cost_values           | 1.14        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.64        |
|    n_updates             | 7290        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.505       |
|    value_loss            | 7.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.86395     |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1550         |
|    total_timesteps       | 1497088      |
| train/                   |              |
|    approx_kl             | 0.0046317116 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 4.5          |
|    cost_values           | 1.36         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.93         |
|    n_updates             | 7300         |
|    policy_gradient_loss  | -0.000729    |
|    std                   | 0.505        |
|    value_loss            | 11.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -1.0735683  |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -810        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1585        |
|    total_timesteps       | 1499136     |
| train/                   |             |
|    approx_kl             | 0.004188087 |
|    clip_fraction         | 0.0061      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.83        |
|    cost_value_loss       | 1.43        |
|    cost_values           | 1.52        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 7310        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.504       |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.70157677 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -808        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1620        |
|    total_timesteps       | 1501184     |
| train/                   |             |
|    approx_kl             | 0.003524657 |
|    clip_fraction         | 0.00288     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 0.0492      |
|    cost_values           | 1.32        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.8         |
|    n_updates             | 7320        |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 0.504       |
|    value_loss            | 16.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.5046473   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1654         |
|    total_timesteps       | 1503232      |
| train/                   |              |
|    approx_kl             | 0.0058198227 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 3.97         |
|    cost_values           | 1.14         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25           |
|    n_updates             | 7330         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.504        |
|    value_loss            | 42.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.72011954 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -815        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1689        |
|    total_timesteps       | 1505280     |
| train/                   |             |
|    approx_kl             | 0.007607557 |
|    clip_fraction         | 0.0429      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 0.273       |
|    cost_values           | 1.15        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 7340        |
|    policy_gradient_loss  | -0.0044     |
|    std                   | 0.504       |
|    value_loss            | 25.5        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -1.1298681 |
| rollout/           |            |
|    ep_len_mean     | 991        |
|    ep_rew_mean     | -815       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1507328    |
-----------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.61721873 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -816        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 1509376     |
| train/                   |             |
|    approx_kl             | 0.002475912 |
|    clip_fraction         | 0.00513     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 3.23        |
|    cost_values           | 1.23        |
|    entropy               | -1.45       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 7360        |
|    policy_gradient_loss  | -0.000389   |
|    std                   | 0.499       |
|    value_loss            | 5.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.44312683  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1511424      |
| train/                   |              |
|    approx_kl             | 0.0026834616 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 0.472        |
|    cost_values           | 1.49         |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.72         |
|    n_updates             | 7370         |
|    policy_gradient_loss  | -0.000454    |
|    std                   | 0.498        |
|    value_loss            | 12.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.2303183   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 1513472      |
| train/                   |              |
|    approx_kl             | 0.0021363855 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 1.03         |
|    cost_values           | 1.3          |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 7380         |
|    policy_gradient_loss  | 0.000765     |
|    std                   | 0.498        |
|    value_loss            | 43.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8187505  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -818        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 1515520     |
| train/                   |             |
|    approx_kl             | 0.003376454 |
|    clip_fraction         | 0.00273     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 1.65        |
|    cost_values           | 1.06        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.4        |
|    n_updates             | 7390        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.498       |
|    value_loss            | 34.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.3269282  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -816        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 1517568     |
| train/                   |             |
|    approx_kl             | 0.001953805 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 1.76        |
|    cost_values           | 1           |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.72        |
|    n_updates             | 7400        |
|    policy_gradient_loss  | -0.000153   |
|    std                   | 0.498       |
|    value_loss            | 12.5        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.27          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.27          |
| reward                   | -0.9823017    |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -812          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 7             |
|    time_elapsed          | 231           |
|    total_timesteps       | 1519616       |
| train/                   |               |
|    approx_kl             | 0.00031422375 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.58          |
|    cost_value_loss       | 3.65          |
|    cost_values           | 1.03          |
|    entropy               | -1.44         |
|    entropy_loss          | -1.44         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.53          |
|    n_updates             | 7410          |
|    policy_gradient_loss  | 0.000399      |
|    std                   | 0.498         |
|    value_loss            | 17            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.59665495  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1521664      |
| train/                   |              |
|    approx_kl             | 0.0025035404 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.906        |
|    cost_value_loss       | 0.14         |
|    cost_values           | 0.928        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.9          |
|    n_updates             | 7420         |
|    policy_gradient_loss  | -0.000824    |
|    std                   | 0.501        |
|    value_loss            | 3.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.618        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.618        |
| reward                   | -0.79626256  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 1523712      |
| train/                   |              |
|    approx_kl             | 0.0011005478 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 0.994        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.19         |
|    n_updates             | 7430         |
|    policy_gradient_loss  | 0.00107      |
|    std                   | 0.502        |
|    value_loss            | 9.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.49         |
| reward                   | -0.6594395   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 1525760      |
| train/                   |              |
|    approx_kl             | 0.0024941193 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.915        |
|    cost_value_loss       | 0.148        |
|    cost_values           | 0.973        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 7440         |
|    policy_gradient_loss  | 9.16e-05     |
|    std                   | 0.502        |
|    value_loss            | 14.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.38         |
| reward                   | -0.67706895  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -826         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 1527808      |
| train/                   |              |
|    approx_kl             | 0.0037976773 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 1            |
|    cost_value_loss       | 0.896        |
|    cost_values           | 0.932        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.86         |
|    n_updates             | 7450         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.503        |
|    value_loss            | 19.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.17        |
| reward                   | -0.559884   |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -826        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 403         |
|    total_timesteps       | 1529856     |
| train/                   |             |
|    approx_kl             | 0.004268845 |
|    clip_fraction         | 0.00903     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 4.02        |
|    cost_values           | 1.14        |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.8        |
|    n_updates             | 7460        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.503       |
|    value_loss            | 27.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.29         |
| reward                   | -1.0684723   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 1531904      |
| train/                   |              |
|    approx_kl             | 0.0046985764 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.0396       |
|    cost_values           | 1.19         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 7470         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.504        |
|    value_loss            | 13           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.69          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.69          |
| reward                   | -0.9055496    |
| rollout/                 |               |
|    ep_len_mean           | 993           |
|    ep_rew_mean           | -826          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 14            |
|    time_elapsed          | 473           |
|    total_timesteps       | 1533952       |
| train/                   |               |
|    approx_kl             | 0.00024120804 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.05          |
|    cost_value_loss       | 5.69          |
|    cost_values           | 1.02          |
|    entropy               | -1.47         |
|    entropy_loss          | -1.47         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.21          |
|    n_updates             | 7480          |
|    policy_gradient_loss  | -5.69e-05     |
|    std                   | 0.504         |
|    value_loss            | 10.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.89676106  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 507          |
|    total_timesteps       | 1536000      |
| train/                   |              |
|    approx_kl             | 6.674143e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.86         |
|    cost_value_loss       | 0.0251       |
|    cost_values           | 0.988        |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 7490         |
|    policy_gradient_loss  | 1.38e-05     |
|    std                   | 0.504        |
|    value_loss            | 30.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45009553  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 541          |
|    total_timesteps       | 1538048      |
| train/                   |              |
|    approx_kl             | 0.0027626758 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.789        |
|    cost_value_loss       | 0.0626       |
|    cost_values           | 0.865        |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.75         |
|    n_updates             | 7500         |
|    policy_gradient_loss  | -0.000755    |
|    std                   | 0.505        |
|    value_loss            | 6.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.77472174 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -820        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 576         |
|    total_timesteps       | 1540096     |
| train/                   |             |
|    approx_kl             | 0.007658693 |
|    clip_fraction         | 0.0364      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 1.89        |
|    cost_values           | 0.836       |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35          |
|    n_updates             | 7510        |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.504       |
|    value_loss            | 42.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.75757563  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 1542144      |
| train/                   |              |
|    approx_kl             | 0.0010330747 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 1.02         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.35         |
|    n_updates             | 7520         |
|    policy_gradient_loss  | 0.000328     |
|    std                   | 0.504        |
|    value_loss            | 8.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.6803962   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 644          |
|    total_timesteps       | 1544192      |
| train/                   |              |
|    approx_kl             | 0.0041473005 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 2.89         |
|    cost_values           | 1.21         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.74         |
|    n_updates             | 7530         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.505        |
|    value_loss            | 4.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.53000736  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 679          |
|    total_timesteps       | 1546240      |
| train/                   |              |
|    approx_kl             | 0.0043049892 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 1.14         |
|    cost_values           | 1.45         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.35         |
|    n_updates             | 7540         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.503        |
|    value_loss            | 7.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.3721833   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 713          |
|    total_timesteps       | 1548288      |
| train/                   |              |
|    approx_kl             | 0.0034334564 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 3.92         |
|    cost_values           | 1.67         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 7550         |
|    policy_gradient_loss  | -0.000948    |
|    std                   | 0.503        |
|    value_loss            | 26.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.98259157  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 748          |
|    total_timesteps       | 1550336      |
| train/                   |              |
|    approx_kl             | 0.0049665384 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 1.44         |
|    cost_values           | 1.82         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.59         |
|    n_updates             | 7560         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.504        |
|    value_loss            | 14.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.0979078   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -823         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 782          |
|    total_timesteps       | 1552384      |
| train/                   |              |
|    approx_kl             | 0.0028611869 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.0944       |
|    cost_values           | 1.54         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.81         |
|    n_updates             | 7570         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.504        |
|    value_loss            | 8.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.68041456  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -829         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 816          |
|    total_timesteps       | 1554432      |
| train/                   |              |
|    approx_kl             | 0.0030132604 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 0.326        |
|    cost_values           | 1.35         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.02         |
|    n_updates             | 7580         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.505        |
|    value_loss            | 18.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -1.0446374    |
| rollout/                 |               |
|    ep_len_mean           | 986           |
|    ep_rew_mean           | -821          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 25            |
|    time_elapsed          | 851           |
|    total_timesteps       | 1556480       |
| train/                   |               |
|    approx_kl             | 0.00031671085 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.979         |
|    cost_value_loss       | 0.0239        |
|    cost_values           | 1.05          |
|    entropy               | -1.47         |
|    entropy_loss          | -1.47         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.33          |
|    n_updates             | 7590          |
|    policy_gradient_loss  | -7.7e-05      |
|    std                   | 0.505         |
|    value_loss            | 26.1          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.6969715  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -816        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 885         |
|    total_timesteps       | 1558528     |
| train/                   |             |
|    approx_kl             | 0.001022364 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 5.29        |
|    cost_values           | 0.99        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.7        |
|    n_updates             | 7600        |
|    policy_gradient_loss  | -0.00075    |
|    std                   | 0.505       |
|    value_loss            | 50.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.83357203 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -814        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 920         |
|    total_timesteps       | 1560576     |
| train/                   |             |
|    approx_kl             | 0.005050841 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.794       |
|    cost_values           | 1           |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 7610        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.505       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -1.1070659  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -811        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 954         |
|    total_timesteps       | 1562624     |
| train/                   |             |
|    approx_kl             | 0.003529131 |
|    clip_fraction         | 0.0205      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.845       |
|    cost_value_loss       | 0.0166      |
|    cost_values           | 0.87        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 7620        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.508       |
|    value_loss            | 8.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.71251965  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -811         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 989          |
|    total_timesteps       | 1564672      |
| train/                   |              |
|    approx_kl             | 0.0016720452 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 4.8          |
|    cost_values           | 1.19         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 7630         |
|    policy_gradient_loss  | 5.2e-05      |
|    std                   | 0.507        |
|    value_loss            | 18.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -1.0805663  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -811        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1023        |
|    total_timesteps       | 1566720     |
| train/                   |             |
|    approx_kl             | 0.005835777 |
|    clip_fraction         | 0.0304      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 0.555       |
|    cost_values           | 1.51        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.2         |
|    n_updates             | 7640        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.508       |
|    value_loss            | 17.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2786638   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1058         |
|    total_timesteps       | 1568768      |
| train/                   |              |
|    approx_kl             | 0.0005737357 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 1.36         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.16         |
|    n_updates             | 7650         |
|    policy_gradient_loss  | 1.58e-05     |
|    std                   | 0.509        |
|    value_loss            | 16.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2242559  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -803        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1092        |
|    total_timesteps       | 1570816     |
| train/                   |             |
|    approx_kl             | 0.002975077 |
|    clip_fraction         | 0.00132     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 0.742       |
|    cost_values           | 1.19        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33          |
|    n_updates             | 7660        |
|    policy_gradient_loss  | -7.84e-05   |
|    std                   | 0.509       |
|    value_loss            | 47.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.7344352   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -808         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1127         |
|    total_timesteps       | 1572864      |
| train/                   |              |
|    approx_kl             | 0.0023794055 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 1.6          |
|    cost_values           | 1.34         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 7670         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.507        |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.57940096  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -808         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1161         |
|    total_timesteps       | 1574912      |
| train/                   |              |
|    approx_kl             | 0.0034474079 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 2.16         |
|    cost_values           | 1.49         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 7680         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.506        |
|    value_loss            | 23.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.46         |
| reward                   | -1.0532728   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1196         |
|    total_timesteps       | 1576960      |
| train/                   |              |
|    approx_kl             | 0.0010735148 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 4.36         |
|    cost_values           | 1.76         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.52         |
|    n_updates             | 7690         |
|    policy_gradient_loss  | 7.14e-05     |
|    std                   | 0.505        |
|    value_loss            | 9.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.156922    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1230         |
|    total_timesteps       | 1579008      |
| train/                   |              |
|    approx_kl             | 0.0064120656 |
|    clip_fraction         | 0.0433       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 0.679        |
|    cost_values           | 1.98         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 7700         |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.504        |
|    value_loss            | 20.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -0.82115513  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1265         |
|    total_timesteps       | 1581056      |
| train/                   |              |
|    approx_kl             | 0.0067417864 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 1.83         |
|    cost_values           | 1.78         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.22         |
|    n_updates             | 7710         |
|    policy_gradient_loss  | -7.49e-05    |
|    std                   | 0.503        |
|    value_loss            | 12.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.9774448    |
| rollout/                 |               |
|    ep_len_mean           | 978           |
|    ep_rew_mean           | -827          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1299          |
|    total_timesteps       | 1583104       |
| train/                   |               |
|    approx_kl             | 0.00074526854 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.49          |
|    cost_value_loss       | 0.0883        |
|    cost_values           | 1.69          |
|    entropy               | -1.46         |
|    entropy_loss          | -1.46         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 24.3          |
|    n_updates             | 7720          |
|    policy_gradient_loss  | -0.000142     |
|    std                   | 0.503         |
|    value_loss            | 64.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.9128472   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -826         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1334         |
|    total_timesteps       | 1585152      |
| train/                   |              |
|    approx_kl             | 0.0005891117 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 0.726        |
|    cost_values           | 1.37         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.16         |
|    n_updates             | 7730         |
|    policy_gradient_loss  | -0.000209    |
|    std                   | 0.503        |
|    value_loss            | 21.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.8844828   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -832         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1368         |
|    total_timesteps       | 1587200      |
| train/                   |              |
|    approx_kl             | 0.0021932744 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 0.513        |
|    cost_values           | 1.14         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 7740         |
|    policy_gradient_loss  | -0.000353    |
|    std                   | 0.503        |
|    value_loss            | 28.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.87         |
| reward                   | -0.82009894  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -836         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1403         |
|    total_timesteps       | 1589248      |
| train/                   |              |
|    approx_kl             | 0.0017087187 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.9          |
|    cost_value_loss       | 0.0301       |
|    cost_values           | 0.946        |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 7750         |
|    policy_gradient_loss  | -0.000873    |
|    std                   | 0.506        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.26         |
| reward                   | -0.8608345   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -844         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1437         |
|    total_timesteps       | 1591296      |
| train/                   |              |
|    approx_kl             | 0.0036772802 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.733        |
|    cost_value_loss       | 0.0249       |
|    cost_values           | 0.872        |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 7760         |
|    policy_gradient_loss  | -0.000969    |
|    std                   | 0.508        |
|    value_loss            | 39.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.832        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.832        |
| reward                   | -0.6648917   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -849         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1472         |
|    total_timesteps       | 1593344      |
| train/                   |              |
|    approx_kl             | 0.0037946692 |
|    clip_fraction         | 0.00796      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.923        |
|    cost_value_loss       | 0.917        |
|    cost_values           | 0.768        |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 7770         |
|    policy_gradient_loss  | -0.000885    |
|    std                   | 0.508        |
|    value_loss            | 23.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.36         |
| reward                   | -0.8308111   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -853         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1507         |
|    total_timesteps       | 1595392      |
| train/                   |              |
|    approx_kl             | 0.0006877413 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.655        |
|    cost_value_loss       | 0.0244       |
|    cost_values           | 0.799        |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 7780         |
|    policy_gradient_loss  | -0.000283    |
|    std                   | 0.508        |
|    value_loss            | 31.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.83328474  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -851         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1541         |
|    total_timesteps       | 1597440      |
| train/                   |              |
|    approx_kl             | 0.0033312843 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.809        |
|    cost_value_loss       | 0.483        |
|    cost_values           | 0.779        |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 7790         |
|    policy_gradient_loss  | -0.000469    |
|    std                   | 0.508        |
|    value_loss            | 18.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.753       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.753       |
| reward                   | -1.0510737  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -857        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1576        |
|    total_timesteps       | 1599488     |
| train/                   |             |
|    approx_kl             | 0.004307387 |
|    clip_fraction         | 0.0197      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.961       |
|    cost_value_loss       | 1.01        |
|    cost_values           | 0.871       |
|    entropy               | -1.49       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 7800        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.509       |
|    value_loss            | 3.99        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.06         |
| reward                   | -0.5836653   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -856         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1611         |
|    total_timesteps       | 1601536      |
| train/                   |              |
|    approx_kl             | 0.0029060515 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 3.67         |
|    cost_values           | 1.21         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 7810         |
|    policy_gradient_loss  | -0.000727    |
|    std                   | 0.509        |
|    value_loss            | 3.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.39        |
| reward                   | -0.97032535 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -855        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1646        |
|    total_timesteps       | 1603584     |
| train/                   |             |
|    approx_kl             | 0.002505788 |
|    clip_fraction         | 0.00249     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.24        |
|    cost_value_loss       | 0.0575      |
|    cost_values           | 1.4         |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.4        |
|    n_updates             | 7820        |
|    policy_gradient_loss  | -4.33e-05   |
|    std                   | 0.509       |
|    value_loss            | 42.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6875316   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -859         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1680         |
|    total_timesteps       | 1605632      |
| train/                   |              |
|    approx_kl             | 0.0043791085 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.974        |
|    cost_value_loss       | 0.017        |
|    cost_values           | 1.02         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.77         |
|    n_updates             | 7830         |
|    policy_gradient_loss  | -0.000294    |
|    std                   | 0.51         |
|    value_loss            | 4.07         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.76       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.76       |
| reward             | -1.3337104 |
| rollout/           |            |
|    ep_len_mean     | 983        |
|    ep_rew_mean     | -862       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1607680    |
-----------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -1.0993392  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -870        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 1609728     |
| train/                   |             |
|    approx_kl             | 0.002224448 |
|    clip_fraction         | 0.000391    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.825       |
|    cost_value_loss       | 0.0986      |
|    cost_values           | 0.938       |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 7850        |
|    policy_gradient_loss  | -0.000457   |
|    std                   | 0.503       |
|    value_loss            | 30.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.749196    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -873         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1611776      |
| train/                   |              |
|    approx_kl             | 0.0033204951 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.39         |
|    cost_values           | 0.971        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 7860         |
|    policy_gradient_loss  | -0.000185    |
|    std                   | 0.503        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.1482339   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -872         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 1613824      |
| train/                   |              |
|    approx_kl             | 0.0022090108 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.348        |
|    cost_values           | 0.998        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7            |
|    n_updates             | 7870         |
|    policy_gradient_loss  | -0.000681    |
|    std                   | 0.503        |
|    value_loss            | 13.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.62804335 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -879        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 1615872     |
| train/                   |             |
|    approx_kl             | 0.004163889 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.924       |
|    cost_value_loss       | 0.272       |
|    cost_values           | 0.955       |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.9        |
|    n_updates             | 7880        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.502       |
|    value_loss            | 22.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.068168    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -881         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1617920      |
| train/                   |              |
|    approx_kl             | 0.0016665427 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.756        |
|    cost_value_loss       | 0.0175       |
|    cost_values           | 0.858        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 7890         |
|    policy_gradient_loss  | -0.000263    |
|    std                   | 0.501        |
|    value_loss            | 25.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.697        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.697        |
| reward                   | -0.79793394  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 1619968      |
| train/                   |              |
|    approx_kl             | 0.0019386234 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.777        |
|    cost_value_loss       | 0.272        |
|    cost_values           | 0.749        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.99         |
|    n_updates             | 7900         |
|    policy_gradient_loss  | -0.000496    |
|    std                   | 0.501        |
|    value_loss            | 18.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.81          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.81          |
| reward                   | -0.8992886    |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -872          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 8             |
|    time_elapsed          | 266           |
|    total_timesteps       | 1622016       |
| train/                   |               |
|    approx_kl             | 0.00036095228 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.97          |
|    cost_value_loss       | 9.1           |
|    cost_values           | 0.906         |
|    entropy               | -1.46         |
|    entropy_loss          | -1.46         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 34.4          |
|    n_updates             | 7910          |
|    policy_gradient_loss  | -0.000133     |
|    std                   | 0.501         |
|    value_loss            | 56.8          |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.395       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.395       |
| reward                   | -0.800372   |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -870        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 300         |
|    total_timesteps       | 1624064     |
| train/                   |             |
|    approx_kl             | 0.004971366 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.677       |
|    cost_values           | 1.01        |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 7920        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.502       |
|    value_loss            | 4.73        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.196         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.196         |
| reward                   | -0.73969793   |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -873          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 10            |
|    time_elapsed          | 335           |
|    total_timesteps       | 1626112       |
| train/                   |               |
|    approx_kl             | 0.00063326006 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.913         |
|    cost_value_loss       | 0.264         |
|    cost_values           | 0.964         |
|    entropy               | -1.46         |
|    entropy_loss          | -1.46         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.72          |
|    n_updates             | 7930          |
|    policy_gradient_loss  | -3.33e-05     |
|    std                   | 0.503         |
|    value_loss            | 4.17          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.61         |
| reward                   | -0.7261339   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -872         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 1628160      |
| train/                   |              |
|    approx_kl             | 0.0030837434 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.757        |
|    cost_value_loss       | 0.0152       |
|    cost_values           | 0.841        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.29         |
|    n_updates             | 7940         |
|    policy_gradient_loss  | -5.22e-05    |
|    std                   | 0.503        |
|    value_loss            | 3            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.65         |
| reward                   | -0.8120174   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -879         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 1630208      |
| train/                   |              |
|    approx_kl             | 0.0004607612 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.817        |
|    cost_value_loss       | 0.421        |
|    cost_values           | 0.749        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.28         |
|    n_updates             | 7950         |
|    policy_gradient_loss  | 0.00215      |
|    std                   | 0.502        |
|    value_loss            | 8.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.65         |
| reward                   | -0.903188    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -874         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 1632256      |
| train/                   |              |
|    approx_kl             | 0.0050307782 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.63         |
|    cost_value_loss       | 0.0151       |
|    cost_values           | 0.734        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.72         |
|    n_updates             | 7960         |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.503        |
|    value_loss            | 15.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.78023976 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -876        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 472         |
|    total_timesteps       | 1634304     |
| train/                   |             |
|    approx_kl             | 0.004934254 |
|    clip_fraction         | 0.0575      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.588       |
|    cost_value_loss       | 0.0393      |
|    cost_values           | 0.597       |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.3         |
|    n_updates             | 7970        |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 0.502       |
|    value_loss            | 19.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.05         |
| reward                   | -1.0618778   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -879         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 1636352      |
| train/                   |              |
|    approx_kl             | 0.0017995955 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.486        |
|    cost_value_loss       | 0.00851      |
|    cost_values           | 0.563        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 7980         |
|    policy_gradient_loss  | 0.000808     |
|    std                   | 0.502        |
|    value_loss            | 28.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.917267    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -885         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 541          |
|    total_timesteps       | 1638400      |
| train/                   |              |
|    approx_kl             | 0.0043065264 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.672        |
|    cost_value_loss       | 0.774        |
|    cost_values           | 0.56         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.76         |
|    n_updates             | 7990         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.503        |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3550918  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -888        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 575         |
|    total_timesteps       | 1640448     |
| train/                   |             |
|    approx_kl             | 0.005814179 |
|    clip_fraction         | 0.0358      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.554       |
|    cost_value_loss       | 0.044       |
|    cost_values           | 0.614       |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.36        |
|    n_updates             | 8000        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.502       |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.83142734  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -898         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 1642496      |
| train/                   |              |
|    approx_kl             | 0.0036268379 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.924        |
|    cost_value_loss       | 1.65         |
|    cost_values           | 0.647        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16           |
|    n_updates             | 8010         |
|    policy_gradient_loss  | -0.000578    |
|    std                   | 0.502        |
|    value_loss            | 33.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.4836757   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 644          |
|    total_timesteps       | 1644544      |
| train/                   |              |
|    approx_kl             | 0.0013483639 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.705        |
|    cost_value_loss       | 0.208        |
|    cost_values           | 0.784        |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 8020         |
|    policy_gradient_loss  | -0.000205    |
|    std                   | 0.502        |
|    value_loss            | 24.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.4376712   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -909         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 679          |
|    total_timesteps       | 1646592      |
| train/                   |              |
|    approx_kl             | 0.0040546954 |
|    clip_fraction         | 0.0606       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.779        |
|    cost_value_loss       | 0.417        |
|    cost_values           | 0.778        |
|    entropy               | -1.43        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 8030         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.494        |
|    value_loss            | 23.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.41        |
| reward                   | -0.8682163  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -908        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 713         |
|    total_timesteps       | 1648640     |
| train/                   |             |
|    approx_kl             | 0.004714501 |
|    clip_fraction         | 0.0204      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.959       |
|    cost_value_loss       | 1.22        |
|    cost_values           | 0.819       |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.1        |
|    n_updates             | 8040        |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.492       |
|    value_loss            | 43.8        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.89       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.89       |
| reward                   | -1.0083922 |
| rollout/                 |            |
|    ep_len_mean           | 985        |
|    ep_rew_mean           | -908       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 22         |
|    time_elapsed          | 748        |
|    total_timesteps       | 1650688    |
| train/                   |            |
|    approx_kl             | 0.00796482 |
|    clip_fraction         | 0.0398     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.985      |
|    cost_value_loss       | 0.733      |
|    cost_values           | 0.954      |
|    entropy               | -1.42      |
|    entropy_loss          | -1.42      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 16.7       |
|    n_updates             | 8050       |
|    policy_gradient_loss  | -0.00247   |
|    std                   | 0.492      |
|    value_loss            | 29.5       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.4066714  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -907        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 782         |
|    total_timesteps       | 1652736     |
| train/                   |             |
|    approx_kl             | 0.005049902 |
|    clip_fraction         | 0.00957     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.901       |
|    cost_value_loss       | 0.201       |
|    cost_values           | 0.911       |
|    entropy               | -1.4        |
|    entropy_loss          | -1.41       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.85        |
|    n_updates             | 8060        |
|    policy_gradient_loss  | -0.000475   |
|    std                   | 0.487       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.0474042   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -913         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 816          |
|    total_timesteps       | 1654784      |
| train/                   |              |
|    approx_kl             | 0.0027480607 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.781        |
|    cost_value_loss       | 0.0352       |
|    cost_values           | 0.829        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.81         |
|    n_updates             | 8070         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.486        |
|    value_loss            | 16.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.7027956   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -916         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 850          |
|    total_timesteps       | 1656832      |
| train/                   |              |
|    approx_kl             | 0.0017063989 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.812        |
|    cost_value_loss       | 0.448        |
|    cost_values           | 0.788        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 8080         |
|    policy_gradient_loss  | 0.000414     |
|    std                   | 0.486        |
|    value_loss            | 26.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -1.0168986   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -921         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 885          |
|    total_timesteps       | 1658880      |
| train/                   |              |
|    approx_kl             | 0.0037927188 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.685        |
|    cost_values           | 0.837        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 8090         |
|    policy_gradient_loss  | -0.000961    |
|    std                   | 0.485        |
|    value_loss            | 30.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.349        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.349        |
| reward                   | -0.5163987   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -927         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 920          |
|    total_timesteps       | 1660928      |
| train/                   |              |
|    approx_kl             | 0.0021135649 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.866        |
|    cost_value_loss       | 0.235        |
|    cost_values           | 0.871        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.04         |
|    n_updates             | 8100         |
|    policy_gradient_loss  | -0.000433    |
|    std                   | 0.485        |
|    value_loss            | 15.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.7424756   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -927         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 954          |
|    total_timesteps       | 1662976      |
| train/                   |              |
|    approx_kl             | 0.0031071126 |
|    clip_fraction         | 0.002        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.79         |
|    cost_value_loss       | 0.125        |
|    cost_values           | 0.853        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.2         |
|    n_updates             | 8110         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.485        |
|    value_loss            | 53.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.37         |
| reward                   | -1.1498886   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -930         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 989          |
|    total_timesteps       | 1665024      |
| train/                   |              |
|    approx_kl             | 0.0027435664 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.709        |
|    cost_value_loss       | 0.0463       |
|    cost_values           | 0.78         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.06         |
|    n_updates             | 8120         |
|    policy_gradient_loss  | -0.000235    |
|    std                   | 0.485        |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.63         |
| reward                   | -1.0457858   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1023         |
|    total_timesteps       | 1667072      |
| train/                   |              |
|    approx_kl             | 0.0047654295 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.692        |
|    cost_value_loss       | 0.188        |
|    cost_values           | 0.699        |
|    entropy               | -1.38        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.78         |
|    n_updates             | 8130         |
|    policy_gradient_loss  | -0.000926    |
|    std                   | 0.482        |
|    value_loss            | 11.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.91199315 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -944        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 1669120     |
| train/                   |             |
|    approx_kl             | 0.003253805 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.579       |
|    cost_value_loss       | 0.0124      |
|    cost_values           | 0.675       |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 8140        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.481       |
|    value_loss            | 26.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.878873   |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -947        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 32          |
|    time_elapsed          | 1092        |
|    total_timesteps       | 1671168     |
| train/                   |             |
|    approx_kl             | 0.004913464 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.797       |
|    cost_value_loss       | 0.68        |
|    cost_values           | 0.684       |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.6        |
|    n_updates             | 8150        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.481       |
|    value_loss            | 39.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.74056864  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -948         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1126         |
|    total_timesteps       | 1673216      |
| train/                   |              |
|    approx_kl             | 0.0050412533 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.719        |
|    cost_value_loss       | 0.147        |
|    cost_values           | 0.74         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.96         |
|    n_updates             | 8160         |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.481        |
|    value_loss            | 18.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2232091   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -952         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1160         |
|    total_timesteps       | 1675264      |
| train/                   |              |
|    approx_kl             | 0.0037007078 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.836        |
|    cost_values           | 0.83         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 8170         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.481        |
|    value_loss            | 24.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.8905398   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -955         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1194         |
|    total_timesteps       | 1677312      |
| train/                   |              |
|    approx_kl             | 0.0034849788 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.935        |
|    cost_value_loss       | 0.361        |
|    cost_values           | 0.971        |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 8180         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.48         |
|    value_loss            | 24.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8503391  |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -953        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1229        |
|    total_timesteps       | 1679360     |
| train/                   |             |
|    approx_kl             | 0.003105086 |
|    clip_fraction         | 0.0189      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.41        |
|    cost_values           | 0.998       |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.47        |
|    n_updates             | 8190        |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.48        |
|    value_loss            | 18.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.83         |
| reward                   | -0.8984636   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -946         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1263         |
|    total_timesteps       | 1681408      |
| train/                   |              |
|    approx_kl             | 0.0045491345 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.88         |
|    cost_value_loss       | 0.106        |
|    cost_values           | 0.947        |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.98         |
|    n_updates             | 8200         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.481        |
|    value_loss            | 12.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5871548  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -940        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1298        |
|    total_timesteps       | 1683456     |
| train/                   |             |
|    approx_kl             | 0.005157953 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.857       |
|    cost_values           | 0.965       |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 54.9        |
|    n_updates             | 8210        |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 0.481       |
|    value_loss            | 76.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.578021    |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -937         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1332         |
|    total_timesteps       | 1685504      |
| train/                   |              |
|    approx_kl             | 0.0036486064 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 0.858        |
|    cost_values           | 0.995        |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.4         |
|    n_updates             | 8220         |
|    policy_gradient_loss  | 0.000234     |
|    std                   | 0.481        |
|    value_loss            | 65.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.561       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.561       |
| reward                   | -0.7510143  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -935        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1367        |
|    total_timesteps       | 1687552     |
| train/                   |             |
|    approx_kl             | 0.008339025 |
|    clip_fraction         | 0.0191      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 1.23        |
|    cost_values           | 1.18        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 8230        |
|    policy_gradient_loss  | -0.000608   |
|    std                   | 0.483       |
|    value_loss            | 29.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.48         |
| reward                   | -0.9664724   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -931         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1401         |
|    total_timesteps       | 1689600      |
| train/                   |              |
|    approx_kl             | 0.0032401101 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.996        |
|    cost_values           | 1.17         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 8240         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.482        |
|    value_loss            | 33.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.56         |
| reward                   | -0.2718297   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1435         |
|    total_timesteps       | 1691648      |
| train/                   |              |
|    approx_kl             | 0.0029668454 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 1.71         |
|    cost_values           | 1.15         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 8250         |
|    policy_gradient_loss  | -0.000485    |
|    std                   | 0.482        |
|    value_loss            | 23.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.57         |
| reward                   | -0.67778075  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -935         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1470         |
|    total_timesteps       | 1693696      |
| train/                   |              |
|    approx_kl             | 8.390291e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.0702       |
|    cost_values           | 1.05         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.7         |
|    n_updates             | 8260         |
|    policy_gradient_loss  | 0.000209     |
|    std                   | 0.482        |
|    value_loss            | 66.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.7568219  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -936        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1504        |
|    total_timesteps       | 1695744     |
| train/                   |             |
|    approx_kl             | 0.006534002 |
|    clip_fraction         | 0.0484      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.902       |
|    cost_value_loss       | 0.257       |
|    cost_values           | 0.898       |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 8270        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.481       |
|    value_loss            | 27.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.43         |
| reward                   | -0.7885357   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1538         |
|    total_timesteps       | 1697792      |
| train/                   |              |
|    approx_kl             | 0.0014487242 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.869        |
|    cost_value_loss       | 0.194        |
|    cost_values           | 0.878        |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.03         |
|    n_updates             | 8280         |
|    policy_gradient_loss  | -0.000251    |
|    std                   | 0.479        |
|    value_loss            | 16.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.5439712   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1573         |
|    total_timesteps       | 1699840      |
| train/                   |              |
|    approx_kl             | 0.0050173625 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.42         |
|    cost_values           | 0.92         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.58         |
|    n_updates             | 8290         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.479        |
|    value_loss            | 21.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.77307576  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1607         |
|    total_timesteps       | 1701888      |
| train/                   |              |
|    approx_kl             | 0.0006171642 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 1.68         |
|    cost_values           | 0.998        |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 8300         |
|    policy_gradient_loss  | -0.000297    |
|    std                   | 0.478        |
|    value_loss            | 62.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.75981677  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -916         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1642         |
|    total_timesteps       | 1703936      |
| train/                   |              |
|    approx_kl             | 0.0029586349 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 1.96         |
|    cost_values           | 1            |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 8310         |
|    policy_gradient_loss  | -0.000512    |
|    std                   | 0.478        |
|    value_loss            | 11.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3478336  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -917        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1676        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.005082499 |
|    clip_fraction         | 0.00742     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.26        |
|    cost_values           | 1           |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.1        |
|    n_updates             | 8320        |
|    policy_gradient_loss  | -0.000867   |
|    std                   | 0.478       |
|    value_loss            | 51.5        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
----------------------------------
| avg_speed          | 8         |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8         |
| reward             | -0.856013 |
| rollout/           |           |
|    ep_len_mean     | 974       |
|    ep_rew_mean     | -919      |
| time/              |           |
|    fps             | 84        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 1708032   |
----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2333711   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 1710080      |
| train/                   |              |
|    approx_kl             | 0.0049408902 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.802        |
|    cost_value_loss       | 0.104        |
|    cost_values           | 0.833        |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 8340         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.476        |
|    value_loss            | 27.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8869988   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -912         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 1712128      |
| train/                   |              |
|    approx_kl             | 0.0033761286 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 2.15         |
|    cost_values           | 0.957        |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.14         |
|    n_updates             | 8350         |
|    policy_gradient_loss  | -0.000593    |
|    std                   | 0.475        |
|    value_loss            | 16.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.74648696  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -910         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 1714176      |
| train/                   |              |
|    approx_kl             | 0.0035704365 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.979        |
|    cost_value_loss       | 0.329        |
|    cost_values           | 0.951        |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 8360         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.474        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7606711   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -912         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 1716224      |
| train/                   |              |
|    approx_kl             | 0.0035812221 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.646        |
|    cost_values           | 0.983        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.87         |
|    n_updates             | 8370         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.474        |
|    value_loss            | 11.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2098169   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -920         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 1718272      |
| train/                   |              |
|    approx_kl             | 0.0015289616 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.01         |
|    cost_values           | 1.05         |
|    entropy               | -1.35        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.18         |
|    n_updates             | 8380         |
|    policy_gradient_loss  | -0.000212    |
|    std                   | 0.475        |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5252636   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 1720320      |
| train/                   |              |
|    approx_kl             | 0.0041581593 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.964        |
|    cost_value_loss       | 0.122        |
|    cost_values           | 0.962        |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.72         |
|    n_updates             | 8390         |
|    policy_gradient_loss  | -0.000135    |
|    std                   | 0.476        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7584548   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -920         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1722368      |
| train/                   |              |
|    approx_kl             | 0.0054001724 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.04         |
|    cost_values           | 1.01         |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 8400         |
|    policy_gradient_loss  | -0.000631    |
|    std                   | 0.476        |
|    value_loss            | 20.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.97496027 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -924        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 300         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.003989537 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 0.483       |
|    cost_values           | 0.991       |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.2         |
|    n_updates             | 8410        |
|    policy_gradient_loss  | -0.000326   |
|    std                   | 0.475       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5953073   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -927         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 1726464      |
| train/                   |              |
|    approx_kl             | 0.0017927061 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.962        |
|    cost_value_loss       | 0.255        |
|    cost_values           | 0.988        |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.1         |
|    n_updates             | 8420         |
|    policy_gradient_loss  | -0.000422    |
|    std                   | 0.476        |
|    value_loss            | 63.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.6494893  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -916        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 1728512     |
| train/                   |             |
|    approx_kl             | 0.002730161 |
|    clip_fraction         | 0.00181     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 2.6         |
|    cost_values           | 1.07        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.02        |
|    n_updates             | 8430        |
|    policy_gradient_loss  | -0.000434   |
|    std                   | 0.476       |
|    value_loss            | 14.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.96774256  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -911         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 1730560      |
| train/                   |              |
|    approx_kl             | 0.0005184044 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.502        |
|    cost_values           | 1.06         |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25           |
|    n_updates             | 8440         |
|    policy_gradient_loss  | -9.56e-05    |
|    std                   | 0.476        |
|    value_loss            | 55.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -1.4382107   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -907         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 1732608      |
| train/                   |              |
|    approx_kl             | 0.0014333517 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.864        |
|    cost_value_loss       | 0.153        |
|    cost_values           | 0.898        |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.22         |
|    n_updates             | 8450         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.475        |
|    value_loss            | 19.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.7576305   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -910         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 472          |
|    total_timesteps       | 1734656      |
| train/                   |              |
|    approx_kl             | 0.0024705168 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 1.67         |
|    cost_values           | 0.955        |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.32         |
|    n_updates             | 8460         |
|    policy_gradient_loss  | 0.000413     |
|    std                   | 0.475        |
|    value_loss            | 19.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.3458408   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -907         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 1736704      |
| train/                   |              |
|    approx_kl             | 0.0017237691 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.94         |
|    cost_value_loss       | 0.216        |
|    cost_values           | 0.948        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 8470         |
|    policy_gradient_loss  | -0.000106    |
|    std                   | 0.473        |
|    value_loss            | 18.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.96          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.96          |
| reward                   | -1.0859073    |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -902          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 16            |
|    time_elapsed          | 541           |
|    total_timesteps       | 1738752       |
| train/                   |               |
|    approx_kl             | 0.00057333696 |
|    clip_fraction         | 0.0263        |
|    clip_range            | 0.2           |
|    cost_returns          | 0.911         |
|    cost_value_loss       | 0.345         |
|    cost_values           | 0.919         |
|    entropy               | -1.34         |
|    entropy_loss          | -1.34         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.82          |
|    n_updates             | 8480          |
|    policy_gradient_loss  | -0.000415     |
|    std                   | 0.472         |
|    value_loss            | 14.5          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.8061897  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 575         |
|    total_timesteps       | 1740800     |
| train/                   |             |
|    approx_kl             | 0.007817822 |
|    clip_fraction         | 0.0679      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 1.2         |
|    cost_values           | 0.988       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.95        |
|    n_updates             | 8490        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.472       |
|    value_loss            | 11.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3476058   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 1742848      |
| train/                   |              |
|    approx_kl             | 0.0007473615 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.718        |
|    cost_values           | 0.992        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.84         |
|    n_updates             | 8500         |
|    policy_gradient_loss  | -0.000218    |
|    std                   | 0.473        |
|    value_loss            | 6.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.65         |
| reward                   | -0.6568614   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1744896      |
| train/                   |              |
|    approx_kl             | 0.0009365615 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.817        |
|    cost_value_loss       | 0.0291       |
|    cost_values           | 0.967        |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 8510         |
|    policy_gradient_loss  | 0.000103     |
|    std                   | 0.475        |
|    value_loss            | 32.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.78        |
| reward                   | -0.8175415  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -901        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 679         |
|    total_timesteps       | 1746944     |
| train/                   |             |
|    approx_kl             | 0.001289641 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.765       |
|    cost_value_loss       | 0.0334      |
|    cost_values           | 0.877       |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 8520        |
|    policy_gradient_loss  | -0.000493   |
|    std                   | 0.475       |
|    value_loss            | 34          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.075585    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -894         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 714          |
|    total_timesteps       | 1748992      |
| train/                   |              |
|    approx_kl             | 0.0039479546 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.688        |
|    cost_value_loss       | 0.0103       |
|    cost_values           | 0.742        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.15         |
|    n_updates             | 8530         |
|    policy_gradient_loss  | -0.000965    |
|    std                   | 0.473        |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5485069   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -891         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 1751040      |
| train/                   |              |
|    approx_kl             | 0.0016583755 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 3.66         |
|    cost_values           | 0.842        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 8540         |
|    policy_gradient_loss  | -0.000336    |
|    std                   | 0.472        |
|    value_loss            | 40.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1060069   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 784          |
|    total_timesteps       | 1753088      |
| train/                   |              |
|    approx_kl             | 0.0041203965 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.84         |
|    cost_value_loss       | 0.0164       |
|    cost_values           | 0.922        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 8550         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.472        |
|    value_loss            | 26.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.6260527   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -896         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 819          |
|    total_timesteps       | 1755136      |
| train/                   |              |
|    approx_kl             | 0.0038392083 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.929        |
|    cost_value_loss       | 0.747        |
|    cost_values           | 0.883        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.41         |
|    n_updates             | 8560         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.471        |
|    value_loss            | 12.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.8899931  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -897        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 853         |
|    total_timesteps       | 1757184     |
| train/                   |             |
|    approx_kl             | 0.005107806 |
|    clip_fraction         | 0.0335      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.02        |
|    cost_values           | 1.08        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.9        |
|    n_updates             | 8570        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.471       |
|    value_loss            | 31.1        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.86          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.86          |
| reward                   | -0.961143     |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -896          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 26            |
|    time_elapsed          | 888           |
|    total_timesteps       | 1759232       |
| train/                   |               |
|    approx_kl             | 0.00040146717 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.26          |
|    cost_value_loss       | 1.02          |
|    cost_values           | 1.02          |
|    entropy               | -1.33         |
|    entropy_loss          | -1.33         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 18.8          |
|    n_updates             | 8580          |
|    policy_gradient_loss  | 0.000135      |
|    std                   | 0.471         |
|    value_loss            | 35.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.7812037   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 923          |
|    total_timesteps       | 1761280      |
| train/                   |              |
|    approx_kl             | 0.0053152316 |
|    clip_fraction         | 0.0695       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.947        |
|    cost_values           | 1.01         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 8590         |
|    policy_gradient_loss  | -0.00453     |
|    std                   | 0.472        |
|    value_loss            | 19.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6846828   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -889         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 0.0027994425 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 2.03         |
|    cost_values           | 1.27         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 8600         |
|    policy_gradient_loss  | -0.000335    |
|    std                   | 0.471        |
|    value_loss            | 33           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3777726   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -885         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 1765376      |
| train/                   |              |
|    approx_kl             | 0.0009350967 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.592        |
|    cost_values           | 1.48         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.56         |
|    n_updates             | 8610         |
|    policy_gradient_loss  | -9.09e-05    |
|    std                   | 0.47         |
|    value_loss            | 17.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1783754  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -874        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1028        |
|    total_timesteps       | 1767424     |
| train/                   |             |
|    approx_kl             | 0.003914328 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 0.89        |
|    cost_values           | 1.21        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.75        |
|    n_updates             | 8620        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.47        |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1047993   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 1769472      |
| train/                   |              |
|    approx_kl             | 0.0046443264 |
|    clip_fraction         | 0.0747       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.763        |
|    cost_values           | 1.21         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.5         |
|    n_updates             | 8630         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.47         |
|    value_loss            | 77.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -0.92755044   |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -870          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 32            |
|    time_elapsed          | 1097          |
|    total_timesteps       | 1771520       |
| train/                   |               |
|    approx_kl             | 0.00069042866 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.51          |
|    cost_value_loss       | 1.45          |
|    cost_values           | 1.14          |
|    entropy               | -1.33         |
|    entropy_loss          | -1.33         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.6          |
|    n_updates             | 8640          |
|    policy_gradient_loss  | 0.000192      |
|    std                   | 0.47          |
|    value_loss            | 33.5          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.71          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.71          |
| reward                   | -1.0000563    |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -869          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 33            |
|    time_elapsed          | 1132          |
|    total_timesteps       | 1773568       |
| train/                   |               |
|    approx_kl             | 2.7673377e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.6           |
|    cost_value_loss       | 2.32          |
|    cost_values           | 1.04          |
|    entropy               | -1.33         |
|    entropy_loss          | -1.33         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.7          |
|    n_updates             | 8650          |
|    policy_gradient_loss  | 0.000111      |
|    std                   | 0.471         |
|    value_loss            | 25.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.6832727   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -867         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1167         |
|    total_timesteps       | 1775616      |
| train/                   |              |
|    approx_kl             | 0.0039892374 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.903        |
|    cost_value_loss       | 0.195        |
|    cost_values           | 0.969        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 8660         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.47         |
|    value_loss            | 37.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5452657   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -868         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1202         |
|    total_timesteps       | 1777664      |
| train/                   |              |
|    approx_kl             | 0.0057112016 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.789        |
|    cost_values           | 0.958        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.82         |
|    n_updates             | 8670         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.47         |
|    value_loss            | 17.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.57247907 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -873        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1236        |
|    total_timesteps       | 1779712     |
| train/                   |             |
|    approx_kl             | 0.004263805 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.939       |
|    cost_value_loss       | 0.408       |
|    cost_values           | 0.98        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.8        |
|    n_updates             | 8680        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.47        |
|    value_loss            | 43.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.4969491   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -873         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1271         |
|    total_timesteps       | 1781760      |
| train/                   |              |
|    approx_kl             | 0.0015838662 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 1.18         |
|    cost_values           | 0.985        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.4         |
|    n_updates             | 8690         |
|    policy_gradient_loss  | -0.000792    |
|    std                   | 0.47         |
|    value_loss            | 59.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4152596   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1305         |
|    total_timesteps       | 1783808      |
| train/                   |              |
|    approx_kl             | 0.0049156556 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.941        |
|    cost_value_loss       | 0.371        |
|    cost_values           | 0.977        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 8700         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.469        |
|    value_loss            | 23.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.8419562   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1340         |
|    total_timesteps       | 1785856      |
| train/                   |              |
|    approx_kl             | 0.0045644953 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.687        |
|    cost_values           | 0.977        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.46         |
|    n_updates             | 8710         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.47         |
|    value_loss            | 17.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2623011   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -876         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1374         |
|    total_timesteps       | 1787904      |
| train/                   |              |
|    approx_kl             | 0.0020778526 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.884        |
|    cost_values           | 1            |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 8720         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.47         |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -1.7648118  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -872        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1408        |
|    total_timesteps       | 1789952     |
| train/                   |             |
|    approx_kl             | 7.11772e-05 |
|    clip_fraction         | 0.00527     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.702       |
|    cost_values           | 1.02        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 8730        |
|    policy_gradient_loss  | 7.43e-05    |
|    std                   | 0.473       |
|    value_loss            | 27.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9067286  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -875        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1442        |
|    total_timesteps       | 1792000     |
| train/                   |             |
|    approx_kl             | 0.003998025 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.863       |
|    cost_value_loss       | 0.0377      |
|    cost_values           | 0.896       |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 8740        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.474       |
|    value_loss            | 22          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3868592   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -879         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1477         |
|    total_timesteps       | 1794048      |
| train/                   |              |
|    approx_kl             | 0.0018870293 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.94         |
|    cost_value_loss       | 0.778        |
|    cost_values           | 0.906        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.5         |
|    n_updates             | 8750         |
|    policy_gradient_loss  | -0.000654    |
|    std                   | 0.474        |
|    value_loss            | 48.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.450377    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -887         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1511         |
|    total_timesteps       | 1796096      |
| train/                   |              |
|    approx_kl             | 0.0032634865 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.862        |
|    cost_value_loss       | 0.176        |
|    cost_values           | 0.874        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 8760         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.471        |
|    value_loss            | 21.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.89418787  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1546         |
|    total_timesteps       | 1798144      |
| train/                   |              |
|    approx_kl             | 0.0017921894 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.714        |
|    cost_value_loss       | 0.0197       |
|    cost_values           | 0.834        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 8770         |
|    policy_gradient_loss  | 0.00101      |
|    std                   | 0.47         |
|    value_loss            | 24.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.6698518   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -899         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1580         |
|    total_timesteps       | 1800192      |
| train/                   |              |
|    approx_kl             | 0.0015330605 |
|    clip_fraction         | 0.00977      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.684        |
|    cost_value_loss       | 0.0489       |
|    cost_values           | 0.694        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 8780         |
|    policy_gradient_loss  | -0.000404    |
|    std                   | 0.472        |
|    value_loss            | 22.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.5472445   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -908         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1615         |
|    total_timesteps       | 1802240      |
| train/                   |              |
|    approx_kl             | 0.0034346315 |
|    clip_fraction         | 0.00308      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.575        |
|    cost_value_loss       | 0.0155       |
|    cost_values           | 0.665        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 8790         |
|    policy_gradient_loss  | -0.0008      |
|    std                   | 0.472        |
|    value_loss            | 36.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.66823924  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -909         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1650         |
|    total_timesteps       | 1804288      |
| train/                   |              |
|    approx_kl             | 0.0026038329 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.676        |
|    cost_value_loss       | 0.407        |
|    cost_values           | 0.632        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 8800         |
|    policy_gradient_loss  | -0.000528    |
|    std                   | 0.471        |
|    value_loss            | 26.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.79         |
| reward                   | -0.6503037   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -912         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1684         |
|    total_timesteps       | 1806336      |
| train/                   |              |
|    approx_kl             | 0.0018324035 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.535        |
|    cost_value_loss       | 0.0116       |
|    cost_values           | 0.62         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.82         |
|    n_updates             | 8810         |
|    policy_gradient_loss  | -0.000311    |
|    std                   | 0.471        |
|    value_loss            | 7.31         |
-------------------------------------------
-----------------------------------
| avg_speed          | 6.88       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 6.88       |
| reward             | -0.6527769 |
| rollout/           |            |
|    ep_len_mean     | 976        |
|    ep_rew_mean     | -913       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1808384    |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -0.81979907  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1810432      |
| train/                   |              |
|    approx_kl             | 0.0027019833 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.853        |
|    cost_value_loss       | 0.718        |
|    cost_values           | 0.755        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.99         |
|    n_updates             | 8830         |
|    policy_gradient_loss  | -0.000306    |
|    std                   | 0.47         |
|    value_loss            | 19.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0128577  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -918        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1812480     |
| train/                   |             |
|    approx_kl             | 0.003727313 |
|    clip_fraction         | 0.0165      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.936       |
|    cost_value_loss       | 0.583       |
|    cost_values           | 0.868       |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.5        |
|    n_updates             | 8840        |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.47        |
|    value_loss            | 34.8        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.1           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.1           |
| reward                   | -0.73535854   |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -923          |
| time/                    |               |
|    fps                   | 63            |
|    iterations            | 4             |
|    time_elapsed          | 128           |
|    total_timesteps       | 1814528       |
| train/                   |               |
|    approx_kl             | 0.00047243192 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.814         |
|    cost_value_loss       | 0.106         |
|    cost_values           | 0.913         |
|    entropy               | -1.33         |
|    entropy_loss          | -1.33         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.43          |
|    n_updates             | 8850          |
|    policy_gradient_loss  | -0.000199     |
|    std                   | 0.47          |
|    value_loss            | 18.6          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.77          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.77          |
| reward                   | -0.74997175   |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -922          |
| time/                    |               |
|    fps                   | 62            |
|    iterations            | 5             |
|    time_elapsed          | 163           |
|    total_timesteps       | 1816576       |
| train/                   |               |
|    approx_kl             | 0.00070455414 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.727         |
|    cost_value_loss       | 0.0185        |
|    cost_values           | 0.841         |
|    entropy               | -1.33         |
|    entropy_loss          | -1.33         |
|    explained_variance    | 1.79e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.8          |
|    n_updates             | 8860          |
|    policy_gradient_loss  | -0.000203     |
|    std                   | 0.47          |
|    value_loss            | 33.5          |
--------------------------------------------
-----------------------------------------
| avg_speed                | 7.74       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.74       |
| reward                   | -0.474274  |
| rollout/                 |            |
|    ep_len_mean           | 976        |
|    ep_rew_mean           | -927       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 6          |
|    time_elapsed          | 198        |
|    total_timesteps       | 1818624    |
| train/                   |            |
|    approx_kl             | 0.00276178 |
|    clip_fraction         | 0.0215     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.895      |
|    cost_value_loss       | 0.883      |
|    cost_values           | 0.871      |
|    entropy               | -1.33      |
|    entropy_loss          | -1.33      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 15.6       |
|    n_updates             | 8870       |
|    policy_gradient_loss  | -0.00088   |
|    std                   | 0.47       |
|    value_loss            | 30.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.7029827   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -931         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1820672      |
| train/                   |              |
|    approx_kl             | 0.0029308423 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.756        |
|    cost_value_loss       | 0.124        |
|    cost_values           | 0.825        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 8880         |
|    policy_gradient_loss  | -0.000944    |
|    std                   | 0.47         |
|    value_loss            | 22.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.64981276  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 1822720      |
| train/                   |              |
|    approx_kl             | 0.0034166821 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 1.24         |
|    cost_values           | 0.956        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 8890         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.47         |
|    value_loss            | 32.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.1574856   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -923         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 1824768      |
| train/                   |              |
|    approx_kl             | 0.0023584536 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.982        |
|    cost_value_loss       | 0.294        |
|    cost_values           | 0.961        |
|    entropy               | -1.32        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.19         |
|    n_updates             | 8900         |
|    policy_gradient_loss  | -0.000755    |
|    std                   | 0.469        |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3555194  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -934        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 336         |
|    total_timesteps       | 1826816     |
| train/                   |             |
|    approx_kl             | 0.004644097 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.961       |
|    cost_value_loss       | 0.375       |
|    cost_values           | 0.953       |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 8910        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.469       |
|    value_loss            | 27.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -1.0674813  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -941        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 370         |
|    total_timesteps       | 1828864     |
| train/                   |             |
|    approx_kl             | 0.010239401 |
|    clip_fraction         | 0.043       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.867       |
|    cost_value_loss       | 0.242       |
|    cost_values           | 0.878       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 8920        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.473       |
|    value_loss            | 19.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.69615316 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -943        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 404         |
|    total_timesteps       | 1830912     |
| train/                   |             |
|    approx_kl             | 0.001015746 |
|    clip_fraction         | 0.000342    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.955       |
|    cost_value_loss       | 0.625       |
|    cost_values           | 0.913       |
|    entropy               | -1.35       |
|    entropy_loss          | -1.34       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.1        |
|    n_updates             | 8930        |
|    policy_gradient_loss  | 8.44e-05    |
|    std                   | 0.475       |
|    value_loss            | 36.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2911975   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -938         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 1832960      |
| train/                   |              |
|    approx_kl             | 0.0044736024 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.87         |
|    cost_value_loss       | 0.0897       |
|    cost_values           | 0.88         |
|    entropy               | -1.34        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.52         |
|    n_updates             | 8940         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.473        |
|    value_loss            | 8.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.79         |
| reward                   | -0.5646996   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -934         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 1835008      |
| train/                   |              |
|    approx_kl             | 0.0044886917 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 3.61         |
|    cost_values           | 0.964        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 8950         |
|    policy_gradient_loss  | -0.00094     |
|    std                   | 0.472        |
|    value_loss            | 30.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.7          |
| reward                   | -0.7441331   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 507          |
|    total_timesteps       | 1837056      |
| train/                   |              |
|    approx_kl             | 0.0011407239 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 0.998        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.4         |
|    n_updates             | 8960         |
|    policy_gradient_loss  | -0.000425    |
|    std                   | 0.472        |
|    value_loss            | 63.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.43        |
| reward                   | -0.83414704 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -936        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 542         |
|    total_timesteps       | 1839104     |
| train/                   |             |
|    approx_kl             | 0.001563489 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.917       |
|    cost_value_loss       | 0.291       |
|    cost_values           | 0.966       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.77        |
|    n_updates             | 8970        |
|    policy_gradient_loss  | -0.000559   |
|    std                   | 0.472       |
|    value_loss            | 13.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.95        |
| reward                   | -0.7723737  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -936        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 576         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.003373889 |
|    clip_fraction         | 0.0114      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.795       |
|    cost_value_loss       | 0.0497      |
|    cost_values           | 0.845       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.94        |
|    n_updates             | 8980        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.472       |
|    value_loss            | 6.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9677993   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 1843200      |
| train/                   |              |
|    approx_kl             | 0.0016453603 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.64         |
|    cost_value_loss       | 0.0173       |
|    cost_values           | 0.756        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.1         |
|    n_updates             | 8990         |
|    policy_gradient_loss  | -0.000547    |
|    std                   | 0.472        |
|    value_loss            | 47.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -0.58665633  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1845248      |
| train/                   |              |
|    approx_kl             | 0.0014578229 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.24         |
|    cost_values           | 0.768        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 9000         |
|    policy_gradient_loss  | -0.000884    |
|    std                   | 0.473        |
|    value_loss            | 29.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.27        |
| reward                   | -0.8140461  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -933        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 680         |
|    total_timesteps       | 1847296     |
| train/                   |             |
|    approx_kl             | 0.004300851 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.925       |
|    cost_value_loss       | 0.55        |
|    cost_values           | 0.901       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.61        |
|    n_updates             | 9010        |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.473       |
|    value_loss            | 13.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0463309   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -927         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 714          |
|    total_timesteps       | 1849344      |
| train/                   |              |
|    approx_kl             | 0.0049095238 |
|    clip_fraction         | 0.00923      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.9          |
|    cost_value_loss       | 0.456        |
|    cost_values           | 0.918        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 9020         |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.472        |
|    value_loss            | 22.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.296        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.296        |
| reward                   | -0.8446355   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -920         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 1851392      |
| train/                   |              |
|    approx_kl             | 0.0018584111 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 2.93         |
|    cost_values           | 0.981        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 9030         |
|    policy_gradient_loss  | -0.000745    |
|    std                   | 0.472        |
|    value_loss            | 23.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.157        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.157        |
| reward                   | -0.7647831   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 783          |
|    total_timesteps       | 1853440      |
| train/                   |              |
|    approx_kl             | 0.0067431736 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.945        |
|    cost_values           | 0.999        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 9040         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.473        |
|    value_loss            | 53.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.58         |
| reward                   | -0.67004657  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -912         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 818          |
|    total_timesteps       | 1855488      |
| train/                   |              |
|    approx_kl             | 0.0025434066 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.812        |
|    cost_value_loss       | 0.0147       |
|    cost_values           | 0.878        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.94         |
|    n_updates             | 9050         |
|    policy_gradient_loss  | -0.000435    |
|    std                   | 0.472        |
|    value_loss            | 6.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.234        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.234        |
| reward                   | -0.73547566  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -905         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 1857536      |
| train/                   |              |
|    approx_kl             | 0.0037643919 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.653        |
|    cost_value_loss       | 0.0159       |
|    cost_values           | 0.752        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.374        |
|    n_updates             | 9060         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.471        |
|    value_loss            | 2.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.68         |
| reward                   | -0.5961344   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -906         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 1859584      |
| train/                   |              |
|    approx_kl             | 0.0043816473 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.531        |
|    cost_value_loss       | 0.00689      |
|    cost_values           | 0.571        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.9          |
|    n_updates             | 9070         |
|    policy_gradient_loss  | -0.000253    |
|    std                   | 0.471        |
|    value_loss            | 6.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.67        |
| reward                   | -0.96396756 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -906        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 921         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.006467097 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.915       |
|    cost_value_loss       | 2.73        |
|    cost_values           | 0.73        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 9080        |
|    policy_gradient_loss  | -0.000634   |
|    std                   | 0.47        |
|    value_loss            | 6.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.37         |
| reward                   | -0.84067345  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -900         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1863680      |
| train/                   |              |
|    approx_kl             | 0.0050967215 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 1.73         |
|    cost_values           | 1.2          |
|    entropy               | -1.31        |
|    entropy_loss          | -1.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.48         |
|    n_updates             | 9090         |
|    policy_gradient_loss  | 3.75e-05     |
|    std                   | 0.466        |
|    value_loss            | 3.24         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.65          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.65          |
| reward                   | -0.56073415   |
| rollout/                 |               |
|    ep_len_mean           | 983           |
|    ep_rew_mean           | -905          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 29            |
|    time_elapsed          | 990           |
|    total_timesteps       | 1865728       |
| train/                   |               |
|    approx_kl             | 0.00059925206 |
|    clip_fraction         | 0.0062        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.07          |
|    cost_value_loss       | 0.02          |
|    cost_values           | 1.09          |
|    entropy               | -1.29         |
|    entropy_loss          | -1.3          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 2.85          |
|    n_updates             | 9100          |
|    policy_gradient_loss  | -0.000312     |
|    std                   | 0.462         |
|    value_loss            | 5.64          |
--------------------------------------------
------------------------------------------
| avg_speed                | 4.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.48        |
| reward                   | -0.8590015  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -904        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1024        |
|    total_timesteps       | 1867776     |
| train/                   |             |
|    approx_kl             | 0.003635452 |
|    clip_fraction         | 0.00537     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 2.46        |
|    cost_values           | 0.991       |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 9110        |
|    policy_gradient_loss  | -0.000719   |
|    std                   | 0.462       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.76931673 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -905        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 1869824     |
| train/                   |             |
|    approx_kl             | 0.007432224 |
|    clip_fraction         | 0.0432      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.852       |
|    cost_value_loss       | 0.0175      |
|    cost_values           | 0.875       |
|    entropy               | -1.28       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 9120        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.46        |
|    value_loss            | 3.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.7946542  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -900        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1094        |
|    total_timesteps       | 1871872     |
| train/                   |             |
|    approx_kl             | 0.004859584 |
|    clip_fraction         | 0.0256      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.828       |
|    cost_value_loss       | 0.194       |
|    cost_values           | 0.839       |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.93        |
|    n_updates             | 9130        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.461       |
|    value_loss            | 5.42        |
------------------------------------------
--------------------------------------------
| avg_speed                | 7.92          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.92          |
| reward                   | -0.8712084    |
| rollout/                 |               |
|    ep_len_mean           | 983           |
|    ep_rew_mean           | -898          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 33            |
|    time_elapsed          | 1129          |
|    total_timesteps       | 1873920       |
| train/                   |               |
|    approx_kl             | 0.00025777417 |
|    clip_fraction         | 0.019         |
|    clip_range            | 0.2           |
|    cost_returns          | 1.22          |
|    cost_value_loss       | 1.67          |
|    cost_values           | 1.11          |
|    entropy               | -1.29         |
|    entropy_loss          | -1.29         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.84          |
|    n_updates             | 9140          |
|    policy_gradient_loss  | -0.00104      |
|    std                   | 0.461         |
|    value_loss            | 8.59          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6487194   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 1875968      |
| train/                   |              |
|    approx_kl             | 0.0018545843 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 1.72         |
|    cost_values           | 1.04         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 9150         |
|    policy_gradient_loss  | 0.00069      |
|    std                   | 0.461        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.7218228  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -891        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1198        |
|    total_timesteps       | 1878016     |
| train/                   |             |
|    approx_kl             | 0.003081274 |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.964       |
|    cost_value_loss       | 0.0371      |
|    cost_values           | 1.01        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.62        |
|    n_updates             | 9160        |
|    policy_gradient_loss  | -0.000923   |
|    std                   | 0.462       |
|    value_loss            | 3.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.8743534   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1233         |
|    total_timesteps       | 1880064      |
| train/                   |              |
|    approx_kl             | 0.0047656866 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.22         |
|    cost_values           | 1.01         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.64         |
|    n_updates             | 9170         |
|    policy_gradient_loss  | -0.000393    |
|    std                   | 0.462        |
|    value_loss            | 4.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.1558499  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -889        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1267        |
|    total_timesteps       | 1882112     |
| train/                   |             |
|    approx_kl             | 0.005562663 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 3.08        |
|    cost_values           | 1.32        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 9180        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.461       |
|    value_loss            | 8.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0830498   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -887         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1302         |
|    total_timesteps       | 1884160      |
| train/                   |              |
|    approx_kl             | 0.0019537227 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.124        |
|    cost_values           | 1.51         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 9190         |
|    policy_gradient_loss  | -0.000411    |
|    std                   | 0.461        |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2050189  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -885        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1336        |
|    total_timesteps       | 1886208     |
| train/                   |             |
|    approx_kl             | 0.003840609 |
|    clip_fraction         | 0.00283     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 0.0416      |
|    cost_values           | 1.07        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 9200        |
|    policy_gradient_loss  | -0.000625   |
|    std                   | 0.46        |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.6694819   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -883         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1371         |
|    total_timesteps       | 1888256      |
| train/                   |              |
|    approx_kl             | 0.0014065795 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.889        |
|    cost_value_loss       | 0.16         |
|    cost_values           | 0.924        |
|    entropy               | -1.27        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 9210         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.458        |
|    value_loss            | 14.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -1.0928873  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -876        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1405        |
|    total_timesteps       | 1890304     |
| train/                   |             |
|    approx_kl             | 0.002283434 |
|    clip_fraction         | 0.00391     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.731       |
|    cost_value_loss       | 0.0207      |
|    cost_values           | 0.831       |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 9220        |
|    policy_gradient_loss  | -0.000221   |
|    std                   | 0.457       |
|    value_loss            | 6.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.8167476  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -874        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1440        |
|    total_timesteps       | 1892352     |
| train/                   |             |
|    approx_kl             | 0.003990164 |
|    clip_fraction         | 0.0262      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.732       |
|    cost_value_loss       | 0.768       |
|    cost_values           | 0.713       |
|    entropy               | -1.26       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.63        |
|    n_updates             | 9230        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.454       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.55197334 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -871        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1475        |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.006629889 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.783       |
|    cost_value_loss       | 0.813       |
|    cost_values           | 0.762       |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 9240        |
|    policy_gradient_loss  | -4.19e-05   |
|    std                   | 0.454       |
|    value_loss            | 7.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.794        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.794        |
| reward                   | -0.817175    |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -857         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1509         |
|    total_timesteps       | 1896448      |
| train/                   |              |
|    approx_kl             | 0.0048629134 |
|    clip_fraction         | 0.0386       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.741        |
|    cost_value_loss       | 0.193        |
|    cost_values           | 0.754        |
|    entropy               | -1.25        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.51         |
|    n_updates             | 9250         |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.453        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.76         |
| reward                   | -0.74184567  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -853         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1543         |
|    total_timesteps       | 1898496      |
| train/                   |              |
|    approx_kl             | 0.0016901908 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.861        |
|    cost_value_loss       | 0.802        |
|    cost_values           | 0.766        |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 9260         |
|    policy_gradient_loss  | 0.00136      |
|    std                   | 0.453        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -0.691699    |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -844         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1578         |
|    total_timesteps       | 1900544      |
| train/                   |              |
|    approx_kl             | 0.0076605305 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.977        |
|    cost_value_loss       | 1.52         |
|    cost_values           | 0.939        |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 9270         |
|    policy_gradient_loss  | -0.000853    |
|    std                   | 0.451        |
|    value_loss            | 5.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5            |
| reward                   | -0.6053588   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1613         |
|    total_timesteps       | 1902592      |
| train/                   |              |
|    approx_kl             | 0.0033950363 |
|    clip_fraction         | 0.0815       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 5.48         |
|    cost_values           | 1.1          |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 9280         |
|    policy_gradient_loss  | -0.000207    |
|    std                   | 0.451        |
|    value_loss            | 8.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.67172754 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -827        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1648        |
|    total_timesteps       | 1904640     |
| train/                   |             |
|    approx_kl             | 0.003103581 |
|    clip_fraction         | 0.00195     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 0.835       |
|    cost_values           | 1.09        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 9290        |
|    policy_gradient_loss  | -0.000857   |
|    std                   | 0.451       |
|    value_loss            | 34.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.88014954  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1682         |
|    total_timesteps       | 1906688      |
| train/                   |              |
|    approx_kl             | 0.0060618473 |
|    clip_fraction         | 0.0728       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.922        |
|    cost_value_loss       | 0.486        |
|    cost_values           | 0.927        |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 9300         |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 0.452        |
|    value_loss            | 8.01         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.42764035 |
| rollout/           |             |
|    ep_len_mean     | 991         |
|    ep_rew_mean     | -823        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1908736     |
------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.033181    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1910784      |
| train/                   |              |
|    approx_kl             | 0.0031912061 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.625        |
|    cost_value_loss       | 0.00885      |
|    cost_values           | 0.657        |
|    entropy               | -1.24        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.67         |
|    n_updates             | 9320         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.45         |
|    value_loss            | 4.94         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.91          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.91          |
| reward                   | -0.94620764   |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -808          |
| time/                    |               |
|    fps                   | 65            |
|    iterations            | 3             |
|    time_elapsed          | 93            |
|    total_timesteps       | 1912832       |
| train/                   |               |
|    approx_kl             | 0.00018945357 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.16          |
|    cost_value_loss       | 6.28          |
|    cost_values           | 0.864         |
|    entropy               | -1.24         |
|    entropy_loss          | -1.24         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.3           |
|    n_updates             | 9330          |
|    policy_gradient_loss  | 8.46e-06      |
|    std                   | 0.449         |
|    value_loss            | 11.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.90341485  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -802         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1914880      |
| train/                   |              |
|    approx_kl             | 0.0056983484 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.91         |
|    cost_value_loss       | 0.0227       |
|    cost_values           | 0.956        |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 9340         |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.449        |
|    value_loss            | 13.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.8898533   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1916928      |
| train/                   |              |
|    approx_kl             | 0.0015920763 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 3.85         |
|    cost_values           | 1.09         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 9350         |
|    policy_gradient_loss  | -9.42e-05    |
|    std                   | 0.449        |
|    value_loss            | 6.9          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80243236 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -796        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.006293212 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.0399      |
|    cost_values           | 1.17        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 9360        |
|    policy_gradient_loss  | -0.000978   |
|    std                   | 0.45        |
|    value_loss            | 8.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.96235156 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 1921024     |
| train/                   |             |
|    approx_kl             | 0.003649504 |
|    clip_fraction         | 0.00845     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.844       |
|    cost_value_loss       | 0.124       |
|    cost_values           | 0.895       |
|    entropy               | -1.23       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 9370        |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.449       |
|    value_loss            | 5.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1315796  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 1923072     |
| train/                   |             |
|    approx_kl             | 0.005251035 |
|    clip_fraction         | 0.0296      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 3.77        |
|    cost_values           | 1.12        |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.07        |
|    n_updates             | 9380        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.447       |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.47039297  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 1925120      |
| train/                   |              |
|    approx_kl             | 0.0030497888 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.0245       |
|    cost_values           | 1.09         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.25         |
|    n_updates             | 9390         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.446        |
|    value_loss            | 8.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8459809   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 1927168      |
| train/                   |              |
|    approx_kl             | 0.0021063527 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 4.79         |
|    cost_values           | 1.28         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.9          |
|    n_updates             | 9400         |
|    policy_gradient_loss  | -0.000275    |
|    std                   | 0.446        |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.2418952  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -780        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 1929216     |
| train/                   |             |
|    approx_kl             | 0.003793468 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 1.36        |
|    cost_values           | 1.59        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.3         |
|    n_updates             | 9410        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.445       |
|    value_loss            | 8.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.48390818  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 1931264      |
| train/                   |              |
|    approx_kl             | 0.0052590817 |
|    clip_fraction         | 0.0596       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 0.0414       |
|    cost_values           | 1.36         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.28         |
|    n_updates             | 9420         |
|    policy_gradient_loss  | -0.0049      |
|    std                   | 0.445        |
|    value_loss            | 14.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.9790075   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 1933312      |
| train/                   |              |
|    approx_kl             | 0.0055344356 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 13           |
|    cost_values           | 1.22         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 9430         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.445        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.9159318  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 473         |
|    total_timesteps       | 1935360     |
| train/                   |             |
|    approx_kl             | 0.004748238 |
|    clip_fraction         | 0.00923     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 2.31        |
|    cost_values           | 1.48        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 9440        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.445       |
|    value_loss            | 11.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0346694   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 507          |
|    total_timesteps       | 1937408      |
| train/                   |              |
|    approx_kl             | 0.0067112027 |
|    clip_fraction         | 0.0331       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.684        |
|    cost_values           | 1.29         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.22        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 9450         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.444        |
|    value_loss            | 35.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4474839   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 1939456      |
| train/                   |              |
|    approx_kl             | 0.0031641135 |
|    clip_fraction         | 0.00688      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.0272       |
|    cost_values           | 1.11         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.91         |
|    n_updates             | 9460         |
|    policy_gradient_loss  | -0.000421    |
|    std                   | 0.443        |
|    value_loss            | 6.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.78         |
| reward                   | -0.73005027  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 1941504      |
| train/                   |              |
|    approx_kl             | 0.0044078194 |
|    clip_fraction         | 0.00811      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.31         |
|    cost_values           | 0.909        |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.33         |
|    n_updates             | 9470         |
|    policy_gradient_loss  | -0.000903    |
|    std                   | 0.443        |
|    value_loss            | 9.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.8863524   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 611          |
|    total_timesteps       | 1943552      |
| train/                   |              |
|    approx_kl             | 0.0027256957 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 0.925        |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 9480         |
|    policy_gradient_loss  | -0.00079     |
|    std                   | 0.444        |
|    value_loss            | 39.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0461226  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 646         |
|    total_timesteps       | 1945600     |
| train/                   |             |
|    approx_kl             | 0.003248556 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 4.23        |
|    cost_values           | 1.13        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.1         |
|    n_updates             | 9490        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.443       |
|    value_loss            | 7.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.46224305  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 1947648      |
| train/                   |              |
|    approx_kl             | 0.0009442499 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 1.73         |
|    cost_values           | 1.44         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.7          |
|    n_updates             | 9500         |
|    policy_gradient_loss  | -0.000426    |
|    std                   | 0.441        |
|    value_loss            | 9.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.682384    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 1949696      |
| train/                   |              |
|    approx_kl             | 0.0017851661 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 0.512        |
|    cost_values           | 1.36         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.9         |
|    n_updates             | 9510         |
|    policy_gradient_loss  | 2.5e-05      |
|    std                   | 0.441        |
|    value_loss            | 47.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.48590168  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 1951744      |
| train/                   |              |
|    approx_kl             | 0.0024117331 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 7.18         |
|    cost_values           | 1.18         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.25         |
|    n_updates             | 9520         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.441        |
|    value_loss            | 14.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.93452436 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 784         |
|    total_timesteps       | 1953792     |
| train/                   |             |
|    approx_kl             | 0.003880252 |
|    clip_fraction         | 0.0243      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 2.44        |
|    cost_values           | 1.28        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 9530        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.44        |
|    value_loss            | 5.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8373224   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 818          |
|    total_timesteps       | 1955840      |
| train/                   |              |
|    approx_kl             | 0.0052329665 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.605        |
|    cost_values           | 1.33         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 9540         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.44         |
|    value_loss            | 9.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7185541  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 852         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.004887691 |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 2.6         |
|    cost_values           | 1.21        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.16        |
|    n_updates             | 9550        |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.439       |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.61190706  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 1959936      |
| train/                   |              |
|    approx_kl             | 0.0045855874 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.0385       |
|    cost_values           | 1.23         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 9560         |
|    policy_gradient_loss  | -0.000474    |
|    std                   | 0.438        |
|    value_loss            | 9.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.62         |
| reward                   | -0.75671506  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 921          |
|    total_timesteps       | 1961984      |
| train/                   |              |
|    approx_kl             | 0.0039385357 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 1.98         |
|    cost_values           | 1.04         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 9570         |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.438        |
|    value_loss            | 8.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7581545   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1964032      |
| train/                   |              |
|    approx_kl             | 0.0006039479 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 4.03         |
|    cost_values           | 1.18         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 9580         |
|    policy_gradient_loss  | -0.000149    |
|    std                   | 0.437        |
|    value_loss            | 39.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.92          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.92          |
| reward                   | -1.0028887    |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -746          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 29            |
|    time_elapsed          | 991           |
|    total_timesteps       | 1966080       |
| train/                   |               |
|    approx_kl             | 0.00046661234 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.07          |
|    cost_value_loss       | 0.147         |
|    cost_values           | 1.07          |
|    entropy               | -1.18         |
|    entropy_loss          | -1.18         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.78          |
|    n_updates             | 9590          |
|    policy_gradient_loss  | 7.63e-05      |
|    std                   | 0.437         |
|    value_loss            | 7.41          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7963616  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -745        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 1968128     |
| train/                   |             |
|    approx_kl             | 0.002405292 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.853       |
|    cost_value_loss       | 0.0241      |
|    cost_values           | 0.945       |
|    entropy               | -1.17       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 9600        |
|    policy_gradient_loss  | -0.000953   |
|    std                   | 0.435       |
|    value_loss            | 9.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9906577  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 1970176     |
| train/                   |             |
|    approx_kl             | 0.005750915 |
|    clip_fraction         | 0.0405      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.773       |
|    cost_value_loss       | 0.216       |
|    cost_values           | 0.79        |
|    entropy               | -1.18       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 9610        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.436       |
|    value_loss            | 19.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8428328   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1094         |
|    total_timesteps       | 1972224      |
| train/                   |              |
|    approx_kl             | 0.0016756306 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.674        |
|    cost_value_loss       | 0.0578       |
|    cost_values           | 0.719        |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.45         |
|    n_updates             | 9620         |
|    policy_gradient_loss  | -0.000189    |
|    std                   | 0.437        |
|    value_loss            | 7.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8643291  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -747        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 1974272     |
| train/                   |             |
|    approx_kl             | 0.003782139 |
|    clip_fraction         | 0.0123      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.543       |
|    cost_value_loss       | 0.0106      |
|    cost_values           | 0.627       |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.54        |
|    n_updates             | 9630        |
|    policy_gradient_loss  | -0.000448   |
|    std                   | 0.437       |
|    value_loss            | 18          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9423702  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1163        |
|    total_timesteps       | 1976320     |
| train/                   |             |
|    approx_kl             | 0.004200321 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.875       |
|    cost_value_loss       | 2.07        |
|    cost_values           | 0.686       |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.1         |
|    n_updates             | 9640        |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.436       |
|    value_loss            | 4.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.0151209   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1197         |
|    total_timesteps       | 1978368      |
| train/                   |              |
|    approx_kl             | 0.0033156935 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.748        |
|    cost_value_loss       | 0.0766       |
|    cost_values           | 0.9          |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.37         |
|    n_updates             | 9650         |
|    policy_gradient_loss  | -0.000842    |
|    std                   | 0.435        |
|    value_loss            | 8.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.81627005 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1232        |
|    total_timesteps       | 1980416     |
| train/                   |             |
|    approx_kl             | 0.003973539 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.949       |
|    cost_value_loss       | 1.1         |
|    cost_values           | 0.91        |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2           |
|    n_updates             | 9660        |
|    policy_gradient_loss  | -0.000503   |
|    std                   | 0.435       |
|    value_loss            | 2.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0018158   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1268         |
|    total_timesteps       | 1982464      |
| train/                   |              |
|    approx_kl             | 0.0038866038 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.389        |
|    cost_values           | 0.994        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.43         |
|    n_updates             | 9670         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.435        |
|    value_loss            | 7.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4764634  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1304        |
|    total_timesteps       | 1984512     |
| train/                   |             |
|    approx_kl             | 0.003656125 |
|    clip_fraction         | 0.0428      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.888       |
|    cost_value_loss       | 0.125       |
|    cost_values           | 0.902       |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.68        |
|    n_updates             | 9680        |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.436       |
|    value_loss            | 5.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42768314  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1339         |
|    total_timesteps       | 1986560      |
| train/                   |              |
|    approx_kl             | 0.0015035649 |
|    clip_fraction         | 0.00859      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.913        |
|    cost_value_loss       | 0.234        |
|    cost_values           | 0.905        |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.32         |
|    n_updates             | 9690         |
|    policy_gradient_loss  | -0.000131    |
|    std                   | 0.437        |
|    value_loss            | 5.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.1230085   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1374         |
|    total_timesteps       | 1988608      |
| train/                   |              |
|    approx_kl             | 0.0036335988 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 0.939        |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.92         |
|    n_updates             | 9700         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.436        |
|    value_loss            | 6.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.91634196  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1410         |
|    total_timesteps       | 1990656      |
| train/                   |              |
|    approx_kl             | 0.0053779795 |
|    clip_fraction         | 0.0415       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.811        |
|    cost_value_loss       | 0.0209       |
|    cost_values           | 0.921        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.58         |
|    n_updates             | 9710         |
|    policy_gradient_loss  | -0.00351     |
|    std                   | 0.436        |
|    value_loss            | 8.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1205792   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 1992704      |
| train/                   |              |
|    approx_kl             | 0.0039048712 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.67         |
|    cost_value_loss       | 0.0134       |
|    cost_values           | 0.764        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.92         |
|    n_updates             | 9720         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.435        |
|    value_loss            | 6.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6587723  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1479        |
|    total_timesteps       | 1994752     |
| train/                   |             |
|    approx_kl             | 0.004557616 |
|    clip_fraction         | 0.0281      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.599       |
|    cost_value_loss       | 0.0204      |
|    cost_values           | 0.617       |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.81        |
|    n_updates             | 9730        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.435       |
|    value_loss            | 7.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0315744   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1514         |
|    total_timesteps       | 1996800      |
| train/                   |              |
|    approx_kl             | 0.0065552453 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 3.95         |
|    cost_values           | 0.895        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.3         |
|    n_updates             | 9740         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.435        |
|    value_loss            | 43.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8733937   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1549         |
|    total_timesteps       | 1998848      |
| train/                   |              |
|    approx_kl             | 0.0033444774 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 1.51         |
|    cost_values           | 1.44         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.17         |
|    n_updates             | 9750         |
|    policy_gradient_loss  | -0.000618    |
|    std                   | 0.433        |
|    value_loss            | 12.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3547809   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1584         |
|    total_timesteps       | 2000896      |
| train/                   |              |
|    approx_kl             | 0.0038066772 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 1.58         |
|    cost_values           | 1.42         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 9760         |
|    policy_gradient_loss  | -0.000985    |
|    std                   | 0.433        |
|    value_loss            | 38.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7151614   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1618         |
|    total_timesteps       | 2002944      |
| train/                   |              |
|    approx_kl             | 0.0036808446 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 4.11         |
|    cost_values           | 1.5          |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.28         |
|    n_updates             | 9770         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.433        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7024669  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1653        |
|    total_timesteps       | 2004992     |
| train/                   |             |
|    approx_kl             | 0.006169095 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 4.41        |
|    cost_values           | 1.81        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 9780        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.433       |
|    value_loss            | 31.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85184085  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1687         |
|    total_timesteps       | 2007040      |
| train/                   |              |
|    approx_kl             | 0.0010099405 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 1.26         |
|    cost_values           | 1.76         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.5         |
|    n_updates             | 9790         |
|    policy_gradient_loss  | -0.000146    |
|    std                   | 0.433        |
|    value_loss            | 44.7         |
-------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.95082885 |
| rollout/           |             |
|    ep_len_mean     | 971         |
|    ep_rew_mean     | -747        |
| time/              |             |
|    fps             | 82          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2009088     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91593814  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2011136      |
| train/                   |              |
|    approx_kl             | 0.0033029355 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 1.79         |
|    cost_values           | 1.65         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 9810         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.432        |
|    value_loss            | 21.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.1644334 |
| rollout/                 |            |
|    ep_len_mean           | 971        |
|    ep_rew_mean           | -751       |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 3          |
|    time_elapsed          | 94         |
|    total_timesteps       | 2013184    |
| train/                   |            |
|    approx_kl             | 0.00538261 |
|    clip_fraction         | 0.0562     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.6        |
|    cost_value_loss       | 0.248      |
|    cost_values           | 1.59       |
|    entropy               | -1.17      |
|    entropy_loss          | -1.16      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.76       |
|    n_updates             | 9820       |
|    policy_gradient_loss  | -0.00314   |
|    std                   | 0.434      |
|    value_loss            | 3.55       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.6697003   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2015232      |
| train/                   |              |
|    approx_kl             | 0.0010299978 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 0.0508       |
|    cost_values           | 1.4          |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.01         |
|    n_updates             | 9830         |
|    policy_gradient_loss  | -0.000147    |
|    std                   | 0.434        |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.82191724  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 2017280      |
| train/                   |              |
|    approx_kl             | 0.0056351866 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 4.89         |
|    cost_values           | 1.16         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 9840         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.435        |
|    value_loss            | 23.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.97378236  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2019328      |
| train/                   |              |
|    approx_kl             | 0.0050595775 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 3.16         |
|    cost_values           | 1.38         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.38         |
|    n_updates             | 9850         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.435        |
|    value_loss            | 3.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7801462   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 233          |
|    total_timesteps       | 2021376      |
| train/                   |              |
|    approx_kl             | 0.0030275285 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.0622       |
|    cost_values           | 1.38         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.13         |
|    n_updates             | 9860         |
|    policy_gradient_loss  | -0.000151    |
|    std                   | 0.434        |
|    value_loss            | 4.08         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.46580166   |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -745          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 8             |
|    time_elapsed          | 268           |
|    total_timesteps       | 2023424       |
| train/                   |               |
|    approx_kl             | 0.00011285684 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.15          |
|    cost_value_loss       | 0.171         |
|    cost_values           | 1.11          |
|    entropy               | -1.17         |
|    entropy_loss          | -1.17         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.9           |
|    n_updates             | 9870          |
|    policy_gradient_loss  | 0.000494      |
|    std                   | 0.434         |
|    value_loss            | 14.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0751776   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 2025472      |
| train/                   |              |
|    approx_kl             | 0.0066078776 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 1.15         |
|    cost_values           | 1            |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 9880         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.434        |
|    value_loss            | 34.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0216589   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 2027520      |
| train/                   |              |
|    approx_kl             | 0.0021175593 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.825        |
|    cost_value_loss       | 0.0166       |
|    cost_values           | 0.902        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.56         |
|    n_updates             | 9890         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.434        |
|    value_loss            | 5.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.98586816  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 2029568      |
| train/                   |              |
|    approx_kl             | 0.0017431898 |
|    clip_fraction         | 0.00488      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.661        |
|    cost_value_loss       | 0.0219       |
|    cost_values           | 0.795        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 9900         |
|    policy_gradient_loss  | 0.00164      |
|    std                   | 0.434        |
|    value_loss            | 26.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6847792   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 2031616      |
| train/                   |              |
|    approx_kl             | 0.0032869566 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.742        |
|    cost_value_loss       | 0.15         |
|    cost_values           | 0.746        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.93         |
|    n_updates             | 9910         |
|    policy_gradient_loss  | -7.99e-05    |
|    std                   | 0.434        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.7690934   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 2033664      |
| train/                   |              |
|    approx_kl             | 0.0031510815 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 1.07         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.49         |
|    n_updates             | 9920         |
|    policy_gradient_loss  | -0.000559    |
|    std                   | 0.435        |
|    value_loss            | 4.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.36637986 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 474         |
|    total_timesteps       | 2035712     |
| train/                   |             |
|    approx_kl             | 0.00322445  |
|    clip_fraction         | 0.021       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.77        |
|    cost_value_loss       | 3.39        |
|    cost_values           | 1.2         |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.83        |
|    n_updates             | 9930        |
|    policy_gradient_loss  | -0.000542   |
|    std                   | 0.435       |
|    value_loss            | 4.59        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.73340535   |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -758          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 15            |
|    time_elapsed          | 509           |
|    total_timesteps       | 2037760       |
| train/                   |               |
|    approx_kl             | 0.00068016443 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.71          |
|    cost_value_loss       | 2.54          |
|    cost_values           | 1.19          |
|    entropy               | -1.17         |
|    entropy_loss          | -1.17         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.94          |
|    n_updates             | 9940          |
|    policy_gradient_loss  | -0.000311     |
|    std                   | 0.435         |
|    value_loss            | 18.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.852307    |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 2039808      |
| train/                   |              |
|    approx_kl             | 0.0022562654 |
|    clip_fraction         | 0.00244      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 4.45         |
|    cost_values           | 1.27         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.09         |
|    n_updates             | 9950         |
|    policy_gradient_loss  | -0.000356    |
|    std                   | 0.435        |
|    value_loss            | 12.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.1          |
| reward                   | -0.72608435  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 578          |
|    total_timesteps       | 2041856      |
| train/                   |              |
|    approx_kl             | 0.0021233645 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 0.13         |
|    cost_values           | 1.45         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.75         |
|    n_updates             | 9960         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.435        |
|    value_loss            | 8.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.22         |
| reward                   | -0.87673545  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 612          |
|    total_timesteps       | 2043904      |
| train/                   |              |
|    approx_kl             | 0.0018355288 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.382        |
|    cost_values           | 1.08         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.96         |
|    n_updates             | 9970         |
|    policy_gradient_loss  | -0.000274    |
|    std                   | 0.435        |
|    value_loss            | 5.94         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.65917325   |
| rollout/                 |               |
|    ep_len_mean           | 974           |
|    ep_rew_mean           | -759          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 19            |
|    time_elapsed          | 647           |
|    total_timesteps       | 2045952       |
| train/                   |               |
|    approx_kl             | 0.00030443474 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.795         |
|    cost_value_loss       | 0.0249        |
|    cost_values           | 0.93          |
|    entropy               | -1.17         |
|    entropy_loss          | -1.17         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.31          |
|    n_updates             | 9980          |
|    policy_gradient_loss  | -2.22e-05     |
|    std                   | 0.435         |
|    value_loss            | 3.83          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66735345  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 681          |
|    total_timesteps       | 2048000      |
| train/                   |              |
|    approx_kl             | 0.0010268432 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.701        |
|    cost_value_loss       | 0.0147       |
|    cost_values           | 0.799        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.06         |
|    n_updates             | 9990         |
|    policy_gradient_loss  | -0.000158    |
|    std                   | 0.436        |
|    value_loss            | 5.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.5967281  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -763        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 715         |
|    total_timesteps       | 2050048     |
| train/                   |             |
|    approx_kl             | 0.004177581 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.616       |
|    cost_value_loss       | 0.00905     |
|    cost_values           | 0.674       |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.58        |
|    n_updates             | 10000       |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.434       |
|    value_loss            | 3.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7852102   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 2052096      |
| train/                   |              |
|    approx_kl             | 0.0039039224 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.635        |
|    cost_value_loss       | 0.33         |
|    cost_values           | 0.615        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 10010        |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.433        |
|    value_loss            | 6.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9317275   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 783          |
|    total_timesteps       | 2054144      |
| train/                   |              |
|    approx_kl             | 0.0053138738 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.571        |
|    cost_value_loss       | 0.0847       |
|    cost_values           | 0.617        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 10020        |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.433        |
|    value_loss            | 7.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6026097   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 818          |
|    total_timesteps       | 2056192      |
| train/                   |              |
|    approx_kl             | 0.0029790183 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.588        |
|    cost_value_loss       | 0.198        |
|    cost_values           | 0.589        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.46         |
|    n_updates             | 10030        |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.432        |
|    value_loss            | 3.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.75911087  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 853          |
|    total_timesteps       | 2058240      |
| train/                   |              |
|    approx_kl             | 0.0027682926 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 3.96         |
|    cost_values           | 0.907        |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.19         |
|    n_updates             | 10040        |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.43         |
|    value_loss            | 6.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.23082836  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 2060288      |
| train/                   |              |
|    approx_kl             | 0.0036174753 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.0621       |
|    cost_values           | 1.02         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.21         |
|    n_updates             | 10050        |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.436        |
|    value_loss            | 4.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5388227   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 922          |
|    total_timesteps       | 2062336      |
| train/                   |              |
|    approx_kl             | 0.0009774361 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 0.411        |
|    cost_values           | 0.995        |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.73         |
|    n_updates             | 10060        |
|    policy_gradient_loss  | 0.000617     |
|    std                   | 0.437        |
|    value_loss            | 8.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.74532515  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 957          |
|    total_timesteps       | 2064384      |
| train/                   |              |
|    approx_kl             | 0.0032272758 |
|    clip_fraction         | 0.00845      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 4.62         |
|    cost_values           | 1.23         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 10070        |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.437        |
|    value_loss            | 24.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.761065    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 992          |
|    total_timesteps       | 2066432      |
| train/                   |              |
|    approx_kl             | 0.0025775353 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 1.49         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.33         |
|    n_updates             | 10080        |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.438        |
|    value_loss            | 2.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80498314 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1026        |
|    total_timesteps       | 2068480     |
| train/                   |             |
|    approx_kl             | 0.004748287 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 2.2         |
|    cost_values           | 1.49        |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.31        |
|    n_updates             | 10090       |
|    policy_gradient_loss  | -0.000809   |
|    std                   | 0.438       |
|    value_loss            | 4.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8279071   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1061         |
|    total_timesteps       | 2070528      |
| train/                   |              |
|    approx_kl             | 0.0040783216 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 6.03         |
|    cost_values           | 1.59         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 10100        |
|    policy_gradient_loss  | -0.000585    |
|    std                   | 0.438        |
|    value_loss            | 4.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0680497   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1095         |
|    total_timesteps       | 2072576      |
| train/                   |              |
|    approx_kl             | 0.0061373897 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 0.114        |
|    cost_values           | 1.68         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 10110        |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.438        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.95706123  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1130         |
|    total_timesteps       | 2074624      |
| train/                   |              |
|    approx_kl             | 0.0055757696 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 3.91         |
|    cost_values           | 1.38         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 10120        |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.438        |
|    value_loss            | 8.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1944586   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 2076672      |
| train/                   |              |
|    approx_kl             | 0.0056484393 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 0.0372       |
|    cost_values           | 1.24         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.99         |
|    n_updates             | 10130        |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.438        |
|    value_loss            | 9.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.71110094  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1198         |
|    total_timesteps       | 2078720      |
| train/                   |              |
|    approx_kl             | 0.0035580634 |
|    clip_fraction         | 0.00273      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.617        |
|    cost_values           | 0.972        |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.26         |
|    n_updates             | 10140        |
|    policy_gradient_loss  | -0.000406    |
|    std                   | 0.438        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.415554    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1233         |
|    total_timesteps       | 2080768      |
| train/                   |              |
|    approx_kl             | 0.0018087879 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 3.82         |
|    cost_values           | 1.17         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.56         |
|    n_updates             | 10150        |
|    policy_gradient_loss  | -5.64e-05    |
|    std                   | 0.438        |
|    value_loss            | 6.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9886082   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1268         |
|    total_timesteps       | 2082816      |
| train/                   |              |
|    approx_kl             | 0.0028942814 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 1.05         |
|    cost_values           | 1.38         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 10160        |
|    policy_gradient_loss  | -0.000612    |
|    std                   | 0.438        |
|    value_loss            | 9.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.726566    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1302         |
|    total_timesteps       | 2084864      |
| train/                   |              |
|    approx_kl             | 0.0023276652 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.116        |
|    cost_values           | 1.08         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.21         |
|    n_updates             | 10170        |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.437        |
|    value_loss            | 6.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.07         |
| reward                   | -0.77420795  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 2086912      |
| train/                   |              |
|    approx_kl             | 0.0064202445 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.987        |
|    cost_value_loss       | 0.835        |
|    cost_values           | 0.984        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.63         |
|    n_updates             | 10180        |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.436        |
|    value_loss            | 4.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.94773364  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1371         |
|    total_timesteps       | 2088960      |
| train/                   |              |
|    approx_kl             | 0.0041848565 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.882        |
|    cost_value_loss       | 0.0827       |
|    cost_values           | 0.962        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 10190        |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.435        |
|    value_loss            | 10           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.857832   |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1406        |
|    total_timesteps       | 2091008     |
| train/                   |             |
|    approx_kl             | 0.007896574 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.958       |
|    cost_value_loss       | 0.775       |
|    cost_values           | 0.918       |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.5        |
|    n_updates             | 10200       |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.435       |
|    value_loss            | 36.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6729572  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1440        |
|    total_timesteps       | 2093056     |
| train/                   |             |
|    approx_kl             | 0.005439422 |
|    clip_fraction         | 0.0206      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.764       |
|    cost_value_loss       | 0.0226      |
|    cost_values           | 0.893       |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.45        |
|    n_updates             | 10210       |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.435       |
|    value_loss            | 8.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.73372304  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1474         |
|    total_timesteps       | 2095104      |
| train/                   |              |
|    approx_kl             | 0.0043698773 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.685        |
|    cost_value_loss       | 0.0148       |
|    cost_values           | 0.784        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.63         |
|    n_updates             | 10220        |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.435        |
|    value_loss            | 6.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0328974   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1508         |
|    total_timesteps       | 2097152      |
| train/                   |              |
|    approx_kl             | 0.0039063133 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.753        |
|    cost_value_loss       | 0.407        |
|    cost_values           | 0.738        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.63         |
|    n_updates             | 10230        |
|    policy_gradient_loss  | -0.000581    |
|    std                   | 0.433        |
|    value_loss            | 9.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0991418  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1543        |
|    total_timesteps       | 2099200     |
| train/                   |             |
|    approx_kl             | 0.001122883 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.748       |
|    cost_value_loss       | 0.228       |
|    cost_values           | 0.757       |
|    entropy               | -1.15       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 10240       |
|    policy_gradient_loss  | -0.000371   |
|    std                   | 0.431       |
|    value_loss            | 23.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.33         |
| reward                   | -0.576068    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1578         |
|    total_timesteps       | 2101248      |
| train/                   |              |
|    approx_kl             | 0.0014781044 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.924        |
|    cost_value_loss       | 1.17         |
|    cost_values           | 0.901        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.56         |
|    n_updates             | 10250        |
|    policy_gradient_loss  | 3.69e-05     |
|    std                   | 0.433        |
|    value_loss            | 17.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.93         |
| reward                   | -0.7396579   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1613         |
|    total_timesteps       | 2103296      |
| train/                   |              |
|    approx_kl             | 0.0007323428 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 4.27         |
|    cost_values           | 0.99         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.1          |
|    n_updates             | 10260        |
|    policy_gradient_loss  | 3.78e-05     |
|    std                   | 0.433        |
|    value_loss            | 15.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.02         |
| reward                   | -0.9236704   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1647         |
|    total_timesteps       | 2105344      |
| train/                   |              |
|    approx_kl             | 0.0054896846 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2.32         |
|    cost_values           | 1.01         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 10270        |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.433        |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.79587215  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1681         |
|    total_timesteps       | 2107392      |
| train/                   |              |
|    approx_kl             | 0.0009533092 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.825        |
|    cost_value_loss       | 0.0276       |
|    cost_values           | 0.971        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 10280        |
|    policy_gradient_loss  | -0.000306    |
|    std                   | 0.433        |
|    value_loss            | 25.5         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
-----------------------------------
| avg_speed          | 7.95       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.95       |
| reward             | -0.9006202 |
| rollout/           |            |
|    ep_len_mean     | 988        |
|    ep_rew_mean     | -771       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2109440    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81685275  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2111488      |
| train/                   |              |
|    approx_kl             | 0.0047519314 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.641        |
|    cost_value_loss       | 0.0119       |
|    cost_values           | 0.727        |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.81         |
|    n_updates             | 10300        |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.434        |
|    value_loss            | 4.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.1468986  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -761        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.004456657 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 2.05        |
|    cost_values           | 0.877       |
|    entropy               | -1.15       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 10310       |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.431       |
|    value_loss            | 11.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5429871   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 2115584      |
| train/                   |              |
|    approx_kl             | 0.0024807912 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.952        |
|    cost_value_loss       | 0.223        |
|    cost_values           | 0.944        |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.93         |
|    n_updates             | 10320        |
|    policy_gradient_loss  | 7.2e-05      |
|    std                   | 0.43         |
|    value_loss            | 6.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.82356983  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 2117632      |
| train/                   |              |
|    approx_kl             | 0.0007228343 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 9.13         |
|    cost_values           | 1.31         |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 10330        |
|    policy_gradient_loss  | -4.56e-06    |
|    std                   | 0.43         |
|    value_loss            | 30.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8731546  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -759        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 196         |
|    total_timesteps       | 2119680     |
| train/                   |             |
|    approx_kl             | 0.004877801 |
|    clip_fraction         | 0.0352      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 2.2         |
|    cost_values           | 1.85        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 10340       |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.43        |
|    value_loss            | 9.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.80359524 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -768        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 230         |
|    total_timesteps       | 2121728     |
| train/                   |             |
|    approx_kl             | 0.004163787 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.96        |
|    cost_value_loss       | 1.41        |
|    cost_values           | 1.75        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 10350       |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.43        |
|    value_loss            | 6.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.75254875 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -771        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 264         |
|    total_timesteps       | 2123776     |
| train/                   |             |
|    approx_kl             | 0.006003916 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 0.563       |
|    cost_values           | 1.54        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 10360       |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.43        |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9139015   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 2125824      |
| train/                   |              |
|    approx_kl             | 0.0022759398 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.026        |
|    cost_values           | 1.12         |
|    entropy               | -1.14        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.46         |
|    n_updates             | 10370        |
|    policy_gradient_loss  | -0.000351    |
|    std                   | 0.429        |
|    value_loss            | 5.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.65886754 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -761        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 333         |
|    total_timesteps       | 2127872     |
| train/                   |             |
|    approx_kl             | 0.004912056 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 1.44        |
|    cost_values           | 1.03        |
|    entropy               | -1.14       |
|    entropy_loss          | -1.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 10380       |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.428       |
|    value_loss            | 7.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3399481  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -763        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 367         |
|    total_timesteps       | 2129920     |
| train/                   |             |
|    approx_kl             | 0.009983441 |
|    clip_fraction         | 0.0392      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 1.46        |
|    cost_values           | 1.12        |
|    entropy               | -1.14       |
|    entropy_loss          | -1.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.28        |
|    n_updates             | 10390       |
|    policy_gradient_loss  | -0.000937   |
|    std                   | 0.428       |
|    value_loss            | 8.7         |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.7014928 |
| rollout/                 |            |
|    ep_len_mean           | 994        |
|    ep_rew_mean           | -763       |
| time/                    |            |
|    fps                   | 61         |
|    iterations            | 12         |
|    time_elapsed          | 401        |
|    total_timesteps       | 2131968    |
| train/                   |            |
|    approx_kl             | 0.00301819 |
|    clip_fraction         | 0.044      |
|    clip_range            | 0.2        |
|    cost_returns          | 1.44       |
|    cost_value_loss       | 1.14       |
|    cost_values           | 1.24       |
|    entropy               | -1.14      |
|    entropy_loss          | -1.14      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 11.7       |
|    n_updates             | 10400      |
|    policy_gradient_loss  | -5.34e-05  |
|    std                   | 0.428      |
|    value_loss            | 21.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.69002557  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 436          |
|    total_timesteps       | 2134016      |
| train/                   |              |
|    approx_kl             | 0.0038292417 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 2.34         |
|    cost_values           | 1.38         |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.61         |
|    n_updates             | 10410        |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.426        |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.624436    |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 470          |
|    total_timesteps       | 2136064      |
| train/                   |              |
|    approx_kl             | 0.0043017464 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.0875       |
|    cost_values           | 1.42         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.39         |
|    n_updates             | 10420        |
|    policy_gradient_loss  | -0.000881    |
|    std                   | 0.425        |
|    value_loss            | 7.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.81295747  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 504          |
|    total_timesteps       | 2138112      |
| train/                   |              |
|    approx_kl             | 0.0035378286 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 6.41         |
|    cost_values           | 1.21         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.34         |
|    n_updates             | 10430        |
|    policy_gradient_loss  | -0.000836    |
|    std                   | 0.425        |
|    value_loss            | 9.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3944187  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -767        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 538         |
|    total_timesteps       | 2140160     |
| train/                   |             |
|    approx_kl             | 0.003458268 |
|    clip_fraction         | 0.00259     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.24        |
|    cost_value_loss       | 0.466       |
|    cost_values           | 1.22        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 10440       |
|    policy_gradient_loss  | -0.000267   |
|    std                   | 0.424       |
|    value_loss            | 4.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7369634  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 573         |
|    total_timesteps       | 2142208     |
| train/                   |             |
|    approx_kl             | 0.003528757 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.971       |
|    cost_value_loss       | 0.324       |
|    cost_values           | 0.967       |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.42        |
|    n_updates             | 10450       |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.424       |
|    value_loss            | 15.4        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.95       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.95       |
| reward                   | -1.1842049 |
| rollout/                 |            |
|    ep_len_mean           | 994        |
|    ep_rew_mean           | -771       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 18         |
|    time_elapsed          | 607        |
|    total_timesteps       | 2144256    |
| train/                   |            |
|    approx_kl             | 0.00475024 |
|    clip_fraction         | 0.00659    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.832      |
|    cost_value_loss       | 0.0881     |
|    cost_values           | 0.925      |
|    entropy               | -1.12      |
|    entropy_loss          | -1.12      |
|    explained_variance    | 1.19e-07   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.31       |
|    n_updates             | 10460      |
|    policy_gradient_loss  | -0.000727  |
|    std                   | 0.424      |
|    value_loss            | 11.6       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 2.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.76         |
| reward                   | -0.6779398   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 642          |
|    total_timesteps       | 2146304      |
| train/                   |              |
|    approx_kl             | 0.0027722735 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.752        |
|    cost_value_loss       | 0.0516       |
|    cost_values           | 0.856        |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.28         |
|    n_updates             | 10470        |
|    policy_gradient_loss  | -0.000601    |
|    std                   | 0.424        |
|    value_loss            | 16.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.73         |
| reward                   | -0.8597609   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 676          |
|    total_timesteps       | 2148352      |
| train/                   |              |
|    approx_kl             | 0.0022323565 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 4.26         |
|    cost_values           | 0.95         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.03         |
|    n_updates             | 10480        |
|    policy_gradient_loss  | -0.000486    |
|    std                   | 0.424        |
|    value_loss            | 12.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5895193 |
| rollout/                 |            |
|    ep_len_mean           | 994        |
|    ep_rew_mean           | -773       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 21         |
|    time_elapsed          | 711        |
|    total_timesteps       | 2150400    |
| train/                   |            |
|    approx_kl             | 0.00519038 |
|    clip_fraction         | 0.0358     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.907      |
|    cost_value_loss       | 0.0515     |
|    cost_values           | 0.932      |
|    entropy               | -1.11      |
|    entropy_loss          | -1.12      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 3.64       |
|    n_updates             | 10490      |
|    policy_gradient_loss  | -0.00134   |
|    std                   | 0.421      |
|    value_loss            | 7.33       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4418781   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 745          |
|    total_timesteps       | 2152448      |
| train/                   |              |
|    approx_kl             | 0.0028067636 |
|    clip_fraction         | 0.0572       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.755        |
|    cost_value_loss       | 0.0226       |
|    cost_values           | 0.885        |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 10500        |
|    policy_gradient_loss  | -0.000883    |
|    std                   | 0.421        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6649981   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 779          |
|    total_timesteps       | 2154496      |
| train/                   |              |
|    approx_kl             | 0.0004512014 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.769        |
|    cost_value_loss       | 0.203        |
|    cost_values           | 0.811        |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.6          |
|    n_updates             | 10510        |
|    policy_gradient_loss  | -5.71e-05    |
|    std                   | 0.422        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0541952   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 814          |
|    total_timesteps       | 2156544      |
| train/                   |              |
|    approx_kl             | 0.0024882352 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.73         |
|    cost_values           | 0.943        |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 10520        |
|    policy_gradient_loss  | -0.000506    |
|    std                   | 0.422        |
|    value_loss            | 9.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.53820187  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 848          |
|    total_timesteps       | 2158592      |
| train/                   |              |
|    approx_kl             | 0.0022372128 |
|    clip_fraction         | 0.00532      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 1.7          |
|    cost_values           | 1.09         |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 10530        |
|    policy_gradient_loss  | -0.000544    |
|    std                   | 0.422        |
|    value_loss            | 8.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.7380521   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 882          |
|    total_timesteps       | 2160640      |
| train/                   |              |
|    approx_kl             | 0.0033742732 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.938        |
|    cost_value_loss       | 0.0257       |
|    cost_values           | 1.02         |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.95         |
|    n_updates             | 10540        |
|    policy_gradient_loss  | -0.000266    |
|    std                   | 0.422        |
|    value_loss            | 7.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.41921034  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -787         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 916          |
|    total_timesteps       | 2162688      |
| train/                   |              |
|    approx_kl             | 0.0057939487 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.742        |
|    cost_value_loss       | 0.0114       |
|    cost_values           | 0.783        |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.41         |
|    n_updates             | 10550        |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.421        |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9076892   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -787         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 951          |
|    total_timesteps       | 2164736      |
| train/                   |              |
|    approx_kl             | 0.0023661482 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.606        |
|    cost_value_loss       | 0.0141       |
|    cost_values           | 0.7          |
|    entropy               | -1.1         |
|    entropy_loss          | -1.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.73         |
|    n_updates             | 10560        |
|    policy_gradient_loss  | -0.000389    |
|    std                   | 0.42         |
|    value_loss            | 14.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.49518925  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 985          |
|    total_timesteps       | 2166784      |
| train/                   |              |
|    approx_kl             | 0.0018341357 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.497        |
|    cost_value_loss       | 0.00605      |
|    cost_values           | 0.548        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.56         |
|    n_updates             | 10570        |
|    policy_gradient_loss  | -0.000818    |
|    std                   | 0.419        |
|    value_loss            | 5.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5044608  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -786        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 2168832     |
| train/                   |             |
|    approx_kl             | 0.004190119 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.905       |
|    cost_value_loss       | 1.96        |
|    cost_values           | 0.667       |
|    entropy               | -1.09       |
|    entropy_loss          | -1.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.59        |
|    n_updates             | 10580       |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.418       |
|    value_loss            | 11.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67221856  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1054         |
|    total_timesteps       | 2170880      |
| train/                   |              |
|    approx_kl             | 0.0036680405 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.87         |
|    cost_values           | 1.01         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.04         |
|    n_updates             | 10590        |
|    policy_gradient_loss  | -0.000457    |
|    std                   | 0.419        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78613883  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -777         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1088         |
|    total_timesteps       | 2172928      |
| train/                   |              |
|    approx_kl             | 0.0049977927 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.988        |
|    cost_value_loss       | 0.374        |
|    cost_values           | 0.972        |
|    entropy               | -1.1         |
|    entropy_loss          | -1.09        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.26         |
|    n_updates             | 10600        |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.419        |
|    value_loss            | 8.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6336125  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -777        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1123        |
|    total_timesteps       | 2174976     |
| train/                   |             |
|    approx_kl             | 0.003111871 |
|    clip_fraction         | 0.0335      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.981       |
|    cost_value_loss       | 0.439       |
|    cost_values           | 0.975       |
|    entropy               | -1.1        |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.8         |
|    n_updates             | 10610       |
|    policy_gradient_loss  | -0.00214    |
|    std                   | 0.419       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.2529159   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1158         |
|    total_timesteps       | 2177024      |
| train/                   |              |
|    approx_kl             | 0.0043662423 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.806        |
|    cost_value_loss       | 0.0198       |
|    cost_values           | 0.914        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.06         |
|    n_updates             | 10620        |
|    policy_gradient_loss  | -0.000654    |
|    std                   | 0.419        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7718215   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -779         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1193         |
|    total_timesteps       | 2179072      |
| train/                   |              |
|    approx_kl             | 0.0039551244 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.786        |
|    cost_value_loss       | 0.253        |
|    cost_values           | 0.797        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 10630        |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.419        |
|    value_loss            | 12.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.9279475    |
| rollout/                 |               |
|    ep_len_mean           | 994           |
|    ep_rew_mean           | -780          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 36            |
|    time_elapsed          | 1228          |
|    total_timesteps       | 2181120       |
| train/                   |               |
|    approx_kl             | 0.00010291497 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.643         |
|    cost_value_loss       | 0.0162        |
|    cost_values           | 0.753         |
|    entropy               | -1.09         |
|    entropy_loss          | -1.09         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.4           |
|    n_updates             | 10640         |
|    policy_gradient_loss  | 1.2e-05       |
|    std                   | 0.418         |
|    value_loss            | 11.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.028921    |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -777         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 37           |
|    time_elapsed          | 1262         |
|    total_timesteps       | 2183168      |
| train/                   |              |
|    approx_kl             | 0.0037205121 |
|    clip_fraction         | 0.00723      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.812        |
|    cost_value_loss       | 0.633        |
|    cost_values           | 0.733        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.13         |
|    n_updates             | 10650        |
|    policy_gradient_loss  | -0.000884    |
|    std                   | 0.418        |
|    value_loss            | 6.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1117605   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1297         |
|    total_timesteps       | 2185216      |
| train/                   |              |
|    approx_kl             | 0.0025421071 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.925        |
|    cost_value_loss       | 0.971        |
|    cost_values           | 0.866        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.36         |
|    n_updates             | 10660        |
|    policy_gradient_loss  | -0.000928    |
|    std                   | 0.417        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.81661874  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1332         |
|    total_timesteps       | 2187264      |
| train/                   |              |
|    approx_kl             | 0.0047028176 |
|    clip_fraction         | 0.0438       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.768        |
|    cost_value_loss       | 0.0243       |
|    cost_values           | 0.905        |
|    entropy               | -1.08        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 10670        |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.417        |
|    value_loss            | 25.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.40530202  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1366         |
|    total_timesteps       | 2189312      |
| train/                   |              |
|    approx_kl             | 0.0028067606 |
|    clip_fraction         | 0.00947      |
|    clip_range            | 0.2          |
|    cost_returns          | 1            |
|    cost_value_loss       | 0.823        |
|    cost_values           | 0.932        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 10680        |
|    policy_gradient_loss  | -0.00084     |
|    std                   | 0.417        |
|    value_loss            | 7.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.44         |
| reward                   | -0.64464915  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1401         |
|    total_timesteps       | 2191360      |
| train/                   |              |
|    approx_kl             | 0.0015838578 |
|    clip_fraction         | 0.0686       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.37         |
|    cost_values           | 1.12         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 10690        |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.418        |
|    value_loss            | 7.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.89         |
| reward                   | -0.77060187  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1436         |
|    total_timesteps       | 2193408      |
| train/                   |              |
|    approx_kl             | 0.0034019111 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 0.0183       |
|    cost_values           | 0.958        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.46         |
|    n_updates             | 10700        |
|    policy_gradient_loss  | -0.000681    |
|    std                   | 0.418        |
|    value_loss            | 10.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.97        |
| reward                   | -0.6162045  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -788        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1470        |
|    total_timesteps       | 2195456     |
| train/                   |             |
|    approx_kl             | 0.008574273 |
|    clip_fraction         | 0.0557      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 1.08        |
|    cost_values           | 1.01        |
|    entropy               | -1.1        |
|    entropy_loss          | -1.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 10710       |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.419       |
|    value_loss            | 7.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.54         |
| reward                   | -0.9214654   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1505         |
|    total_timesteps       | 2197504      |
| train/                   |              |
|    approx_kl             | 0.0012729419 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 5.8          |
|    cost_values           | 1.02         |
|    entropy               | -1.1         |
|    entropy_loss          | -1.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.63         |
|    n_updates             | 10720        |
|    policy_gradient_loss  | 0.00264      |
|    std                   | 0.419        |
|    value_loss            | 14.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.658458    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1540         |
|    total_timesteps       | 2199552      |
| train/                   |              |
|    approx_kl             | 0.0018396149 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 1.4          |
|    cost_values           | 1.01         |
|    entropy               | -1.1         |
|    entropy_loss          | -1.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.56         |
|    n_updates             | 10730        |
|    policy_gradient_loss  | -0.000187    |
|    std                   | 0.42         |
|    value_loss            | 4.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.46530423 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -785        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1574        |
|    total_timesteps       | 2201600     |
| train/                   |             |
|    approx_kl             | 0.004180716 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.423       |
|    cost_values           | 1.01        |
|    entropy               | -1.1        |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 10740       |
|    policy_gradient_loss  | -0.000482   |
|    std                   | 0.419       |
|    value_loss            | 4.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7664673   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1609         |
|    total_timesteps       | 2203648      |
| train/                   |              |
|    approx_kl             | 0.0055745123 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.817        |
|    cost_value_loss       | 0.018        |
|    cost_values           | 0.907        |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.07         |
|    n_updates             | 10750        |
|    policy_gradient_loss  | -0.000223    |
|    std                   | 0.418        |
|    value_loss            | 6.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.74845123  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1643         |
|    total_timesteps       | 2205696      |
| train/                   |              |
|    approx_kl             | 0.0055539827 |
|    clip_fraction         | 0.0435       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.952        |
|    cost_value_loss       | 0.923        |
|    cost_values           | 0.898        |
|    entropy               | -1.08        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.5          |
|    n_updates             | 10760        |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 0.415        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.97         |
| reward                   | -0.91697705  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1677         |
|    total_timesteps       | 2207744      |
| train/                   |              |
|    approx_kl             | 0.0042421827 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.809        |
|    cost_value_loss       | 0.0154       |
|    cost_values           | 0.844        |
|    entropy               | -1.07        |
|    entropy_loss          | -1.07        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.46         |
|    n_updates             | 10770        |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.413        |
|    value_loss            | 6.86         |
-------------------------------------------
-----------------------------------
| avg_speed          | 3.88       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 3.88       |
| reward             | -0.8724656 |
| rollout/           |            |
|    ep_len_mean     | 994        |
|    ep_rew_mean     | -779       |
| time/              |            |
|    fps             | 84         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2209792    |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.5501997   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 2211840      |
| train/                   |              |
|    approx_kl             | 0.0054652956 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.842        |
|    cost_values           | 1.08         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.82         |
|    n_updates             | 10790        |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.412        |
|    value_loss            | 14.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.3         |
| reward                   | -0.8535629  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2213888     |
| train/                   |             |
|    approx_kl             | 0.001804962 |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.94        |
|    cost_value_loss       | 0.342       |
|    cost_values           | 0.965       |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.7        |
|    n_updates             | 10800       |
|    policy_gradient_loss  | -0.000539   |
|    std                   | 0.412       |
|    value_loss            | 40.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.29         |
| reward                   | -0.67690545  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2215936      |
| train/                   |              |
|    approx_kl             | 0.0013470033 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.978        |
|    cost_values           | 0.986        |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 10810        |
|    policy_gradient_loss  | -0.000264    |
|    std                   | 0.412        |
|    value_loss            | 34.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.59        |
| reward                   | -0.74561656 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -777        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 2217984     |
| train/                   |             |
|    approx_kl             | 0.004545035 |
|    clip_fraction         | 0.02        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 2.64        |
|    cost_values           | 1.06        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.83        |
|    n_updates             | 10820       |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.411       |
|    value_loss            | 10.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.85569847  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -777         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 2220032      |
| train/                   |              |
|    approx_kl             | 0.0011507847 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.916        |
|    cost_value_loss       | 0.0207       |
|    cost_values           | 0.999        |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 10830        |
|    policy_gradient_loss  | -0.000329    |
|    std                   | 0.411        |
|    value_loss            | 15.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1000443   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -777         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 2222080      |
| train/                   |              |
|    approx_kl             | 0.0041980445 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 2.18         |
|    cost_values           | 1            |
|    entropy               | -1.05        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.12         |
|    n_updates             | 10840        |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.41         |
|    value_loss            | 4.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.675336    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 2224128      |
| train/                   |              |
|    approx_kl             | 0.0055995057 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 1.82         |
|    cost_values           | 1.05         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.26         |
|    n_updates             | 10850        |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.41         |
|    value_loss            | 8.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7479628   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 2226176      |
| train/                   |              |
|    approx_kl             | 0.0013056912 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 3.34         |
|    cost_values           | 1.08         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 10860        |
|    policy_gradient_loss  | -0.000363    |
|    std                   | 0.41         |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.5859607   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -781         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 2228224      |
| train/                   |              |
|    approx_kl             | 0.0059855105 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.333        |
|    cost_values           | 0.993        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.44         |
|    n_updates             | 10870        |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.41         |
|    value_loss            | 7.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.0557299   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -783         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 2230272      |
| train/                   |              |
|    approx_kl             | 0.0014660077 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.04         |
|    cost_values           | 0.994        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 10880        |
|    policy_gradient_loss  | -7.25e-05    |
|    std                   | 0.41         |
|    value_loss            | 6.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.93         |
| reward                   | -0.86014664  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -787         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 2232320      |
| train/                   |              |
|    approx_kl             | 0.0042078192 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 1.49         |
|    cost_values           | 0.997        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 10890        |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.41         |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.9058855   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 2234368      |
| train/                   |              |
|    approx_kl             | 0.0049709016 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.816        |
|    cost_value_loss       | 0.0293       |
|    cost_values           | 0.967        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.52         |
|    n_updates             | 10900        |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.41         |
|    value_loss            | 13.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.7603796   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -792         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 472          |
|    total_timesteps       | 2236416      |
| train/                   |              |
|    approx_kl             | 0.0051044575 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.24         |
|    cost_values           | 0.988        |
|    entropy               | -1.06        |
|    entropy_loss          | -1.05        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 10910        |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.411        |
|    value_loss            | 5.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.2          |
| reward                   | -0.6127198   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 507          |
|    total_timesteps       | 2238464      |
| train/                   |              |
|    approx_kl             | 0.0026635386 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.843        |
|    cost_value_loss       | 0.0151       |
|    cost_values           | 0.906        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.28         |
|    n_updates             | 10920        |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.409        |
|    value_loss            | 4.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.37         |
| reward                   | -0.7923565   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 2240512      |
| train/                   |              |
|    approx_kl             | 0.0015113864 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.779        |
|    cost_value_loss       | 0.138        |
|    cost_values           | 0.79         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.9         |
|    n_updates             | 10930        |
|    policy_gradient_loss  | -0.000413    |
|    std                   | 0.408        |
|    value_loss            | 49.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.82         |
| reward                   | -0.70359105  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 576          |
|    total_timesteps       | 2242560      |
| train/                   |              |
|    approx_kl             | 0.0035707094 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.1          |
|    cost_values           | 0.873        |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 10940        |
|    policy_gradient_loss  | -0.000339    |
|    std                   | 0.408        |
|    value_loss            | 8.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.667       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.667       |
| reward                   | -0.62233585 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -785        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 610         |
|    total_timesteps       | 2244608     |
| train/                   |             |
|    approx_kl             | 0.005842719 |
|    clip_fraction         | 0.0491      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.979       |
|    cost_value_loss       | 0.632       |
|    cost_values           | 0.981       |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 10950       |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.407       |
|    value_loss            | 7.36        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.12       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.12       |
| reward                   | -0.7592452 |
| rollout/                 |            |
|    ep_len_mean           | 981        |
|    ep_rew_mean           | -784       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 19         |
|    time_elapsed          | 644        |
|    total_timesteps       | 2246656    |
| train/                   |            |
|    approx_kl             | 0.0032872  |
|    clip_fraction         | 0.0176     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.808      |
|    cost_value_loss       | 0.015      |
|    cost_values           | 0.871      |
|    entropy               | -1.03      |
|    entropy_loss          | -1.04      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.26       |
|    n_updates             | 10960      |
|    policy_gradient_loss  | -0.000723  |
|    std                   | 0.405      |
|    value_loss            | 4.72       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0227       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0227       |
| reward                   | -0.7389255   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -779         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 678          |
|    total_timesteps       | 2248704      |
| train/                   |              |
|    approx_kl             | 0.0035790552 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.651        |
|    cost_value_loss       | 0.0155       |
|    cost_values           | 0.752        |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.32         |
|    n_updates             | 10970        |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.405        |
|    value_loss            | 7.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.48        |
| reward                   | -0.900003   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 712         |
|    total_timesteps       | 2250752     |
| train/                   |             |
|    approx_kl             | 0.003088174 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.555       |
|    cost_value_loss       | 0.00719     |
|    cost_values           | 0.612       |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.26        |
|    n_updates             | 10980       |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.405       |
|    value_loss            | 3.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.79        |
| reward                   | -0.8964076  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 747         |
|    total_timesteps       | 2252800     |
| train/                   |             |
|    approx_kl             | 0.003974214 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.458       |
|    cost_value_loss       | 0.00362     |
|    cost_values           | 0.461       |
|    entropy               | -1.02       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.501       |
|    n_updates             | 10990       |
|    policy_gradient_loss  | -0.000206   |
|    std                   | 0.404       |
|    value_loss            | 0.978       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.7934591  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 781         |
|    total_timesteps       | 2254848     |
| train/                   |             |
|    approx_kl             | 0.005197139 |
|    clip_fraction         | 0.0243      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.851       |
|    cost_value_loss       | 1.32        |
|    cost_values           | 0.572       |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.77        |
|    n_updates             | 11000       |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.404       |
|    value_loss            | 15.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.72        |
| reward                   | -0.7106122  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 816         |
|    total_timesteps       | 2256896     |
| train/                   |             |
|    approx_kl             | 0.004116856 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.934       |
|    cost_value_loss       | 1.24        |
|    cost_values           | 0.912       |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.909       |
|    n_updates             | 11010       |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.404       |
|    value_loss            | 0.881       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.88         |
| reward                   | -0.81352586  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 850          |
|    total_timesteps       | 2258944      |
| train/                   |              |
|    approx_kl             | 0.0030976932 |
|    clip_fraction         | 0.00381      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.8          |
|    cost_value_loss       | 0.112        |
|    cost_values           | 0.82         |
|    entropy               | -1.03        |
|    entropy_loss          | -1.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.06         |
|    n_updates             | 11020        |
|    policy_gradient_loss  | -5.31e-05    |
|    std                   | 0.405        |
|    value_loss            | 2.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -1.1274954  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -767        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 886         |
|    total_timesteps       | 2260992     |
| train/                   |             |
|    approx_kl             | 0.005642293 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 3.24        |
|    cost_values           | 0.938       |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.43        |
|    n_updates             | 11030       |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.404       |
|    value_loss            | 4.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.126       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.126       |
| reward                   | -0.7189956  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -773        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 920         |
|    total_timesteps       | 2263040     |
| train/                   |             |
|    approx_kl             | 0.004323328 |
|    clip_fraction         | 0.0256      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.822       |
|    cost_value_loss       | 0.0135      |
|    cost_values           | 0.884       |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.11        |
|    n_updates             | 11040       |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.404       |
|    value_loss            | 2.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.395        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.395        |
| reward                   | -0.92561734  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 955          |
|    total_timesteps       | 2265088      |
| train/                   |              |
|    approx_kl             | 7.045045e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.663        |
|    cost_value_loss       | 0.0142       |
|    cost_values           | 0.759        |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.33         |
|    n_updates             | 11050        |
|    policy_gradient_loss  | 0.000145     |
|    std                   | 0.404        |
|    value_loss            | 8.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.98         |
| reward                   | -0.8168503   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 989          |
|    total_timesteps       | 2267136      |
| train/                   |              |
|    approx_kl             | 0.0028752892 |
|    clip_fraction         | 0.00498      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.571        |
|    cost_value_loss       | 0.00598      |
|    cost_values           | 0.602        |
|    entropy               | -1.01        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.67         |
|    n_updates             | 11060        |
|    policy_gradient_loss  | -0.000412    |
|    std                   | 0.401        |
|    value_loss            | 3.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.08         |
| reward                   | -0.87316656  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -777         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1023         |
|    total_timesteps       | 2269184      |
| train/                   |              |
|    approx_kl             | 0.0068937694 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.478        |
|    cost_value_loss       | 0.00449      |
|    cost_values           | 0.505        |
|    entropy               | -0.995       |
|    entropy_loss          | -1           |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.484        |
|    n_updates             | 11070        |
|    policy_gradient_loss  | -0.000406    |
|    std                   | 0.398        |
|    value_loss            | 1.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.72         |
| reward                   | -0.96402186  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1057         |
|    total_timesteps       | 2271232      |
| train/                   |              |
|    approx_kl             | 0.0046123667 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.4          |
|    cost_value_loss       | 0.00623      |
|    cost_values           | 0.467        |
|    entropy               | -0.992       |
|    entropy_loss          | -0.993       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 11080        |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.398        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.56        |
| reward                   | -0.98397046 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 32          |
|    time_elapsed          | 1091        |
|    total_timesteps       | 2273280     |
| train/                   |             |
|    approx_kl             | 0.003635792 |
|    clip_fraction         | 0.0187      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.353       |
|    cost_value_loss       | 0.00193     |
|    cost_values           | 0.362       |
|    entropy               | -0.991      |
|    entropy_loss          | -0.992      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.858       |
|    n_updates             | 11090       |
|    policy_gradient_loss  | -0.00084    |
|    std                   | 0.397       |
|    value_loss            | 1.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.37         |
| reward                   | -0.46335685  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -775         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1125         |
|    total_timesteps       | 2275328      |
| train/                   |              |
|    approx_kl             | 0.0041845175 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.294        |
|    cost_value_loss       | 0.0016       |
|    cost_values           | 0.309        |
|    entropy               | -0.986       |
|    entropy_loss          | -0.989       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.22         |
|    n_updates             | 11100        |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.396        |
|    value_loss            | 4.44         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.81          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.81          |
| reward                   | -0.95540786   |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -765          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 34            |
|    time_elapsed          | 1160          |
|    total_timesteps       | 2277376       |
| train/                   |               |
|    approx_kl             | 0.00060737657 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.29          |
|    cost_value_loss       | 7.3           |
|    cost_values           | 0.506         |
|    entropy               | -0.983        |
|    entropy_loss          | -0.984        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.72          |
|    n_updates             | 11110         |
|    policy_gradient_loss  | -0.000373     |
|    std                   | 0.396         |
|    value_loss            | 14.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0499       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0499       |
| reward                   | -0.55864954  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1194         |
|    total_timesteps       | 2279424      |
| train/                   |              |
|    approx_kl             | 0.0031897146 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.786        |
|    cost_value_loss       | 0.572        |
|    cost_values           | 0.831        |
|    entropy               | -0.984       |
|    entropy_loss          | -0.984       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.26         |
|    n_updates             | 11120        |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.396        |
|    value_loss            | 6.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0736       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0736       |
| reward                   | -0.79070866  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1229         |
|    total_timesteps       | 2281472      |
| train/                   |              |
|    approx_kl             | 0.0069286316 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.788        |
|    cost_value_loss       | 0.459        |
|    cost_values           | 0.786        |
|    entropy               | -0.988       |
|    entropy_loss          | -0.986       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.14         |
|    n_updates             | 11130        |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.397        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.12         |
| reward                   | -0.8893749   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1264         |
|    total_timesteps       | 2283520      |
| train/                   |              |
|    approx_kl             | 0.0033866698 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.644        |
|    cost_value_loss       | 0.0091       |
|    cost_values           | 0.695        |
|    entropy               | -0.993       |
|    entropy_loss          | -0.991       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.43         |
|    n_updates             | 11140        |
|    policy_gradient_loss  | 0.000663     |
|    std                   | 0.398        |
|    value_loss            | 5.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.91        |
| reward                   | -0.8928375  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -759        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1298        |
|    total_timesteps       | 2285568     |
| train/                   |             |
|    approx_kl             | 0.004102746 |
|    clip_fraction         | 0.0343      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.517       |
|    cost_value_loss       | 0.00545     |
|    cost_values           | 0.547       |
|    entropy               | -0.996      |
|    entropy_loss          | -0.995      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.51        |
|    n_updates             | 11150       |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.398       |
|    value_loss            | 3.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.185        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.185        |
| reward                   | -0.7097275   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1332         |
|    total_timesteps       | 2287616      |
| train/                   |              |
|    approx_kl             | 0.0028862073 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.976        |
|    cost_value_loss       | 1.95         |
|    cost_values           | 0.839        |
|    entropy               | -0.996       |
|    entropy_loss          | -0.997       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 11160        |
|    policy_gradient_loss  | -8.39e-05    |
|    std                   | 0.398        |
|    value_loss            | 6.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.441        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.441        |
| reward                   | -0.56966114  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1366         |
|    total_timesteps       | 2289664      |
| train/                   |              |
|    approx_kl             | 0.0035815723 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.772        |
|    cost_value_loss       | 0.0111       |
|    cost_values           | 0.81         |
|    entropy               | -0.993       |
|    entropy_loss          | -0.995       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.65         |
|    n_updates             | 11170        |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.398        |
|    value_loss            | 9.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.04         |
| reward                   | -0.6763798   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1400         |
|    total_timesteps       | 2291712      |
| train/                   |              |
|    approx_kl             | 0.0065973164 |
|    clip_fraction         | 0.0435       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.635        |
|    cost_value_loss       | 0.00702      |
|    cost_values           | 0.65         |
|    entropy               | -0.995       |
|    entropy_loss          | -0.993       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.608        |
|    n_updates             | 11180        |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.398        |
|    value_loss            | 1.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.242        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.242        |
| reward                   | -0.66285926  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1435         |
|    total_timesteps       | 2293760      |
| train/                   |              |
|    approx_kl             | 0.0036363248 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.51         |
|    cost_value_loss       | 0.00378      |
|    cost_values           | 0.516        |
|    entropy               | -0.991       |
|    entropy_loss          | -0.994       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.81         |
|    n_updates             | 11190        |
|    policy_gradient_loss  | -0.000929    |
|    std                   | 0.397        |
|    value_loss            | 3.7          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.81          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.81          |
| reward                   | -0.68628174   |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -757          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 43            |
|    time_elapsed          | 1469          |
|    total_timesteps       | 2295808       |
| train/                   |               |
|    approx_kl             | 2.6274269e-05 |
|    clip_fraction         | 0.00151       |
|    clip_range            | 0.2           |
|    cost_returns          | 0.411         |
|    cost_value_loss       | 0.00568       |
|    cost_values           | 0.472         |
|    entropy               | -0.99         |
|    entropy_loss          | -0.99         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.15          |
|    n_updates             | 11200         |
|    policy_gradient_loss  | 0.00135       |
|    std                   | 0.397         |
|    value_loss            | 3.44          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.526        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.526        |
| reward                   | -0.8319082   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1503         |
|    total_timesteps       | 2297856      |
| train/                   |              |
|    approx_kl             | 0.0030936254 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.351        |
|    cost_value_loss       | 0.00323      |
|    cost_values           | 0.39         |
|    entropy               | -0.991       |
|    entropy_loss          | -0.99        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.84         |
|    n_updates             | 11210        |
|    policy_gradient_loss  | -0.000774    |
|    std                   | 0.397        |
|    value_loss            | 4.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.8379918  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1538        |
|    total_timesteps       | 2299904     |
| train/                   |             |
|    approx_kl             | 0.005993895 |
|    clip_fraction         | 0.0407      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.265       |
|    cost_value_loss       | 0.00115     |
|    cost_values           | 0.275       |
|    entropy               | -0.983      |
|    entropy_loss          | -0.988      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.74        |
|    n_updates             | 11220       |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.396       |
|    value_loss            | 5.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.51         |
| reward                   | -0.44847757  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1572         |
|    total_timesteps       | 2301952      |
| train/                   |              |
|    approx_kl             | 0.0017500566 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.223        |
|    cost_value_loss       | 0.00149      |
|    cost_values           | 0.254        |
|    entropy               | -0.98        |
|    entropy_loss          | -0.981       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.898        |
|    n_updates             | 11230        |
|    policy_gradient_loss  | 0.000501     |
|    std                   | 0.395        |
|    value_loss            | 3.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.78        |
| reward                   | -0.81371844 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1606        |
|    total_timesteps       | 2304000     |
| train/                   |             |
|    approx_kl             | 0.002569415 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.19        |
|    cost_value_loss       | 0.000584    |
|    cost_values           | 0.192       |
|    entropy               | -0.967      |
|    entropy_loss          | -0.975      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.11        |
|    n_updates             | 11240       |
|    policy_gradient_loss  | -9.55e-05   |
|    std                   | 0.393       |
|    value_loss            | 2.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.14         |
| reward                   | -0.8603721   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1640         |
|    total_timesteps       | 2306048      |
| train/                   |              |
|    approx_kl             | 0.0042406935 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.149        |
|    cost_value_loss       | 0.000637     |
|    cost_values           | 0.167        |
|    entropy               | -0.964       |
|    entropy_loss          | -0.964       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.11         |
|    n_updates             | 11250        |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.392        |
|    value_loss            | 5.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.216        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.216        |
| reward                   | -0.83177555  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1675         |
|    total_timesteps       | 2308096      |
| train/                   |              |
|    approx_kl             | 0.0037902193 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.261        |
|    cost_value_loss       | 0.381        |
|    cost_values           | 0.225        |
|    entropy               | -0.963       |
|    entropy_loss          | -0.964       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.06         |
|    n_updates             | 11260        |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.392        |
|    value_loss            | 2.12         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/wsu78eti
------------------------------------
| avg_speed          | 1.04        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.04        |
| reward             | -0.67549866 |
| rollout/           |             |
|    ep_len_mean     | 988         |
|    ep_rew_mean     | -761        |
| time/              |             |
|    fps             | 82          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2310144     |
------------------------------------
-------------------------------------------
| avg_speed                | 2.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.18         |
| reward                   | -0.68276393  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2312192      |
| train/                   |              |
|    approx_kl             | 0.0063078855 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.19         |
|    cost_value_loss       | 0.000624     |
|    cost_values           | 0.197        |
|    entropy               | -0.963       |
|    entropy_loss          | -0.962       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.755        |
|    n_updates             | 11280        |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.392        |
|    value_loss            | 1.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.5         |
| reward                   | -0.65675825 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 94          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.003926623 |
|    clip_fraction         | 0.0273      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.159       |
|    cost_value_loss       | 0.000596    |
|    cost_values           | 0.172       |
|    entropy               | -0.963      |
|    entropy_loss          | -0.963      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.195       |
|    n_updates             | 11290       |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.392       |
|    value_loss            | 0.908       |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.21         |
| reward                   | -0.64950264  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2316288      |
| train/                   |              |
|    approx_kl             | 0.0058761593 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.127        |
|    cost_value_loss       | 0.000284     |
|    cost_values           | 0.128        |
|    entropy               | -0.96        |
|    entropy_loss          | -0.961       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.89         |
|    n_updates             | 11300        |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.391        |
|    value_loss            | 3.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.57         |
| reward                   | -0.7804581   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 2318336      |
| train/                   |              |
|    approx_kl             | 0.0039703776 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0997       |
|    cost_value_loss       | 0.000213     |
|    cost_values           | 0.108        |
|    entropy               | -0.961       |
|    entropy_loss          | -0.961       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.28         |
|    n_updates             | 11310        |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.391        |
|    value_loss            | 3.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.7947264   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 2320384      |
| train/                   |              |
|    approx_kl             | 0.0014407933 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0798       |
|    cost_value_loss       | 0.000111     |
|    cost_values           | 0.0831       |
|    entropy               | -0.961       |
|    entropy_loss          | -0.961       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.88         |
|    n_updates             | 11320        |
|    policy_gradient_loss  | -0.000688    |
|    std                   | 0.392        |
|    value_loss            | 1.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.65         |
| reward                   | -0.48903298  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 2322432      |
| train/                   |              |
|    approx_kl             | 0.0006124773 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0655       |
|    cost_value_loss       | 0.000115     |
|    cost_values           | 0.0665       |
|    entropy               | -0.955       |
|    entropy_loss          | -0.959       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.989        |
|    n_updates             | 11330        |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.39         |
|    value_loss            | 2.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.159       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.159       |
| reward                   | -0.8684073  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -754        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 2324480     |
| train/                   |             |
|    approx_kl             | 0.003125668 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.288       |
|    cost_value_loss       | 0.541       |
|    cost_values           | 0.233       |
|    entropy               | -0.952      |
|    entropy_loss          | -0.954      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.16        |
|    n_updates             | 11340       |
|    policy_gradient_loss  | -0.000855   |
|    std                   | 0.39        |
|    value_loss            | 2.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.421        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.421        |
| reward                   | -0.8027869   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 2326528      |
| train/                   |              |
|    approx_kl             | 0.0016996199 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.241        |
|    cost_value_loss       | 0.13         |
|    cost_values           | 0.258        |
|    entropy               | -0.953       |
|    entropy_loss          | -0.952       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.06         |
|    n_updates             | 11350        |
|    policy_gradient_loss  | -0.00011     |
|    std                   | 0.39         |
|    value_loss            | 3.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.13         |
| reward                   | -0.7193853   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 2328576      |
| train/                   |              |
|    approx_kl             | 0.0056689233 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 7.47         |
|    cost_values           | 0.819        |
|    entropy               | -0.952       |
|    entropy_loss          | -0.952       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.66         |
|    n_updates             | 11360        |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.39         |
|    value_loss            | 3.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.192       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.192       |
| reward                   | -0.6946598  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 2330624     |
| train/                   |             |
|    approx_kl             | 0.003791213 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 0.71        |
|    cost_values           | 1.22        |
|    entropy               | -0.947      |
|    entropy_loss          | -0.95       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.734       |
|    n_updates             | 11370       |
|    policy_gradient_loss  | -0.000795   |
|    std                   | 0.389       |
|    value_loss            | 0.943       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.277        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.277        |
| reward                   | -0.80974054  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 2332672      |
| train/                   |              |
|    approx_kl             | 0.0019201532 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.019        |
|    cost_values           | 1.03         |
|    entropy               | -0.952       |
|    entropy_loss          | -0.948       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.486        |
|    n_updates             | 11380        |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.39         |
|    value_loss            | 1.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.44         |
| reward                   | -0.7948448   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 2334720      |
| train/                   |              |
|    approx_kl             | 0.0019092773 |
|    clip_fraction         | 0.00762      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.79         |
|    cost_value_loss       | 0.00957      |
|    cost_values           | 0.81         |
|    entropy               | -0.95        |
|    entropy_loss          | -0.953       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.178        |
|    n_updates             | 11390        |
|    policy_gradient_loss  | 0.000174     |
|    std                   | 0.389        |
|    value_loss            | 0.362        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.19        |
| reward                   | -0.89433163 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 471         |
|    total_timesteps       | 2336768     |
| train/                   |             |
|    approx_kl             | 0.00459539  |
|    clip_fraction         | 0.00864     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.781       |
|    cost_value_loss       | 0.467       |
|    cost_values           | 0.777       |
|    entropy               | -0.937      |
|    entropy_loss          | -0.945      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.18        |
|    n_updates             | 11400       |
|    policy_gradient_loss  | -0.000356   |
|    std                   | 0.387       |
|    value_loss            | 2.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.303       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.303       |
| reward                   | -0.6664297  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 505         |
|    total_timesteps       | 2338816     |
| train/                   |             |
|    approx_kl             | 0.002637364 |
|    clip_fraction         | 0.00439     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.645       |
|    cost_value_loss       | 0.0112      |
|    cost_values           | 0.721       |
|    entropy               | -0.932      |
|    entropy_loss          | -0.933      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.546       |
|    n_updates             | 11410       |
|    policy_gradient_loss  | 0.000136    |
|    std                   | 0.386       |
|    value_loss            | 2.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.203        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.203        |
| reward                   | -0.75834936  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 539          |
|    total_timesteps       | 2340864      |
| train/                   |              |
|    approx_kl             | 0.0048522386 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.537        |
|    cost_value_loss       | 0.00608      |
|    cost_values           | 0.578        |
|    entropy               | -0.93        |
|    entropy_loss          | -0.931       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.787        |
|    n_updates             | 11420        |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.385        |
|    value_loss            | 2.15         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.48          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.48          |
| reward                   | -0.9213305    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -746          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 17            |
|    time_elapsed          | 573           |
|    total_timesteps       | 2342912       |
| train/                   |               |
|    approx_kl             | 0.00040677976 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.13          |
|    cost_value_loss       | 4.25          |
|    cost_values           | 0.733         |
|    entropy               | -0.929        |
|    entropy_loss          | -0.929        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.29          |
|    n_updates             | 11430         |
|    policy_gradient_loss  | -4.27e-05     |
|    std                   | 0.385         |
|    value_loss            | 6.36          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.25         |
| reward                   | -0.74160993  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 607          |
|    total_timesteps       | 2344960      |
| train/                   |              |
|    approx_kl             | 0.0036741898 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.8          |
|    cost_value_loss       | 0.0206       |
|    cost_values           | 0.897        |
|    entropy               | -0.927       |
|    entropy_loss          | -0.928       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.468        |
|    n_updates             | 11440        |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.385        |
|    value_loss            | 1.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.2          |
| reward                   | -0.88308835  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 642          |
|    total_timesteps       | 2347008      |
| train/                   |              |
|    approx_kl             | 0.0011239317 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.64         |
|    cost_value_loss       | 0.00758      |
|    cost_values           | 0.673        |
|    entropy               | -0.92        |
|    entropy_loss          | -0.925       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.26         |
|    n_updates             | 11450        |
|    policy_gradient_loss  | 6.11e-05     |
|    std                   | 0.384        |
|    value_loss            | 2.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.24         |
| reward                   | -0.72653174  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 676          |
|    total_timesteps       | 2349056      |
| train/                   |              |
|    approx_kl             | 0.0038324185 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.535        |
|    cost_value_loss       | 0.00667      |
|    cost_values           | 0.585        |
|    entropy               | -0.916       |
|    entropy_loss          | -0.918       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.649        |
|    n_updates             | 11460        |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.383        |
|    value_loss            | 1.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.78         |
| reward                   | -0.7079674   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 710          |
|    total_timesteps       | 2351104      |
| train/                   |              |
|    approx_kl             | 0.0048840316 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.432        |
|    cost_value_loss       | 0.0044       |
|    cost_values           | 0.474        |
|    entropy               | -0.914       |
|    entropy_loss          | -0.915       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.52         |
|    n_updates             | 11470        |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.382        |
|    value_loss            | 5.57         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.18        |
| reward                   | -0.833136   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -751        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 744         |
|    total_timesteps       | 2353152     |
| train/                   |             |
|    approx_kl             | 0.004846684 |
|    clip_fraction         | 0.0217      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 3.79        |
|    cost_values           | 0.703       |
|    entropy               | -0.915      |
|    entropy_loss          | -0.914      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 11480       |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.383       |
|    value_loss            | 5.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.33         |
| reward                   | -0.642905    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 778          |
|    total_timesteps       | 2355200      |
| train/                   |              |
|    approx_kl             | 0.0044258856 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.853        |
|    cost_value_loss       | 0.02         |
|    cost_values           | 0.919        |
|    entropy               | -0.915       |
|    entropy_loss          | -0.915       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.53         |
|    n_updates             | 11490        |
|    policy_gradient_loss  | -0.000618    |
|    std                   | 0.383        |
|    value_loss            | 3.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.78         |
| reward                   | -0.515577    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 813          |
|    total_timesteps       | 2357248      |
| train/                   |              |
|    approx_kl             | 0.0022387654 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.555        |
|    cost_values           | 0.849        |
|    entropy               | -0.914       |
|    entropy_loss          | -0.915       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 11500        |
|    policy_gradient_loss  | -0.000565    |
|    std                   | 0.382        |
|    value_loss            | 5.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.35         |
| reward                   | -0.9251449   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 847          |
|    total_timesteps       | 2359296      |
| train/                   |              |
|    approx_kl             | 0.0054027922 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.709        |
|    cost_value_loss       | 0.0101       |
|    cost_values           | 0.749        |
|    entropy               | -0.919       |
|    entropy_loss          | -0.916       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.68         |
|    n_updates             | 11510        |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.383        |
|    value_loss            | 5.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.908        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.908        |
| reward                   | -0.6890568   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 881          |
|    total_timesteps       | 2361344      |
| train/                   |              |
|    approx_kl             | 0.0043176375 |
|    clip_fraction         | 0.045        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.595        |
|    cost_value_loss       | 0.00591      |
|    cost_values           | 0.614        |
|    entropy               | -0.926       |
|    entropy_loss          | -0.923       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.82         |
|    n_updates             | 11520        |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.385        |
|    value_loss            | 3.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.446        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.446        |
| reward                   | -0.8496271   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 915          |
|    total_timesteps       | 2363392      |
| train/                   |              |
|    approx_kl             | 0.0006662763 |
|    clip_fraction         | 0.00728      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.478        |
|    cost_value_loss       | 0.00373      |
|    cost_values           | 0.495        |
|    entropy               | -0.935       |
|    entropy_loss          | -0.929       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.631        |
|    n_updates             | 11530        |
|    policy_gradient_loss  | -0.000301    |
|    std                   | 0.387        |
|    value_loss            | 1.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.585       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.585       |
| reward                   | -0.8032345  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -745        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 950         |
|    total_timesteps       | 2365440     |
| train/                   |             |
|    approx_kl             | 0.003950415 |
|    clip_fraction         | 0.00303     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.389       |
|    cost_value_loss       | 0.00389     |
|    cost_values           | 0.435       |
|    entropy               | -0.939      |
|    entropy_loss          | -0.939      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.1         |
|    n_updates             | 11540       |
|    policy_gradient_loss  | -0.000973   |
|    std                   | 0.387       |
|    value_loss            | 5.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.89         |
| reward                   | -0.80175716  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 985          |
|    total_timesteps       | 2367488      |
| train/                   |              |
|    approx_kl             | 0.0060210247 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.329        |
|    cost_value_loss       | 0.00263      |
|    cost_values           | 0.364        |
|    entropy               | -0.94        |
|    entropy_loss          | -0.939       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.813        |
|    n_updates             | 11550        |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.388        |
|    value_loss            | 2.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.169       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.169       |
| reward                   | -0.75104994 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -742        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 2369536     |
| train/                   |             |
|    approx_kl             | 0.003359444 |
|    clip_fraction         | 0.0126      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.27        |
|    cost_value_loss       | 0.00138     |
|    cost_values           | 0.284       |
|    entropy               | -0.941      |
|    entropy_loss          | -0.941      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.274       |
|    n_updates             | 11560       |
|    policy_gradient_loss  | -0.000894   |
|    std                   | 0.388       |
|    value_loss            | 0.899       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.343        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.343        |
| reward                   | -0.8242131   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1054         |
|    total_timesteps       | 2371584      |
| train/                   |              |
|    approx_kl             | 0.0041904896 |
|    clip_fraction         | 0.00532      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.52         |
|    cost_value_loss       | 0.86         |
|    cost_values           | 0.42         |
|    entropy               | -0.939       |
|    entropy_loss          | -0.941       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.877        |
|    n_updates             | 11570        |
|    policy_gradient_loss  | -0.000576    |
|    std                   | 0.387        |
|    value_loss            | 1.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.56         |
| reward                   | -0.8998985   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1088         |
|    total_timesteps       | 2373632      |
| train/                   |              |
|    approx_kl             | 0.0026348452 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.447        |
|    cost_value_loss       | 0.00358      |
|    cost_values           | 0.467        |
|    entropy               | -0.928       |
|    entropy_loss          | -0.935       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.417        |
|    n_updates             | 11580        |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.385        |
|    value_loss            | 0.896        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.29         |
| reward                   | -0.80134565  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1123         |
|    total_timesteps       | 2375680      |
| train/                   |              |
|    approx_kl             | 0.0072588054 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.364        |
|    cost_value_loss       | 0.00286      |
|    cost_values           | 0.396        |
|    entropy               | -0.922       |
|    entropy_loss          | -0.923       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.88         |
|    n_updates             | 11590        |
|    policy_gradient_loss  | 0.000141     |
|    std                   | 0.384        |
|    value_loss            | 5.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.58        |
| reward                   | -0.76256377 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 34          |
|    time_elapsed          | 1158        |
|    total_timesteps       | 2377728     |
| train/                   |             |
|    approx_kl             | 0.004862149 |
|    clip_fraction         | 0.00669     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.394       |
|    cost_value_loss       | 0.193       |
|    cost_values           | 0.373       |
|    entropy               | -0.921      |
|    entropy_loss          | -0.921      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 11600       |
|    policy_gradient_loss  | -0.000625   |
|    std                   | 0.384       |
|    value_loss            | 5.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.76        |
| reward                   | -0.7808251  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 35          |
|    time_elapsed          | 1192        |
|    total_timesteps       | 2379776     |
| train/                   |             |
|    approx_kl             | 0.002866903 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.328       |
|    cost_value_loss       | 0.00609     |
|    cost_values           | 0.345       |
|    entropy               | -0.921      |
|    entropy_loss          | -0.921      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.13        |
|    n_updates             | 11610       |
|    policy_gradient_loss  | -0.000481   |
|    std                   | 0.384       |
|    value_loss            | 2.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.53         |
| reward                   | -0.8573404   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1226         |
|    total_timesteps       | 2381824      |
| train/                   |              |
|    approx_kl             | 0.0067219953 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.265        |
|    cost_value_loss       | 0.00271      |
|    cost_values           | 0.309        |
|    entropy               | -0.921       |
|    entropy_loss          | -0.921       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.72         |
|    n_updates             | 11620        |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.384        |
|    value_loss            | 13.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.73        |
| reward                   | -0.8046547  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1261        |
|    total_timesteps       | 2383872     |
| train/                   |             |
|    approx_kl             | 0.004123326 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.234       |
|    cost_value_loss       | 0.00107     |
|    cost_values           | 0.248       |
|    entropy               | -0.917      |
|    entropy_loss          | -0.919      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.641       |
|    n_updates             | 11630       |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.383       |
|    value_loss            | 1.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.46         |
| reward                   | -0.7422758   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1295         |
|    total_timesteps       | 2385920      |
| train/                   |              |
|    approx_kl             | 0.0042994893 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.188        |
|    cost_value_loss       | 0.000972     |
|    cost_values           | 0.209        |
|    entropy               | -0.916       |
|    entropy_loss          | -0.916       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.1          |
|    n_updates             | 11640        |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 0.383        |
|    value_loss            | 3.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.952        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.952        |
| reward                   | -0.8114602   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1330         |
|    total_timesteps       | 2387968      |
| train/                   |              |
|    approx_kl             | 0.0033992757 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.399        |
|    cost_value_loss       | 0.685        |
|    cost_values           | 0.365        |
|    entropy               | -0.914       |
|    entropy_loss          | -0.915       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.69         |
|    n_updates             | 11650        |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.383        |
|    value_loss            | 2.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.34        |
| reward                   | -0.9876969  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -754        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 40          |
|    time_elapsed          | 1365        |
|    total_timesteps       | 2390016     |
| train/                   |             |
|    approx_kl             | 0.004388067 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.56        |
|    cost_value_loss       | 0.581       |
|    cost_values           | 0.518       |
|    entropy               | -0.915      |
|    entropy_loss          | -0.913      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.861       |
|    n_updates             | 11660       |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.383       |
|    value_loss            | 1.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.61         |
| reward                   | -0.92576104  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1399         |
|    total_timesteps       | 2392064      |
| train/                   |              |
|    approx_kl             | 0.0007612619 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.469        |
|    cost_value_loss       | 0.0176       |
|    cost_values           | 0.477        |
|    entropy               | -0.928       |
|    entropy_loss          | -0.92        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.55         |
|    n_updates             | 11670        |
|    policy_gradient_loss  | -4.2e-05     |
|    std                   | 0.385        |
|    value_loss            | 3.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.8799536  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -759        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1433        |
|    total_timesteps       | 2394112     |
| train/                   |             |
|    approx_kl             | 0.002865227 |
|    clip_fraction         | 0.0191      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 4.9         |
|    cost_values           | 1.07        |
|    entropy               | -0.928      |
|    entropy_loss          | -0.93       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 11680       |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.385       |
|    value_loss            | 3.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8480778  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1468        |
|    total_timesteps       | 2396160     |
| train/                   |             |
|    approx_kl             | 0.004594065 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 0.0375      |
|    cost_values           | 1.09        |
|    entropy               | -0.926      |
|    entropy_loss          | -0.927      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 11690       |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.385       |
|    value_loss            | 5.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.86497957  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1502         |
|    total_timesteps       | 2398208      |
| train/                   |              |
|    approx_kl             | 0.0018275862 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.801        |
|    cost_value_loss       | 0.0264       |
|    cost_values           | 0.933        |
|    entropy               | -0.925       |
|    entropy_loss          | -0.926       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.45         |
|    n_updates             | 11700        |
|    policy_gradient_loss  | -0.000255    |
|    std                   | 0.384        |
|    value_loss            | 4.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.6164245   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1537         |
|    total_timesteps       | 2400256      |
| train/                   |              |
|    approx_kl             | 0.0040728645 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.829        |
|    cost_value_loss       | 0.31         |
|    cost_values           | 0.815        |
|    entropy               | -0.925       |
|    entropy_loss          | -0.925       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.98         |
|    n_updates             | 11710        |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.385        |
|    value_loss            | 9.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.6424472  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -762        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1571        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.002858707 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.921       |
|    cost_value_loss       | 0.738       |
|    cost_values           | 0.905       |
|    entropy               | -0.916      |
|    entropy_loss          | -0.922      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.98        |
|    n_updates             | 11720       |
|    policy_gradient_loss  | -0.000797   |
|    std                   | 0.383       |
|    value_loss            | 4.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8484393  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -764        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1606        |
|    total_timesteps       | 2404352     |
| train/                   |             |
|    approx_kl             | 0.004557064 |
|    clip_fraction         | 0.0224      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 2.75        |
|    cost_values           | 1.09        |
|    entropy               | -0.912      |
|    entropy_loss          | -0.912      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 11730       |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.382       |
|    value_loss            | 6.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.82914406  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1640         |
|    total_timesteps       | 2406400      |
| train/                   |              |
|    approx_kl             | 0.0053800363 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 5.73         |
|    cost_values           | 1.36         |
|    entropy               | -0.909       |
|    entropy_loss          | -0.91        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 11740        |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.381        |
|    value_loss            | 4.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.03        |
| reward                   | -0.40583858 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -760        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1675        |
|    total_timesteps       | 2408448     |
| train/                   |             |
|    approx_kl             | 0.005897632 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 0.0527      |
|    cost_values           | 1.36        |
|    entropy               | -0.905      |
|    entropy_loss          | -0.907      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.599       |
|    n_updates             | 11750       |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.381       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------
| avg_speed          | 0.287       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.287       |
| reward             | -0.71412516 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -759        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2410496     |
------------------------------------
------------------------------------------
| avg_speed                | 6.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.05        |
| reward                   | -0.88311493 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -760        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.003594142 |
|    clip_fraction         | 0.0177      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 1.02        |
|    cost_values           | 0.996       |
|    entropy               | -0.902      |
|    entropy_loss          | -0.903      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.03        |
|    n_updates             | 11770       |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.38        |
|    value_loss            | 5.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.5          |
| reward                   | -0.87944835  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 92           |
|    total_timesteps       | 2414592      |
| train/                   |              |
|    approx_kl             | 0.0051175747 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.887        |
|    cost_value_loss       | 0.131        |
|    cost_values           | 0.897        |
|    entropy               | -0.9         |
|    entropy_loss          | -0.902       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.84         |
|    n_updates             | 11780        |
|    policy_gradient_loss  | -0.000702    |
|    std                   | 0.38         |
|    value_loss            | 1.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.38         |
| reward                   | -0.5251401   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 2416640      |
| train/                   |              |
|    approx_kl             | 0.0068751536 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.815        |
|    cost_value_loss       | 0.182        |
|    cost_values           | 0.855        |
|    entropy               | -0.898       |
|    entropy_loss          | -0.898       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.31         |
|    n_updates             | 11790        |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.379        |
|    value_loss            | 11.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.83         |
| reward                   | -0.7299832   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 2418688      |
| train/                   |              |
|    approx_kl             | 0.0024971114 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.728        |
|    cost_value_loss       | 0.0838       |
|    cost_values           | 0.795        |
|    entropy               | -0.897       |
|    entropy_loss          | -0.897       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.32         |
|    n_updates             | 11800        |
|    policy_gradient_loss  | -0.000549    |
|    std                   | 0.379        |
|    value_loss            | 7.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.76         |
| reward                   | -0.5995759   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 2420736      |
| train/                   |              |
|    approx_kl             | 0.0014326838 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 4.73         |
|    cost_values           | 0.933        |
|    entropy               | -0.898       |
|    entropy_loss          | -0.898       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.29         |
|    n_updates             | 11810        |
|    policy_gradient_loss  | -0.00034     |
|    std                   | 0.379        |
|    value_loss            | 7.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.42         |
| reward                   | -0.74950784  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 2422784      |
| train/                   |              |
|    approx_kl             | 0.0004025281 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.963        |
|    cost_value_loss       | 0.298        |
|    cost_values           | 0.95         |
|    entropy               | -0.897       |
|    entropy_loss          | -0.898       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 11820        |
|    policy_gradient_loss  | -7.6e-05     |
|    std                   | 0.379        |
|    value_loss            | 34.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.32         |
| reward                   | -0.5618847   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 2424832      |
| train/                   |              |
|    approx_kl             | 0.0022281753 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.882        |
|    cost_value_loss       | 0.411        |
|    cost_values           | 0.892        |
|    entropy               | -0.896       |
|    entropy_loss          | -0.897       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.53         |
|    n_updates             | 11830        |
|    policy_gradient_loss  | -0.000431    |
|    std                   | 0.379        |
|    value_loss            | 2.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.09        |
| reward                   | -0.8129839  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 299         |
|    total_timesteps       | 2426880     |
| train/                   |             |
|    approx_kl             | 0.001278822 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 1           |
|    cost_value_loss       | 1.09        |
|    cost_values           | 0.974       |
|    entropy               | -0.906      |
|    entropy_loss          | -0.901      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 11840       |
|    policy_gradient_loss  | 2.92e-05    |
|    std                   | 0.381       |
|    value_loss            | 3.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.56         |
| reward                   | -0.65018344  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 2428928      |
| train/                   |              |
|    approx_kl             | 0.0055968724 |
|    clip_fraction         | 0.0575       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.919        |
|    cost_value_loss       | 0.295        |
|    cost_values           | 0.932        |
|    entropy               | -0.905       |
|    entropy_loss          | -0.907       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.13         |
|    n_updates             | 11850        |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.381        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.6322208   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -761         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 2430976      |
| train/                   |              |
|    approx_kl             | 0.0051082866 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.34         |
|    cost_values           | 1.03         |
|    entropy               | -0.896       |
|    entropy_loss          | -0.901       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 11860        |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.379        |
|    value_loss            | 9.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.3807237   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 2433024      |
| train/                   |              |
|    approx_kl             | 0.0032026488 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.842        |
|    cost_value_loss       | 0.0175       |
|    cost_values           | 0.9          |
|    entropy               | -0.895       |
|    entropy_loss          | -0.895       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.49         |
|    n_updates             | 11870        |
|    policy_gradient_loss  | -0.000911    |
|    std                   | 0.379        |
|    value_loss            | 3.42         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.8987625 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -758       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 13         |
|    time_elapsed          | 438        |
|    total_timesteps       | 2435072    |
| train/                   |            |
|    approx_kl             | 0.00439724 |
|    clip_fraction         | 0.0277     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.876      |
|    cost_value_loss       | 0.415      |
|    cost_values           | 0.849      |
|    entropy               | -0.895     |
|    entropy_loss          | -0.896     |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.36       |
|    n_updates             | 11880      |
|    policy_gradient_loss  | -0.00243   |
|    std                   | 0.379      |
|    value_loss            | 14.7       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.3089532  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 473         |
|    total_timesteps       | 2437120     |
| train/                   |             |
|    approx_kl             | 0.004314298 |
|    clip_fraction         | 0.00454     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.869       |
|    cost_value_loss       | 0.39        |
|    cost_values           | 0.873       |
|    entropy               | -0.894      |
|    entropy_loss          | -0.894      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.81        |
|    n_updates             | 11890       |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.379       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.8594125   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 2439168      |
| train/                   |              |
|    approx_kl             | 0.0039380877 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.87         |
|    cost_value_loss       | 0.372        |
|    cost_values           | 0.87         |
|    entropy               | -0.892       |
|    entropy_loss          | -0.893       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.62         |
|    n_updates             | 11900        |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.378        |
|    value_loss            | 7.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.86952317 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 542         |
|    total_timesteps       | 2441216     |
| train/                   |             |
|    approx_kl             | 0.003777204 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 0.878       |
|    cost_values           | 0.949       |
|    entropy               | -0.888      |
|    entropy_loss          | -0.89       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.76        |
|    n_updates             | 11910       |
|    policy_gradient_loss  | -0.00203    |
|    std                   | 0.378       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.88202053  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 576          |
|    total_timesteps       | 2443264      |
| train/                   |              |
|    approx_kl             | 0.0025942556 |
|    clip_fraction         | 0.00815      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.801        |
|    cost_value_loss       | 0.0146       |
|    cost_values           | 0.869        |
|    entropy               | -0.884       |
|    entropy_loss          | -0.886       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.477        |
|    n_updates             | 11920        |
|    policy_gradient_loss  | -0.000919    |
|    std                   | 0.377        |
|    value_loss            | 1.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.3526812  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 611         |
|    total_timesteps       | 2445312     |
| train/                   |             |
|    approx_kl             | 0.001413153 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.675       |
|    cost_value_loss       | 0.0559      |
|    cost_values           | 0.715       |
|    entropy               | -0.883      |
|    entropy_loss          | -0.883      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.733       |
|    n_updates             | 11930       |
|    policy_gradient_loss  | 1.87e-05    |
|    std                   | 0.377       |
|    value_loss            | 1.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.72743267 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 645         |
|    total_timesteps       | 2447360     |
| train/                   |             |
|    approx_kl             | 0.004557015 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.832       |
|    cost_value_loss       | 1.09        |
|    cost_values           | 0.758       |
|    entropy               | -0.881      |
|    entropy_loss          | -0.882      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.89        |
|    n_updates             | 11940       |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.376       |
|    value_loss            | 7.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.38        |
| reward                   | -0.52515525 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 680         |
|    total_timesteps       | 2449408     |
| train/                   |             |
|    approx_kl             | 0.005637287 |
|    clip_fraction         | 0.0431      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.819       |
|    cost_value_loss       | 0.545       |
|    cost_values           | 0.831       |
|    entropy               | -0.881      |
|    entropy_loss          | -0.881      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 11950       |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.376       |
|    value_loss            | 8.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.53311867  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 2451456      |
| train/                   |              |
|    approx_kl             | 0.0018689055 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.679        |
|    cost_value_loss       | 0.014        |
|    cost_values           | 0.77         |
|    entropy               | -0.878       |
|    entropy_loss          | -0.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.95         |
|    n_updates             | 11960        |
|    policy_gradient_loss  | -0.000727    |
|    std                   | 0.376        |
|    value_loss            | 6.95         |
-------------------------------------------
