wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230728_214209-bdfcd509-c721-4731-9142-0294935d8fb4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cpo_step_per_epoch50000-af06
wandb: â­ï¸ View project at https://wandb.ai/ecrl/fast-safe-rl
wandb: ğŸš€ View run at https://wandb.ai/ecrl/fast-safe-rl/runs/bdfcd509-c721-4731-9142-0294935d8fb4
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230728_214209-4b433a18-fc9f-4a25-acea-caf4c1455ccd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cpo_step_per_epoch50000-89b7
wandb: â­ï¸ View project at https://wandb.ai/ecrl/fast-safe-rl
wandb: ğŸš€ View run at https://wandb.ai/ecrl/fast-safe-rl/runs/4b433a18-fc9f-4a25-acea-caf4c1455ccd
[32;1mLogging data to logs/fast-safe-rl/parking-v0-cost-10/cpo_step_per_epoch50000-af06/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "backtrack_coeff":	0.8,
    "batch_size":	99999,
    "buffer_size":	100000,
    "cost_limit":	10,
    "damping_coeff":	0.1,
    "deterministic_eval":	true,
    "device":	"cuda",
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal-high-reward.txt",
    "episode_per_collect":	20,
    "epoch":	500,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "l2_reg":	0.001,
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.001,
    "max_backtracks":	100,
    "max_batchsize":	99999,
    "name":	"cpo_step_per_epoch50000-af06",
    "norm_adv":	true,
    "optim_critic_iters":	10,
    "prefix":	"cpo",
    "project":	"fast-safe-rl",
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	50000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "verbose":	true,
    "worker":	"ShmemVectorEnv"
}
Observation Space: Dict('achieved_goal': Box(-inf, inf, (6,), float64), 'desired_goal': Box(-inf, inf, (6,), float64), 'observation': Box(-inf, inf, (6,), float64))
Action Space: Box(-1.0, 1.0, (2,), float32)
Render Mode: None
[32;1mLogging data to logs/fast-safe-rl/parking-v0-cost-10/cpo_step_per_epoch50000-89b7/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "backtrack_coeff":	0.8,
    "batch_size":	99999,
    "buffer_size":	100000,
    "cost_limit":	10,
    "damping_coeff":	0.1,
    "deterministic_eval":	true,
    "device":	"cuda",
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	20,
    "epoch":	500,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "l2_reg":	0.001,
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.001,
    "max_backtracks":	100,
    "max_batchsize":	99999,
    "name":	"cpo_step_per_epoch50000-89b7",
    "norm_adv":	true,
    "optim_critic_iters":	10,
    "prefix":	"cpo",
    "project":	"fast-safe-rl",
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	50000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "verbose":	true,
    "worker":	"ShmemVectorEnv"
}
Observation Space: Dict('achieved_goal': Box(-inf, inf, (6,), float64), 'desired_goal': Box(-inf, inf, (6,), float64), 'observation': Box(-inf, inf, (6,), float64))
Action Space: Box(-1.0, 1.0, (2,), float32)
Render Mode: None
Epoch #1:   0%|          | 0/50000 [00:00<?, ?it/s]Epoch #1:   0%|          | 20/50000 [00:00<05:49, 143.00it/s]Epoch #1:   0%|          | 20/50000 [00:00<05:49, 143.00it/s, cost=0, length=1, rew=-.465]Epoch #1:   0%|          | 40/50000 [00:00<14:46, 56.37it/s, cost=0, length=1, rew=-.465] Epoch #1:   0%|          | 40/50000 [00:01<14:46, 56.37it/s, cost=0, length=1, rew=-.488]Epoch #1:   0%|          | 60/50000 [00:01<20:07, 41.36it/s, cost=0, length=1, rew=-.488]Epoch #1:   0%|          | 60/50000 [00:01<20:07, 41.36it/s, cost=0, length=1, rew=-.435]Epoch #1:   0%|          | 80/50000 [00:01<21:48, 38.15it/s, cost=0, length=1, rew=-.435]Epoch #1:   0%|          | 80/50000 [00:02<21:48, 38.15it/s, cost=0, length=1, rew=-.448]Epoch #1:   0%|          | 100/50000 [00:02<21:42, 38.31it/s, cost=0, length=1, rew=-.448]Epoch #1:   0%|          | 100/50000 [00:02<21:42, 38.31it/s, cost=0, length=1, rew=-.473]Epoch #1:   0%|          | 120/50000 [00:02<22:04, 37.67it/s, cost=0, length=1, rew=-.473]Epoch #1:   0%|          | 120/50000 [00:03<22:04, 37.67it/s, cost=0, length=1, rew=-.447]Epoch #1:   0%|          | 140/50000 [00:03<23:02, 36.06it/s, cost=0, length=1, rew=-.447]Epoch #1:   0%|          | 140/50000 [00:03<23:02, 36.06it/s, cost=0, length=1, rew=-.455]Epoch #1:   0%|          | 160/50000 [00:04<23:01, 36.07it/s, cost=0, length=1, rew=-.455]Epoch #1:   0%|          | 160/50000 [00:04<23:01, 36.07it/s, cost=0, length=1, rew=-.477]Epoch #1:   0%|          | 180/50000 [00:04<22:40, 36.62it/s, cost=0, length=1, rew=-.477]Epoch #1:   0%|          | 180/50000 [00:05<22:40, 36.62it/s, cost=0, length=1, rew=-.489]Epoch #1:   0%|          | 200/50000 [00:05<23:05, 35.93it/s, cost=0, length=1, rew=-.489]Epoch #1:   0%|          | 200/50000 [00:05<23:05, 35.93it/s, cost=0, length=1, rew=-.474]Epoch #1:   0%|          | 220/50000 [00:05<21:40, 38.27it/s, cost=0, length=1, rew=-.474]Epoch #1:   0%|          | 220/50000 [00:06<21:40, 38.27it/s, cost=0, length=1, rew=-.451]Epoch #1:   0%|          | 240/50000 [00:06<22:22, 37.07it/s, cost=0, length=1, rew=-.451]/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/cpo.py:302: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  lam = torch.tensor(lam)
Epoch #1:   0%|          | 240/50000 [00:06<22:22, 37.07it/s, cost=0, length=1, rew=-.465]Epoch #1:   1%|          | 260/50000 [00:06<24:10, 34.29it/s, cost=0, length=1, rew=-.465]Epoch #1:   1%|          | 260/50000 [00:07<24:10, 34.29it/s, cost=0, length=1, rew=-.488]Epoch #1:   1%|          | 280/50000 [00:07<22:32, 36.75it/s, cost=0, length=1, rew=-.488]Epoch #1:   1%|          | 280/50000 [00:07<22:32, 36.75it/s, cost=0, length=1, rew=-.441]Epoch #1:   1%|          | 300/50000 [00:07<22:27, 36.90it/s, cost=0, length=1, rew=-.441]Epoch #1:   1%|          | 300/50000 [00:08<22:27, 36.90it/s, cost=0, length=1, rew=-.453]Epoch #1:   1%|          | 320/50000 [00:08<22:44, 36.41it/s, cost=0, length=1, rew=-.453]Epoch #1:   1%|          | 320/50000 [00:08<22:44, 36.41it/s, cost=0, length=1, rew=-.451]Epoch #1:   1%|          | 340/50000 [00:09<23:25, 35.33it/s, cost=0, length=1, rew=-.451]Epoch #1:   1%|          | 340/50000 [00:09<23:25, 35.33it/s, cost=0, length=1, rew=-.469]Epoch #1:   1%|          | 360/50000 [00:09<23:14, 35.61it/s, cost=0, length=1, rew=-.469]Epoch #1:   1%|          | 360/50000 [00:10<23:14, 35.61it/s, cost=0, length=1, rew=-.49] Epoch #1:   1%|          | 380/50000 [00:10<22:40, 36.48it/s, cost=0, length=1, rew=-.49]Epoch #1:   1%|          | 380/50000 [00:10<22:40, 36.48it/s, cost=0, length=1, rew=-.448]Epoch #1:   1%|          | 400/50000 [00:10<22:52, 36.13it/s, cost=0, length=1, rew=-.448]Epoch #1:   1%|          | 400/50000 [00:11<22:52, 36.13it/s, cost=0, length=1, rew=-.481]Epoch #1:   1%|          | 420/50000 [00:11<22:40, 36.44it/s, cost=0, length=1, rew=-.481]Epoch #1:   1%|          | 420/50000 [00:11<22:40, 36.44it/s, cost=0, length=1, rew=-.472]Epoch #1:   1%|          | 440/50000 [00:11<22:26, 36.80it/s, cost=0, length=1, rew=-.472]Epoch #1:   1%|          | 440/50000 [00:12<22:26, 36.80it/s, cost=0, length=1, rew=-.492]Epoch #1:   1%|          | 460/50000 [00:12<22:33, 36.61it/s, cost=0, length=1, rew=-.492]Epoch #1:   1%|          | 460/50000 [00:12<22:33, 36.61it/s, cost=0, length=1, rew=-.47] Epoch #1:   1%|          | 480/50000 [00:12<21:49, 37.82it/s, cost=0, length=1, rew=-.47]Epoch #1:   1%|          | 480/50000 [00:13<21:49, 37.82it/s, cost=0, length=1, rew=-.447]Epoch #1:   1%|1         | 500/50000 [00:13<22:31, 36.63it/s, cost=0, length=1, rew=-.447]Epoch #1:   1%|1         | 500/50000 [00:13<22:31, 36.63it/s, cost=0, length=1, rew=-.44] Epoch #1:   1%|1         | 520/50000 [00:13<22:03, 37.38it/s, cost=0, length=1, rew=-.44]Epoch #1:   1%|1         | 520/50000 [00:14<22:03, 37.38it/s, cost=0, length=1, rew=-.469]Epoch #1:   1%|1         | 540/50000 [00:14<22:22, 36.84it/s, cost=0, length=1, rew=-.469]Epoch #1:   1%|1         | 540/50000 [00:14<22:22, 36.84it/s, cost=0, length=1, rew=-.476]Epoch #1:   1%|1         | 560/50000 [00:14<21:50, 37.72it/s, cost=0, length=1, rew=-.476]Epoch #1:   1%|1         | 560/50000 [00:15<21:50, 37.72it/s, cost=0, length=1, rew=-.441]Epoch #1:   1%|1         | 580/50000 [00:15<20:45, 39.67it/s, cost=0, length=1, rew=-.441]Epoch #1:   1%|1         | 580/50000 [00:15<20:45, 39.67it/s, cost=0, length=1, rew=-.445]Epoch #1:   1%|1         | 600/50000 [00:15<21:03, 39.10it/s, cost=0, length=1, rew=-.445]Epoch #1:   1%|1         | 600/50000 [00:16<21:03, 39.10it/s, cost=0, length=1, rew=-.465]Epoch #1:   1%|1         | 620/50000 [00:16<22:17, 36.91it/s, cost=0, length=1, rew=-.465]Epoch #1:   1%|1         | 620/50000 [00:17<22:17, 36.91it/s, cost=0, length=1, rew=-.494]Epoch #1:   1%|1         | 640/50000 [00:17<22:42, 36.22it/s, cost=0, length=1, rew=-.494]Epoch #1:   1%|1         | 640/50000 [00:17<22:42, 36.22it/s, cost=0, length=1, rew=-.468]Epoch #1:   1%|1         | 660/50000 [00:17<22:13, 37.00it/s, cost=0, length=1, rew=-.468]Epoch #1:   1%|1         | 660/50000 [00:18<22:13, 37.00it/s, cost=0, length=1, rew=-.501]Epoch #1:   1%|1         | 680/50000 [00:18<22:05, 37.21it/s, cost=0, length=1, rew=-.501]Epoch #1:   1%|1         | 680/50000 [00:18<22:05, 37.21it/s, cost=0, length=1, rew=-.489]Epoch #1:   1%|1         | 700/50000 [00:18<22:35, 36.36it/s, cost=0, length=1, rew=-.489]Epoch #1:   1%|1         | 700/50000 [00:18<22:06, 37.17it/s, cost=0, length=1, rew=-.489]
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/CPO/train_cpo_1.py", line 202, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/CPO/train_cpo_1.py", line 168, in train
    agent.learn(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/agent/cpo_agent.py", line 233, in learn
    return super().learn(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/agent/base_agent.py", line 319, in learn
    for epoch, _epoch_stat, info in trainer:
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 205, in __next__
    self.policy_update_fn(stats_train)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/onpolicy.py", line 102, in policy_update_fn
    self.policy.update(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 351, in update
    self.learn(batch, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/cpo.py", line 367, in learn
    loss_actor, stats_actor = self.policy_loss(minibatch)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/cpo.py", line 323, in policy_loss
    dist = self.forward(minibatch).dist
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 180, in forward
    dist = self.dist_fn(*logits)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/agent/cpo_agent.py", line 183, in dist
    return Independent(Normal(*logits), 1)
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/distributions/normal.py", line 56, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/distributions/distribution.py", line 62, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Tensor of shape (20, 2)) of distribution Normal(loc: torch.Size([20, 2]), scale: torch.Size([20, 2])) to satisfy the constraint Real(), but found invalid values:
tensor([[nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan]], device='cuda:0')
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/CPO/train_cpo_1.py", line 202, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/CPO/train_cpo_1.py", line 168, in train
    agent.learn(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/agent/cpo_agent.py", line 233, in learn
    return super().learn(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/agent/base_agent.py", line 319, in learn
    for epoch, _epoch_stat, info in trainer:
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 205, in __next__
    self.policy_update_fn(stats_train)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/onpolicy.py", line 102, in policy_update_fn
    self.policy.update(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 351, in update
    self.learn(batch, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/cpo.py", line 367, in learn
    loss_actor, stats_actor = self.policy_loss(minibatch)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/cpo.py", line 323, in policy_loss
    dist = self.forward(minibatch).dist
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 180, in forward
    dist = self.dist_fn(*logits)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/agent/cpo_agent.py", line 183, in dist
    return Independent(Normal(*logits), 1)
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/distributions/normal.py", line 56, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/distributions/distribution.py", line 62, in __init__
    raise ValueError(
ValueError: Expected parameter loc (Tensor of shape (20, 2)) of distribution Normal(loc: torch.Size([20, 2]), scale: torch.Size([20, 2])) to satisfy the constraint Real(), but found invalid values:
tensor([[nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan],
        [nan, nan]], device='cuda:0')
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: \ 0.027 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: | 0.027 MB of 0.039 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:        loss/cost_loss â–ˆâ–â–‚â–‚â–â–‚â–…â–„â–„â–…â–„â–…â–…â–†â–…â–…â–†â–†â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†
wandb:          loss/entropy â–…â–‡â–†â–„â–‚â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               loss/kl â–â–„â–…â–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–‡â–‡â–‡â–†â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–†â–…â–…
wandb:          loss/optim_A â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒ
wandb:          loss/optim_B â–ˆâ–ˆâ–„â–…â–â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„
wandb:          loss/optim_C â–ˆâ–â–‚â–‚â–â–‚â–…â–„â–„â–…â–„â–…â–…â–†â–…â–…â–†â–†â–…â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–†
wandb:          loss/optim_Q â–ƒâ–…â–†â–…â–…â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…
wandb:          loss/optim_R â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:          loss/optim_S â–…â–…â–ƒâ–„â–ƒâ–‡â–ˆâ–‡â–†â–†â–…â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–
wandb:       loss/optim_case â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–ƒâ–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         loss/optim_nu â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†
wandb:         loss/rew_loss â–â–…â–‡â–…â–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:        loss/step_size â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              loss/vf0 â–ˆâ–‡â–†â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              loss/vf1 â–ˆâ–†â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         loss/vf_total â–ˆâ–†â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            train/cost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/length â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/reward â–…â–â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–†â–†â–†â–†â–…â–†â–†â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–…â–…
wandb:       update/cum_cost â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        update/episode â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: update/gradient_steps â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:        loss/cost_loss -0.00089
wandb:          loss/entropy 2.8361
wandb:               loss/kl 0.00694
wandb:          loss/optim_A 225.18817
wandb:          loss/optim_B -135.09968
wandb:          loss/optim_C -10.00089
wandb:          loss/optim_Q 0.41387
wandb:          loss/optim_R -5.25799
wandb:          loss/optim_S 0.7134
wandb:       loss/optim_case 2.94853
wandb:        loss/optim_lam nan
wandb:         loss/optim_nu -0.00114
wandb:         loss/rew_loss 0.08834
wandb:        loss/step_size 0.12196
wandb:              loss/vf0 0.01978
wandb:              loss/vf1 0.00592
wandb:         loss/vf_total 0.0257
wandb:            train/cost 0.0
wandb:          train/length 1.0
wandb:          train/reward -0.46633
wandb:       update/cum_cost 0.0
wandb:        update/episode 350.0
wandb: update/gradient_steps 70.0
wandb: 
wandb: ğŸš€ View run cpo_step_per_epoch50000-af06 at: https://wandb.ai/ecrl/fast-safe-rl/runs/bdfcd509-c721-4731-9142-0294935d8fb4
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230728_214209-bdfcd509-c721-4731-9142-0294935d8fb4/logs
srun: error: ddpg.ist.berkeley.edu: task 0: Exited with exit code 1
Epoch #1:   0%|          | 0/50000 [00:00<?, ?it/s]Epoch #1:  25%|##5       | 12710/50000 [00:24<01:12, 512.85it/s]Epoch #1:  25%|##5       | 12710/50000 [00:26<01:12, 512.85it/s, cost=0, length=636, rew=-663]Epoch #1:  25%|##5       | 12710/50000 [00:40<01:12, 512.85it/s, cost=0, length=636, rew=-663]Epoch #1:  51%|#####1    | 25593/50000 [00:50<00:48, 503.20it/s, cost=0, length=636, rew=-663]Epoch #1:  51%|#####1    | 25593/50000 [00:52<00:48, 503.20it/s, cost=0, length=644, rew=-786]Epoch #1:  51%|#####1    | 25593/50000 [01:10<00:48, 503.20it/s, cost=0, length=644, rew=-786]Epoch #1:  80%|#######9  | 39933/50000 [01:20<00:20, 495.30it/s, cost=0, length=644, rew=-786]Epoch #1:  80%|#######9  | 39933/50000 [01:21<00:20, 495.30it/s, cost=0, length=717, rew=-651]Epoch #1:  80%|#######9  | 39933/50000 [01:40<00:20, 495.30it/s, cost=0, length=717, rew=-651]Epoch #1: 52603it [01:45, 496.46it/s, cost=0, length=717, rew=-651]                           Epoch #1: 52603it [01:47, 496.46it/s, cost=0, length=634, rew=-508]Epoch #1: 52603it [01:47, 491.19it/s, cost=0, length=634, rew=-508]
-------------------------------------------------
|              loss/cost_loss |         0.00148 |
|                loss/entropy |            2.78 |
|                     loss/kl |         0.00692 |
|                loss/optim_A |         0.00845 |
|                loss/optim_B |       -5.16e+03 |
|                loss/optim_C |             -10 |
|                loss/optim_Q |          0.0086 |
|                loss/optim_R |       -0.000739 |
|                loss/optim_S |          0.0198 |
|             loss/optim_case |               3 |
|              loss/optim_lam |           0.617 |
|               loss/optim_nu |               0 |
|               loss/rew_loss |          0.0102 |
|              loss/step_size |           0.122 |
|                    loss/vf0 |              90 |
|                    loss/vf1 |          0.0522 |
|               loss/vf_total |              90 |
|                   test/cost |               0 |
|                 test/length |             750 |
|                 test/reward |            -427 |
|                  train/cost |               0 |
|                train/length |             657 |
|                train/reward |            -652 |
|             update/cum_cost |               0 |
|             update/duration |             113 |
|             update/env_step |        5.26e+04 |
|              update/episode |              50 |
|       update/gradient_steps |              10 |
|      update/remaining_epoch |             499 |
|           update/test_speed |             254 |
|            update/test_time |            5.91 |
| update/train_collector_time |             101 |
|     update/train_model_time |            6.13 |
|          update/train_speed |             491 |
-------------------------------------------------
Epoch: 1 {'duration': 113.02869439125061, 'test_time': 5.912127733230591, 'test_speed': 253.71576320465394, 'train_collector_time': 100.98581862449646, 'train_model_time': 6.13074803352356, 'train_speed': 491.08183394208436, 'remaining_epoch': 499, 'best_reward': -427.08262769471753, 'best_cost': 0.0}
Epoch #2:   0%|          | 0/50000 [00:00<?, ?it/s]Epoch #2:  30%|###       | 15000/50000 [00:28<01:06, 524.75it/s]Epoch #2:  30%|###       | 15000/50000 [00:30<01:06, 524.75it/s, cost=0, length=750, rew=-535]Epoch #2:  30%|###       | 15000/50000 [00:46<01:06, 524.75it/s, cost=0, length=750, rew=-535]Epoch #2:  60%|#####9    | 29824/50000 [00:58<00:39, 508.34it/s, cost=0, length=750, rew=-535]Epoch #2:  60%|#####9    | 29824/50000 [01:00<00:39, 508.34it/s, cost=0, length=741, rew=-419]Epoch #2:  60%|#####9    | 29824/50000 [01:16<00:39, 508.34it/s, cost=0, length=741, rew=-419]Epoch #2:  87%|########6 | 43467/50000 [01:26<00:13, 499.88it/s, cost=0, length=741, rew=-419]Epoch #2:  87%|########6 | 43467/50000 [01:27<00:13, 499.88it/s, cost=0, length=682, rew=-379]Epoch #2:  87%|########6 | 43467/50000 [01:36<00:13, 499.88it/s, cost=0, length=682, rew=-379]Epoch #2: 56353it [01:51, 500.90it/s, cost=0, length=682, rew=-379]                           Epoch #2: 56353it [01:53, 500.90it/s, cost=0, length=644, rew=-344]Epoch #2: 56353it [01:53, 498.23it/s, cost=0, length=644, rew=-344]
-------------------------------------------------
|              loss/cost_loss |       -0.000234 |
|                loss/entropy |            2.71 |
|                     loss/kl |         0.00699 |
|                loss/optim_A |         0.00431 |
|                loss/optim_B |        -6.2e+03 |
|                loss/optim_C |             -10 |
|                loss/optim_Q |         0.00492 |
|                loss/optim_R |         0.00034 |
|                loss/optim_S |          0.0216 |
|             loss/optim_case |               3 |
|              loss/optim_lam |           0.483 |
|               loss/optim_nu |               0 |
|               loss/rew_loss |         0.00904 |
|              loss/step_size |           0.166 |
|                    loss/vf0 |            10.7 |
|                    loss/vf1 |         0.00455 |
|               loss/vf_total |            10.7 |
|                   test/cost |               0 |
|                 test/length |             750 |
|                 test/reward |            -345 |
|                  train/cost |               0 |
|            train/cost_limit |              10 |
|                train/length |             704 |
|                train/reward |            -419 |
|             update/cum_cost |               0 |
|             update/duration |             232 |
|             update/env_step |        1.09e+05 |
|              update/episode |             130 |
|       update/gradient_steps |              26 |
|      update/remaining_epoch |             498 |
|           update/test_speed |             253 |
|            update/test_time |            11.8 |
| update/train_collector_time |             207 |
|     update/train_model_time |            12.8 |
|          update/train_speed |             495 |
-------------------------------------------------
Epoch: 2 {'duration': 232.08374762535095, 'test_time': 11.835011720657349, 'test_speed': 253.4851735519339, 'train_collector_time': 207.44858646392822, 'train_model_time': 12.80014944076538, 'train_speed': 494.69523424255937, 'remaining_epoch': 498, 'best_reward': -345.46741453950233, 'best_cost': 0.0}
Epoch #3:   0%|          | 0/50000 [00:00<?, ?it/s]Epoch #3:  25%|##5       | 12659/50000 [00:23<01:09, 535.12it/s]Epoch #3:  25%|##5       | 12659/50000 [00:25<01:09, 535.12it/s, cost=0, length=633, rew=-315]Epoch #3:  25%|##5       | 12659/50000 [00:37<01:09, 535.12it/s, cost=0, length=633, rew=-315]Epoch #3:  51%|#####1    | 25731/50000 [00:49<00:47, 514.01it/s, cost=0, length=633, rew=-315]Epoch #3:  51%|#####1    | 25731/50000 [00:51<00:47, 514.01it/s, cost=0, length=654, rew=-368]Epoch #3:  51%|#####1    | 25731/50000 [01:07<00:47, 514.01it/s, cost=0, length=654, rew=-368]Epoch #3:  77%|#######7  | 38639/50000 [01:15<00:22, 508.40it/s, cost=0, length=654, rew=-368]Epoch #3:  77%|#######7  | 38639/50000 [01:17<00:22, 508.40it/s, cost=0, length=645, rew=-307]Epoch #3:  77%|#######7  | 38639/50000 [01:27<00:22, 508.40it/s, cost=0, length=645, rew=-307]Epoch #3: 52240it [01:42, 507.87it/s, cost=0, length=645, rew=-307]                           Epoch #3: 52240it [01:43, 507.87it/s, cost=0, length=680, rew=-330]Epoch #3: 52240it [01:43, 502.47it/s, cost=0, length=680, rew=-330]
-------------------------------------------------
|              loss/cost_loss |        -0.00338 |
|                loss/entropy |            2.69 |
|                     loss/kl |         0.00695 |
|                loss/optim_A |         0.00426 |
|                loss/optim_B |       -1.86e+04 |
|                loss/optim_C |             -10 |
|                loss/optim_Q |         0.00486 |
|                loss/optim_R |         0.00188 |
|                loss/optim_S |         0.00737 |
|             loss/optim_case |               3 |
|              loss/optim_lam |           0.482 |
|               loss/optim_nu |               0 |
|               loss/rew_loss |          0.0087 |
|              loss/step_size |           0.136 |
|                    loss/vf0 |            7.49 |
|                    loss/vf1 |        0.000548 |
|               loss/vf_total |            7.49 |
|                   test/cost |               0 |
|                 test/length |             750 |
|                 test/reward |            -370 |
|                  train/cost |               0 |
|            train/cost_limit |              10 |
|                train/length |             652 |
|                train/reward |            -330 |
|             update/cum_cost |               0 |
|             update/duration |             342 |
|             update/env_step |        1.61e+05 |
|              update/episode |             210 |
|       update/gradient_steps |              42 |
|      update/remaining_epoch |             497 |
|           update/test_speed |             254 |
|            update/test_time |            17.7 |
| update/train_collector_time |             305 |
|     update/train_model_time |            19.2 |
|          update/train_speed |             497 |
-------------------------------------------------
Epoch: 3 {'duration': 341.96555352211, 'test_time': 17.721890687942505, 'test_speed': 253.92324550685092, 'train_collector_time': 305.06425166130066, 'train_model_time': 19.17941117286682, 'train_speed': 497.1446429854907, 'remaining_epoch': 497, 'best_reward': -345.46741453950233, 'best_cost': 0.0}
slurmstepd: error: *** JOB 31251 ON ddpg.ist.berkeley.edu CANCELLED AT 2023-07-28T21:48:31 ***
