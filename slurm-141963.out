wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240222_193107-h3wsymxd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-firecracker-18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/h3wsymxd
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
Using cpu device
------------------------------------
| avg_speed          | 1.96        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.96        |
| reward             | -0.41147444 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.52e+03   |
| time/              |             |
|    fps             | 70          |
|    iterations      | 1           |
|    time_elapsed    | 28          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 2.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.49         |
| reward                   | -0.88898724  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 2            |
|    time_elapsed          | 55           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0039058137 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.159        |
|    cost_value_loss       | 0.82         |
|    cost_values           | 0.0502       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00486      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 303          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 1            |
|    value_loss            | 673          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.09        |
| reward                   | -0.7336     |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.41e+03   |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 3           |
|    time_elapsed          | 84          |
|    total_timesteps       | 6144        |
| train/                   |             |
|    approx_kl             | 0.004133689 |
|    clip_fraction         | 0.0304      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.62        |
|    cost_value_loss       | 3.03        |
|    cost_values           | 0.308       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0738      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 181         |
|    n_updates             | 20          |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 1           |
|    value_loss            | 369         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.41        |
| reward                   | -0.76359344 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.4e+03    |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 4           |
|    time_elapsed          | 117         |
|    total_timesteps       | 8192        |
| train/                   |             |
|    approx_kl             | 0.006576338 |
|    clip_fraction         | 0.0725      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.493       |
|    cost_value_loss       | 1.01        |
|    cost_values           | 0.415       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0381      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 313         |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 0.997       |
|    value_loss            | 656         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.21         |
| reward                   | -0.7674828   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 5            |
|    time_elapsed          | 147          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0038477723 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.649        |
|    cost_value_loss       | 1.42         |
|    cost_values           | 0.546        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0365       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 272          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.997        |
|    value_loss            | 559          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.873        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.873        |
| reward                   | -1.4833907   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 6            |
|    time_elapsed          | 179          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0035531211 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 2.65         |
|    cost_values           | 0.778        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.063        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 158          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 1            |
|    value_loss            | 324          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.3613633   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 7            |
|    time_elapsed          | 216          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0027350658 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.901        |
|    cost_value_loss       | 0.887        |
|    cost_values           | 0.774        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0369       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 253          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.000887    |
|    std                   | 0.998        |
|    value_loss            | 511          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.16         |
| reward                   | -1.9237603   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 8            |
|    time_elapsed          | 254          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0042021177 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.973        |
|    cost_value_loss       | 1.79         |
|    cost_values           | 0.848        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0563       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 144          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.997        |
|    value_loss            | 312          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -1.0030643   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 9            |
|    time_elapsed          | 290          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0031625056 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.96         |
|    cost_value_loss       | 1.21         |
|    cost_values           | 0.75         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0267       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 298          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.996        |
|    value_loss            | 602          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.4112484  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 334         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.004066289 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 2.24        |
|    cost_values           | 0.856       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0376      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 156         |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 1           |
|    value_loss            | 336         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.6156232  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 11          |
|    time_elapsed          | 376         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.004674567 |
|    clip_fraction         | 0.0376      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.969       |
|    cost_value_loss       | 0.807       |
|    cost_values           | 0.966       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0095      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 427         |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 1           |
|    value_loss            | 874         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.57         |
| reward                   | -0.7082105   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 12           |
|    time_elapsed          | 421          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0043375734 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 0.875        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0656       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 110          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.999        |
|    value_loss            | 226          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.7030189   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 56           |
|    iterations            | 13           |
|    time_elapsed          | 471          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0049993806 |
|    clip_fraction         | 0.0421       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.67         |
|    cost_values           | 0.929        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0353       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 262          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00514     |
|    std                   | 1            |
|    value_loss            | 516          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.88459355  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 55           |
|    iterations            | 14           |
|    time_elapsed          | 520          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0021972347 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 0.908        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0428       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 236          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 1            |
|    value_loss            | 482          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.48        |
| reward                   | -1.8686585  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 53          |
|    iterations            | 15          |
|    time_elapsed          | 574         |
|    total_timesteps       | 30720       |
| train/                   |             |
|    approx_kl             | 0.003097929 |
|    clip_fraction         | 0.0209      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 2.04        |
|    cost_values           | 0.972       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0272      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 133         |
|    n_updates             | 140         |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 1           |
|    value_loss            | 273         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.2295218   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 52           |
|    iterations            | 16           |
|    time_elapsed          | 625          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0049665123 |
|    clip_fraction         | 0.0656       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 1.26         |
|    cost_values           | 0.959        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0268       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 167          |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 0.997        |
|    value_loss            | 337          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -1.4502664   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 17           |
|    time_elapsed          | 687          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0026688427 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.993        |
|    cost_value_loss       | 1.2          |
|    cost_values           | 0.967        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0108       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 323          |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.992        |
|    value_loss            | 681          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3122185   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 49           |
|    iterations            | 18           |
|    time_elapsed          | 742          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0018547414 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.42         |
|    cost_values           | 0.981        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0212       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 309          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.993        |
|    value_loss            | 632          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.1682389  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 48          |
|    iterations            | 19          |
|    time_elapsed          | 809         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.004538219 |
|    clip_fraction         | 0.0448      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 1.49        |
|    cost_values           | 0.992       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0325      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 194         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 0.995       |
|    value_loss            | 407         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.07        |
| reward                   | -1.123109   |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 46          |
|    iterations            | 20          |
|    time_elapsed          | 878         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.003303199 |
|    clip_fraction         | 0.0105      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 2.11        |
|    cost_values           | 0.976       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0248      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 219         |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.994       |
|    value_loss            | 454         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.8376757  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 21          |
|    time_elapsed          | 944         |
|    total_timesteps       | 43008       |
| train/                   |             |
|    approx_kl             | 0.005292456 |
|    clip_fraction         | 0.0223      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 1.74        |
|    cost_values           | 0.941       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0168      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 187         |
|    n_updates             | 200         |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.995       |
|    value_loss            | 389         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.8946425  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 44          |
|    iterations            | 22          |
|    time_elapsed          | 1023        |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.004418846 |
|    clip_fraction         | 0.0596      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.97        |
|    cost_values           | 0.909       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0106      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 149         |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.00403    |
|    std                   | 0.999       |
|    value_loss            | 310         |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.84       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.84       |
| reward                   | -1.0245785 |
| rollout/                 |            |
|    ep_len_mean           | 963        |
|    ep_rew_mean           | -1.28e+03  |
| time/                    |            |
|    fps                   | 42         |
|    iterations            | 23         |
|    time_elapsed          | 1101       |
|    total_timesteps       | 47104      |
| train/                   |            |
|    approx_kl             | 0.0038068  |
|    clip_fraction         | 0.0221     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.21       |
|    cost_value_loss       | 3.24       |
|    cost_values           | 0.957      |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0588     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 228        |
|    n_updates             | 220        |
|    policy_gradient_loss  | -0.00325   |
|    std                   | 1          |
|    value_loss            | 478        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -2.2247875   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 41           |
|    iterations            | 24           |
|    time_elapsed          | 1174         |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0026207557 |
|    clip_fraction         | 0.0062       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 5.19         |
|    cost_values           | 0.94         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0336       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 146          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.996        |
|    value_loss            | 327          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -1.4714376  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 40          |
|    iterations            | 25          |
|    time_elapsed          | 1257        |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.005708089 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.996       |
|    cost_value_loss       | 1.3         |
|    cost_values           | 0.98        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0173      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 232         |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.996       |
|    value_loss            | 481         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.3129915  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 39          |
|    iterations            | 26          |
|    time_elapsed          | 1344        |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.005293671 |
|    clip_fraction         | 0.0601      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 3.57        |
|    cost_values           | 0.967       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0389      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 136         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.996       |
|    value_loss            | 294         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.92        |
| reward                   | -0.34578207 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 38          |
|    iterations            | 27          |
|    time_elapsed          | 1424        |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.00361798  |
|    clip_fraction         | 0.0184      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 3.7         |
|    cost_values           | 0.963       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.0289      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 154         |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 0.99        |
|    value_loss            | 307         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.21        |
| reward                   | -0.64239085 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 38          |
|    iterations            | 28          |
|    time_elapsed          | 1506        |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.005136134 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 3           |
|    cost_values           | 0.974       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.0444      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 126         |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 0.99        |
|    value_loss            | 248         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9033983   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 37           |
|    iterations            | 29           |
|    time_elapsed          | 1596         |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0043434957 |
|    clip_fraction         | 0.0431       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 2.03         |
|    cost_values           | 0.975        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0141       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 217          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00458     |
|    std                   | 0.993        |
|    value_loss            | 459          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7608403   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 36           |
|    iterations            | 30           |
|    time_elapsed          | 1692         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0030873825 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.47         |
|    cost_values           | 0.986        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0106       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 218          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.994        |
|    value_loss            | 461          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.84924775 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 35          |
|    iterations            | 31          |
|    time_elapsed          | 1790        |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.004304272 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.24        |
|    cost_value_loss       | 2.97        |
|    cost_values           | 0.977       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0366      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 160         |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 0.995       |
|    value_loss            | 326         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.95         |
| reward                   | -0.5824557   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 34           |
|    iterations            | 32           |
|    time_elapsed          | 1886         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0047784466 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 2.04         |
|    cost_values           | 0.973        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0237       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.1         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00468     |
|    std                   | 0.996        |
|    value_loss            | 165          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.12         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.12         |
| reward                   | -0.4084192   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 34           |
|    iterations            | 33           |
|    time_elapsed          | 1979         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0050798147 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 4.59         |
|    cost_values           | 0.984        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.019        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 114          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 0.991        |
|    value_loss            | 229          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.44723535  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 33           |
|    iterations            | 34           |
|    time_elapsed          | 2075         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0062908907 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 0.975        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0214       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 125          |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.998        |
|    value_loss            | 257          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.47         |
| reward                   | -0.6329113   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 32           |
|    iterations            | 35           |
|    time_elapsed          | 2177         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0049705193 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 3.02         |
|    cost_values           | 0.99         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0307       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.6         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 1            |
|    value_loss            | 51.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.911        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.911        |
| reward                   | -0.7498876   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 32           |
|    iterations            | 36           |
|    time_elapsed          | 2283         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0062076626 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 4.73         |
|    cost_values           | 0.991        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0219       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 170          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.999        |
|    value_loss            | 342          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.4180772  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 31          |
|    iterations            | 37          |
|    time_elapsed          | 2392        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.004268132 |
|    clip_fraction         | 0.0594      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.87        |
|    cost_value_loss       | 34.4        |
|    cost_values           | 1.09        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0657      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 48.5        |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00689    |
|    std                   | 0.996       |
|    value_loss            | 67.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5505934   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 31           |
|    iterations            | 38           |
|    time_elapsed          | 2503         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0035284343 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 4.49         |
|    cost_values           | 0.995        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00843      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 138          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.991        |
|    value_loss            | 287          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.588       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.588       |
| reward                   | -0.64749926 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 30          |
|    iterations            | 39          |
|    time_elapsed          | 2612        |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.004664803 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 1.62        |
|    cost_values           | 0.976       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00902     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 162         |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.991       |
|    value_loss            | 331         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.59700704  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 30           |
|    iterations            | 40           |
|    time_elapsed          | 2725         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0038490747 |
|    clip_fraction         | 0.0418       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 17.2         |
|    cost_values           | 1            |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0154       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00429     |
|    std                   | 0.993        |
|    value_loss            | 224          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.344        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.344        |
| reward                   | -0.6016134   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 41           |
|    time_elapsed          | 2843         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0049899514 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 24.9         |
|    cost_values           | 1.23         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0302       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00436     |
|    std                   | 1            |
|    value_loss            | 21.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.4140929   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 42           |
|    time_elapsed          | 2960         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0018582928 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.9          |
|    cost_value_loss       | 26.9         |
|    cost_values           | 1.74         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0223       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.1         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1            |
|    value_loss            | 50.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.6          |
| reward                   | -0.7893331   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 43           |
|    time_elapsed          | 3082         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0029447626 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 9.33         |
|    cost_values           | 1.84         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0146       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.1         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 1.01         |
|    value_loss            | 80.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.9603707   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 44           |
|    time_elapsed          | 3200         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0047789975 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 9.8          |
|    cost_values           | 1.51         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0107       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.9         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 1.01         |
|    value_loss            | 101          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.97195524  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 45           |
|    time_elapsed          | 3326         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0042557055 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 3.05         |
|    cost_values           | 1.08         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.00349      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.5         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 1.02         |
|    value_loss            | 184          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -1.7889768   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 46           |
|    time_elapsed          | 3450         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0032095343 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 9.18         |
|    cost_values           | 0.969        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.00414      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81.9         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 1.02         |
|    value_loss            | 174          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.44         |
| reward                   | -1.9334878   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 47           |
|    time_elapsed          | 3578         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0035013023 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.47         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 1.05         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.00987      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.1         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 1.02         |
|    value_loss            | 90.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.8802019   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 48           |
|    time_elapsed          | 3707         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0049738763 |
|    clip_fraction         | 0.0494       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 6.11         |
|    cost_values           | 1.02         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.00756      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.7         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00569     |
|    std                   | 1.02         |
|    value_loss            | 181          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4532095   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 49           |
|    time_elapsed          | 3842         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0060698963 |
|    clip_fraction         | 0.0468       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 1.01         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.00664      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.5         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 1.03         |
|    value_loss            | 176          |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/h3wsymxd
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.7476742 |
| rollout/           |            |
|    ep_len_mean     | 968        |
|    ep_rew_mean     | -1.12e+03  |
| time/              |            |
|    fps             | 14         |
|    iterations      | 1          |
|    time_elapsed    | 142        |
|    total_timesteps | 102400     |
-----------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3286011  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 2           |
|    time_elapsed          | 279         |
|    total_timesteps       | 104448      |
| train/                   |             |
|    approx_kl             | 0.003910943 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 1.01        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00661     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 55          |
|    n_updates             | 500         |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 1.03        |
|    value_loss            | 96.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.90516263 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 3           |
|    time_elapsed          | 416         |
|    total_timesteps       | 106496      |
| train/                   |             |
|    approx_kl             | 0.004543846 |
|    clip_fraction         | 0.0476      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 8.35        |
|    cost_values           | 1           |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.00688     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.5        |
|    n_updates             | 510         |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 1.04        |
|    value_loss            | 99.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.12         |
| reward                   | -0.6734437   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 4            |
|    time_elapsed          | 568          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0044665276 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.89         |
|    cost_values           | 0.999        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00572      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.2         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00432     |
|    std                   | 1.04         |
|    value_loss            | 188          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -1.1451735  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 5           |
|    time_elapsed          | 713         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.002430391 |
|    clip_fraction         | 0.0189      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 3.15        |
|    cost_values           | 1           |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.00446     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 275         |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 1.04        |
|    value_loss            | 555         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -0.7703025   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 6            |
|    time_elapsed          | 859          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0032303005 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 7.1          |
|    cost_values           | 1            |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00827      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67           |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 1.04         |
|    value_loss            | 138          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.58         |
| reward                   | -1.5699598   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 7            |
|    time_elapsed          | 1028         |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0037993363 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 1.13         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00613      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.5         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 1.04         |
|    value_loss            | 50.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.82         |
| reward                   | -0.7087703   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 8            |
|    time_elapsed          | 1181         |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0044096485 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 6.12         |
|    cost_values           | 1.26         |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.012        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.5         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 1.05         |
|    value_loss            | 57.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.5418017   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 9            |
|    time_elapsed          | 1347         |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0036634738 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 7.05         |
|    cost_values           | 1.02         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.0107       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.6         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 1.05         |
|    value_loss            | 109          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -1.0026562   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 10           |
|    time_elapsed          | 1510         |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0046786424 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 1.71         |
|    cost_values           | 0.99         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.00489      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.1         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00632     |
|    std                   | 1.05         |
|    value_loss            | 70.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -1.0886605  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 11          |
|    time_elapsed          | 1682        |
|    total_timesteps       | 122880      |
| train/                   |             |
|    approx_kl             | 0.005078636 |
|    clip_fraction         | 0.0514      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 6.41        |
|    cost_values           | 1           |
|    entropy               | -2.93       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.0069      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.9        |
|    n_updates             | 590         |
|    policy_gradient_loss  | -0.00545    |
|    std                   | 1.05        |
|    value_loss            | 76.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.73         |
| reward                   | -2.2433107   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 12           |
|    time_elapsed          | 1848         |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0058075627 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 11           |
|    cost_values           | 1            |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.00916      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42           |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00545     |
|    std                   | 1.05         |
|    value_loss            | 77.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.5972049  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 13          |
|    time_elapsed          | 2030        |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.005653172 |
|    clip_fraction         | 0.0759      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 4.73        |
|    cost_values           | 1           |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.00506     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 71.5        |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.00729    |
|    std                   | 1.06        |
|    value_loss            | 140         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -1.4057353   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 14           |
|    time_elapsed          | 2195         |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0043221787 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 1.04         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.00384      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.6         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00672     |
|    std                   | 1.05         |
|    value_loss            | 132          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.88         |
| reward                   | -0.7774743   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 15           |
|    time_elapsed          | 2380         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0037623188 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.9          |
|    cost_values           | 1            |
|    entropy               | -2.93        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0108       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 102          |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 1.05         |
|    value_loss            | 209          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.762        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.762        |
| reward                   | -1.1185637   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 16           |
|    time_elapsed          | 2560         |
|    total_timesteps       | 133120       |
| train/                   |              |
|    approx_kl             | 0.0033480208 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 17.1         |
|    cost_values           | 1.06         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00516      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.3         |
|    n_updates             | 640          |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 1.04         |
|    value_loss            | 78.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.6043197   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 17           |
|    time_elapsed          | 2734         |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0046644215 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 4.82         |
|    cost_values           | 1.03         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00292      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.7         |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 1.04         |
|    value_loss            | 66.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -1.3628988  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 18          |
|    time_elapsed          | 2923        |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.003994673 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.27        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 1           |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.00766     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 40          |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 1.05        |
|    value_loss            | 78.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.01         |
| reward                   | -1.1819338   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 19           |
|    time_elapsed          | 3101         |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0067724176 |
|    clip_fraction         | 0.0706       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 4.07         |
|    cost_values           | 1            |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00748      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.6         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00761     |
|    std                   | 1.05         |
|    value_loss            | 88.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.06         |
| reward                   | -1.2719717   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 20           |
|    time_elapsed          | 3295         |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0053905454 |
|    clip_fraction         | 0.0615       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 3.47         |
|    cost_values           | 1            |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00615      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.1         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00657     |
|    std                   | 1.04         |
|    value_loss            | 189          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.89        |
| reward                   | -0.8275325  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -997        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 21          |
|    time_elapsed          | 3486        |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.003698645 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1           |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.012       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28          |
|    n_updates             | 690         |
|    policy_gradient_loss  | -0.00494    |
|    std                   | 1.04        |
|    value_loss            | 57.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.05        |
| reward                   | -1.2950616  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -988        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 22          |
|    time_elapsed          | 3675        |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.004331467 |
|    clip_fraction         | 0.0276      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 5.67        |
|    cost_values           | 1           |
|    entropy               | -2.9        |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.00752     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.5        |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.00437    |
|    std                   | 1.03        |
|    value_loss            | 58.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00866     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00866     |
| reward                   | -0.5592955  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -977        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 23          |
|    time_elapsed          | 3881        |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.008245356 |
|    clip_fraction         | 0.0583      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1.01        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00609     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.2        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00552    |
|    std                   | 1.03        |
|    value_loss            | 30.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.64         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.64         |
| reward                   | -0.6168327   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -968         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 24           |
|    time_elapsed          | 4084         |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0037299006 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 3.69         |
|    cost_values           | 0.991        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0135       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.7         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 1.03         |
|    value_loss            | 74.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.4          |
| reward                   | -0.52952796  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -961         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 25           |
|    time_elapsed          | 4288         |
|    total_timesteps       | 151552       |
| train/                   |              |
|    approx_kl             | 0.0054534073 |
|    clip_fraction         | 0.0639       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 4.37         |
|    cost_values           | 1            |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00947      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 730          |
|    policy_gradient_loss  | -0.00669     |
|    std                   | 1.04         |
|    value_loss            | 33.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.16         |
| reward                   | -0.53777665  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -951         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 26           |
|    time_elapsed          | 4495         |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0063016242 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 4.17         |
|    cost_values           | 1.01         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00366      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 1.04         |
|    value_loss            | 26           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.91         |
| reward                   | -0.77480686  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 27           |
|    time_elapsed          | 4705         |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0065427357 |
|    clip_fraction         | 0.0529       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 5.2          |
|    cost_values           | 1.01         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0149       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00527     |
|    std                   | 1.04         |
|    value_loss            | 22.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.5          |
| reward                   | -0.33977583  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -921         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 28           |
|    time_elapsed          | 4919         |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0051586474 |
|    clip_fraction         | 0.0432       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 2.53         |
|    cost_values           | 1            |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00581      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.4         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 1.04         |
|    value_loss            | 98.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.81         |
| reward                   | -1.0452256   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -917         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 29           |
|    time_elapsed          | 5128         |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0057872594 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 5.92         |
|    cost_values           | 1            |
|    entropy               | -2.9         |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0302       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.94         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 1.04         |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.21        |
| reward                   | -0.53272426 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -917        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 30          |
|    time_elapsed          | 5340        |
|    total_timesteps       | 161792      |
| train/                   |             |
|    approx_kl             | 0.005069416 |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 1.83        |
|    cost_values           | 0.998       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00407     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 780         |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 1.03        |
|    value_loss            | 36.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.22         |
| reward                   | -0.6650284   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -921         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 31           |
|    time_elapsed          | 5559         |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0025288109 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 1            |
|    cost_value_loss       | 0.795        |
|    cost_values           | 0.993        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00332      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.6         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 1.04         |
|    value_loss            | 67.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.91         |
| reward                   | -0.71642447  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -916         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 32           |
|    time_elapsed          | 5774         |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0064689964 |
|    clip_fraction         | 0.0605       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.889        |
|    cost_values           | 0.996        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00187      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00672     |
|    std                   | 1.04         |
|    value_loss            | 22.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.62        |
| reward                   | -0.8309375  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -915        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 33          |
|    time_elapsed          | 5994        |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.007971772 |
|    clip_fraction         | 0.067       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 1.78        |
|    cost_values           | 1           |
|    entropy               | -2.94       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.0147      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.94        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.00606    |
|    std                   | 1.06        |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.4          |
| reward                   | -0.50995725  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -918         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 34           |
|    time_elapsed          | 6217         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0046368353 |
|    clip_fraction         | 0.0776       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 3.62         |
|    cost_values           | 1            |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.00658      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 1.06         |
|    value_loss            | 61.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -1.0301688   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -915         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 35           |
|    time_elapsed          | 6445         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0035880897 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 3.11         |
|    cost_values           | 0.999        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0147       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.1         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 1.07         |
|    value_loss            | 138          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.107118    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -907         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 36           |
|    time_elapsed          | 6671         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0067000864 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 2.98         |
|    cost_values           | 1            |
|    entropy               | -2.94        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.0232       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.00532     |
|    std                   | 1.06         |
|    value_loss            | 32.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.29        |
| reward                   | -0.96199334 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -898        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 37          |
|    time_elapsed          | 6899        |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.004119904 |
|    clip_fraction         | 0.0281      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 1.53        |
|    cost_values           | 0.991       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.0198      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24          |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 1.05        |
|    value_loss            | 56.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.97         |
| reward                   | -0.7202726   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 38           |
|    time_elapsed          | 7135         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0035151346 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.64         |
|    cost_values           | 0.995        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0261       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32           |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 1.06         |
|    value_loss            | 64.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.60939056  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -904         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 39           |
|    time_elapsed          | 7368         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0061730603 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.64         |
|    cost_values           | 0.989        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0401       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00522     |
|    std                   | 1.06         |
|    value_loss            | 25.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.17        |
| reward                   | -0.662947   |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -910        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 40          |
|    time_elapsed          | 7598        |
|    total_timesteps       | 182272      |
| train/                   |             |
|    approx_kl             | 0.005095306 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 2.96        |
|    cost_values           | 0.976       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.0531      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 880         |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 1.05        |
|    value_loss            | 24.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.21         |
| reward                   | -0.91173553  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -898         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 41           |
|    time_elapsed          | 7825         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0040498283 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 0.923        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.0942       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 1.05         |
|    value_loss            | 36           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -1.1192245  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -894        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 42          |
|    time_elapsed          | 8044        |
|    total_timesteps       | 186368      |
| train/                   |             |
|    approx_kl             | 0.003913762 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 2.45        |
|    cost_values           | 0.86        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.157       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.4        |
|    n_updates             | 900         |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 1.05        |
|    value_loss            | 43          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.80347717  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -892         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 43           |
|    time_elapsed          | 8270         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0047388375 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.929        |
|    cost_value_loss       | 1.47         |
|    cost_values           | 0.69         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.515        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 1.05         |
|    value_loss            | 28.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.32        |
| reward                   | -0.81340194 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -894        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 44          |
|    time_elapsed          | 8521        |
|    total_timesteps       | 190464      |
| train/                   |             |
|    approx_kl             | 0.004063624 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 4.91        |
|    cost_values           | 0.726       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 920         |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 1.04        |
|    value_loss            | 19.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -1.2052134  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -887        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 45          |
|    time_elapsed          | 8774        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.005090325 |
|    clip_fraction         | 0.053       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 2.39        |
|    cost_values           | 0.792       |
|    entropy               | -2.89       |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.166       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.00525    |
|    std                   | 1.03        |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.19646303  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 46           |
|    time_elapsed          | 9027         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0046128994 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 2.88         |
|    cost_values           | 0.824        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.779        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 1.03         |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.56         |
| reward                   | -1.1089717   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -872         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 47           |
|    time_elapsed          | 9289         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0063926233 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 5.28         |
|    cost_values           | 0.8          |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.378        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00485     |
|    std                   | 1.03         |
|    value_loss            | 34.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.17        |
| reward                   | -1.2340738  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -881        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 48          |
|    time_elapsed          | 9548        |
|    total_timesteps       | 198656      |
| train/                   |             |
|    approx_kl             | 0.003920969 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.7         |
|    cost_value_loss       | 5.63        |
|    cost_values           | 0.882       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.716       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.17        |
|    n_updates             | 960         |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 1.03        |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.17         |
| reward                   | -0.7029068   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -881         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 49           |
|    time_elapsed          | 9806         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0023360413 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 0.891        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.629        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 1.04         |
|    value_loss            | 33.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 5.13       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 5.13       |
| reward             | -1.0842327 |
| rollout/           |            |
|    ep_len_mean     | 963        |
|    ep_rew_mean     | -872       |
| time/              |            |
|    fps             | 7          |
|    iterations      | 1          |
|    time_elapsed    | 262        |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.615851    |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -852         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 2            |
|    time_elapsed          | 523          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0047850674 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 0.844        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.76         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.64         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 1.04         |
|    value_loss            | 16.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.01         |
| reward                   | -1.0470026   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 3            |
|    time_elapsed          | 779          |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0020699715 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 5.83         |
|    cost_values           | 0.877        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.507        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 1.04         |
|    value_loss            | 47.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.06        |
| reward                   | -0.5952411  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -855        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 4           |
|    time_elapsed          | 1048        |
|    total_timesteps       | 208896      |
| train/                   |             |
|    approx_kl             | 0.004317901 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 3.43        |
|    cost_values           | 0.874       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.618       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 1010        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 1.04        |
|    value_loss            | 21          |
------------------------------------------
------------------------------------------
| avg_speed                | 5.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.69        |
| reward                   | -0.84677386 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 5           |
|    time_elapsed          | 1316        |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.006202884 |
|    clip_fraction         | 0.0282      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 0.894       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.761       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00554    |
|    std                   | 1.04        |
|    value_loss            | 25.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.77         |
| reward                   | -0.8224733   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 6            |
|    time_elapsed          | 1589         |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0044908063 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 3.93         |
|    cost_values           | 0.857        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.647        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 1.04         |
|    value_loss            | 36.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7            |
| reward                   | -1.3325106   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -838         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 7            |
|    time_elapsed          | 1863         |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0033261618 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 2.53         |
|    cost_values           | 0.791        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.791        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 1.04         |
|    value_loss            | 53.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.76         |
| reward                   | -1.7742529   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -845         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 8            |
|    time_elapsed          | 2141         |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0024937284 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 2.19         |
|    cost_values           | 0.783        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.619        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 1.04         |
|    value_loss            | 70.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.65         |
| reward                   | -0.7061361   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -848         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 9            |
|    time_elapsed          | 2425         |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0035078472 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.712        |
|    cost_value_loss       | 0.445        |
|    cost_values           | 0.74         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.626        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.7         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 1.04         |
|    value_loss            | 89           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.74         |
| reward                   | -1.1032164   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 10           |
|    time_elapsed          | 2698         |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0048714136 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 3.33         |
|    cost_values           | 0.774        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.706        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.5         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00358     |
|    std                   | 1.04         |
|    value_loss            | 75.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.5489297   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 11           |
|    time_elapsed          | 2986         |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0053432067 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 3.47         |
|    cost_values           | 0.836        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.837        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 1.04         |
|    value_loss            | 22.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.03         |
| reward                   | -0.83331585  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 12           |
|    time_elapsed          | 3271         |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0029123677 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 3.04         |
|    cost_values           | 0.86         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.826        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.6         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 1.04         |
|    value_loss            | 41.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.59         |
| reward                   | -0.5164614   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -849         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 13           |
|    time_elapsed          | 3558         |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0049984613 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 3.21         |
|    cost_values           | 0.889        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.851        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 1.04         |
|    value_loss            | 24.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.3          |
| reward                   | -0.88723683  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -849         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 14           |
|    time_elapsed          | 3842         |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0050099473 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 4.39         |
|    cost_values           | 0.857        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.701        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67.8         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 1.04         |
|    value_loss            | 127          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2179213   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -845         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 15           |
|    time_elapsed          | 4141         |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0045853406 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 1.48         |
|    cost_values           | 0.85         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.656        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 1.04         |
|    value_loss            | 35.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.3397421   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -845         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 16           |
|    time_elapsed          | 4435         |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0022448334 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 6.7          |
|    cost_values           | 0.891        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.814        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 1.03         |
|    value_loss            | 32.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.2988625   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -841         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 17           |
|    time_elapsed          | 4734         |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0032590758 |
|    clip_fraction         | 0.00781      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.25         |
|    cost_values           | 0.838        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.812        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.7         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 1.03         |
|    value_loss            | 44.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -1.5523211   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -840         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 18           |
|    time_elapsed          | 5034         |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0073950244 |
|    clip_fraction         | 0.0571       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 2.73         |
|    cost_values           | 0.854        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.608        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00659     |
|    std                   | 1.03         |
|    value_loss            | 30.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -1.1111286  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -841        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 19          |
|    time_elapsed          | 5337        |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.004587598 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 4.11        |
|    cost_values           | 0.851       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.696       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.7        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.00545    |
|    std                   | 1.03        |
|    value_loss            | 49.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.62         |
| reward                   | -0.43520066  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -834         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 20           |
|    time_elapsed          | 5633         |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0065368013 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 6.84         |
|    cost_values           | 0.876        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 1170         |
|    policy_gradient_loss  | -0.00611     |
|    std                   | 1.03         |
|    value_loss            | 17.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.12        |
| reward                   | -0.3586879  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -824        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 21          |
|    time_elapsed          | 5936        |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.004559282 |
|    clip_fraction         | 0.0423      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 0.911       |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.2        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 1.03        |
|    value_loss            | 30.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.82        |
| reward                   | -0.74262154 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -825        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 22          |
|    time_elapsed          | 6248        |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.004306306 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 7.27        |
|    cost_values           | 1.02        |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.9        |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 1.03        |
|    value_loss            | 40.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.5         |
| reward                   | -0.7106248  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -823        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 23          |
|    time_elapsed          | 6563        |
|    total_timesteps       | 247808      |
| train/                   |             |
|    approx_kl             | 0.005936855 |
|    clip_fraction         | 0.033       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.34        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 0.916       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.8        |
|    n_updates             | 1200        |
|    policy_gradient_loss  | -0.00658    |
|    std                   | 1.03        |
|    value_loss            | 30.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.884        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.884        |
| reward                   | -0.35941026  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 24           |
|    time_elapsed          | 6874         |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0050171446 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 6.13         |
|    cost_values           | 0.919        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 1.03         |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8892968   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 25           |
|    time_elapsed          | 7192         |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0047947816 |
|    clip_fraction         | 0.0391       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 0.997        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.439        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.3         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -0.0055      |
|    std                   | 1.03         |
|    value_loss            | 27.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.51         |
| reward                   | -0.6863003   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -816         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 26           |
|    time_elapsed          | 7522         |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0048674024 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 7.91         |
|    cost_values           | 0.999        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.25         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00406     |
|    std                   | 1.03         |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.3         |
| reward                   | -0.71694565 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -810        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 27          |
|    time_elapsed          | 7861        |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.004974066 |
|    clip_fraction         | 0.0419      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.44        |
|    cost_value_loss       | 4.11        |
|    cost_values           | 0.895       |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.2        |
|    n_updates             | 1240        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 1.03        |
|    value_loss            | 39.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.136       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.136       |
| reward                   | -1.1037858  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -809        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 28          |
|    time_elapsed          | 8192        |
|    total_timesteps       | 258048      |
| train/                   |             |
|    approx_kl             | 0.004919444 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 2.32        |
|    cost_values           | 0.767       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.702       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 1250        |
|    policy_gradient_loss  | -0.00406    |
|    std                   | 1.03        |
|    value_loss            | 23.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.39008436 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -809        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 29          |
|    time_elapsed          | 8513        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.005744853 |
|    clip_fraction         | 0.0316      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 5.28        |
|    cost_values           | 0.877       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.74        |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 1.03        |
|    value_loss            | 8.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.29        |
| reward                   | -0.82275283 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -798        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 30          |
|    time_elapsed          | 8833        |
|    total_timesteps       | 262144      |
| train/                   |             |
|    approx_kl             | 0.006568443 |
|    clip_fraction         | 0.0435      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.98        |
|    cost_value_loss       | 5.35        |
|    cost_values           | 0.871       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.83        |
|    n_updates             | 1270        |
|    policy_gradient_loss  | -0.00633    |
|    std                   | 1.03        |
|    value_loss            | 14.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.08         |
| reward                   | -1.228337    |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 31           |
|    time_elapsed          | 9164         |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0037452055 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 3.1          |
|    cost_values           | 0.794        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.4         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 1.03         |
|    value_loss            | 50.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.18        |
| reward                   | -0.30705598 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -791        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 32          |
|    time_elapsed          | 9499        |
|    total_timesteps       | 266240      |
| train/                   |             |
|    approx_kl             | 0.006846114 |
|    clip_fraction         | 0.0372      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 2.96        |
|    cost_values           | 0.746       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.4        |
|    n_updates             | 1290        |
|    policy_gradient_loss  | -0.00475    |
|    std                   | 1.03        |
|    value_loss            | 68.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.81         |
| reward                   | -0.4106216   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 33           |
|    time_elapsed          | 9836         |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0023929756 |
|    clip_fraction         | 0.00474      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 7.82         |
|    cost_values           | 0.886        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.96         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.000868    |
|    std                   | 1.03         |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.94         |
| reward                   | -0.61285985  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -777         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 34           |
|    time_elapsed          | 10174        |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0057175485 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 4.67         |
|    cost_values           | 0.852        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00538     |
|    std                   | 1.03         |
|    value_loss            | 17.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.77        |
| reward                   | -0.37745094 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 35          |
|    time_elapsed          | 10519       |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.006318671 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 9.03        |
|    cost_values           | 1.08        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.278       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.6         |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -0.00625    |
|    std                   | 1.02        |
|    value_loss            | 5.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.46        |
| reward                   | -0.7790015  |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 36          |
|    time_elapsed          | 10864       |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.003213957 |
|    clip_fraction         | 0.0245      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 7.42        |
|    cost_values           | 1.1         |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 1.02        |
|    value_loss            | 17.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.68504864  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 37           |
|    time_elapsed          | 11223        |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0060222032 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 4.16         |
|    cost_values           | 1.05         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.791        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.92         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 1.02         |
|    value_loss            | 5.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.6890225  |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 38          |
|    time_elapsed          | 11565       |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.005462949 |
|    clip_fraction         | 0.0406      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 9.72        |
|    cost_values           | 0.806       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.97        |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.00614    |
|    std                   | 1.02        |
|    value_loss            | 8.64        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.75       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.75       |
| reward                   | -0.3830453 |
| rollout/                 |            |
|    ep_len_mean           | 933        |
|    ep_rew_mean           | -771       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 39         |
|    time_elapsed          | 11919      |
|    total_timesteps       | 280576     |
| train/                   |            |
|    approx_kl             | 0.00481801 |
|    clip_fraction         | 0.0498     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.87       |
|    cost_value_loss       | 6.98       |
|    cost_values           | 0.906      |
|    entropy               | -2.87      |
|    entropy_loss          | -2.88      |
|    explained_variance    | 0.868      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.85       |
|    n_updates             | 1360       |
|    policy_gradient_loss  | -0.00614   |
|    std                   | 1.02       |
|    value_loss            | 10.8       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.72        |
| reward                   | -0.68958324 |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -768        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 40          |
|    time_elapsed          | 12282       |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.004202093 |
|    clip_fraction         | 0.00664     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.38        |
|    cost_values           | 0.8         |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.73        |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 1.02        |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.538        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.538        |
| reward                   | -0.4838212   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 41           |
|    time_elapsed          | 12634        |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0072694784 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 0.707        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.837        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 1.02         |
|    value_loss            | 18.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.45        |
| reward                   | -0.19905496 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -773        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 42          |
|    time_elapsed          | 12997       |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.005135062 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.969       |
|    cost_value_loss       | 2.62        |
|    cost_values           | 0.743       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.815       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.28        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.00454    |
|    std                   | 1.02        |
|    value_loss            | 16.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.56         |
| reward                   | -0.34738618  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 43           |
|    time_elapsed          | 13351        |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0030352322 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 8.27         |
|    cost_values           | 0.88         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.000418    |
|    std                   | 1.02         |
|    value_loss            | 5.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.759        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.759        |
| reward                   | -0.74763894  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 44           |
|    time_elapsed          | 13726        |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0025575943 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 4.95         |
|    cost_values           | 0.822        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.2         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 1.02         |
|    value_loss            | 60.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8023298   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 14098        |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0035378658 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 7.86         |
|    cost_values           | 0.936        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.79         |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 1.02         |
|    value_loss            | 20.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.40060365  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 46           |
|    time_elapsed          | 14485        |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0027326378 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 0.881        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 1.01         |
|    value_loss            | 26.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7546997   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 47           |
|    time_elapsed          | 14868        |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0055230088 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 6.89         |
|    cost_values           | 0.823        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.00657     |
|    std                   | 1.01         |
|    value_loss            | 31           |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.13        |
| reward                   | -1.300678   |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 48          |
|    time_elapsed          | 15256       |
|    total_timesteps       | 299008      |
| train/                   |             |
|    approx_kl             | 0.004189115 |
|    clip_fraction         | 0.0233      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 0.954       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.3        |
|    n_updates             | 1450        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 1.01        |
|    value_loss            | 17          |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.37         |
| reward                   | -1.2398926   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 49           |
|    time_elapsed          | 15650        |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0057305964 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 2.18         |
|    cost_values           | 0.844        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.2         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.000589    |
|    std                   | 1.01         |
|    value_loss            | 52.6         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/h3wsymxd
------------------------------------
| avg_speed          | 7.87        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.87        |
| reward             | -0.45284304 |
| rollout/           |             |
|    ep_len_mean     | 921         |
|    ep_rew_mean     | -760        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 386         |
|    total_timesteps | 303104      |
------------------------------------
------------------------------------------
| avg_speed                | 7.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.46        |
| reward                   | -0.6345473  |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -754        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 780         |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.004583448 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 5.76        |
|    cost_values           | 0.87        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47.3        |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.0046     |
|    std                   | 1.02        |
|    value_loss            | 89.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7481184   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 3            |
|    time_elapsed          | 1163         |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0020952201 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 3.27         |
|    cost_values           | 0.873        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.92         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 1.02         |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.76442873  |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 4            |
|    time_elapsed          | 1558         |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0047129365 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 5.17         |
|    cost_values           | 0.835        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 1.02         |
|    value_loss            | 28.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9390686   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 5            |
|    time_elapsed          | 1958         |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0037809429 |
|    clip_fraction         | 0.0441       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.79         |
|    cost_values           | 0.689        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.3          |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.00736     |
|    std                   | 1.01         |
|    value_loss            | 19.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.02         |
| reward                   | -0.6462638   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2369         |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0035555903 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.959        |
|    cost_value_loss       | 1.14         |
|    cost_values           | 0.807        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 1.01         |
|    value_loss            | 23.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.27        |
| reward                   | -0.4727466  |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -730        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 7           |
|    time_elapsed          | 2775        |
|    total_timesteps       | 315392      |
| train/                   |             |
|    approx_kl             | 0.004887876 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 3.6         |
|    cost_values           | 0.83        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 1530        |
|    policy_gradient_loss  | -0.00428    |
|    std                   | 1.01        |
|    value_loss            | 26.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.21        |
| reward                   | -0.86786646 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 8           |
|    time_elapsed          | 3137        |
|    total_timesteps       | 317440      |
| train/                   |             |
|    approx_kl             | 0.005203078 |
|    clip_fraction         | 0.019       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.53        |
|    cost_value_loss       | 3.48        |
|    cost_values           | 0.93        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.88        |
|    n_updates             | 1540        |
|    policy_gradient_loss  | -0.00619    |
|    std                   | 1.01        |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.31        |
| reward                   | -0.46285132 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -725        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3502        |
|    total_timesteps       | 319488      |
| train/                   |             |
|    approx_kl             | 0.007784808 |
|    clip_fraction         | 0.0754      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.78        |
|    cost_values           | 0.795       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.1        |
|    n_updates             | 1550        |
|    policy_gradient_loss  | -0.00834    |
|    std                   | 1           |
|    value_loss            | 31.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.46        |
| reward                   | -0.9494142  |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 10          |
|    time_elapsed          | 3873        |
|    total_timesteps       | 321536      |
| train/                   |             |
|    approx_kl             | 0.004223524 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 2.06        |
|    cost_values           | 0.846       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 1560        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 1           |
|    value_loss            | 28.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.55        |
| reward                   | -0.916121   |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 11          |
|    time_elapsed          | 4232        |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.004756819 |
|    clip_fraction         | 0.0325      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 8.23        |
|    cost_values           | 0.954       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.99        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | -0.00481    |
|    std                   | 1           |
|    value_loss            | 6.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.59        |
| reward                   | -0.6327317  |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 12          |
|    time_elapsed          | 4604        |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.009945726 |
|    clip_fraction         | 0.0777      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 2.16        |
|    cost_values           | 0.785       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.0113     |
|    std                   | 0.998       |
|    value_loss            | 9.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.63         |
| reward                   | -1.3486793   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 13           |
|    time_elapsed          | 4983         |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0065639475 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 5.43         |
|    cost_values           | 0.755        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.75         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00615     |
|    std                   | 0.999        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.64         |
| reward                   | -0.5699074   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 14           |
|    time_elapsed          | 5360         |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0040107258 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 6.06         |
|    cost_values           | 0.796        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.9          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.997        |
|    value_loss            | 21.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.26        |
| reward                   | -0.5607947  |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 15          |
|    time_elapsed          | 5734        |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.005344523 |
|    clip_fraction         | 0.0623      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 3.62        |
|    cost_values           | 0.763       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.54        |
|    n_updates             | 1610        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.996       |
|    value_loss            | 17.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.6          |
| reward                   | -0.8448446   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6102         |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0042331005 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 4.83         |
|    cost_values           | 1.02         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.362        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00577     |
|    std                   | 0.99         |
|    value_loss            | 3.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.23         |
| reward                   | -0.45758578  |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 17           |
|    time_elapsed          | 6462         |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0028810985 |
|    clip_fraction         | 0.00581      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 0.871        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.988        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.25         |
| reward                   | -0.7267048   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 6825         |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0072966805 |
|    clip_fraction         | 0.0801       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 9.51         |
|    cost_values           | 1.16         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.468        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.99         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00656     |
|    std                   | 0.986        |
|    value_loss            | 5.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0719957  |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 19          |
|    time_elapsed          | 7190        |
|    total_timesteps       | 339968      |
| train/                   |             |
|    approx_kl             | 0.004352294 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 7.46        |
|    cost_values           | 1.47        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.766       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.38        |
|    n_updates             | 1650        |
|    policy_gradient_loss  | -0.00318    |
|    std                   | 0.986       |
|    value_loss            | 8.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0375       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0375       |
| reward                   | -0.5484423   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7573         |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0040069786 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 3.2          |
|    cost_values           | 0.913        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.845        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.986        |
|    value_loss            | 29.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.65         |
| reward                   | -0.64909565  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 21           |
|    time_elapsed          | 7905         |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0044239066 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 0.775        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.91         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00459     |
|    std                   | 0.984        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.04         |
| reward                   | -0.53498375  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 22           |
|    time_elapsed          | 8239         |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0069466317 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.29         |
|    cost_value_loss       | 29.1         |
|    cost_values           | 0.827        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.00508     |
|    std                   | 0.985        |
|    value_loss            | 9.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.46        |
| reward                   | -0.7380428  |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 23          |
|    time_elapsed          | 8577        |
|    total_timesteps       | 348160      |
| train/                   |             |
|    approx_kl             | 0.004394508 |
|    clip_fraction         | 0.015       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.06        |
|    cost_value_loss       | 29.2        |
|    cost_values           | 1.03        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00552     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 1690        |
|    policy_gradient_loss  | -0.00428    |
|    std                   | 0.98        |
|    value_loss            | 7.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.1         |
| reward                   | -0.5466215  |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 8911        |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.008972738 |
|    clip_fraction         | 0.0488      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 35.5        |
|    cost_values           | 1.04        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00342     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.53        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00861    |
|    std                   | 0.978       |
|    value_loss            | 9.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.57097083 |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 25          |
|    time_elapsed          | 9252        |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.005654444 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 7.46        |
|    cost_values           | 0.998       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.07        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.00486    |
|    std                   | 0.977       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.712868    |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 9594         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0051757894 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2.56         |
|    cost_values           | 0.655        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.977        |
|    value_loss            | 55.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5740301   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 27           |
|    time_elapsed          | 9940         |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0045766192 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 7.67         |
|    cost_values           | 0.66         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.3         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.978        |
|    value_loss            | 31           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.67778474  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 10286        |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0059698056 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.77         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 0.915        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.739        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 0.978        |
|    value_loss            | 29.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.13         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.13         |
| reward                   | -0.43828207  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 10648        |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0077036135 |
|    clip_fraction         | 0.0517       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.861        |
|    cost_value_loss       | 1.73         |
|    cost_values           | 0.626        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.66         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00665     |
|    std                   | 0.978        |
|    value_loss            | 16.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.31004515 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 30          |
|    time_elapsed          | 11000       |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.006627612 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.7         |
|    cost_value_loss       | 4.54        |
|    cost_values           | 0.775       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.00687    |
|    std                   | 0.975       |
|    value_loss            | 31.1        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -0.5567449 |
| rollout/                 |            |
|    ep_len_mean           | 934        |
|    ep_rew_mean           | -711       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 31         |
|    time_elapsed          | 11363      |
|    total_timesteps       | 364544     |
| train/                   |            |
|    approx_kl             | 0.00457309 |
|    clip_fraction         | 0.016      |
|    clip_range            | 0.2        |
|    cost_returns          | 1.1        |
|    cost_value_loss       | 2.27       |
|    cost_values           | 0.674      |
|    entropy               | -2.78      |
|    entropy_loss          | -2.78      |
|    explained_variance    | 0.926      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.07       |
|    n_updates             | 1770       |
|    policy_gradient_loss  | -0.00294   |
|    std                   | 0.975      |
|    value_loss            | 14.6       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.3         |
| reward                   | -0.84382135 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 11724       |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.00843033  |
|    clip_fraction         | 0.049       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.754       |
|    cost_value_loss       | 0.77        |
|    cost_values           | 0.623       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00787    |
|    std                   | 0.978       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.85         |
| reward                   | -0.979086    |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 12087        |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0057843816 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 3.92         |
|    cost_values           | 0.651        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.00486     |
|    std                   | 0.976        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.76706684 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -714        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 34          |
|    time_elapsed          | 12445       |
|    total_timesteps       | 370688      |
| train/                   |             |
|    approx_kl             | 0.004538982 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 2.64        |
|    cost_values           | 0.688       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 1800        |
|    policy_gradient_loss  | -0.00245    |
|    std                   | 0.974       |
|    value_loss            | 12.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.02        |
| reward                   | -0.5489051  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 35          |
|    time_elapsed          | 12794       |
|    total_timesteps       | 372736      |
| train/                   |             |
|    approx_kl             | 0.007526178 |
|    clip_fraction         | 0.0635      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 4.37        |
|    cost_values           | 0.788       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.72        |
|    n_updates             | 1810        |
|    policy_gradient_loss  | -0.00701    |
|    std                   | 0.971       |
|    value_loss            | 11.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.12        |
| reward                   | -0.6117674  |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 36          |
|    time_elapsed          | 13140       |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.003090477 |
|    clip_fraction         | 0.00474     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 7.56        |
|    cost_values           | 0.725       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 0.971       |
|    value_loss            | 9.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.693        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.693        |
| reward                   | -0.41144988  |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 37           |
|    time_elapsed          | 13496        |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0052695367 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 3.07         |
|    cost_values           | 0.66         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00428     |
|    std                   | 0.972        |
|    value_loss            | 26.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.68        |
| reward                   | -0.75793964 |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 38          |
|    time_elapsed          | 13859       |
|    total_timesteps       | 378880      |
| train/                   |             |
|    approx_kl             | 0.007054615 |
|    clip_fraction         | 0.044       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 0.842       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.9        |
|    n_updates             | 1840        |
|    policy_gradient_loss  | -0.00746    |
|    std                   | 0.972       |
|    value_loss            | 34.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.5220194  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 39          |
|    time_elapsed          | 14221       |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.004768065 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.49        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 0.883       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.76        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.974       |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.224       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.224       |
| reward                   | -0.5101497  |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 40          |
|    time_elapsed          | 14580       |
|    total_timesteps       | 382976      |
| train/                   |             |
|    approx_kl             | 0.006272568 |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.36        |
|    cost_value_loss       | 7.49        |
|    cost_values           | 0.904       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.25        |
|    n_updates             | 1860        |
|    policy_gradient_loss  | -0.00733    |
|    std                   | 0.973       |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.322        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.322        |
| reward                   | -0.37288243  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 14942        |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0050172517 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 38.5         |
|    cost_values           | 0.988        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.702        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.97         |
|    value_loss            | 22.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.98        |
| reward                   | -0.42291275 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -694        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 42          |
|    time_elapsed          | 15310       |
|    total_timesteps       | 387072      |
| train/                   |             |
|    approx_kl             | 0.005386063 |
|    clip_fraction         | 0.032       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.6         |
|    cost_value_loss       | 3.83        |
|    cost_values           | 0.797       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.72        |
|    n_updates             | 1880        |
|    policy_gradient_loss  | -0.00536    |
|    std                   | 0.968       |
|    value_loss            | 16.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.78         |
| reward                   | -0.7536648   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 43           |
|    time_elapsed          | 15674        |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0036418603 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 7.02         |
|    cost_values           | 0.801        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.85         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.0053      |
|    std                   | 0.966        |
|    value_loss            | 12.8         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 4.19       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.19       |
| reward                   | -0.5551763 |
| rollout/                 |            |
|    ep_len_mean           | 924        |
|    ep_rew_mean           | -691       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 44         |
|    time_elapsed          | 16039      |
|    total_timesteps       | 391168     |
| train/                   |            |
|    approx_kl             | 0.00799262 |
|    clip_fraction         | 0.0673     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.83       |
|    cost_value_loss       | 5.22       |
|    cost_values           | 0.861      |
|    entropy               | -2.77      |
|    entropy_loss          | -2.76      |
|    explained_variance    | 0.867      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.74       |
|    n_updates             | 1900       |
|    policy_gradient_loss  | -0.00778   |
|    std                   | 0.967      |
|    value_loss            | 8.24       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.47        |
| reward                   | -1.0975006  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 45          |
|    time_elapsed          | 16411       |
|    total_timesteps       | 393216      |
| train/                   |             |
|    approx_kl             | 0.005087128 |
|    clip_fraction         | 0.0486      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 5.51        |
|    cost_values           | 0.908       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.733       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.85        |
|    n_updates             | 1910        |
|    policy_gradient_loss  | -0.00572    |
|    std                   | 0.966       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.228        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.228        |
| reward                   | -0.25832674  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 46           |
|    time_elapsed          | 16783        |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0061875237 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 9.01         |
|    cost_values           | 0.946        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.707        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 0.964        |
|    value_loss            | 19.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.31         |
| reward                   | -0.42056143  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 47           |
|    time_elapsed          | 17158        |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0046906937 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 4.49         |
|    cost_values           | 0.921        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.66         |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00464     |
|    std                   | 0.962        |
|    value_loss            | 6.57         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.6229344  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -682        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 48          |
|    time_elapsed          | 17534       |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.011216916 |
|    clip_fraction         | 0.0708      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.61        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 0.88        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.0101     |
|    std                   | 0.959       |
|    value_loss            | 8.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.81562173 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -682        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 49          |
|    time_elapsed          | 17909       |
|    total_timesteps       | 401408      |
| train/                   |             |
|    approx_kl             | 0.004011865 |
|    clip_fraction         | 0.0206      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 0.934       |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.81        |
|    n_updates             | 1950        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.958       |
|    value_loss            | 8.36        |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.68040746 |
| rollout/           |             |
|    ep_len_mean     | 943         |
|    ep_rew_mean     | -675        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 381         |
|    total_timesteps | 403456      |
------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.46620762 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -671        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 760         |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.006251063 |
|    clip_fraction         | 0.0634      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 6.96        |
|    cost_values           | 0.984       |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 1970        |
|    policy_gradient_loss  | -0.00821    |
|    std                   | 0.96        |
|    value_loss            | 7.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.5658522   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 3            |
|    time_elapsed          | 1140         |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0071349465 |
|    clip_fraction         | 0.0546       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 6.31         |
|    cost_values           | 1.03         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.71         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.47         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00653     |
|    std                   | 0.952        |
|    value_loss            | 5.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.37         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.37         |
| reward                   | -0.7684479   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 4            |
|    time_elapsed          | 1520         |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0041454644 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 3.6          |
|    cost_values           | 1.05         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.773        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.87         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00355     |
|    std                   | 0.95         |
|    value_loss            | 6.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.28        |
| reward                   | -0.45231062 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -661        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 5           |
|    time_elapsed          | 1893        |
|    total_timesteps       | 411648      |
| train/                   |             |
|    approx_kl             | 0.007947153 |
|    clip_fraction         | 0.075       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 4.88        |
|    cost_values           | 0.963       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 2000        |
|    policy_gradient_loss  | -0.00793    |
|    std                   | 0.944       |
|    value_loss            | 5.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -0.7481451   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -652         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2266         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0075183455 |
|    clip_fraction         | 0.0823       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 0.975        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00708     |
|    std                   | 0.94         |
|    value_loss            | 9.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.9218499   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 7            |
|    time_elapsed          | 2643         |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0052669775 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 0.975        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.25         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 0.939        |
|    value_loss            | 3.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.3357495   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -651         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 8            |
|    time_elapsed          | 3018         |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0027916094 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 5.57         |
|    cost_values           | 0.858        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.86         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.938        |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.75714314 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -644        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3397        |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.00632653  |
|    clip_fraction         | 0.0816      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 3.3         |
|    cost_values           | 0.911       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.99        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00962    |
|    std                   | 0.937       |
|    value_loss            | 4.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.65         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.65         |
| reward                   | -0.5086329   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -651         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 10           |
|    time_elapsed          | 3777         |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0042585623 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 8.22         |
|    cost_values           | 0.915        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.23         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 0.938        |
|    value_loss            | 3.46         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.422      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.422      |
| reward                   | -0.7115085 |
| rollout/                 |            |
|    ep_len_mean           | 943        |
|    ep_rew_mean           | -640       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 11         |
|    time_elapsed          | 4163       |
|    total_timesteps       | 423936     |
| train/                   |            |
|    approx_kl             | 0.00580975 |
|    clip_fraction         | 0.0457     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.16       |
|    cost_value_loss       | 2.47       |
|    cost_values           | 0.774      |
|    entropy               | -2.71      |
|    entropy_loss          | -2.7       |
|    explained_variance    | 0.916      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.09       |
|    n_updates             | 2060       |
|    policy_gradient_loss  | -0.00452   |
|    std                   | 0.939      |
|    value_loss            | 17.6       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.615       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.615       |
| reward                   | -0.4497476  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -644        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 12          |
|    time_elapsed          | 4551        |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.005553664 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.991       |
|    cost_value_loss       | 1.63        |
|    cost_values           | 0.835       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 0.938       |
|    value_loss            | 9.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8062436  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -640        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 13          |
|    time_elapsed          | 4940        |
|    total_timesteps       | 428032      |
| train/                   |             |
|    approx_kl             | 0.008685943 |
|    clip_fraction         | 0.0876      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 1.05        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.71        |
|    n_updates             | 2080        |
|    policy_gradient_loss  | -0.00726    |
|    std                   | 0.939       |
|    value_loss            | 5.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.97         |
| reward                   | -0.3958603   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -641         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 14           |
|    time_elapsed          | 5331         |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0071065538 |
|    clip_fraction         | 0.0696       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 6.05         |
|    cost_values           | 1.09         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.569        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 2090         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.937        |
|    value_loss            | 23.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.608       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.608       |
| reward                   | -0.53881454 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -642        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 15          |
|    time_elapsed          | 5720        |
|    total_timesteps       | 432128      |
| train/                   |             |
|    approx_kl             | 0.006040836 |
|    clip_fraction         | 0.0513      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 0.882       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 2100        |
|    policy_gradient_loss  | -0.00675    |
|    std                   | 0.942       |
|    value_loss            | 5.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.303       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.303       |
| reward                   | -0.42473516 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -620        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 16          |
|    time_elapsed          | 6113        |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.016214471 |
|    clip_fraction         | 0.0776      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 1.19        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.715       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.95        |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.68        |
| reward                   | -0.4433492  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -619        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 6506        |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.005471475 |
|    clip_fraction         | 0.256       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 1.42        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.363       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | 0.00494     |
|    std                   | 0.951       |
|    value_loss            | 30.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.96        |
| reward                   | -0.9653913  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -615        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 18          |
|    time_elapsed          | 6898        |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.003382132 |
|    clip_fraction         | 0.0732      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 3.04        |
|    cost_values           | 1.18        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -0.00874    |
|    std                   | 0.95        |
|    value_loss            | 5.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.88         |
| reward                   | -0.42418328  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -617         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 7295         |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0023317095 |
|    clip_fraction         | 0.0646       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 3.61         |
|    cost_values           | 0.878        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.000212    |
|    std                   | 0.951        |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.77802044  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7700         |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0061717494 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 8.61         |
|    cost_values           | 0.837        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.2          |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.951        |
|    value_loss            | 8.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.65486956 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -619        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 8103        |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.007474695 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 0.728       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.24        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00546    |
|    std                   | 0.953       |
|    value_loss            | 16.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.13        |
| reward                   | -1.585374   |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -610        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 22          |
|    time_elapsed          | 8506        |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.006886116 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.12        |
|    cost_value_loss       | 6.82        |
|    cost_values           | 0.871       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7           |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.953       |
|    value_loss            | 7.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -1.1050712   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -608         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 8913         |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0033050668 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 4.3          |
|    cost_values           | 0.851        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.01         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.951        |
|    value_loss            | 11.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.5674503  |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -619        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 9318        |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.006565866 |
|    clip_fraction         | 0.0535      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.2         |
|    cost_value_loss       | 6.82        |
|    cost_values           | 0.858       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.6        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.952       |
|    value_loss            | 27.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.56668425 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -612        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 25          |
|    time_elapsed          | 9721        |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.004546589 |
|    clip_fraction         | 0.0294      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 3.14        |
|    cost_values           | 0.804       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.953       |
|    value_loss            | 23.3        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.91       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.91       |
| reward                   | -0.7227859 |
| rollout/                 |            |
|    ep_len_mean           | 944        |
|    ep_rew_mean           | -616       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 26         |
|    time_elapsed          | 10128      |
|    total_timesteps       | 454656     |
| train/                   |            |
|    approx_kl             | 0.0048719  |
|    clip_fraction         | 0.0409     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.41       |
|    cost_value_loss       | 11         |
|    cost_values           | 0.965      |
|    entropy               | -2.73      |
|    entropy_loss          | -2.74      |
|    explained_variance    | 0.903      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.74       |
|    n_updates             | 2210       |
|    policy_gradient_loss  | -0.0069    |
|    std                   | 0.948      |
|    value_loss            | 4.03       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.6024166  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -612        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 27          |
|    time_elapsed          | 10539       |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.005388869 |
|    clip_fraction         | 0.0342      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 0.962       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.63        |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.00526    |
|    std                   | 0.943       |
|    value_loss            | 6.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.22         |
| reward                   | -0.27454975  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -606         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 10952        |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0051611313 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 6.06         |
|    cost_values           | 0.936        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.66         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.78         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00481     |
|    std                   | 0.945        |
|    value_loss            | 8.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.69         |
| reward                   | -0.3706727   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -602         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 11366        |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0053931577 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.949        |
|    cost_value_loss       | 0.506        |
|    cost_values           | 0.836        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.82         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.00735     |
|    std                   | 0.947        |
|    value_loss            | 15.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.33        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.33        |
| reward                   | -0.5141743  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -609        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 30          |
|    time_elapsed          | 11779       |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.004687121 |
|    clip_fraction         | 0.0433      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 7.31        |
|    cost_values           | 0.963       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.69        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.86        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.946       |
|    value_loss            | 2.99        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -0.6603833   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -609         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 31           |
|    time_elapsed          | 12195        |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0043931194 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 2.72         |
|    cost_values           | 0.738        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.946        |
|    value_loss            | 35.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.6041486  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -612        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 12614       |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.002391139 |
|    clip_fraction         | 0.0238      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 0.794       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.1        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.947       |
|    value_loss            | 31.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.5023909  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -611        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 33          |
|    time_elapsed          | 13041       |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.005645085 |
|    clip_fraction         | 0.0501      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 2.9         |
|    cost_values           | 0.71        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.6        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00458    |
|    std                   | 0.946       |
|    value_loss            | 58.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.32996324  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -617         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 13489        |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0050945627 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 3.24         |
|    cost_values           | 0.892        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 0.946        |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.9549206   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 35           |
|    time_elapsed          | 13936        |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0033340587 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 8.38         |
|    cost_values           | 0.83         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.948        |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.341        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.341        |
| reward                   | -0.51876456  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -631         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 14386        |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0063925115 |
|    clip_fraction         | 0.0719       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.825        |
|    cost_value_loss       | 0.476        |
|    cost_values           | 0.772        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.72         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00918     |
|    std                   | 0.948        |
|    value_loss            | 13.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.372       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.372       |
| reward                   | -0.6048459  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -628        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 37          |
|    time_elapsed          | 14848       |
|    total_timesteps       | 477184      |
| train/                   |             |
|    approx_kl             | 0.006443995 |
|    clip_fraction         | 0.0421      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 4.03        |
|    cost_values           | 0.737       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.9        |
|    n_updates             | 2320        |
|    policy_gradient_loss  | -0.00677    |
|    std                   | 0.947       |
|    value_loss            | 35.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.823        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.823        |
| reward                   | -0.29768795  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -629         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 38           |
|    time_elapsed          | 15308        |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0065833125 |
|    clip_fraction         | 0.0402       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 9.59         |
|    cost_values           | 0.97         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.902        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00698     |
|    std                   | 0.944        |
|    value_loss            | 3.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.915252    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -627         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 39           |
|    time_elapsed          | 15771        |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0071080485 |
|    clip_fraction         | 0.0484       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 14           |
|    cost_values           | 1.13         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.527        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.96         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.941        |
|    value_loss            | 4.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.81        |
| reward                   | -0.49435484 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -622        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 40          |
|    time_elapsed          | 16234       |
|    total_timesteps       | 483328      |
| train/                   |             |
|    approx_kl             | 0.009185976 |
|    clip_fraction         | 0.0641      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.95        |
|    cost_value_loss       | 5.34        |
|    cost_values           | 1.07        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 2350        |
|    policy_gradient_loss  | -0.00696    |
|    std                   | 0.943       |
|    value_loss            | 26.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.63392365 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -617        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 41          |
|    time_elapsed          | 16702       |
|    total_timesteps       | 485376      |
| train/                   |             |
|    approx_kl             | 0.004205511 |
|    clip_fraction         | 0.0169      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 3.47        |
|    cost_values           | 0.956       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 2360        |
|    policy_gradient_loss  | -0.00399    |
|    std                   | 0.943       |
|    value_loss            | 7.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.25         |
| reward                   | -0.47857776  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -620         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 42           |
|    time_elapsed          | 17175        |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0050202906 |
|    clip_fraction         | 0.052        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 1.11         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.724        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00572     |
|    std                   | 0.938        |
|    value_loss            | 4.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0856       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0856       |
| reward                   | -0.603767    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -623         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 17644        |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0022409619 |
|    clip_fraction         | 0.00923      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 2.73         |
|    cost_values           | 1.01         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.000844    |
|    std                   | 0.936        |
|    value_loss            | 27.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.306       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.306       |
| reward                   | -0.45920888 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -619        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 44          |
|    time_elapsed          | 18122       |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.004756373 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 6.91        |
|    cost_values           | 0.82        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.13        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.00584    |
|    std                   | 0.936       |
|    value_loss            | 6.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.39         |
| reward                   | -0.99145895  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 18596        |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0045483215 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 8.02         |
|    cost_values           | 0.941        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.8         |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 0.936        |
|    value_loss            | 26.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.186751    |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -616         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 19068        |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0063949367 |
|    clip_fraction         | 0.0611       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 1.69         |
|    cost_values           | 0.867        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00752     |
|    std                   | 0.929        |
|    value_loss            | 9.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6582428  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -623        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 47          |
|    time_elapsed          | 19548       |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.003494916 |
|    clip_fraction         | 0.0456      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.77        |
|    cost_value_loss       | 8.1         |
|    cost_values           | 0.764       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.926       |
|    value_loss            | 19.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30473977 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -623        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 48          |
|    time_elapsed          | 20027       |
|    total_timesteps       | 499712      |
| train/                   |             |
|    approx_kl             | 0.00504185  |
|    clip_fraction         | 0.0414      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 5.31        |
|    cost_values           | 0.859       |
|    entropy               | -2.69       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41          |
|    n_updates             | 2430        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.928       |
|    value_loss            | 81.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.46218213 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -622        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 20507       |
|    total_timesteps       | 501760      |
| train/                   |             |
|    approx_kl             | 0.007088299 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 3.57        |
|    cost_values           | 0.87        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 2440        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.928       |
|    value_loss            | 8.61        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/h3wsymxd
------------------------------------
| avg_speed          | 8.03        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.03        |
| reward             | -0.75803673 |
| rollout/           |             |
|    ep_len_mean     | 966         |
|    ep_rew_mean     | -622        |
| time/              |             |
|    fps             | 4           |
|    iterations      | 1           |
|    time_elapsed    | 482         |
|    total_timesteps | 503808      |
------------------------------------
------------------------------------------
| avg_speed                | 0.613       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.613       |
| reward                   | -0.6029193  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -621        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 2           |
|    time_elapsed          | 966         |
|    total_timesteps       | 505856      |
| train/                   |             |
|    approx_kl             | 0.005135717 |
|    clip_fraction         | 0.0409      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.7         |
|    cost_value_loss       | 3.3         |
|    cost_values           | 0.969       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.489       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 2460        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.924       |
|    value_loss            | 5.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.395        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.395        |
| reward                   | -0.5922479   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -617         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1450         |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0070788953 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 4.03         |
|    cost_values           | 0.984        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.863        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00632     |
|    std                   | 0.917        |
|    value_loss            | 3.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.04        |
| reward                   | -0.43211892 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -619        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1939        |
|    total_timesteps       | 509952      |
| train/                   |             |
|    approx_kl             | 0.006445199 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 2.7         |
|    cost_values           | 0.992       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.747       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.96        |
|    n_updates             | 2480        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.914       |
|    value_loss            | 2.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.975        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.975        |
| reward                   | -0.42179403  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -617         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 5            |
|    time_elapsed          | 2430         |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0064645205 |
|    clip_fraction         | 0.0399       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 4.21         |
|    cost_values           | 0.979        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.74         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.42         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00536     |
|    std                   | 0.911        |
|    value_loss            | 4.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.02         |
| reward                   | -0.36211082  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -615         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 6            |
|    time_elapsed          | 2917         |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0056748823 |
|    clip_fraction         | 0.0356       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.17         |
|    cost_values           | 0.966        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.364        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.95         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.00648     |
|    std                   | 0.911        |
|    value_loss            | 5.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.29        |
| reward                   | -0.39574024 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -616        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 7           |
|    time_elapsed          | 3411        |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.006993971 |
|    clip_fraction         | 0.066       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 0.699       |
|    cost_values           | 0.97        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.678       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.52        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00784    |
|    std                   | 0.904       |
|    value_loss            | 3.87        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.17         |
| reward                   | -0.7035224   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -608         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 8            |
|    time_elapsed          | 3913         |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0048232283 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 8.85         |
|    cost_values           | 1            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.581        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.79         |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00498     |
|    std                   | 0.894        |
|    value_loss            | 3.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.5831104   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -609         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4415         |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0044500474 |
|    clip_fraction         | 0.0451       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 2.46         |
|    cost_values           | 1.01         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.449        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.76         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.004       |
|    std                   | 0.891        |
|    value_loss            | 2.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.61        |
| reward                   | -0.55777794 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -604        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 10          |
|    time_elapsed          | 4921        |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.005287732 |
|    clip_fraction         | 0.0708      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.78        |
|    cost_value_loss       | 4.69        |
|    cost_values           | 0.981       |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.635       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.72        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.00749    |
|    std                   | 0.892       |
|    value_loss            | 2.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.53733987 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -607        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 11          |
|    time_elapsed          | 5429        |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.004276107 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.64        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 1.02        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.303       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.00473    |
|    std                   | 0.892       |
|    value_loss            | 13.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5362763   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -602         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 5937         |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0065954514 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 2.72         |
|    cost_values           | 1.07         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.799        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.54         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.892        |
|    value_loss            | 10           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.5522154  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -606        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 13          |
|    time_elapsed          | 6445        |
|    total_timesteps       | 528384      |
| train/                   |             |
|    approx_kl             | 0.006752558 |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 1.27        |
|    cost_values           | 0.951       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.0594      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 2570        |
|    policy_gradient_loss  | -0.00575    |
|    std                   | 0.886       |
|    value_loss            | 14.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -0.8313698  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -608        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 14          |
|    time_elapsed          | 6944        |
|    total_timesteps       | 530432      |
| train/                   |             |
|    approx_kl             | 0.005511525 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 1.52        |
|    cost_values           | 0.957       |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | -0.032      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 2580        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.883       |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.44433492  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -612         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 15           |
|    time_elapsed          | 7456         |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0049140397 |
|    clip_fraction         | 0.0468       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 5.48         |
|    cost_values           | 0.968        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.95         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 0.88         |
|    value_loss            | 4.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.3449859  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -613        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 16          |
|    time_elapsed          | 7967        |
|    total_timesteps       | 534528      |
| train/                   |             |
|    approx_kl             | 0.006412497 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 9.74        |
|    cost_values           | 0.984       |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.39        |
|    n_updates             | 2600        |
|    policy_gradient_loss  | -0.00532    |
|    std                   | 0.877       |
|    value_loss            | 2.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5134697   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -605         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 17           |
|    time_elapsed          | 8487         |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0051942375 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 6.36         |
|    cost_values           | 1.09         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.714        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.51         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 0.876        |
|    value_loss            | 2.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.67        |
| reward                   | -0.5210501  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -602        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 18          |
|    time_elapsed          | 8998        |
|    total_timesteps       | 538624      |
| train/                   |             |
|    approx_kl             | 0.005295386 |
|    clip_fraction         | 0.0978      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.07        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.08        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.7         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 2620        |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.875       |
|    value_loss            | 5.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.99        |
| reward                   | -0.5360842  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -601        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 19          |
|    time_elapsed          | 9514        |
|    total_timesteps       | 540672      |
| train/                   |             |
|    approx_kl             | 0.010889241 |
|    clip_fraction         | 0.0815      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 1.84        |
|    cost_values           | 1.05        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | -0.209      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3           |
|    n_updates             | 2630        |
|    policy_gradient_loss  | -0.0067     |
|    std                   | 0.87        |
|    value_loss            | 4.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.86        |
| reward                   | -0.31406417 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -598        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 20          |
|    time_elapsed          | 10038       |
|    total_timesteps       | 542720      |
| train/                   |             |
|    approx_kl             | 0.006466185 |
|    clip_fraction         | 0.0807      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 2.93        |
|    cost_values           | 1.1         |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 2640        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.87        |
|    value_loss            | 4.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.5372288   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -592         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 21           |
|    time_elapsed          | 10549        |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0074908603 |
|    clip_fraction         | 0.0633       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 6.23         |
|    cost_values           | 1.02         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.32         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00874     |
|    std                   | 0.868        |
|    value_loss            | 2.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.56825244 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -598        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 22          |
|    time_elapsed          | 11072       |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.006107684 |
|    clip_fraction         | 0.0649      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 4.71        |
|    cost_values           | 1.24        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.0569      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.68        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.865       |
|    value_loss            | 3.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.48861125  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -601         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 11592        |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0069026407 |
|    clip_fraction         | 0.0561       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 2.16         |
|    cost_values           | 1.13         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.794        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | 0.00112      |
|    std                   | 0.864        |
|    value_loss            | 41.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.44095218 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -602        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 12107       |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.00312409  |
|    clip_fraction         | 0.00327     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.78        |
|    cost_value_loss       | 2.08        |
|    cost_values           | 1.09        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.57        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.864       |
|    value_loss            | 8.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42909297 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -611        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 25          |
|    time_elapsed          | 12628       |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.005764094 |
|    clip_fraction         | 0.0253      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 1.89        |
|    cost_values           | 0.873       |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.17        |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00665    |
|    std                   | 0.863       |
|    value_loss            | 8.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.46489933 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -619        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 26          |
|    time_elapsed          | 13157       |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.003949167 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.816       |
|    cost_value_loss       | 0.255       |
|    cost_values           | 0.783       |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 56.7        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.863       |
|    value_loss            | 120         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7631463   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -627         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 13681        |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0041937614 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.997        |
|    cost_value_loss       | 1.03         |
|    cost_values           | 0.747        |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.6         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.862        |
|    value_loss            | 53.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.8176006  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -622        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 28          |
|    time_elapsed          | 14208       |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.005070651 |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.743       |
|    cost_value_loss       | 0.735       |
|    cost_values           | 0.692       |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41          |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.862       |
|    value_loss            | 98.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8715008   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -615         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 14742        |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0066772453 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.839        |
|    cost_value_loss       | 0.288        |
|    cost_values           | 0.849        |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.793        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.56         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.00603     |
|    std                   | 0.862        |
|    value_loss            | 7.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5872154  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -611        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 30          |
|    time_elapsed          | 15273       |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.006342585 |
|    clip_fraction         | 0.0476      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.823       |
|    cost_value_loss       | 0.536       |
|    cost_values           | 0.72        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.8        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.00621    |
|    std                   | 0.861       |
|    value_loss            | 63.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.67328715 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -613        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 31          |
|    time_elapsed          | 15809       |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.007974399 |
|    clip_fraction         | 0.0559      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 3.12        |
|    cost_values           | 0.75        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00877    |
|    std                   | 0.861       |
|    value_loss            | 8.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.76826125 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -611        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 32          |
|    time_elapsed          | 16348       |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.003982912 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.932       |
|    cost_value_loss       | 0.636       |
|    cost_values           | 0.837       |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.005      |
|    std                   | 0.861       |
|    value_loss            | 5           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.279544   |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -609        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 33          |
|    time_elapsed          | 16890       |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.004199409 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 3.49        |
|    cost_values           | 0.922       |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.57        |
|    n_updates             | 2770        |
|    policy_gradient_loss  | -0.00541    |
|    std                   | 0.861       |
|    value_loss            | 5           |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.76075345  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -600         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 34           |
|    time_elapsed          | 17431        |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0032097897 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 0.959        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.837        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.23         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.855        |
|    value_loss            | 2.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.854598    |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -602         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 35           |
|    time_elapsed          | 17978        |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0024487956 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 2.59         |
|    cost_values           | 0.941        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.856        |
|    value_loss            | 5.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.53536654 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -604        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 36          |
|    time_elapsed          | 18521       |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.00536756  |
|    clip_fraction         | 0.0634      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 9.62        |
|    cost_values           | 1.02        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.00714    |
|    std                   | 0.855       |
|    value_loss            | 2.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -0.6420137   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -609         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 19071        |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0033840546 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 4.01         |
|    cost_values           | 1.09         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00382     |
|    std                   | 0.856        |
|    value_loss            | 5.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.39855355  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -607         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 19622        |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0048535024 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 4.08         |
|    cost_values           | 0.998        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.864        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.05         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 0.857        |
|    value_loss            | 2.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4665973   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -607         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 39           |
|    time_elapsed          | 20166        |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0027196892 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 2.88         |
|    cost_values           | 0.942        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.65         |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.00359     |
|    std                   | 0.859        |
|    value_loss            | 4.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.83        |
| reward                   | -0.32972997 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -595        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 40          |
|    time_elapsed          | 20716       |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.008427575 |
|    clip_fraction         | 0.0714      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.34        |
|    cost_value_loss       | 5.49        |
|    cost_values           | 0.996       |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.336       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.21        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.00565    |
|    std                   | 0.859       |
|    value_loss            | 13.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5454137   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -594         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 21270        |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0028197232 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 4.19         |
|    cost_values           | 0.981        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.858        |
|    value_loss            | 20.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.5582303   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -600         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 21829        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0068003554 |
|    clip_fraction         | 0.0526       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.81         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 1.23         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.778        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00488     |
|    std                   | 0.855        |
|    value_loss            | 2.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.384        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.384        |
| reward                   | -0.52175045  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -594         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 43           |
|    time_elapsed          | 22400        |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0062995437 |
|    clip_fraction         | 0.0575       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 4.22         |
|    cost_values           | 1.71         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.498        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.54         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 0.854        |
|    value_loss            | 3.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -0.4128859   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -585         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 44           |
|    time_elapsed          | 22958        |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0039160266 |
|    clip_fraction         | 0.0494       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.8          |
|    cost_value_loss       | 8.96         |
|    cost_values           | 2.01         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.112        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.0063      |
|    std                   | 0.855        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.149       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.149       |
| reward                   | -0.53866976 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -580        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 23522       |
|    total_timesteps       | 593920      |
| train/                   |             |
|    approx_kl             | 0.005674761 |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.22        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.000248    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.51        |
|    n_updates             | 2890        |
|    policy_gradient_loss  | -0.00582    |
|    std                   | 0.857       |
|    value_loss            | 3.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.86        |
| reward                   | -0.62166697 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -581        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 46          |
|    time_elapsed          | 24087       |
|    total_timesteps       | 595968      |
| train/                   |             |
|    approx_kl             | 0.007873598 |
|    clip_fraction         | 0.0752      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.48        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 2.38        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | -0.158      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.26        |
|    n_updates             | 2900        |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 0.857       |
|    value_loss            | 16          |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.58         |
| reward                   | -0.35739598  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -581         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 47           |
|    time_elapsed          | 24651        |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0068174973 |
|    clip_fraction         | 0.0576       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.96         |
|    cost_value_loss       | 4.32         |
|    cost_values           | 2.37         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 4.01e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.81         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 0.855        |
|    value_loss            | 2.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.656        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.656        |
| reward                   | -0.5083337   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -583         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 48           |
|    time_elapsed          | 25216        |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0036287808 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.2          |
|    cost_value_loss       | 13.5         |
|    cost_values           | 2.11         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.905        |
|    lagrangian_multiplier | 0.00108      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.58         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.851        |
|    value_loss            | 3.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.577        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.577        |
| reward                   | -0.328714    |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 49           |
|    time_elapsed          | 25785        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0018659176 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 9.11         |
|    cost_values           | 2.08         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.786        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.71         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.85         |
|    value_loss            | 6.25         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.835       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.835       |
| reward             | -0.40129507 |
| rollout/           |             |
|    ep_len_mean     | 950         |
|    ep_rew_mean     | -578        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 568         |
|    total_timesteps | 604160      |
------------------------------------
------------------------------------------
| avg_speed                | 0.983       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.983       |
| reward                   | -0.38663527 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -574        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1139        |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.009644438 |
|    clip_fraction         | 0.071       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 2.97        |
|    cost_values           | 2.29        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.407       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.87        |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.00721    |
|    std                   | 0.852       |
|    value_loss            | 4.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.31578252 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -575        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 3           |
|    time_elapsed          | 1719        |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.006927594 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 2.52        |
|    cost_values           | 2.49        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.136       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | 0.000761    |
|    std                   | 0.846       |
|    value_loss            | 1.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.49441156  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 4            |
|    time_elapsed          | 2295         |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0074886857 |
|    clip_fraction         | 0.146        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.67         |
|    cost_value_loss       | 8.31         |
|    cost_values           | 2.59         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | -0.959       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.42         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | 0.00136      |
|    std                   | 0.843        |
|    value_loss            | 4.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.49437714 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -572        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2864        |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.007065497 |
|    clip_fraction         | 0.0588      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 5.42        |
|    cost_values           | 2.79        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0.00193     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.12        |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.00747    |
|    std                   | 0.846       |
|    value_loss            | 2.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.18         |
| reward                   | -0.35931373  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 6            |
|    time_elapsed          | 3441         |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0054765083 |
|    clip_fraction         | 0.0854       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.18         |
|    cost_value_loss       | 9.67         |
|    cost_values           | 2.9          |
|    entropy               | -2.52        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.856        |
|    lagrangian_multiplier | 0.00353      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.00616     |
|    std                   | 0.854        |
|    value_loss            | 2.14         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.86       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 3.86       |
| reward                   | -0.5313312 |
| rollout/                 |            |
|    ep_len_mean           | 956        |
|    ep_rew_mean           | -575       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 7          |
|    time_elapsed          | 4024       |
|    total_timesteps       | 616448     |
| train/                   |            |
|    approx_kl             | 0.00850714 |
|    clip_fraction         | 0.0756     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.6        |
|    cost_value_loss       | 6.65       |
|    cost_values           | 2.62       |
|    entropy               | -2.52      |
|    entropy_loss          | -2.52      |
|    explained_variance    | 0.505      |
|    lagrangian_multiplier | 0.0243     |
|    learning_rate         | 0.0003     |
|    loss                  | 2.79       |
|    n_updates             | 3000       |
|    policy_gradient_loss  | -0.000358  |
|    std                   | 0.855      |
|    value_loss            | 18.7       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.05        |
| reward                   | -0.3915877  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -573        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 4608        |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.002310433 |
|    clip_fraction         | 0.00728     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 21.6        |
|    cost_values           | 2.43        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.321       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.854       |
|    value_loss            | 6.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.462        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.462        |
| reward                   | -0.49566066  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -567         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 9            |
|    time_elapsed          | 5197         |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0040178495 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.74         |
|    cost_value_loss       | 8.71         |
|    cost_values           | 2.68         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | -0.43        |
|    lagrangian_multiplier | 0.00141      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.852        |
|    value_loss            | 4.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.426       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.426       |
| reward                   | -0.36520293 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -572        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 10          |
|    time_elapsed          | 5787        |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.006364562 |
|    clip_fraction         | 0.077       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 38.9        |
|    cost_values           | 2.8         |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.201       |
|    lagrangian_multiplier | 0.00468     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.1         |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.85        |
|    value_loss            | 8.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.44         |
| reward                   | -0.36422613  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -567         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 11           |
|    time_elapsed          | 6381         |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0051708836 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 2.93         |
|    cost_values           | 2.79         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.765        |
|    lagrangian_multiplier | 0.00021      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.16         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00622     |
|    std                   | 0.848        |
|    value_loss            | 3.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.40321735 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -567        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 12          |
|    time_elapsed          | 6973        |
|    total_timesteps       | 626688      |
| train/                   |             |
|    approx_kl             | 0.011752798 |
|    clip_fraction         | 0.063       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.94        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | -0.294      |
|    lagrangian_multiplier | 0.00246     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 3050        |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 0.843       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.14        |
| reward                   | -0.24662712 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -568        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 7569        |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.004323587 |
|    clip_fraction         | 0.067       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 4.65        |
|    cost_values           | 2.77        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | -0.407      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.000251   |
|    std                   | 0.839       |
|    value_loss            | 2.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.11         |
| reward                   | -0.42714846  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -569         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 14           |
|    time_elapsed          | 8163         |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0046490026 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.78         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.72         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.533        |
|    lagrangian_multiplier | 0.000446     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.89         |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.838        |
|    value_loss            | 5.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.07        |
| reward                   | -0.4271087  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -567        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 15          |
|    time_elapsed          | 8761        |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.001938204 |
|    clip_fraction         | 0.00137     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.56        |
|    cost_value_loss       | 1.3         |
|    cost_values           | 2.5         |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.811       |
|    n_updates             | 3080        |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.838       |
|    value_loss            | 2.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.21        |
| reward                   | -0.25955504 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -570        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 16          |
|    time_elapsed          | 9364        |
|    total_timesteps       | 634880      |
| train/                   |             |
|    approx_kl             | 0.005564793 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 2.91        |
|    cost_values           | 2.22        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.195       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.13        |
|    n_updates             | 3090        |
|    policy_gradient_loss  | -0.00805    |
|    std                   | 0.835       |
|    value_loss            | 1.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.5795144   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -568         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 9960         |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0036609021 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 4.16         |
|    cost_values           | 2.07         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.75         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.836        |
|    value_loss            | 6.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.5951148   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -567         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 10560        |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0042416463 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 1.02         |
|    cost_values           | 1.92         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.139        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.55         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.836        |
|    value_loss            | 3.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.68902206 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -569        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 19          |
|    time_elapsed          | 11156       |
|    total_timesteps       | 641024      |
| train/                   |             |
|    approx_kl             | 0.005267355 |
|    clip_fraction         | 0.0666      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 2.97        |
|    cost_values           | 1.74        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.532       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 3120        |
|    policy_gradient_loss  | -0.00535    |
|    std                   | 0.834       |
|    value_loss            | 2.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.59         |
| reward                   | -0.8164253   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -558         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 20           |
|    time_elapsed          | 11760        |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0040076165 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 2.01         |
|    cost_values           | 1.59         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.76         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 0.831        |
|    value_loss            | 3.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.6069768  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -556        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 12369       |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.008396602 |
|    clip_fraction         | 0.0705      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.72        |
|    cost_value_loss       | 5.29        |
|    cost_values           | 1.55        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.00918    |
|    std                   | 0.832       |
|    value_loss            | 2.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.39774197  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 22           |
|    time_elapsed          | 12976        |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0034918915 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 4.28         |
|    cost_values           | 1.63         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -0.607       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4            |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.831        |
|    value_loss            | 7.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.24        |
| reward                   | -0.74221206 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -550        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 13581       |
|    total_timesteps       | 649216      |
| train/                   |             |
|    approx_kl             | 0.007365131 |
|    clip_fraction         | 0.0611      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 1.07        |
|    cost_values           | 1.48        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.306       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.74        |
|    n_updates             | 3160        |
|    policy_gradient_loss  | -0.00669    |
|    std                   | 0.832       |
|    value_loss            | 2.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.7281363   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 14194        |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0073176194 |
|    clip_fraction         | 0.0672       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 2.56         |
|    cost_values           | 1.33         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.445        |
|    lagrangian_multiplier | 0.000212     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.67         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.832        |
|    value_loss            | 55.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.585        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.585        |
| reward                   | -0.5522251   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -536         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 14811        |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0029485906 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 1.44         |
|    cost_values           | 1.01         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.82         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.5          |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.832        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.485        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.485        |
| reward                   | -0.6604846   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 26           |
|    time_elapsed          | 15418        |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0011788338 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.5          |
|    cost_values           | 0.775        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.847        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.832        |
|    value_loss            | 21.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.97         |
| reward                   | -0.3582742   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -531         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 27           |
|    time_elapsed          | 16026        |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0052352548 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 0.721        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 0.832        |
|    value_loss            | 48.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.73648405 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -532        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 28          |
|    time_elapsed          | 16643       |
|    total_timesteps       | 659456      |
| train/                   |             |
|    approx_kl             | 0.011936182 |
|    clip_fraction         | 0.0657      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.837       |
|    cost_value_loss       | 0.436       |
|    cost_values           | 0.719       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.213       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 3210        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.826       |
|    value_loss            | 5.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.72         |
| reward                   | -0.45331046  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -529         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 29           |
|    time_elapsed          | 17250        |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0058006886 |
|    clip_fraction         | 0.155        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.952        |
|    cost_value_loss       | 0.907        |
|    cost_values           | 0.727        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.457        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.76         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.829        |
|    value_loss            | 2.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.95         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.95         |
| reward                   | -0.5658944   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 17877        |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0030493734 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.954        |
|    cost_value_loss       | 1.27         |
|    cost_values           | 0.768        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.596        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.7          |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00502     |
|    std                   | 0.829        |
|    value_loss            | 5.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.72         |
| reward                   | -0.6699129   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 31           |
|    time_elapsed          | 18507        |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0055003176 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 6.48         |
|    cost_values           | 0.851        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.695        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00429     |
|    std                   | 0.83         |
|    value_loss            | 2.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.49134126 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -526        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 32          |
|    time_elapsed          | 19138       |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.00464341  |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 2.78        |
|    cost_values           | 0.83        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.63        |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.00424    |
|    std                   | 0.83        |
|    value_loss            | 6.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.08         |
| reward                   | -0.50479025  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 19768        |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0036921096 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 0.878        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.669        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.23         |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.83         |
|    value_loss            | 3.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.70508814  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 34           |
|    time_elapsed          | 20399        |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0050525023 |
|    clip_fraction         | 0.0561       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 4.52         |
|    cost_values           | 0.922        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.899        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.56         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00647     |
|    std                   | 0.828        |
|    value_loss            | 3.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0495      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0495      |
| reward                   | -0.32389054 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -524        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 35          |
|    time_elapsed          | 21035       |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.004519822 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 8.6         |
|    cost_values           | 0.874       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.7        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.828       |
|    value_loss            | 40.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.34        |
| reward                   | -0.35804975 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -521        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 36          |
|    time_elapsed          | 21657       |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.005407558 |
|    clip_fraction         | 0.0437      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.985       |
|    cost_value_loss       | 0.855       |
|    cost_values           | 0.85        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.264       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.34        |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.828       |
|    value_loss            | 2.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.74         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.74         |
| reward                   | -0.59370387  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 22288        |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0040065935 |
|    clip_fraction         | 0.141        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 4.81         |
|    cost_values           | 0.947        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.809        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.04         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | 0.0034       |
|    std                   | 0.826        |
|    value_loss            | 2.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7            |
| reward                   | -0.5391977   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 22924        |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0027387512 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 1.64         |
|    cost_values           | 0.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.744        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.95         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.000583    |
|    std                   | 0.825        |
|    value_loss            | 4.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.4822187   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -519         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 39           |
|    time_elapsed          | 23564        |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0028638192 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 5.34         |
|    cost_values           | 0.887        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.178        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.75         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.824        |
|    value_loss            | 2.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.07         |
| reward                   | -0.58654886  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -528         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 24210        |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0034743655 |
|    clip_fraction         | 0.00552      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.51         |
|    cost_values           | 0.913        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.663        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.824        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.04         |
| reward                   | -0.503442    |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -529         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 24847        |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0017780515 |
|    clip_fraction         | 0.00215      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 3.73         |
|    cost_values           | 0.825        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.9         |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.000904    |
|    std                   | 0.823        |
|    value_loss            | 40.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.08         |
| reward                   | -0.4346668   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 25495        |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0030973272 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.941        |
|    cost_value_loss       | 0.294        |
|    cost_values           | 0.863        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.44         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.3          |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.823        |
|    value_loss            | 4            |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.51        |
| reward                   | -0.8590094  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -530        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 43          |
|    time_elapsed          | 26150       |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.009031175 |
|    clip_fraction         | 0.0415      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 4.63        |
|    cost_values           | 0.855       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.391       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.819       |
|    value_loss            | 1.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.69        |
| reward                   | -0.57375735 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 44          |
|    time_elapsed          | 26789       |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.005359994 |
|    clip_fraction         | 0.0474      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 0.899       |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.119       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.817       |
|    value_loss            | 18.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.7         |
| reward                   | -0.4170008  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -535        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 27445       |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.004245314 |
|    clip_fraction         | 0.0175      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 4.29        |
|    cost_values           | 0.957       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.382       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.818       |
|    value_loss            | 7.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.4992181  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -535        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 46          |
|    time_elapsed          | 28110       |
|    total_timesteps       | 696320      |
| train/                   |             |
|    approx_kl             | 0.006201333 |
|    clip_fraction         | 0.0216      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 3.94        |
|    cost_values           | 1.02        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.257       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.76        |
|    n_updates             | 3390        |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.817       |
|    value_loss            | 17.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.95         |
| reward                   | -0.47302985  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 47           |
|    time_elapsed          | 28773        |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0073368712 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.964        |
|    cost_value_loss       | 0.377        |
|    cost_values           | 0.827        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.648        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.38         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 0.812        |
|    value_loss            | 3.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.96         |
| reward                   | -0.31884548  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -536         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 48           |
|    time_elapsed          | 29441        |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0068154978 |
|    clip_fraction         | 0.0425       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.07         |
|    cost_values           | 0.747        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.797        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.2          |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.811        |
|    value_loss            | 3.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.73         |
| reward                   | -0.67670345  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 49           |
|    time_elapsed          | 30104        |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0068509774 |
|    clip_fraction         | 0.0575       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 2.74         |
|    cost_values           | 0.753        |
|    entropy               | -2.41        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.733        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.35         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 0.809        |
|    value_loss            | 3.17         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/h3wsymxd
-----------------------------------
| avg_speed          | 2.07       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.07       |
| reward             | -0.4848954 |
| rollout/           |            |
|    ep_len_mean     | 983        |
|    ep_rew_mean     | -542       |
| time/              |            |
|    fps             | 3          |
|    iterations      | 1          |
|    time_elapsed    | 655        |
|    total_timesteps | 704512     |
-----------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.3298706  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -543        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1302        |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.004128239 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 2.84        |
|    cost_values           | 0.82        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.807       |
|    value_loss            | 2.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -0.47743103  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -549         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1957         |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0044084843 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.962        |
|    cost_values           | 0.802        |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.819        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.33         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 0.804        |
|    value_loss            | 3.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.18         |
| reward                   | -0.4158376   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -551         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 4            |
|    time_elapsed          | 2620         |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0028968547 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.928        |
|    cost_values           | 0.677        |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.733        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.66         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.803        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.31         |
| reward                   | -0.6255464   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 5            |
|    time_elapsed          | 3285         |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0056282813 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 1.91         |
|    cost_values           | 0.822        |
|    entropy               | -2.39        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.634        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.89         |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.0049      |
|    std                   | 0.8          |
|    value_loss            | 4.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.5967568  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 6           |
|    time_elapsed          | 3952        |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.005169766 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 1.8         |
|    cost_values           | 0.783       |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.416       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.798       |
|    value_loss            | 15.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.82        |
| reward                   | -0.7284971  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -550        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 7           |
|    time_elapsed          | 4620        |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.004868318 |
|    clip_fraction         | 0.0363      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 2.02        |
|    cost_values           | 0.772       |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.804       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.64        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 0.797       |
|    value_loss            | 2.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -0.28450716 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -555        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 5280        |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.005124531 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 1.75        |
|    cost_values           | 0.84        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.16        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.795       |
|    value_loss            | 5.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.31356093  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -552         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 9            |
|    time_elapsed          | 5945         |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0033477363 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 1.9          |
|    cost_values           | 0.877        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.588        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.38         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00522     |
|    std                   | 0.793        |
|    value_loss            | 5.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.5592283  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -551        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 10          |
|    time_elapsed          | 6617        |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.005538109 |
|    clip_fraction         | 0.0613      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.88        |
|    cost_values           | 0.813       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.711       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.37        |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.793       |
|    value_loss            | 1.68        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -0.7539085   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 11           |
|    time_elapsed          | 7294         |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0048469743 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 4.58         |
|    cost_values           | 0.876        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.762        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.793        |
|    value_loss            | 3.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.22         |
| reward                   | -0.5869999   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -552         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 12           |
|    time_elapsed          | 7978         |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0012331171 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 2.68         |
|    cost_values           | 0.92         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.683        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.25         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.792        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5776439  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -550        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 8662        |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.004448042 |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 3.02        |
|    cost_values           | 0.956       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.223       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.79        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.00637    |
|    std                   | 0.793       |
|    value_loss            | 13.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.31514236 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -551        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 14          |
|    time_elapsed          | 9336        |
|    total_timesteps       | 731136      |
| train/                   |             |
|    approx_kl             | 0.009534175 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 0.533       |
|    cost_values           | 0.864       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.796       |
|    n_updates             | 3560        |
|    policy_gradient_loss  | -0.0108     |
|    std                   | 0.793       |
|    value_loss            | 1.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.36032918  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 10018        |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0038455774 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 2.38         |
|    cost_values           | 0.881        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.75         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.07         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.0059      |
|    std                   | 0.793        |
|    value_loss            | 3.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.57        |
| reward                   | -0.62818354 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -548        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 16          |
|    time_elapsed          | 10702       |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.006525562 |
|    clip_fraction         | 0.0416      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 5.44        |
|    cost_values           | 0.957       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.671       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.1         |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00666    |
|    std                   | 0.792       |
|    value_loss            | 1.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1510341   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -556         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 11374        |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0028709064 |
|    clip_fraction         | 0.0083       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 2.53         |
|    cost_values           | 1.08         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.584        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.52         |
|    n_updates             | 3590         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.79         |
|    value_loss            | 2.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.77         |
| reward                   | -0.687222    |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -561         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 12056        |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0014756175 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.12         |
|    cost_values           | 0.9          |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.623        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.98         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | 0.000977     |
|    std                   | 0.79         |
|    value_loss            | 31.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.57870805  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -561         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 12739        |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0009095658 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.22         |
|    cost_values           | 0.819        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.04         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.79         |
|    value_loss            | 25.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.54065245  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -559         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 20           |
|    time_elapsed          | 13434        |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0068935687 |
|    clip_fraction         | 0.0747       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 3.03         |
|    cost_values           | 0.98         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.897        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.88         |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.0089      |
|    std                   | 0.788        |
|    value_loss            | 1.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.7          |
| reward                   | -0.66384876  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -558         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 21           |
|    time_elapsed          | 14126        |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0037467228 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.992        |
|    cost_values           | 0.954        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.616        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.53         |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 0.788        |
|    value_loss            | 2.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.35        |
| reward                   | -0.26932636 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -549        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 22          |
|    time_elapsed          | 14821       |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.008522527 |
|    clip_fraction         | 0.0658      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 2.37        |
|    cost_values           | 0.955       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.57        |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.007      |
|    std                   | 0.788       |
|    value_loss            | 1.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.4868768   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 23           |
|    time_elapsed          | 15508        |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0057995706 |
|    clip_fraction         | 0.0554       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 4.41         |
|    cost_values           | 1.03         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.888        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.68         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.00542     |
|    std                   | 0.787        |
|    value_loss            | 2.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.26         |
| reward                   | -0.35244313  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 16208        |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0073301448 |
|    clip_fraction         | 0.0693       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 2.81         |
|    cost_values           | 1.04         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.706        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.04         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00628     |
|    std                   | 0.784        |
|    value_loss            | 1.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.5033679  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -537        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 25          |
|    time_elapsed          | 16911       |
|    total_timesteps       | 753664      |
| train/                   |             |
|    approx_kl             | 0.004863019 |
|    clip_fraction         | 0.0461      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 7.23        |
|    cost_values           | 1.09        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.66        |
|    n_updates             | 3670        |
|    policy_gradient_loss  | -0.00475    |
|    std                   | 0.783       |
|    value_loss            | 2.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.6          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.6          |
| reward                   | -0.5118845   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 26           |
|    time_elapsed          | 17603        |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0047813044 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 2.19         |
|    cost_values           | 1.06         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.782        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.71         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00395     |
|    std                   | 0.782        |
|    value_loss            | 2.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.43        |
| reward                   | -0.30927885 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -538        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 27          |
|    time_elapsed          | 18303       |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.006362794 |
|    clip_fraction         | 0.0549      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 0.969       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.789       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.9         |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 0.783       |
|    value_loss            | 2.35        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -2.3736055 |
| rollout/                 |            |
|    ep_len_mean           | 981        |
|    ep_rew_mean           | -535       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 28         |
|    time_elapsed          | 19016      |
|    total_timesteps       | 759808     |
| train/                   |            |
|    approx_kl             | 0.00745607 |
|    clip_fraction         | 0.0321     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.09       |
|    cost_value_loss       | 1.61       |
|    cost_values           | 0.907      |
|    entropy               | -2.35      |
|    entropy_loss          | -2.35      |
|    explained_variance    | 0.914      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.07       |
|    n_updates             | 3700       |
|    policy_gradient_loss  | -0.00426   |
|    std                   | 0.782      |
|    value_loss            | 1.62       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.47957158  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 29           |
|    time_elapsed          | 19724        |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0016098528 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.32         |
|    cost_values           | 0.822        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.78         |
|    n_updates             | 3710         |
|    policy_gradient_loss  | -0.000485    |
|    std                   | 0.781        |
|    value_loss            | 29.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.9         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.9         |
| reward                   | -0.34437957 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -538        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 30          |
|    time_elapsed          | 20434       |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.004283275 |
|    clip_fraction         | 0.0552      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.916       |
|    cost_value_loss       | 0.299       |
|    cost_values           | 0.954       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.361       |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.00385    |
|    std                   | 0.783       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.298       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.298       |
| reward                   | -0.56001467 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -538        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 31          |
|    time_elapsed          | 21144       |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.011523191 |
|    clip_fraction         | 0.0675      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 1.21        |
|    cost_values           | 0.975       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.766       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.83        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.785       |
|    value_loss            | 0.862       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.59934634  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 32           |
|    time_elapsed          | 21851        |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0039314087 |
|    clip_fraction         | 0.0838       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.74         |
|    cost_values           | 0.921        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.773        |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.00548     |
|    std                   | 0.787        |
|    value_loss            | 1.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.45850623 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -543        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 33          |
|    time_elapsed          | 22561       |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.00330114  |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 1.64        |
|    cost_values           | 0.81        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.56        |
|    n_updates             | 3750        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.788       |
|    value_loss            | 30.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.4424831  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -541        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 34          |
|    time_elapsed          | 23275       |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.002830288 |
|    clip_fraction         | 0.00669     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.941       |
|    cost_value_loss       | 1.12        |
|    cost_values           | 0.827       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.88        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.788       |
|    value_loss            | 21.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.401       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.401       |
| reward                   | -0.22153562 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 35          |
|    time_elapsed          | 23992       |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.006029838 |
|    clip_fraction         | 0.0432      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 2.02        |
|    cost_values           | 0.899       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.738       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00502    |
|    std                   | 0.788       |
|    value_loss            | 2.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.53644335 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -545        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 36          |
|    time_elapsed          | 24703       |
|    total_timesteps       | 776192      |
| train/                   |             |
|    approx_kl             | 0.003847192 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 3.08        |
|    cost_values           | 0.772       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.77        |
|    n_updates             | 3780        |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.788       |
|    value_loss            | 18.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.24832     |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 37           |
|    time_elapsed          | 25422        |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0045055454 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 0.924        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.76         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.00715     |
|    std                   | 0.787        |
|    value_loss            | 2.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.42572436 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -545        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 38          |
|    time_elapsed          | 26139       |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.004735366 |
|    clip_fraction         | 0.0414      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 3.2         |
|    cost_values           | 0.93        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.00463    |
|    std                   | 0.787       |
|    value_loss            | 2.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.44        |
| reward                   | -0.54689056 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -540        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 39          |
|    time_elapsed          | 26852       |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.005639841 |
|    clip_fraction         | 0.0253      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.44        |
|    cost_value_loss       | 2.43        |
|    cost_values           | 0.979       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.632       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.33        |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.785       |
|    value_loss            | 0.986       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.33         |
| reward                   | -0.42861196  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 40           |
|    time_elapsed          | 27571        |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0053012418 |
|    clip_fraction         | 0.0599       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 2.62         |
|    cost_values           | 0.947        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.761        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.26         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.0069      |
|    std                   | 0.784        |
|    value_loss            | 3.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.75398254 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 41          |
|    time_elapsed          | 28297       |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.006012532 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 1.17        |
|    cost_values           | 0.93        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.817       |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.786       |
|    value_loss            | 1.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.5484435   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 42           |
|    time_elapsed          | 29025        |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0034709296 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 1.52         |
|    cost_values           | 0.957        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.859        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.56         |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.787        |
|    value_loss            | 2.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.4316057  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -542        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 43          |
|    time_elapsed          | 29752       |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.004132238 |
|    clip_fraction         | 0.0158      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 1.75        |
|    cost_values           | 0.844       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 0.787       |
|    value_loss            | 25.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.49         |
| reward                   | -0.42642576  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 44           |
|    time_elapsed          | 30481        |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0034423666 |
|    clip_fraction         | 0.00503      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 2.75         |
|    cost_values           | 0.925        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.787        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.57020277  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 45           |
|    time_elapsed          | 31214        |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0064926483 |
|    clip_fraction         | 0.0369       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 3.51         |
|    cost_values           | 0.892        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.79         |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.788        |
|    value_loss            | 19.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1367747   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 46           |
|    time_elapsed          | 31948        |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0033830777 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 3.51         |
|    cost_values           | 0.978        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.897        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.28         |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00457     |
|    std                   | 0.787        |
|    value_loss            | 3.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.466164   |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -542        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 47          |
|    time_elapsed          | 32690       |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.005681525 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.961       |
|    cost_value_loss       | 0.72        |
|    cost_values           | 0.932       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00339    |
|    std                   | 0.786       |
|    value_loss            | 9.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.206       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.206       |
| reward                   | -0.32861054 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -542        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 48          |
|    time_elapsed          | 33413       |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.008318904 |
|    clip_fraction         | 0.0232      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 1.4         |
|    cost_values           | 0.978       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.577       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.58        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00623    |
|    std                   | 0.786       |
|    value_loss            | 4.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.526        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.526        |
| reward                   | -0.3734572   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 49           |
|    time_elapsed          | 34141        |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0045888303 |
|    clip_fraction         | 0.0671       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 2.93         |
|    cost_values           | 0.985        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.899        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.54         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.00688     |
|    std                   | 0.785        |
|    value_loss            | 2.76         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.06       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.06       |
| reward             | -0.5053875 |
| rollout/           |            |
|    ep_len_mean     | 997        |
|    ep_rew_mean     | -539       |
| time/              |            |
|    fps             | 2          |
|    iterations      | 1          |
|    time_elapsed    | 744        |
|    total_timesteps | 804864     |
-----------------------------------
-------------------------------------------
| avg_speed                | 3.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.8          |
| reward                   | -0.3625879   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 2            |
|    time_elapsed          | 1493         |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0048142085 |
|    clip_fraction         | 0.0448       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 4.69         |
|    cost_values           | 1.03         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.816        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.787        |
|    value_loss            | 3.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.237        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.237        |
| reward                   | -0.48203123  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 3            |
|    time_elapsed          | 2250         |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0014365136 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.95         |
|    cost_value_loss       | 0.457        |
|    cost_values           | 0.966        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.449        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.374        |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.000853    |
|    std                   | 0.788        |
|    value_loss            | 0.849        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.107       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.107       |
| reward                   | -0.48091608 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -528        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 4           |
|    time_elapsed          | 3000        |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.009864913 |
|    clip_fraction         | 0.0794      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 3.78        |
|    cost_values           | 0.978       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.0074     |
|    std                   | 0.79        |
|    value_loss            | 1.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.37662315 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -529        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 5           |
|    time_elapsed          | 3750        |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.005114198 |
|    clip_fraction         | 0.0483      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 3.73        |
|    cost_values           | 0.991       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 0.791       |
|    value_loss            | 0.645       |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.4          |
| reward                   | -0.4456372   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 6            |
|    time_elapsed          | 4503         |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0024047345 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 3.67         |
|    cost_values           | 0.972        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.751        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 3970         |
|    policy_gradient_loss  | 0.000565     |
|    std                   | 0.79         |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -0.36592847  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -526         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 7            |
|    time_elapsed          | 5264         |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0006757601 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 4.62         |
|    cost_values           | 0.934        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.17         |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.000777    |
|    std                   | 0.79         |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.53        |
| reward                   | -0.47051096 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -524        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 8           |
|    time_elapsed          | 6035        |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.00498565  |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 3.34        |
|    cost_values           | 0.973       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 0.79        |
|    value_loss            | 8.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.43523657 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -526        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 9           |
|    time_elapsed          | 6805        |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.004570458 |
|    clip_fraction         | 0.0238      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 5.51        |
|    cost_values           | 0.978       |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.747       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.79        |
|    value_loss            | 3.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4            |
| reward                   | -0.408211    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 10           |
|    time_elapsed          | 7568         |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0030557245 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 4.73         |
|    cost_values           | 0.971        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.729        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.46         |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 0.788        |
|    value_loss            | 5.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.237       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.237       |
| reward                   | -0.4740598  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -519        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 11          |
|    time_elapsed          | 8344        |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.004768178 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 2.6         |
|    cost_values           | 0.984       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.793       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00654    |
|    std                   | 0.786       |
|    value_loss            | 1.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.5890272   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -520         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 12           |
|    time_elapsed          | 9125         |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0061793914 |
|    clip_fraction         | 0.0454       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 4.68         |
|    cost_values           | 0.998        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.872        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.09         |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.00632     |
|    std                   | 0.785        |
|    value_loss            | 1.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.087       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.087       |
| reward                   | -0.5565883  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -525        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 13          |
|    time_elapsed          | 9893        |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.005190779 |
|    clip_fraction         | 0.037       |
|    clip_range            | 0.2         |
|    cost_returns          | 1           |
|    cost_value_loss       | 0.585       |
|    cost_values           | 0.942       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.381       |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.786       |
|    value_loss            | 0.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.495        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.495        |
| reward                   | -0.37904397  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 14           |
|    time_elapsed          | 10663        |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0079865325 |
|    clip_fraction         | 0.115        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 3.42         |
|    cost_values           | 0.907        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.792        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.25         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | 0.00717      |
|    std                   | 0.787        |
|    value_loss            | 18.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.53        |
| reward                   | -0.4253426  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -524        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 15          |
|    time_elapsed          | 11443       |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.007976483 |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 2.78        |
|    cost_values           | 0.924       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.764       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.785       |
|    value_loss            | 1.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.3          |
| reward                   | -0.5278482   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -514         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 16           |
|    time_elapsed          | 12231        |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0058262506 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 4.82         |
|    cost_values           | 0.98         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.503        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.14         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.0053      |
|    std                   | 0.783        |
|    value_loss            | 2.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.49658743  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 17           |
|    time_elapsed          | 13022        |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0046283947 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 5.96         |
|    cost_values           | 0.973        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00483     |
|    std                   | 0.784        |
|    value_loss            | 2.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0818      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0818      |
| reward                   | -0.46198294 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -505        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 18          |
|    time_elapsed          | 13805       |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.004599939 |
|    clip_fraction         | 0.0393      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 6.93        |
|    cost_values           | 0.985       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.782       |
|    value_loss            | 3.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.249       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.249       |
| reward                   | -0.3999718  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -505        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 19          |
|    time_elapsed          | 14589       |
|    total_timesteps       | 841728      |
| train/                   |             |
|    approx_kl             | 0.004297246 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.59        |
|    cost_value_loss       | 23.8        |
|    cost_values           | 1.11        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.6        |
|    n_updates             | 4100        |
|    policy_gradient_loss  | -0.00594    |
|    std                   | 0.78        |
|    value_loss            | 1.78        |
------------------------------------------
slurmstepd: error: *** JOB 141963 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-02-24T19:31:20 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 141963.0 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-02-24T19:31:20 DUE TO TIME LIMIT ***
