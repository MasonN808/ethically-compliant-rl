Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231228_030118-iqmcojg4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D8
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D8/runs/iqmcojg4
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231227_190118-sldy6v5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D4
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D4/runs/sldy6v5j
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231227_190118-nt40u3nz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D8
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D8/runs/nt40u3nz
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231227_190118-7no2t1hm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D4
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D4/runs/7no2t1hm
Using cpu device
-------------------------------------
| reward             | [-0.3714969] |
| time/              |              |
|    fps             | 136          |
|    iterations      | 1            |
|    time_elapsed    | 14           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
-------------------------------------
| reward             | [-0.3129184] |
| time/              |              |
|    fps             | 135          |
|    iterations      | 1            |
|    time_elapsed    | 15           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
--------------------------------------
| reward             | [-0.41171703] |
| time/              |               |
|    fps             | 133           |
|    iterations      | 1             |
|    time_elapsed    | 15            |
|    total_timesteps | 2048          |
--------------------------------------
Using cpu device
--------------------------------------
| reward             | [-0.55651724] |
| time/              |               |
|    fps             | 118           |
|    iterations      | 1             |
|    time_elapsed    | 17            |
|    total_timesteps | 2048          |
--------------------------------------
-------------------------------------------
| reward                   | [-0.5741712] |
| time/                    |              |
|    fps                   | 130          |
|    iterations            | 2            |
|    time_elapsed          | 31           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0066944994 |
|    clip_fraction         | 0.0696       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.247        |
|    cost_value_loss       | 20.1         |
|    cost_values           | 3.48         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0752       |
|    lagrangian_multiplier | 0.517        |
|    learning_rate         | 0.0003       |
|    loss                  | -2.69        |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00691     |
|    std                   | 1.01         |
|    value_loss            | 499          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.40675387] |
| time/                    |               |
|    fps                   | 129           |
|    iterations            | 2             |
|    time_elapsed          | 31            |
|    total_timesteps       | 4096          |
| train/                   |               |
|    approx_kl             | 0.004956397   |
|    clip_fraction         | 0.0298        |
|    clip_range            | 0.2           |
|    cost_returns          | 10.2          |
|    cost_value_loss       | 139           |
|    cost_values           | 1.64          |
|    entropy_loss          | -2.84         |
|    explained_variance    | -0.0186       |
|    lagrangian_multiplier | 0.648         |
|    learning_rate         | 0.0003        |
|    loss                  | 2.65          |
|    n_updates             | 10            |
|    policy_gradient_loss  | -0.0046       |
|    std                   | 1             |
|    value_loss            | 503           |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.38657328] |
| time/                    |               |
|    fps                   | 129           |
|    iterations            | 2             |
|    time_elapsed          | 31            |
|    total_timesteps       | 4096          |
| train/                   |               |
|    approx_kl             | 0.006035597   |
|    clip_fraction         | 0.0473        |
|    clip_range            | 0.2           |
|    cost_returns          | 0.214         |
|    cost_value_loss       | 11.6          |
|    cost_values           | 2.44          |
|    entropy_loss          | -2.86         |
|    explained_variance    | -0.0352       |
|    lagrangian_multiplier | 0.398         |
|    learning_rate         | 0.0003        |
|    loss                  | -2.35         |
|    n_updates             | 10            |
|    policy_gradient_loss  | -0.00708      |
|    std                   | 1.02          |
|    value_loss            | 417           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.7709658] |
| time/                    |              |
|    fps                   | 114          |
|    iterations            | 2            |
|    time_elapsed          | 35           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.002957908  |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.4          |
|    cost_value_loss       | 46.8         |
|    cost_values           | 4.18         |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.0724      |
|    lagrangian_multiplier | 0.407        |
|    learning_rate         | 0.0003       |
|    loss                  | -6.4         |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 1            |
|    value_loss            | 175          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6323642] |
| time/                    |              |
|    fps                   | 128          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.004648436  |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 68.5         |
|    cost_values           | 12.1         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.226       |
|    lagrangian_multiplier | 0.84         |
|    learning_rate         | 0.0003       |
|    loss                  | -13.2        |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 1            |
|    value_loss            | 569          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9969173] |
| time/                    |              |
|    fps                   | 128          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.004532978  |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 109          |
|    cost_values           | 13.1         |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.096        |
|    lagrangian_multiplier | 0.968        |
|    learning_rate         | 0.0003       |
|    loss                  | -15.5        |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 1            |
|    value_loss            | 165          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.4674666] |
| time/                    |              |
|    fps                   | 128          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.004514373  |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 99.5         |
|    cost_values           | 12.1         |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.181       |
|    lagrangian_multiplier | 0.904        |
|    learning_rate         | 0.0003       |
|    loss                  | -15.4        |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00483     |
|    std                   | 1.03         |
|    value_loss            | 98.5         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.81015104] |
| time/                    |               |
|    fps                   | 113           |
|    iterations            | 3             |
|    time_elapsed          | 54            |
|    total_timesteps       | 6144          |
| train/                   |               |
|    approx_kl             | 0.00482597    |
|    clip_fraction         | 0.022         |
|    clip_range            | 0.2           |
|    cost_returns          | 5.58          |
|    cost_value_loss       | 85.3          |
|    cost_values           | 11.9          |
|    entropy_loss          | -2.84         |
|    explained_variance    | 0.271         |
|    lagrangian_multiplier | 0.842         |
|    learning_rate         | 0.0003        |
|    loss                  | -13.7         |
|    n_updates             | 20            |
|    policy_gradient_loss  | -0.0047       |
|    std                   | 1             |
|    value_loss            | 156           |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.77113616] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 4             |
|    time_elapsed          | 64            |
|    total_timesteps       | 8192          |
| train/                   |               |
|    approx_kl             | 0.0016536353  |
|    clip_fraction         | 0.00264       |
|    clip_range            | 0.2           |
|    cost_returns          | 4.05          |
|    cost_value_loss       | 310           |
|    cost_values           | 17.8          |
|    entropy_loss          | -2.84         |
|    explained_variance    | 0.697         |
|    lagrangian_multiplier | 1.28          |
|    learning_rate         | 0.0003        |
|    loss                  | -20           |
|    n_updates             | 30            |
|    policy_gradient_loss  | -0.00153      |
|    std                   | 0.999         |
|    value_loss            | 224           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.3938812] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 4            |
|    time_elapsed          | 64           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0017672097 |
|    clip_fraction         | 0.00327      |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 128          |
|    cost_values           | 22.6         |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.494        |
|    lagrangian_multiplier | 1.32         |
|    learning_rate         | 0.0003       |
|    loss                  | -24.8        |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 1            |
|    value_loss            | 140          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2086424] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 4            |
|    time_elapsed          | 64           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0026309486 |
|    clip_fraction         | 0.00547      |
|    clip_range            | 0.2          |
|    cost_returns          | 11           |
|    cost_value_loss       | 123          |
|    cost_values           | 20.7         |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.117        |
|    lagrangian_multiplier | 1.24         |
|    learning_rate         | 0.0003       |
|    loss                  | -22.9        |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 1.03         |
|    value_loss            | 226          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1214328] |
| time/                    |              |
|    fps                   | 113          |
|    iterations            | 4            |
|    time_elapsed          | 72           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.004367443  |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | -2.98        |
|    cost_value_loss       | 399          |
|    cost_values           | 11.7         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -1.95        |
|    lagrangian_multiplier | 1.06         |
|    learning_rate         | 0.0003       |
|    loss                  | -14.8        |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 1.01         |
|    value_loss            | 305          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.86254495] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 5             |
|    time_elapsed          | 80            |
|    total_timesteps       | 10240         |
| train/                   |               |
|    approx_kl             | 0.0045222286  |
|    clip_fraction         | 0.0151        |
|    clip_range            | 0.2           |
|    cost_returns          | 17.5          |
|    cost_value_loss       | 161           |
|    cost_values           | 28.2          |
|    entropy_loss          | -2.84         |
|    explained_variance    | -0.296        |
|    lagrangian_multiplier | 1.57          |
|    learning_rate         | 0.0003        |
|    loss                  | -30.5         |
|    n_updates             | 40            |
|    policy_gradient_loss  | -0.00545      |
|    std                   | 1             |
|    value_loss            | 145           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.2574307] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 5            |
|    time_elapsed          | 80           |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0058362307 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | -5.41        |
|    cost_value_loss       | 1.02e+03     |
|    cost_values           | 21.4         |
|    entropy_loss          | -2.89        |
|    explained_variance    | -3.14        |
|    lagrangian_multiplier | 1.49         |
|    learning_rate         | 0.0003       |
|    loss                  | -22.6        |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 1.02         |
|    value_loss            | 172          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.747833]  |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 5            |
|    time_elapsed          | 80           |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0048737526 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 21.5         |
|    cost_value_loss       | 112          |
|    cost_values           | 30.4         |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0499       |
|    lagrangian_multiplier | 1.64         |
|    learning_rate         | 0.0003       |
|    loss                  | -30.3        |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00706     |
|    std                   | 1            |
|    value_loss            | 666          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.76224446] |
| time/                    |               |
|    fps                   | 112           |
|    iterations            | 5             |
|    time_elapsed          | 90            |
|    total_timesteps       | 10240         |
| train/                   |               |
|    approx_kl             | 0.0028726715  |
|    clip_fraction         | 0.00425       |
|    clip_range            | 0.2           |
|    cost_returns          | 13.4          |
|    cost_value_loss       | 176           |
|    cost_values           | 23.7          |
|    entropy_loss          | -2.85         |
|    explained_variance    | 0.202         |
|    lagrangian_multiplier | 1.38          |
|    learning_rate         | 0.0003        |
|    loss                  | -26           |
|    n_updates             | 40            |
|    policy_gradient_loss  | -0.00234      |
|    std                   | 1.01          |
|    value_loss            | 208           |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.76980436] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 6             |
|    time_elapsed          | 96            |
|    total_timesteps       | 12288         |
| train/                   |               |
|    approx_kl             | 0.00252143    |
|    clip_fraction         | 0.00405       |
|    clip_range            | 0.2           |
|    cost_returns          | 26.6          |
|    cost_value_loss       | 105           |
|    cost_values           | 36.4          |
|    entropy_loss          | -2.84         |
|    explained_variance    | -0.0204       |
|    lagrangian_multiplier | 1.92          |
|    learning_rate         | 0.0003        |
|    loss                  | -38.6         |
|    n_updates             | 50            |
|    policy_gradient_loss  | -0.00238      |
|    std                   | 1             |
|    value_loss            | 82.2          |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.2860732] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 6            |
|    time_elapsed          | 96           |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0025671036 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 25.2         |
|    cost_value_loss       | 109          |
|    cost_values           | 34.9         |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0594       |
|    lagrangian_multiplier | 1.86         |
|    learning_rate         | 0.0003       |
|    loss                  | -35.5        |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 1.02         |
|    value_loss            | 575          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0607768] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 6            |
|    time_elapsed          | 97           |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0028207318 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.65         |
|    cost_value_loss       | 900          |
|    cost_values           | 33.5         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.405        |
|    lagrangian_multiplier | 1.94         |
|    learning_rate         | 0.0003       |
|    loss                  | -33.3        |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 1            |
|    value_loss            | 135          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6719746] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 6            |
|    time_elapsed          | 109          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.002887226  |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 25.7         |
|    cost_value_loss       | 82.4         |
|    cost_values           | 32.7         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00315      |
|    lagrangian_multiplier | 1.74         |
|    learning_rate         | 0.0003       |
|    loss                  | -33.9        |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 1.01         |
|    value_loss            | 373          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2669588] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 7            |
|    time_elapsed          | 112          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.004487645  |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 35.7         |
|    cost_value_loss       | 128          |
|    cost_values           | 43.2         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.114        |
|    lagrangian_multiplier | 2.27         |
|    learning_rate         | 0.0003       |
|    loss                  | -44.4        |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 1            |
|    value_loss            | 403          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.5070071] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 7            |
|    time_elapsed          | 112          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0019352969 |
|    clip_fraction         | 0.00815      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.78         |
|    cost_value_loss       | 1.5e+03      |
|    cost_values           | 39.8         |
|    entropy_loss          | -2.87        |
|    explained_variance    | -2.6         |
|    lagrangian_multiplier | 2.18         |
|    learning_rate         | 0.0003       |
|    loss                  | -38.3        |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 1.02         |
|    value_loss            | 119          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9864139] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 7            |
|    time_elapsed          | 113          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0045372564 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 31.2         |
|    cost_value_loss       | 165          |
|    cost_values           | 43.4         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.325       |
|    lagrangian_multiplier | 2.28         |
|    learning_rate         | 0.0003       |
|    loss                  | -45.3        |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 1.01         |
|    value_loss            | 172          |
-------------------------------------------
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation temporarily disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.9181936] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 7            |
|    time_elapsed          | 127          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.004037026  |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 29.1         |
|    cost_value_loss       | 125          |
|    cost_values           | 39.6         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.177       |
|    lagrangian_multiplier | 2.09         |
|    learning_rate         | 0.0003       |
|    loss                  | -41          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1.01         |
|    value_loss            | 337          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6164756] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 8            |
|    time_elapsed          | 128          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0041341344 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 47.6         |
|    cost_value_loss       | 88.3         |
|    cost_values           | 49.9         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0254       |
|    lagrangian_multiplier | 2.6          |
|    learning_rate         | 0.0003       |
|    loss                  | -51.4        |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 1.01         |
|    value_loss            | 462          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1481737] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 8            |
|    time_elapsed          | 129          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0048155203 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 36.7         |
|    cost_value_loss       | 156          |
|    cost_values           | 48.5         |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.00858      |
|    lagrangian_multiplier | 2.53         |
|    learning_rate         | 0.0003       |
|    loss                  | -50          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 1.01         |
|    value_loss            | 288          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1474922] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 8            |
|    time_elapsed          | 130          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0037428043 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 36.6         |
|    cost_value_loss       | 209          |
|    cost_values           | 50.2         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.606       |
|    lagrangian_multiplier | 2.61         |
|    learning_rate         | 0.0003       |
|    loss                  | -51.9        |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 1.01         |
|    value_loss            | 208          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9522431] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 9            |
|    time_elapsed          | 145          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0035432796 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 52.9         |
|    cost_value_loss       | 99.4         |
|    cost_values           | 56.6         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00335      |
|    lagrangian_multiplier | 2.93         |
|    learning_rate         | 0.0003       |
|    loss                  | -57.7        |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 1.01         |
|    value_loss            | 642          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.5680338] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 9            |
|    time_elapsed          | 145          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0040630274 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 42.5         |
|    cost_value_loss       | 184          |
|    cost_values           | 55.3         |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.0181      |
|    lagrangian_multiplier | 2.86         |
|    learning_rate         | 0.0003       |
|    loss                  | -56.7        |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 1.01         |
|    value_loss            | 435          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8642751] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 8            |
|    time_elapsed          | 145          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.002981924  |
|    clip_fraction         | 0.00864      |
|    clip_range            | 0.2          |
|    cost_returns          | 36           |
|    cost_value_loss       | 140          |
|    cost_values           | 46.5         |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.159       |
|    lagrangian_multiplier | 2.42         |
|    learning_rate         | 0.0003       |
|    loss                  | -48          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 1.01         |
|    value_loss            | 302          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9908933] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 9            |
|    time_elapsed          | 146          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0039814385 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 44           |
|    cost_value_loss       | 190          |
|    cost_values           | 57           |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.00119     |
|    lagrangian_multiplier | 2.94         |
|    learning_rate         | 0.0003       |
|    loss                  | -58.7        |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 1.02         |
|    value_loss            | 346          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4576023] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 10           |
|    time_elapsed          | 161          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0037809554 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 47.6         |
|    cost_value_loss       | 549          |
|    cost_values           | 62.7         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.403        |
|    lagrangian_multiplier | 3.24         |
|    learning_rate         | 0.0003       |
|    loss                  | -63.7        |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 1.01         |
|    value_loss            | 361          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2855264] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 10           |
|    time_elapsed          | 161          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0029717009 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 48.3         |
|    cost_value_loss       | 211          |
|    cost_values           | 62           |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.00691      |
|    lagrangian_multiplier | 3.2          |
|    learning_rate         | 0.0003       |
|    loss                  | -63.8        |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 1.02         |
|    value_loss            | 212          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.456092] |
| time/                    |             |
|    fps                   | 125         |
|    iterations            | 10          |
|    time_elapsed          | 163         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.00442488  |
|    clip_fraction         | 0.0175      |
|    clip_range            | 0.2         |
|    cost_returns          | 49.4        |
|    cost_value_loss       | 224         |
|    cost_values           | 63.5        |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.00181     |
|    lagrangian_multiplier | 3.27        |
|    learning_rate         | 0.0003      |
|    loss                  | -65.5       |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00418    |
|    std                   | 1.02        |
|    value_loss            | 153         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.0909053] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 9            |
|    time_elapsed          | 164          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0018995191 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 40           |
|    cost_value_loss       | 190          |
|    cost_values           | 53           |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.192       |
|    lagrangian_multiplier | 2.75         |
|    learning_rate         | 0.0003       |
|    loss                  | -54.8        |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 1.01         |
|    value_loss            | 237          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1462842] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 11           |
|    time_elapsed          | 177          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0011036524 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 56.1         |
|    cost_value_loss       | 259          |
|    cost_values           | 68.8         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0499       |
|    lagrangian_multiplier | 3.55         |
|    learning_rate         | 0.0003       |
|    loss                  | -70.6        |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.001       |
|    std                   | 1.01         |
|    value_loss            | 235          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4716192] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 11           |
|    time_elapsed          | 177          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.003543056  |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 53.4         |
|    cost_value_loss       | 254          |
|    cost_values           | 68.5         |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.0015      |
|    lagrangian_multiplier | 3.52         |
|    learning_rate         | 0.0003       |
|    loss                  | -70          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00359     |
|    std                   | 1.02         |
|    value_loss            | 268          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1187668] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 10           |
|    time_elapsed          | 182          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0021839603 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 46           |
|    cost_value_loss       | 206          |
|    cost_values           | 59.6         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0011       |
|    lagrangian_multiplier | 3.08         |
|    learning_rate         | 0.0003       |
|    loss                  | -61.4        |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 1            |
|    value_loss            | 182          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.580651] |
| time/                    |             |
|    fps                   | 122         |
|    iterations            | 11          |
|    time_elapsed          | 183         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.002084486 |
|    clip_fraction         | 0.00166     |
|    clip_range            | 0.2         |
|    cost_returns          | 54.1        |
|    cost_value_loss       | 282         |
|    cost_values           | 69.9        |
|    entropy_loss          | -2.87       |
|    explained_variance    | -0.191      |
|    lagrangian_multiplier | 3.59        |
|    learning_rate         | 0.0003      |
|    loss                  | -71.5       |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 1.02        |
|    value_loss            | 200         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.0556597] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 12           |
|    time_elapsed          | 194          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0026184323 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 66           |
|    cost_value_loss       | 187          |
|    cost_values           | 75.5         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00135      |
|    lagrangian_multiplier | 3.88         |
|    learning_rate         | 0.0003       |
|    loss                  | -77.3        |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1            |
|    value_loss            | 376          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4151189] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 12           |
|    time_elapsed          | 194          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.003608706  |
|    clip_fraction         | 0.00679      |
|    clip_range            | 0.2          |
|    cost_returns          | 57.8         |
|    cost_value_loss       | 325          |
|    cost_values           | 74.8         |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.229       |
|    lagrangian_multiplier | 3.84         |
|    learning_rate         | 0.0003       |
|    loss                  | -76.5        |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 1.01         |
|    value_loss            | 287          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1180854] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 12           |
|    time_elapsed          | 200          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0033454443 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 60           |
|    cost_value_loss       | 302          |
|    cost_values           | 76.3         |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.000808    |
|    lagrangian_multiplier | 3.92         |
|    learning_rate         | 0.0003       |
|    loss                  | -77.8        |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 1.02         |
|    value_loss            | 262          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.5661773] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 11           |
|    time_elapsed          | 201          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0031767432 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 51.5         |
|    cost_value_loss       | 239          |
|    cost_values           | 66.1         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.00676     |
|    lagrangian_multiplier | 3.4          |
|    learning_rate         | 0.0003       |
|    loss                  | -67.5        |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 1.01         |
|    value_loss            | 199          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7929916] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 13           |
|    time_elapsed          | 210          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0032987902 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 69.8         |
|    cost_value_loss       | 229          |
|    cost_values           | 81.9         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.00222     |
|    lagrangian_multiplier | 4.2          |
|    learning_rate         | 0.0003       |
|    loss                  | -83.7        |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 1            |
|    value_loss            | 369          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9212726] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 13           |
|    time_elapsed          | 210          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0050182217 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 64.6         |
|    cost_value_loss       | 319          |
|    cost_values           | 81.2         |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.00654     |
|    lagrangian_multiplier | 4.16         |
|    learning_rate         | 0.0003       |
|    loss                  | -82.7        |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 1.01         |
|    value_loss            | 195          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.2140455] |
| time/                    |              |
|    fps                   | 123          |
|    iterations            | 13           |
|    time_elapsed          | 216          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.004094531  |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 65.2         |
|    cost_value_loss       | 347          |
|    cost_values           | 82.7         |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.000824    |
|    lagrangian_multiplier | 4.24         |
|    learning_rate         | 0.0003       |
|    loss                  | -84.2        |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 1.03         |
|    value_loss            | 235          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.36262637] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 12            |
|    time_elapsed          | 219           |
|    total_timesteps       | 24576         |
| train/                   |               |
|    approx_kl             | 0.004177619   |
|    clip_fraction         | 0.0173        |
|    clip_range            | 0.2           |
|    cost_returns          | 59.8          |
|    cost_value_loss       | 227           |
|    cost_values           | 72.5          |
|    entropy_loss          | -2.86         |
|    explained_variance    | -0.00476      |
|    lagrangian_multiplier | 3.72          |
|    learning_rate         | 0.0003        |
|    loss                  | -74.2         |
|    n_updates             | 110           |
|    policy_gradient_loss  | -0.00438      |
|    std                   | 1.01          |
|    value_loss            | 163           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.5555052] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 14           |
|    time_elapsed          | 226          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0025997404 |
|    clip_fraction         | 0.00649      |
|    clip_range            | 0.2          |
|    cost_returns          | 69.3         |
|    cost_value_loss       | 380          |
|    cost_values           | 87.6         |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.000677     |
|    lagrangian_multiplier | 4.48         |
|    learning_rate         | 0.0003       |
|    loss                  | -89.2        |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 1.01         |
|    value_loss            | 164          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8208975] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 14           |
|    time_elapsed          | 226          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0037546451 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 69.3         |
|    cost_value_loss       | 405          |
|    cost_values           | 88.2         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.338       |
|    lagrangian_multiplier | 4.52         |
|    learning_rate         | 0.0003       |
|    loss                  | -90.1        |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00428     |
|    std                   | 1.01         |
|    value_loss            | 95.6         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1196969] |
| time/                    |              |
|    fps                   | 123          |
|    iterations            | 14           |
|    time_elapsed          | 232          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0036934218 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 70.4         |
|    cost_value_loss       | 394          |
|    cost_values           | 89           |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.00234     |
|    lagrangian_multiplier | 4.56         |
|    learning_rate         | 0.0003       |
|    loss                  | -90.7        |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00453     |
|    std                   | 1.03         |
|    value_loss            | 202          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.9864379] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 13           |
|    time_elapsed          | 238          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.003578881  |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 62           |
|    cost_value_loss       | 320          |
|    cost_values           | 78.8         |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.00131     |
|    lagrangian_multiplier | 4.04         |
|    learning_rate         | 0.0003       |
|    loss                  | -80.6        |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 1.02         |
|    value_loss            | 172          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.888423]  |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 15           |
|    time_elapsed          | 242          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0037641793 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 75.2         |
|    cost_value_loss       | 409          |
|    cost_values           | 93.9         |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.00148     |
|    lagrangian_multiplier | 4.8          |
|    learning_rate         | 0.0003       |
|    loss                  | -95.7        |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 1.01         |
|    value_loss            | 184          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0021346] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 15           |
|    time_elapsed          | 243          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.003169844  |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 80.5         |
|    cost_value_loss       | 296          |
|    cost_values           | 94.5         |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.0249      |
|    lagrangian_multiplier | 4.83         |
|    learning_rate         | 0.0003       |
|    loss                  | -96.1        |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1.01         |
|    value_loss            | 373          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.0295827] |
| time/                    |              |
|    fps                   | 123          |
|    iterations            | 15           |
|    time_elapsed          | 249          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0029390077 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 75.6         |
|    cost_value_loss       | 442          |
|    cost_values           | 95.3         |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.000149    |
|    lagrangian_multiplier | 4.87         |
|    learning_rate         | 0.0003       |
|    loss                  | -97.1        |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 1.03         |
|    value_loss            | 246          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.0637507] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 14           |
|    time_elapsed          | 256          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0005110061 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 67.2         |
|    cost_value_loss       | 365          |
|    cost_values           | 85.2         |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.000584     |
|    lagrangian_multiplier | 4.36         |
|    learning_rate         | 0.0003       |
|    loss                  | -87.2        |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.000733    |
|    std                   | 1.02         |
|    value_loss            | 26.9         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6089696] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 16           |
|    time_elapsed          | 259          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.003979042  |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 80           |
|    cost_value_loss       | 471          |
|    cost_values           | 100          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.00102     |
|    lagrangian_multiplier | 5.12         |
|    learning_rate         | 0.0003       |
|    loss                  | -102         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 1.01         |
|    value_loss            | 182          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0140017] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 16           |
|    time_elapsed          | 259          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0035800193 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 81.4         |
|    cost_value_loss       | 457          |
|    cost_values           | 101          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.00406     |
|    lagrangian_multiplier | 5.15         |
|    learning_rate         | 0.0003       |
|    loss                  | -103         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 1.01         |
|    value_loss            | 117          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.5209355] |
| time/                    |              |
|    fps                   | 119          |
|    iterations            | 16           |
|    time_elapsed          | 273          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.002202617  |
|    clip_fraction         | 0.00293      |
|    clip_range            | 0.2          |
|    cost_returns          | 80.8         |
|    cost_value_loss       | 494          |
|    cost_values           | 102          |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.00416     |
|    lagrangian_multiplier | 5.19         |
|    learning_rate         | 0.0003       |
|    loss                  | -103         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 1.03         |
|    value_loss            | 132          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8695098] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 15           |
|    time_elapsed          | 275          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0022776797 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 72.4         |
|    cost_value_loss       | 413          |
|    cost_values           | 91.5         |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.0004      |
|    lagrangian_multiplier | 4.68         |
|    learning_rate         | 0.0003       |
|    loss                  | -93.5        |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 1.03         |
|    value_loss            | 84.6         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2597895] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 17           |
|    time_elapsed          | 275          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.003556082  |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 85.4         |
|    cost_value_loss       | 511          |
|    cost_values           | 107          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.000941    |
|    lagrangian_multiplier | 5.44         |
|    learning_rate         | 0.0003       |
|    loss                  | -108         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00435     |
|    std                   | 1.01         |
|    value_loss            | 178          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6598076] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 17           |
|    time_elapsed          | 275          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0013982581 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 86.9         |
|    cost_value_loss       | 499          |
|    cost_values           | 107          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.000182    |
|    lagrangian_multiplier | 5.47         |
|    learning_rate         | 0.0003       |
|    loss                  | -109         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 1.01         |
|    value_loss            | 165          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6929969] |
| time/                    |              |
|    fps                   | 119          |
|    iterations            | 17           |
|    time_elapsed          | 290          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0044476707 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 86.5         |
|    cost_value_loss       | 533          |
|    cost_values           | 108          |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.0464      |
|    lagrangian_multiplier | 5.51         |
|    learning_rate         | 0.0003       |
|    loss                  | -109         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00563     |
|    std                   | 1.03         |
|    value_loss            | 580          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9982426] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 18           |
|    time_elapsed          | 291          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0047590327 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 91           |
|    cost_value_loss       | 555          |
|    cost_values           | 113          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.000734    |
|    lagrangian_multiplier | 5.75         |
|    learning_rate         | 0.0003       |
|    loss                  | -114         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 1.01         |
|    value_loss            | 212          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.98522246] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 18            |
|    time_elapsed          | 292           |
|    total_timesteps       | 36864         |
| train/                   |               |
|    approx_kl             | 0.004159788   |
|    clip_fraction         | 0.0147        |
|    clip_range            | 0.2           |
|    cost_returns          | 90.9          |
|    cost_value_loss       | 585           |
|    cost_values           | 113           |
|    entropy_loss          | -2.86         |
|    explained_variance    | 7.34e-05      |
|    lagrangian_multiplier | 5.79          |
|    learning_rate         | 0.0003        |
|    loss                  | -115          |
|    n_updates             | 170           |
|    policy_gradient_loss  | -0.00511      |
|    std                   | 1.01          |
|    value_loss            | 66.7          |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.75645155] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 16            |
|    time_elapsed          | 293           |
|    total_timesteps       | 32768         |
| train/                   |               |
|    approx_kl             | 0.0021706084  |
|    clip_fraction         | 0.0104        |
|    clip_range            | 0.2           |
|    cost_returns          | 77.8          |
|    cost_value_loss       | 455           |
|    cost_values           | 97.8          |
|    entropy_loss          | -2.89         |
|    explained_variance    | -0.000299     |
|    lagrangian_multiplier | 5             |
|    learning_rate         | 0.0003        |
|    loss                  | -99.3         |
|    n_updates             | 150           |
|    policy_gradient_loss  | -0.00427      |
|    std                   | 1.03          |
|    value_loss            | 75.6          |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.7506909] |
| time/                    |              |
|    fps                   | 120          |
|    iterations            | 18           |
|    time_elapsed          | 306          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0028018788 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 90.8         |
|    cost_value_loss       | 618          |
|    cost_values           | 114          |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.083       |
|    lagrangian_multiplier | 5.82         |
|    learning_rate         | 0.0003       |
|    loss                  | -115         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 1.03         |
|    value_loss            | 407          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.4722817] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 19           |
|    time_elapsed          | 308          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.004557199  |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 96.1         |
|    cost_value_loss       | 609          |
|    cost_values           | 119          |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.000166    |
|    lagrangian_multiplier | 6.07         |
|    learning_rate         | 0.0003       |
|    loss                  | -121         |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.0054      |
|    std                   | 1.02         |
|    value_loss            | 129          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4295399] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 19           |
|    time_elapsed          | 308          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0031786999 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 96.7         |
|    cost_value_loss       | 607          |
|    cost_values           | 120          |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.00203     |
|    lagrangian_multiplier | 6.1          |
|    learning_rate         | 0.0003       |
|    loss                  | -122         |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00491     |
|    std                   | 1.02         |
|    value_loss            | 52.1         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3650273] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 17           |
|    time_elapsed          | 311          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0043513775 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 86.7         |
|    cost_value_loss       | 405          |
|    cost_values           | 104          |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.00232     |
|    lagrangian_multiplier | 5.31         |
|    learning_rate         | 0.0003       |
|    loss                  | -106         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.0044      |
|    std                   | 1.03         |
|    value_loss            | 189          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.937252] |
| time/                    |             |
|    fps                   | 120         |
|    iterations            | 19          |
|    time_elapsed          | 323         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.003594229 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | 96.3        |
|    cost_value_loss       | 667         |
|    cost_values           | 120         |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.000196   |
|    lagrangian_multiplier | 6.14        |
|    learning_rate         | 0.0003      |
|    loss                  | -122        |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00386    |
|    std                   | 1.04        |
|    value_loss            | 213         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.8739169] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 20           |
|    time_elapsed          | 324          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.004052626  |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 101          |
|    cost_value_loss       | 696          |
|    cost_values           | 125          |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.000136    |
|    lagrangian_multiplier | 6.39         |
|    learning_rate         | 0.0003       |
|    loss                  | -126         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00504     |
|    std                   | 1.02         |
|    value_loss            | 453          |
-------------------------------------------
------------------------------------------
| reward                   | [-2.014991] |
| time/                    |             |
|    fps                   | 126         |
|    iterations            | 20          |
|    time_elapsed          | 324         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.002766866 |
|    clip_fraction         | 0.00581     |
|    clip_range            | 0.2         |
|    cost_returns          | 101         |
|    cost_value_loss       | 718         |
|    cost_values           | 126         |
|    entropy_loss          | -2.88       |
|    explained_variance    | 4.17e-07    |
|    lagrangian_multiplier | 6.42        |
|    learning_rate         | 0.0003      |
|    loss                  | -128        |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 1.02        |
|    value_loss            | 62.2        |
------------------------------------------
-------------------------------------------
| reward                   | [-0.7975851] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 18           |
|    time_elapsed          | 330          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0053471616 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 89           |
|    cost_value_loss       | 543          |
|    cost_values           | 110          |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.000725     |
|    lagrangian_multiplier | 5.63         |
|    learning_rate         | 0.0003       |
|    loss                  | -112         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00658     |
|    std                   | 1.05         |
|    value_loss            | 165          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.1806555] |
| time/                    |              |
|    fps                   | 120          |
|    iterations            | 20           |
|    time_elapsed          | 340          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.005194967  |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 102          |
|    cost_value_loss       | 714          |
|    cost_values           | 127          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.000149    |
|    lagrangian_multiplier | 6.45         |
|    learning_rate         | 0.0003       |
|    loss                  | -128         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00553     |
|    std                   | 1.04         |
|    value_loss            | 198          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6659119] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 21           |
|    time_elapsed          | 340          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.005625719  |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 106          |
|    cost_value_loss       | 753          |
|    cost_values           | 132          |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.0162      |
|    lagrangian_multiplier | 6.7          |
|    learning_rate         | 0.0003       |
|    loss                  | -133         |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.0054      |
|    std                   | 1.01         |
|    value_loss            | 259          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.2976682] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 21           |
|    time_elapsed          | 341          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0036375388 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 109          |
|    cost_value_loss       | 652          |
|    cost_values           | 132          |
|    entropy_loss          | -2.88        |
|    explained_variance    | -2.29e-05    |
|    lagrangian_multiplier | 6.74         |
|    learning_rate         | 0.0003       |
|    loss                  | -134         |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 1.02         |
|    value_loss            | 99.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.5312973] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 19           |
|    time_elapsed          | 348          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0026591397 |
|    clip_fraction         | 0.01         |
|    clip_range            | 0.2          |
|    cost_returns          | 93.5         |
|    cost_value_loss       | 605          |
|    cost_values           | 117          |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.000511     |
|    lagrangian_multiplier | 5.94         |
|    learning_rate         | 0.0003       |
|    loss                  | -118         |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 1.05         |
|    value_loss            | 37.3         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-3.2654274] |
| time/                    |              |
|    fps                   | 120          |
|    iterations            | 21           |
|    time_elapsed          | 356          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.004254305  |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 107          |
|    cost_value_loss       | 791          |
|    cost_values           | 133          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.000108    |
|    lagrangian_multiplier | 6.77         |
|    learning_rate         | 0.0003       |
|    loss                  | -134         |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00449     |
|    std                   | 1.04         |
|    value_loss            | 384          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.4254048] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 22           |
|    time_elapsed          | 356          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0030395752 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 112          |
|    cost_value_loss       | 776          |
|    cost_values           | 138          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.00027     |
|    lagrangian_multiplier | 7.02         |
|    learning_rate         | 0.0003       |
|    loss                  | -139         |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 1.01         |
|    value_loss            | 292          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.5459685] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 22           |
|    time_elapsed          | 357          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0035889286 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 120          |
|    cost_value_loss       | 511          |
|    cost_values           | 138          |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.000221    |
|    lagrangian_multiplier | 7.05         |
|    learning_rate         | 0.0003       |
|    loss                  | -140         |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 1.03         |
|    value_loss            | 210          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-2.7649863] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 20           |
|    time_elapsed          | 367          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0045306073 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 98.6         |
|    cost_value_loss       | 674          |
|    cost_values           | 123          |
|    entropy_loss          | -2.93        |
|    explained_variance    | -0.00482     |
|    lagrangian_multiplier | 6.26         |
|    learning_rate         | 0.0003       |
|    loss                  | -125         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 1.05         |
|    value_loss            | 103          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.43919557] |
| time/                    |               |
|    fps                   | 120           |
|    iterations            | 22            |
|    time_elapsed          | 372           |
|    total_timesteps       | 45056         |
| train/                   |               |
|    approx_kl             | 0.004289181   |
|    clip_fraction         | 0.0257        |
|    clip_range            | 0.2           |
|    cost_returns          | 112           |
|    cost_value_loss       | 847           |
|    cost_values           | 139           |
|    entropy_loss          | -2.91         |
|    explained_variance    | -0.000274     |
|    lagrangian_multiplier | 7.09          |
|    learning_rate         | 0.0003        |
|    loss                  | -140          |
|    n_updates             | 210           |
|    policy_gradient_loss  | -0.00441      |
|    std                   | 1.03          |
|    value_loss            | 409           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.7438479] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 23           |
|    time_elapsed          | 373          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.00355617   |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 116          |
|    cost_value_loss       | 959          |
|    cost_values           | 144          |
|    entropy_loss          | -2.86        |
|    explained_variance    | 2.12e-05     |
|    lagrangian_multiplier | 7.33         |
|    learning_rate         | 0.0003       |
|    loss                  | -145         |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 1.01         |
|    value_loss            | 258          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.59855694] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 23            |
|    time_elapsed          | 373           |
|    total_timesteps       | 47104         |
| train/                   |               |
|    approx_kl             | 0.004349674   |
|    clip_fraction         | 0.0317        |
|    clip_range            | 0.2           |
|    cost_returns          | 119           |
|    cost_value_loss       | 854           |
|    cost_values           | 145           |
|    entropy_loss          | -2.89         |
|    explained_variance    | -0.0012       |
|    lagrangian_multiplier | 7.37          |
|    learning_rate         | 0.0003        |
|    loss                  | -147          |
|    n_updates             | 220           |
|    policy_gradient_loss  | -0.00742      |
|    std                   | 1.04          |
|    value_loss            | 116           |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.7548908] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 21           |
|    time_elapsed          | 385          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0030854393 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 109          |
|    cost_value_loss       | 562          |
|    cost_values           | 129          |
|    entropy_loss          | -2.94        |
|    explained_variance    | -0.00129     |
|    lagrangian_multiplier | 6.58         |
|    learning_rate         | 0.0003       |
|    loss                  | -131         |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 1.05         |
|    value_loss            | 150          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.67768085] |
| time/                    |               |
|    fps                   | 120           |
|    iterations            | 23            |
|    time_elapsed          | 389           |
|    total_timesteps       | 47104         |
| train/                   |               |
|    approx_kl             | 0.0037617646  |
|    clip_fraction         | 0.0134        |
|    clip_range            | 0.2           |
|    cost_returns          | 116           |
|    cost_value_loss       | 1.04e+03      |
|    cost_values           | 145           |
|    entropy_loss          | -2.9          |
|    explained_variance    | -1.41e-05     |
|    lagrangian_multiplier | 7.4           |
|    learning_rate         | 0.0003        |
|    loss                  | -147          |
|    n_updates             | 220           |
|    policy_gradient_loss  | -0.00315      |
|    std                   | 1.03          |
|    value_loss            | 146           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1324856] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 24           |
|    time_elapsed          | 389          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0046366947 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 122          |
|    cost_value_loss       | 957          |
|    cost_values           | 150          |
|    entropy_loss          | -2.84        |
|    explained_variance    | 3.67e-05     |
|    lagrangian_multiplier | 7.65         |
|    learning_rate         | 0.0003       |
|    loss                  | -152         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00569     |
|    std                   | 0.998        |
|    value_loss            | 204          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.66772467] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 24            |
|    time_elapsed          | 390           |
|    total_timesteps       | 49152         |
| train/                   |               |
|    approx_kl             | 0.0028723124  |
|    clip_fraction         | 0.00747       |
|    clip_range            | 0.2           |
|    cost_returns          | 127           |
|    cost_value_loss       | 756           |
|    cost_values           | 151           |
|    entropy_loss          | -2.9          |
|    explained_variance    | -0.000225     |
|    lagrangian_multiplier | 7.68          |
|    learning_rate         | 0.0003        |
|    loss                  | -153          |
|    n_updates             | 230           |
|    policy_gradient_loss  | -0.00279      |
|    std                   | 1.03          |
|    value_loss            | 77.3          |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.55750245] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 22            |
|    time_elapsed          | 404           |
|    total_timesteps       | 45056         |
| train/                   |               |
|    approx_kl             | 0.0050387215  |
|    clip_fraction         | 0.0378        |
|    clip_range            | 0.2           |
|    cost_returns          | 107           |
|    cost_value_loss       | 1.26e+03      |
|    cost_values           | 135           |
|    entropy_loss          | -2.94         |
|    explained_variance    | -0.672        |
|    lagrangian_multiplier | 6.88          |
|    learning_rate         | 0.0003        |
|    loss                  | -136          |
|    n_updates             | 210           |
|    policy_gradient_loss  | -0.00636      |
|    std                   | 1.06          |
|    value_loss            | 178           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.6289763] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 24           |
|    time_elapsed          | 405          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0031395992 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 123          |
|    cost_value_loss       | 968          |
|    cost_values           | 152          |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.00669     |
|    lagrangian_multiplier | 7.72         |
|    learning_rate         | 0.0003       |
|    loss                  | -153         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 1.03         |
|    value_loss            | 143          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1237526] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 25           |
|    time_elapsed          | 405          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.004512869  |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 128          |
|    cost_value_loss       | 978          |
|    cost_values           | 157          |
|    entropy_loss          | -2.83        |
|    explained_variance    | -4.91e-05    |
|    lagrangian_multiplier | 7.96         |
|    learning_rate         | 0.0003       |
|    loss                  | -158         |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00509     |
|    std                   | 0.997        |
|    value_loss            | 319          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.46063215] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 25            |
|    time_elapsed          | 406           |
|    total_timesteps       | 51200         |
| train/                   |               |
|    approx_kl             | 0.0029014912  |
|    clip_fraction         | 0.00615       |
|    clip_range            | 0.2           |
|    cost_returns          | 133           |
|    cost_value_loss       | 757           |
|    cost_values           | 157           |
|    entropy_loss          | -2.89         |
|    explained_variance    | -8.79e-05     |
|    lagrangian_multiplier | 8             |
|    learning_rate         | 0.0003        |
|    loss                  | -159          |
|    n_updates             | 240           |
|    policy_gradient_loss  | -0.00226      |
|    std                   | 1.03          |
|    value_loss            | 103           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1572609] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 26           |
|    time_elapsed          | 422          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0057097557 |
|    clip_fraction         | 0.0495       |
|    clip_range            | 0.2          |
|    cost_returns          | 133          |
|    cost_value_loss       | 1.03e+03     |
|    cost_values           | 163          |
|    entropy_loss          | -2.83        |
|    explained_variance    | 1.65e-05     |
|    lagrangian_multiplier | 8.28         |
|    learning_rate         | 0.0003       |
|    loss                  | -164         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00602     |
|    std                   | 0.995        |
|    value_loss            | 210          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6542289] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 25           |
|    time_elapsed          | 422          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.005562352  |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 127          |
|    cost_value_loss       | 1.09e+03     |
|    cost_values           | 158          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -2.06e-05    |
|    lagrangian_multiplier | 8.03         |
|    learning_rate         | 0.0003       |
|    loss                  | -160         |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 1.04         |
|    value_loss            | 108          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.5102746] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 26           |
|    time_elapsed          | 422          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0046103518 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 137          |
|    cost_value_loss       | 895          |
|    cost_values           | 163          |
|    entropy_loss          | -2.89        |
|    explained_variance    | -1.56e-05    |
|    lagrangian_multiplier | 8.31         |
|    learning_rate         | 0.0003       |
|    loss                  | -165         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 1.03         |
|    value_loss            | 64.5         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.49935928] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 23            |
|    time_elapsed          | 422           |
|    total_timesteps       | 47104         |
| train/                   |               |
|    approx_kl             | 0.0032248395  |
|    clip_fraction         | 0.0183        |
|    clip_range            | 0.2           |
|    cost_returns          | 117           |
|    cost_value_loss       | 794           |
|    cost_values           | 141           |
|    entropy_loss          | -2.95         |
|    explained_variance    | -0.000244     |
|    lagrangian_multiplier | 7.2           |
|    learning_rate         | 0.0003        |
|    loss                  | -143          |
|    n_updates             | 220           |
|    policy_gradient_loss  | -0.00345      |
|    std                   | 1.06          |
|    value_loss            | 120           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1225358] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 27           |
|    time_elapsed          | 438          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0043661376 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 137          |
|    cost_value_loss       | 1.18e+03     |
|    cost_values           | 169          |
|    entropy_loss          | -2.83        |
|    explained_variance    | 8.16e-05     |
|    lagrangian_multiplier | 8.59         |
|    learning_rate         | 0.0003       |
|    loss                  | -170         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00484     |
|    std                   | 0.993        |
|    value_loss            | 74.5         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7529776] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 26           |
|    time_elapsed          | 438          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.003250905  |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 133          |
|    cost_value_loss       | 1.15e+03     |
|    cost_values           | 164          |
|    entropy_loss          | -2.93        |
|    explained_variance    | -1.37e-05    |
|    lagrangian_multiplier | 8.35         |
|    learning_rate         | 0.0003       |
|    loss                  | -166         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 1.05         |
|    value_loss            | 125          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3903849] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 27           |
|    time_elapsed          | 438          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0019244722 |
|    clip_fraction         | 0.00244      |
|    clip_range            | 0.2          |
|    cost_returns          | 140          |
|    cost_value_loss       | 1.07e+03     |
|    cost_values           | 170          |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.000235     |
|    lagrangian_multiplier | 8.63         |
|    learning_rate         | 0.0003       |
|    loss                  | -172         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 1.03         |
|    value_loss            | 28.7         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8288962] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 24           |
|    time_elapsed          | 441          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.002585059  |
|    clip_fraction         | 0.00649      |
|    clip_range            | 0.2          |
|    cost_returns          | 119          |
|    cost_value_loss       | 941          |
|    cost_values           | 148          |
|    entropy_loss          | -2.96        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 7.52         |
|    learning_rate         | 0.0003       |
|    loss                  | -149         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 1.07         |
|    value_loss            | 148          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6568676] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 28           |
|    time_elapsed          | 454          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0022456823 |
|    clip_fraction         | 0.00781      |
|    clip_range            | 0.2          |
|    cost_returns          | 142          |
|    cost_value_loss       | 1.26e+03     |
|    cost_values           | 175          |
|    entropy_loss          | -2.84        |
|    explained_variance    | 5.54e-06     |
|    lagrangian_multiplier | 8.91         |
|    learning_rate         | 0.0003       |
|    loss                  | -177         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 1            |
|    value_loss            | 136          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7342435] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 27           |
|    time_elapsed          | 455          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0040812353 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 137          |
|    cost_value_loss       | 1.26e+03     |
|    cost_values           | 170          |
|    entropy_loss          | -2.95        |
|    explained_variance    | -1.45e-05    |
|    lagrangian_multiplier | 8.66         |
|    learning_rate         | 0.0003       |
|    loss                  | -172         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 1.06         |
|    value_loss            | 172          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.59379727] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 28            |
|    time_elapsed          | 455           |
|    total_timesteps       | 57344         |
| train/                   |               |
|    approx_kl             | 0.005128348   |
|    clip_fraction         | 0.0406        |
|    clip_range            | 0.2           |
|    cost_returns          | 146           |
|    cost_value_loss       | 1.14e+03      |
|    cost_values           | 176           |
|    entropy_loss          | -2.9          |
|    explained_variance    | -0.000153     |
|    lagrangian_multiplier | 8.94          |
|    learning_rate         | 0.0003        |
|    loss                  | -178          |
|    n_updates             | 270           |
|    policy_gradient_loss  | -0.00714      |
|    std                   | 1.03          |
|    value_loss            | 46.3          |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.59384024] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 25            |
|    time_elapsed          | 459           |
|    total_timesteps       | 51200         |
| train/                   |               |
|    approx_kl             | 0.0057541407  |
|    clip_fraction         | 0.0299        |
|    clip_range            | 0.2           |
|    cost_returns          | 129           |
|    cost_value_loss       | 780           |
|    cost_values           | 154           |
|    entropy_loss          | -2.98         |
|    explained_variance    | -0.00049      |
|    lagrangian_multiplier | 7.83          |
|    learning_rate         | 0.0003        |
|    loss                  | -155          |
|    n_updates             | 240           |
|    policy_gradient_loss  | -0.005        |
|    std                   | 1.08          |
|    value_loss            | 115           |
--------------------------------------------
-------------------------------------------
| reward                   | [-2.5406547] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 29           |
|    time_elapsed          | 470          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0019074129 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 147          |
|    cost_value_loss       | 1.39e+03     |
|    cost_values           | 182          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -9.54e-06    |
|    lagrangian_multiplier | 9.22         |
|    learning_rate         | 0.0003       |
|    loss                  | -183         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 1.01         |
|    value_loss            | 74.5         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.5895607] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 29           |
|    time_elapsed          | 471          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.004180384  |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 148          |
|    cost_value_loss       | 1.34e+03     |
|    cost_values           | 182          |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.000119    |
|    lagrangian_multiplier | 9.26         |
|    learning_rate         | 0.0003       |
|    loss                  | -184         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 1.03         |
|    value_loss            | 36.4         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3245604] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 28           |
|    time_elapsed          | 471          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0050726887 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 143          |
|    cost_value_loss       | 1.3e+03      |
|    cost_values           | 177          |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.000519    |
|    lagrangian_multiplier | 8.98         |
|    learning_rate         | 0.0003       |
|    loss                  | -178         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 1.06         |
|    value_loss            | 106          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.7781519] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 26           |
|    time_elapsed          | 477          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0009970772 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 129          |
|    cost_value_loss       | 1.14e+03     |
|    cost_values           | 160          |
|    entropy_loss          | -2.99        |
|    explained_variance    | 1.59e-05     |
|    lagrangian_multiplier | 8.15         |
|    learning_rate         | 0.0003       |
|    loss                  | -161         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.000749    |
|    std                   | 1.08         |
|    value_loss            | 6.63         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.5750769] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 30           |
|    time_elapsed          | 487          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.004707451  |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 152          |
|    cost_value_loss       | 1.46e+03     |
|    cost_values           | 188          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.00401     |
|    lagrangian_multiplier | 9.54         |
|    learning_rate         | 0.0003       |
|    loss                  | -189         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 1            |
|    value_loss            | 94.2         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8012571] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 30           |
|    time_elapsed          | 487          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0015477785 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 154          |
|    cost_value_loss       | 1.43e+03     |
|    cost_values           | 188          |
|    entropy_loss          | -2.89        |
|    explained_variance    | 4.89e-06     |
|    lagrangian_multiplier | 9.57         |
|    learning_rate         | 0.0003       |
|    loss                  | -190         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 1.02         |
|    value_loss            | 36.3         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.2825778] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 29           |
|    time_elapsed          | 487          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.004680769  |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 148          |
|    cost_value_loss       | 1.44e+03     |
|    cost_values           | 183          |
|    entropy_loss          | -2.96        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 9.29         |
|    learning_rate         | 0.0003       |
|    loss                  | -184         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00444     |
|    std                   | 1.06         |
|    value_loss            | 137          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.6588261] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 27           |
|    time_elapsed          | 496          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.004993495  |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 134          |
|    cost_value_loss       | 1.2e+03      |
|    cost_values           | 166          |
|    entropy_loss          | -3.01        |
|    explained_variance    | -3.19e-05    |
|    lagrangian_multiplier | 8.46         |
|    learning_rate         | 0.0003       |
|    loss                  | -168         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00581     |
|    std                   | 1.09         |
|    value_loss            | 30.7         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.5359175] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 31           |
|    time_elapsed          | 503          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0035281177 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 158          |
|    cost_value_loss       | 1.53e+03     |
|    cost_values           | 194          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000216    |
|    lagrangian_multiplier | 9.85         |
|    learning_rate         | 0.0003       |
|    loss                  | -195         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 1.01         |
|    value_loss            | 134          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.6840014] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 31           |
|    time_elapsed          | 504          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0023637854 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 159          |
|    cost_value_loss       | 1.53e+03     |
|    cost_values           | 195          |
|    entropy_loss          | -2.88        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 9.89         |
|    learning_rate         | 0.0003       |
|    loss                  | -196         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 1.02         |
|    value_loss            | 49.2         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2307843] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 30           |
|    time_elapsed          | 504          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.003390058  |
|    clip_fraction         | 0.00923      |
|    clip_range            | 0.2          |
|    cost_returns          | 153          |
|    cost_value_loss       | 1.5e+03      |
|    cost_values           | 189          |
|    entropy_loss          | -2.96        |
|    explained_variance    | 9.18e-06     |
|    lagrangian_multiplier | 9.61         |
|    learning_rate         | 0.0003       |
|    loss                  | -190         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 1.06         |
|    value_loss            | 135          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.45817056] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 28            |
|    time_elapsed          | 514           |
|    total_timesteps       | 57344         |
| train/                   |               |
|    approx_kl             | 0.003240562   |
|    clip_fraction         | 0.0146        |
|    clip_range            | 0.2           |
|    cost_returns          | 141           |
|    cost_value_loss       | 1.19e+03      |
|    cost_values           | 173           |
|    entropy_loss          | -3.01         |
|    explained_variance    | -0.000117     |
|    lagrangian_multiplier | 8.78          |
|    learning_rate         | 0.0003        |
|    loss                  | -174          |
|    n_updates             | 270           |
|    policy_gradient_loss  | -0.00325      |
|    std                   | 1.09          |
|    value_loss            | 111           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.5217946] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 32           |
|    time_elapsed          | 519          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.003862895  |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 163          |
|    cost_value_loss       | 1.6e+03      |
|    cost_values           | 200          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000831    |
|    lagrangian_multiplier | 10.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -202         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00481     |
|    std                   | 1.01         |
|    value_loss            | 73.3         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6358329] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 32           |
|    time_elapsed          | 520          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.004033179  |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 164          |
|    cost_value_loss       | 1.65e+03     |
|    cost_values           | 201          |
|    entropy_loss          | -2.87        |
|    explained_variance    | -9.89e-06    |
|    lagrangian_multiplier | 10.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -202         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 1.02         |
|    value_loss            | 29.9         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6680921] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 31           |
|    time_elapsed          | 520          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.003483181  |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 158          |
|    cost_value_loss       | 1.64e+03     |
|    cost_values           | 195          |
|    entropy_loss          | -2.95        |
|    explained_variance    | 2.56e-06     |
|    lagrangian_multiplier | 9.92         |
|    learning_rate         | 0.0003       |
|    loss                  | -197         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 1.05         |
|    value_loss            | 53.7         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7713295] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 29           |
|    time_elapsed          | 533          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0031546962 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 145          |
|    cost_value_loss       | 1.37e+03     |
|    cost_values           | 179          |
|    entropy_loss          | -3           |
|    explained_variance    | -5.01e-05    |
|    lagrangian_multiplier | 9.09         |
|    learning_rate         | 0.0003       |
|    loss                  | -181         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.002       |
|    std                   | 1.09         |
|    value_loss            | 105          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1550786] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 33           |
|    time_elapsed          | 535          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.002901698  |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 168          |
|    cost_value_loss       | 1.73e+03     |
|    cost_values           | 206          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -6.31e-05    |
|    lagrangian_multiplier | 10.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -208         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 1            |
|    value_loss            | 35.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.181046]  |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 33           |
|    time_elapsed          | 536          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0019938338 |
|    clip_fraction         | 0.00396      |
|    clip_range            | 0.2          |
|    cost_returns          | 169          |
|    cost_value_loss       | 1.74e+03     |
|    cost_values           | 207          |
|    entropy_loss          | -2.88        |
|    explained_variance    | 6.14e-06     |
|    lagrangian_multiplier | 10.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -209         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 1.02         |
|    value_loss            | 58.1         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.87257755] |
| time/                    |               |
|    fps                   | 121           |
|    iterations            | 32            |
|    time_elapsed          | 537           |
|    total_timesteps       | 65536         |
| train/                   |               |
|    approx_kl             | 0.0057910867  |
|    clip_fraction         | 0.0382        |
|    clip_range            | 0.2           |
|    cost_returns          | 163           |
|    cost_value_loss       | 1.68e+03      |
|    cost_values           | 202           |
|    entropy_loss          | -2.94         |
|    explained_variance    | 8.64e-06      |
|    lagrangian_multiplier | 10.2          |
|    learning_rate         | 0.0003        |
|    loss                  | -203          |
|    n_updates             | 310           |
|    policy_gradient_loss  | -0.00769      |
|    std                   | 1.05          |
|    value_loss            | 152           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.2265087] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 30           |
|    time_elapsed          | 551          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.004399842  |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 149          |
|    cost_value_loss       | 1.49e+03     |
|    cost_values           | 185          |
|    entropy_loss          | -3.01        |
|    explained_variance    | 1.44e-05     |
|    lagrangian_multiplier | 9.41         |
|    learning_rate         | 0.0003       |
|    loss                  | -187         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00568     |
|    std                   | 1.09         |
|    value_loss            | 6.92         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0799974] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 34           |
|    time_elapsed          | 552          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0032368358 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 172          |
|    cost_value_loss       | 1.92e+03     |
|    cost_values           | 213          |
|    entropy_loss          | -2.84        |
|    explained_variance    | -2.03e-05    |
|    lagrangian_multiplier | 10.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -214         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.997        |
|    value_loss            | 91           |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0957363] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 34           |
|    time_elapsed          | 553          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0034193457 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 171          |
|    cost_value_loss       | 2.18e+03     |
|    cost_values           | 213          |
|    entropy_loss          | -2.88        |
|    explained_variance    | 2.86e-06     |
|    lagrangian_multiplier | 10.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -215         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 1.02         |
|    value_loss            | 67.2         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1163956] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 33           |
|    time_elapsed          | 553          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0033751822 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 168          |
|    cost_value_loss       | 1.85e+03     |
|    cost_values           | 208          |
|    entropy_loss          | -2.94        |
|    explained_variance    | 1.35e-05     |
|    lagrangian_multiplier | 10.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -208         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 1.06         |
|    value_loss            | 23           |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0624418] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 35           |
|    time_elapsed          | 568          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0041909902 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 177          |
|    cost_value_loss       | 2.04e+03     |
|    cost_values           | 219          |
|    entropy_loss          | -2.83        |
|    explained_variance    | -2.05e-05    |
|    lagrangian_multiplier | 11.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -220         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.999        |
|    value_loss            | 39.1         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3504161] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 35           |
|    time_elapsed          | 569          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0031098537 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 177          |
|    cost_value_loss       | 2.05e+03     |
|    cost_values           | 220          |
|    entropy_loss          | -2.87        |
|    explained_variance    | 1.08e-05     |
|    lagrangian_multiplier | 11.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -221         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 1.01         |
|    value_loss            | 21.1         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0912428] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 34           |
|    time_elapsed          | 570          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0044032736 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 173          |
|    cost_value_loss       | 1.96e+03     |
|    cost_values           | 214          |
|    entropy_loss          | -2.95        |
|    explained_variance    | -7.43e-05    |
|    lagrangian_multiplier | 10.9         |
|    learning_rate         | 0.0003       |
|    loss                  | -215         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 1.06         |
|    value_loss            | 42.1         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.58401495] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 31            |
|    time_elapsed          | 570           |
|    total_timesteps       | 63488         |
| train/                   |               |
|    approx_kl             | 0.0029465281  |
|    clip_fraction         | 0.00811       |
|    clip_range            | 0.2           |
|    cost_returns          | 154           |
|    cost_value_loss       | 1.58e+03      |
|    cost_values           | 191           |
|    entropy_loss          | -3.01         |
|    explained_variance    | -3.7e-06      |
|    lagrangian_multiplier | 9.72          |
|    learning_rate         | 0.0003        |
|    loss                  | -192          |
|    n_updates             | 300           |
|    policy_gradient_loss  | -0.00236      |
|    std                   | 1.09          |
|    value_loss            | 26.5          |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.3322096] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 36           |
|    time_elapsed          | 584          |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0032845521 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 184          |
|    cost_value_loss       | 2.01e+03     |
|    cost_values           | 225          |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.9e-05     |
|    lagrangian_multiplier | 11.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -226         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00458     |
|    std                   | 1            |
|    value_loss            | 46           |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7419919] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 36           |
|    time_elapsed          | 585          |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.002724155  |
|    clip_fraction         | 0.00552      |
|    clip_range            | 0.2          |
|    cost_returns          | 185          |
|    cost_value_loss       | 2.03e+03     |
|    cost_values           | 226          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.000119    |
|    lagrangian_multiplier | 11.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -227         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 1.01         |
|    value_loss            | 106          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.62632]   |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 35           |
|    time_elapsed          | 586          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0041474868 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 178          |
|    cost_value_loss       | 2.07e+03     |
|    cost_values           | 220          |
|    entropy_loss          | -2.96        |
|    explained_variance    | 6.91e-06     |
|    lagrangian_multiplier | 11.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -222         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 1.06         |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8464364] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 32           |
|    time_elapsed          | 588          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0032688451 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 159          |
|    cost_value_loss       | 1.68e+03     |
|    cost_values           | 198          |
|    entropy_loss          | -3.01        |
|    explained_variance    | 1.06e-05     |
|    lagrangian_multiplier | 10           |
|    learning_rate         | 0.0003       |
|    loss                  | -199         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 1.09         |
|    value_loss            | 24.9         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.5229787] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 37           |
|    time_elapsed          | 601          |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0032668998 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 190          |
|    cost_value_loss       | 2.08e+03     |
|    cost_values           | 231          |
|    entropy_loss          | -2.84        |
|    explained_variance    | -3.27e-05    |
|    lagrangian_multiplier | 11.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -233         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 1            |
|    value_loss            | 64.6         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0276325] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 37           |
|    time_elapsed          | 601          |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0029875822 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 191          |
|    cost_value_loss       | 2.03e+03     |
|    cost_values           | 232          |
|    entropy_loss          | -2.87        |
|    explained_variance    | -1.07e-05    |
|    lagrangian_multiplier | 11.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -234         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 1.01         |
|    value_loss            | 77.1         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.89439666] |
| time/                    |               |
|    fps                   | 122           |
|    iterations            | 36            |
|    time_elapsed          | 603           |
|    total_timesteps       | 73728         |
| train/                   |               |
|    approx_kl             | 0.0039723613  |
|    clip_fraction         | 0.0177        |
|    clip_range            | 0.2           |
|    cost_returns          | 183           |
|    cost_value_loss       | 2.18e+03      |
|    cost_values           | 227           |
|    entropy_loss          | -2.96         |
|    explained_variance    | -6.68e-06     |
|    lagrangian_multiplier | 11.5          |
|    learning_rate         | 0.0003        |
|    loss                  | -228          |
|    n_updates             | 350           |
|    policy_gradient_loss  | -0.00547      |
|    std                   | 1.06          |
|    value_loss            | 26.8          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.8986255] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 33           |
|    time_elapsed          | 606          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0023701247 |
|    clip_fraction         | 0.0021       |
|    clip_range            | 0.2          |
|    cost_returns          | 165          |
|    cost_value_loss       | 1.78e+03     |
|    cost_values           | 204          |
|    entropy_loss          | -3.01        |
|    explained_variance    | 7.99e-06     |
|    lagrangian_multiplier | 10.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -205         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 1.09         |
|    value_loss            | 12.9         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.1389314] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 38           |
|    time_elapsed          | 617          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.005658891  |
|    clip_fraction         | 0.0481       |
|    clip_range            | 0.2          |
|    cost_returns          | 193          |
|    cost_value_loss       | 2.28e+03     |
|    cost_values           | 238          |
|    entropy_loss          | -2.84        |
|    explained_variance    | -6.19e-05    |
|    lagrangian_multiplier | 12.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -239         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00694     |
|    std                   | 1            |
|    value_loss            | 27.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0313463] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 38           |
|    time_elapsed          | 618          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0035417336 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 195          |
|    cost_value_loss       | 2.22e+03     |
|    cost_values           | 238          |
|    entropy_loss          | -2.87        |
|    explained_variance    | 3.99e-06     |
|    lagrangian_multiplier | 12.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -240         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 1.02         |
|    value_loss            | 55.8         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.77658445] |
| time/                    |               |
|    fps                   | 122           |
|    iterations            | 37            |
|    time_elapsed          | 619           |
|    total_timesteps       | 75776         |
| train/                   |               |
|    approx_kl             | 0.0013398115  |
|    clip_fraction         | 0.00132       |
|    clip_range            | 0.2           |
|    cost_returns          | 188           |
|    cost_value_loss       | 2.29e+03      |
|    cost_values           | 233           |
|    entropy_loss          | -2.95         |
|    explained_variance    | 1.1e-05       |
|    lagrangian_multiplier | 11.8          |
|    learning_rate         | 0.0003        |
|    loss                  | -234          |
|    n_updates             | 360           |
|    policy_gradient_loss  | -0.00257      |
|    std                   | 1.06          |
|    value_loss            | 16.7          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.4806417] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 34           |
|    time_elapsed          | 625          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0031813502 |
|    clip_fraction         | 0.00615      |
|    clip_range            | 0.2          |
|    cost_returns          | 170          |
|    cost_value_loss       | 1.89e+03     |
|    cost_values           | 210          |
|    entropy_loss          | -3.01        |
|    explained_variance    | 1.07e-05     |
|    lagrangian_multiplier | 10.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -211         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 1.09         |
|    value_loss            | 16.3         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.82822675] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 39            |
|    time_elapsed          | 634           |
|    total_timesteps       | 79872         |
| train/                   |               |
|    approx_kl             | 0.0019963656  |
|    clip_fraction         | 0.00391       |
|    clip_range            | 0.2           |
|    cost_returns          | 202           |
|    cost_value_loss       | 2.15e+03      |
|    cost_values           | 245           |
|    entropy_loss          | -2.87         |
|    explained_variance    | 2.15e-06      |
|    lagrangian_multiplier | 12.4          |
|    learning_rate         | 0.0003        |
|    loss                  | -246          |
|    n_updates             | 380           |
|    policy_gradient_loss  | -0.00272      |
|    std                   | 1.01          |
|    value_loss            | 84.9          |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.8995315] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 39           |
|    time_elapsed          | 634          |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0056833564 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 198          |
|    cost_value_loss       | 2.41e+03     |
|    cost_values           | 244          |
|    entropy_loss          | -2.83        |
|    explained_variance    | 4.95e-06     |
|    lagrangian_multiplier | 12.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -245         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 0.997        |
|    value_loss            | 58.3         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2153463] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 38           |
|    time_elapsed          | 635          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0013501729 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 193          |
|    cost_value_loss       | 2.41e+03     |
|    cost_values           | 239          |
|    entropy_loss          | -2.94        |
|    explained_variance    | 4.53e-06     |
|    lagrangian_multiplier | 12.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -240         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 1.05         |
|    value_loss            | 10.1         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.025894]  |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 35           |
|    time_elapsed          | 643          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0018953572 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | 175          |
|    cost_value_loss       | 2e+03        |
|    cost_values           | 216          |
|    entropy_loss          | -3.02        |
|    explained_variance    | 1.17e-05     |
|    lagrangian_multiplier | 11           |
|    learning_rate         | 0.0003       |
|    loss                  | -218         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 1.1          |
|    value_loss            | 20.7         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3121706] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 40           |
|    time_elapsed          | 650          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0039812615 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 206          |
|    cost_value_loss       | 2.45e+03     |
|    cost_values           | 251          |
|    entropy_loss          | -2.87        |
|    explained_variance    | 1.97e-06     |
|    lagrangian_multiplier | 12.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -252         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00434     |
|    std                   | 1.02         |
|    value_loss            | 86.4         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0929182] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 40           |
|    time_elapsed          | 650          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0044071544 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 203          |
|    cost_value_loss       | 2.56e+03     |
|    cost_values           | 250          |
|    entropy_loss          | -2.83        |
|    explained_variance    | -2.74e-06    |
|    lagrangian_multiplier | 12.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -251         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 0.998        |
|    value_loss            | 68.7         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1783698] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 39           |
|    time_elapsed          | 652          |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0043404717 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 198          |
|    cost_value_loss       | 2.53e+03     |
|    cost_values           | 245          |
|    entropy_loss          | -2.93        |
|    explained_variance    | 4.11e-06     |
|    lagrangian_multiplier | 12.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -246         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 1.05         |
|    value_loss            | 21.2         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9921493] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 36           |
|    time_elapsed          | 662          |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.002406426  |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 180          |
|    cost_value_loss       | 2.11e+03     |
|    cost_values           | 223          |
|    entropy_loss          | -3.02        |
|    explained_variance    | -4.53e-06    |
|    lagrangian_multiplier | 11.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -224         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 1.1          |
|    value_loss            | 21.7         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4053497] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 41           |
|    time_elapsed          | 666          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.005841639  |
|    clip_fraction         | 0.0432       |
|    clip_range            | 0.2          |
|    cost_returns          | 211          |
|    cost_value_loss       | 2.52e+03     |
|    cost_values           | 257          |
|    entropy_loss          | -2.89        |
|    explained_variance    | 2.26e-06     |
|    lagrangian_multiplier | 13           |
|    learning_rate         | 0.0003       |
|    loss                  | -258         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00724     |
|    std                   | 1.04         |
|    value_loss            | 71.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7424449] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 41           |
|    time_elapsed          | 667          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0042680157 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 209          |
|    cost_value_loss       | 2.62e+03     |
|    cost_values           | 256          |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.13e-05    |
|    lagrangian_multiplier | 13           |
|    learning_rate         | 0.0003       |
|    loss                  | -258         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 1            |
|    value_loss            | 53.9         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0834923] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 40           |
|    time_elapsed          | 668          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.004318554  |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 204          |
|    cost_value_loss       | 2.66e+03     |
|    cost_values           | 252          |
|    entropy_loss          | -2.93        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 12.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -253         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 1.04         |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.5121585] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 37           |
|    time_elapsed          | 680          |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0042738896 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 185          |
|    cost_value_loss       | 2.22e+03     |
|    cost_values           | 229          |
|    entropy_loss          | -3.03        |
|    explained_variance    | 1.11e-05     |
|    lagrangian_multiplier | 11.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -230         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00432     |
|    std                   | 1.1          |
|    value_loss            | 8.18         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.5116731] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 42           |
|    time_elapsed          | 683          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.004418769  |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 215          |
|    cost_value_loss       | 2.69e+03     |
|    cost_values           | 263          |
|    entropy_loss          | -2.9         |
|    explained_variance    | -3.34e-06    |
|    lagrangian_multiplier | 13.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -264         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 1.03         |
|    value_loss            | 54.1         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.5742617] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 42           |
|    time_elapsed          | 683          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.005430716  |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 214          |
|    cost_value_loss       | 2.77e+03     |
|    cost_values           | 263          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -5.89e-05    |
|    lagrangian_multiplier | 13.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -264         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00631     |
|    std                   | 1.02         |
|    value_loss            | 163          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3990283] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 41           |
|    time_elapsed          | 685          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0031117504 |
|    clip_fraction         | 0.00942      |
|    clip_range            | 0.2          |
|    cost_returns          | 209          |
|    cost_value_loss       | 2.78e+03     |
|    cost_values           | 258          |
|    entropy_loss          | -2.92        |
|    explained_variance    | -6.68e-06    |
|    lagrangian_multiplier | 13.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -259         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 1.05         |
|    value_loss            | 57.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7716579] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 38           |
|    time_elapsed          | 699          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0021649706 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 190          |
|    cost_value_loss       | 2.34e+03     |
|    cost_values           | 235          |
|    entropy_loss          | -3.04        |
|    explained_variance    | 1.37e-06     |
|    lagrangian_multiplier | 11.9         |
|    learning_rate         | 0.0003       |
|    loss                  | -236         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 1.11         |
|    value_loss            | 32.7         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.1191406] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 43           |
|    time_elapsed          | 699          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0019983433 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 223          |
|    cost_value_loss       | 2.56e+03     |
|    cost_values           | 270          |
|    entropy_loss          | -2.9         |
|    explained_variance    | -1.67e-06    |
|    lagrangian_multiplier | 13.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -271         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 1.04         |
|    value_loss            | 76.9         |
-------------------------------------------
-------------------------------------------
| reward                   | [-3.4437687] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 43           |
|    time_elapsed          | 699          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0036549545 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 219          |
|    cost_value_loss       | 2.89e+03     |
|    cost_values           | 269          |
|    entropy_loss          | -2.87        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 13.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -270         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 1.01         |
|    value_loss            | 107          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.46641162] |
| time/                    |               |
|    fps                   | 122           |
|    iterations            | 42            |
|    time_elapsed          | 701           |
|    total_timesteps       | 86016         |
| train/                   |               |
|    approx_kl             | 0.0024478147  |
|    clip_fraction         | 0.00371       |
|    clip_range            | 0.2           |
|    cost_returns          | 214           |
|    cost_value_loss       | 2.87e+03      |
|    cost_values           | 264           |
|    entropy_loss          | -2.93         |
|    explained_variance    | -2.62e-06     |
|    lagrangian_multiplier | 13.4          |
|    learning_rate         | 0.0003        |
|    loss                  | -265          |
|    n_updates             | 410           |
|    policy_gradient_loss  | -0.00184      |
|    std                   | 1.05          |
|    value_loss            | 76.6          |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1544448] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 44           |
|    time_elapsed          | 715          |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0037343404 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 227          |
|    cost_value_loss       | 2.82e+03     |
|    cost_values           | 276          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -3.22e-05    |
|    lagrangian_multiplier | 14           |
|    learning_rate         | 0.0003       |
|    loss                  | -277         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 1.04         |
|    value_loss            | 86.1         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.49179474] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 44            |
|    time_elapsed          | 716           |
|    total_timesteps       | 90112         |
| train/                   |               |
|    approx_kl             | 0.003049993   |
|    clip_fraction         | 0.0132        |
|    clip_range            | 0.2           |
|    cost_returns          | 224           |
|    cost_value_loss       | 3.04e+03      |
|    cost_values           | 275           |
|    entropy_loss          | -2.86         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 14            |
|    learning_rate         | 0.0003        |
|    loss                  | -275          |
|    n_updates             | 430           |
|    policy_gradient_loss  | -0.00373      |
|    std                   | 1.01          |
|    value_loss            | 173           |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.0300114] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 39           |
|    time_elapsed          | 717          |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0023996665 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 195          |
|    cost_value_loss       | 2.46e+03     |
|    cost_values           | 241          |
|    entropy_loss          | -3.04        |
|    explained_variance    | 5.78e-06     |
|    lagrangian_multiplier | 12.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -242         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 1.11         |
|    value_loss            | 24.5         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.73313344] |
| time/                    |               |
|    fps                   | 121           |
|    iterations            | 43            |
|    time_elapsed          | 726           |
|    total_timesteps       | 88064         |
| train/                   |               |
|    approx_kl             | 0.004144379   |
|    clip_fraction         | 0.0148        |
|    clip_range            | 0.2           |
|    cost_returns          | 219           |
|    cost_value_loss       | 3e+03         |
|    cost_values           | 270           |
|    entropy_loss          | -2.94         |
|    explained_variance    | -2.38e-06     |
|    lagrangian_multiplier | 13.7          |
|    learning_rate         | 0.0003        |
|    loss                  | -271          |
|    n_updates             | 420           |
|    policy_gradient_loss  | -0.00372      |
|    std                   | 1.06          |
|    value_loss            | 81.9          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.5531671] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 45           |
|    time_elapsed          | 731          |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0015843571 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 232          |
|    cost_value_loss       | 3.03e+03     |
|    cost_values           | 282          |
|    entropy_loss          | -2.91        |
|    explained_variance    | 2.03e-06     |
|    lagrangian_multiplier | 14.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -283         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 1.03         |
|    value_loss            | 42.3         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2343968] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 45           |
|    time_elapsed          | 732          |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.002733754  |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 228          |
|    cost_value_loss       | 3.49e+03     |
|    cost_values           | 281          |
|    entropy_loss          | -2.85        |
|    explained_variance    | 9.54e-07     |
|    lagrangian_multiplier | 14.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -282         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.01         |
|    value_loss            | 43           |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.88743967] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 40            |
|    time_elapsed          | 735           |
|    total_timesteps       | 81920         |
| train/                   |               |
|    approx_kl             | 0.0013096676  |
|    clip_fraction         | 0.000537      |
|    clip_range            | 0.2           |
|    cost_returns          | 200           |
|    cost_value_loss       | 2.58e+03      |
|    cost_values           | 248           |
|    entropy_loss          | -3.05         |
|    explained_variance    | 4.83e-06      |
|    lagrangian_multiplier | 12.6          |
|    learning_rate         | 0.0003        |
|    loss                  | -249          |
|    n_updates             | 390           |
|    policy_gradient_loss  | -0.000768     |
|    std                   | 1.11          |
|    value_loss            | 9.33          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.48869565] |
| time/                    |               |
|    fps                   | 121           |
|    iterations            | 44            |
|    time_elapsed          | 743           |
|    total_timesteps       | 90112         |
| train/                   |               |
|    approx_kl             | 0.0030953584  |
|    clip_fraction         | 0.0106        |
|    clip_range            | 0.2           |
|    cost_returns          | 224           |
|    cost_value_loss       | 3.16e+03      |
|    cost_values           | 276           |
|    entropy_loss          | -2.96         |
|    explained_variance    | -3.84e-05     |
|    lagrangian_multiplier | 14            |
|    learning_rate         | 0.0003        |
|    loss                  | -278          |
|    n_updates             | 430           |
|    policy_gradient_loss  | -0.00258      |
|    std                   | 1.06          |
|    value_loss            | 141           |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.5009007] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 46           |
|    time_elapsed          | 748          |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0037351483 |
|    clip_fraction         | 0.00796      |
|    clip_range            | 0.2          |
|    cost_returns          | 233          |
|    cost_value_loss       | 3.74e+03     |
|    cost_values           | 288          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -2.74e-06    |
|    lagrangian_multiplier | 14.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -289         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 1.04         |
|    value_loss            | 27.5         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0129313] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 46           |
|    time_elapsed          | 748          |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0026716357 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 235          |
|    cost_value_loss       | 3.27e+03     |
|    cost_values           | 288          |
|    entropy_loss          | -2.85        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 14.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -289         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.01         |
|    value_loss            | 32.9         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.27651072] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 41            |
|    time_elapsed          | 754           |
|    total_timesteps       | 83968         |
| train/                   |               |
|    approx_kl             | 0.0046191346  |
|    clip_fraction         | 0.0213        |
|    clip_range            | 0.2           |
|    cost_returns          | 205           |
|    cost_value_loss       | 2.7e+03       |
|    cost_values           | 254           |
|    entropy_loss          | -3.05         |
|    explained_variance    | 5.36e-07      |
|    lagrangian_multiplier | 12.9          |
|    learning_rate         | 0.0003        |
|    loss                  | -254          |
|    n_updates             | 400           |
|    policy_gradient_loss  | -0.00293      |
|    std                   | 1.11          |
|    value_loss            | 13.7          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.4479789] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 45           |
|    time_elapsed          | 759          |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0052238377 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 228          |
|    cost_value_loss       | 3.69e+03     |
|    cost_values           | 283          |
|    entropy_loss          | -2.97        |
|    explained_variance    | -4.01e-05    |
|    lagrangian_multiplier | 14.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -283         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 1.07         |
|    value_loss            | 54.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8257576] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 47           |
|    time_elapsed          | 764          |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.003263596  |
|    clip_fraction         | 0.00884      |
|    clip_range            | 0.2          |
|    cost_returns          | 240          |
|    cost_value_loss       | 3.42e+03     |
|    cost_values           | 294          |
|    entropy_loss          | -2.91        |
|    explained_variance    | 7.15e-07     |
|    lagrangian_multiplier | 14.9         |
|    learning_rate         | 0.0003       |
|    loss                  | -295         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 1.04         |
|    value_loss            | 103          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.6768585] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 47           |
|    time_elapsed          | 765          |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0045446325 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 241          |
|    cost_value_loss       | 3.31e+03     |
|    cost_values           | 294          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000102    |
|    lagrangian_multiplier | 14.9         |
|    learning_rate         | 0.0003       |
|    loss                  | -294         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00508     |
|    std                   | 1            |
|    value_loss            | 87.3         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.22728547] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 42            |
|    time_elapsed          | 772           |
|    total_timesteps       | 86016         |
| train/                   |               |
|    approx_kl             | 0.0025920619  |
|    clip_fraction         | 0.00513       |
|    clip_range            | 0.2           |
|    cost_returns          | 211           |
|    cost_value_loss       | 2.83e+03      |
|    cost_values           | 260           |
|    entropy_loss          | -3.04         |
|    explained_variance    | 7.45e-06      |
|    lagrangian_multiplier | 13.2          |
|    learning_rate         | 0.0003        |
|    loss                  | -261          |
|    n_updates             | 410           |
|    policy_gradient_loss  | -0.00221      |
|    std                   | 1.11          |
|    value_loss            | 11.7          |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.5868465] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 46           |
|    time_elapsed          | 775          |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0019191756 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 234          |
|    cost_value_loss       | 3.47e+03     |
|    cost_values           | 289          |
|    entropy_loss          | -2.97        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 14.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -290         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 1.07         |
|    value_loss            | 81.8         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.63897884] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 48            |
|    time_elapsed          | 780           |
|    total_timesteps       | 98304         |
| train/                   |               |
|    approx_kl             | 0.0050467458  |
|    clip_fraction         | 0.0272        |
|    clip_range            | 0.2           |
|    cost_returns          | 244           |
|    cost_value_loss       | 3.74e+03      |
|    cost_values           | 301           |
|    entropy_loss          | -2.9          |
|    explained_variance    | 4.11e-06      |
|    lagrangian_multiplier | 15.2          |
|    learning_rate         | 0.0003        |
|    loss                  | -301          |
|    n_updates             | 470           |
|    policy_gradient_loss  | -0.00435      |
|    std                   | 1.03          |
|    value_loss            | 37.1          |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1689341] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 48           |
|    time_elapsed          | 781          |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0024646537 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 245          |
|    cost_value_loss       | 3.55e+03     |
|    cost_values           | 300          |
|    entropy_loss          | -2.83        |
|    explained_variance    | 5.36e-07     |
|    lagrangian_multiplier | 15.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -300         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 0.995        |
|    value_loss            | 115          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9654973] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 43           |
|    time_elapsed          | 791          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0033335392 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 216          |
|    cost_value_loss       | 2.96e+03     |
|    cost_values           | 266          |
|    entropy_loss          | -3.03        |
|    explained_variance    | 6.97e-06     |
|    lagrangian_multiplier | 13.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -267         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 1.1          |
|    value_loss            | 9.97         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1249427] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 47           |
|    time_elapsed          | 793          |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.002391857  |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 240          |
|    cost_value_loss       | 3.57e+03     |
|    cost_values           | 295          |
|    entropy_loss          | -2.97        |
|    explained_variance    | -1.43e-06    |
|    lagrangian_multiplier | 15           |
|    learning_rate         | 0.0003       |
|    loss                  | -296         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 1.07         |
|    value_loss            | 94.9         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0374507] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 49           |
|    time_elapsed          | 796          |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0036560004 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 251          |
|    cost_value_loss       | 3.71e+03     |
|    cost_values           | 307          |
|    entropy_loss          | -2.91        |
|    explained_variance    | 1.97e-06     |
|    lagrangian_multiplier | 15.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -307         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.04         |
|    value_loss            | 33.2         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.5416783] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 49           |
|    time_elapsed          | 797          |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0053838063 |
|    clip_fraction         | 0.0248       |
|    clip_range            | 0.2          |
|    cost_returns          | 249          |
|    cost_value_loss       | 3.8e+03      |
|    cost_values           | 306          |
|    entropy_loss          | -2.82        |
|    explained_variance    | -4.89e-06    |
|    lagrangian_multiplier | 15.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -307         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00453     |
|    std                   | 0.99         |
|    value_loss            | 32.3         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.4700069] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 44           |
|    time_elapsed          | 809          |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0031070197 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | 221          |
|    cost_value_loss       | 3.1e+03      |
|    cost_values           | 273          |
|    entropy_loss          | -3.02        |
|    explained_variance    | 3.81e-06     |
|    lagrangian_multiplier | 13.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -273         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 1.1          |
|    value_loss            | 8.71         |
-------------------------------------------
------------------------------------------
| reward                   | [-0.856284] |
| time/                    |             |
|    fps                   | 121         |
|    iterations            | 48          |
|    time_elapsed          | 810         |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.004507375 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 244         |
|    cost_value_loss       | 3.76e+03    |
|    cost_values           | 301         |
|    entropy_loss          | -2.97       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 15.3        |
|    learning_rate         | 0.0003      |
|    loss                  | -302        |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 1.07        |
|    value_loss            | 40.6        |
------------------------------------------
Directory already exists: PPOL_New/models/New-PPOL-SpeedLimit=4/model_epoch(0)_timesteps(100000)
--------------------------------------
| reward             | [-0.67200744] |
| time/              |               |
|    fps             | 134           |
|    iterations      | 1             |
|    time_elapsed    | 15            |
|    total_timesteps | 102400        |
--------------------------------------
Directory already exists: PPOL_New/models/New-PPOL-SpeedLimit=8/model_epoch(0)_timesteps(100000)
-------------------------------------
| reward             | [-1.6547124] |
| time/              |              |
|    fps             | 135          |
|    iterations      | 1            |
|    time_elapsed    | 15           |
|    total_timesteps | 102400       |
-------------------------------------
-------------------------------------------
| reward                   | [-1.4170396] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 49           |
|    time_elapsed          | 827          |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0034344895 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 250          |
|    cost_value_loss       | 3.91e+03     |
|    cost_values           | 308          |
|    entropy_loss          | -2.96        |
|    explained_variance    | 6.56e-07     |
|    lagrangian_multiplier | 15.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -308         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 1.06         |
|    value_loss            | 72.1         |
-------------------------------------------
------------------------------------------
| reward                   | [-0.569294] |
| time/                    |             |
|    fps                   | 111         |
|    iterations            | 45          |
|    time_elapsed          | 827         |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.006272391 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 224         |
|    cost_value_loss       | 3.6e+03     |
|    cost_values           | 279         |
|    entropy_loss          | -3.02       |
|    explained_variance    | -1.43e-06   |
|    lagrangian_multiplier | 14.1        |
|    learning_rate         | 0.0003      |
|    loss                  | -279        |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00628    |
|    std                   | 1.1         |
|    value_loss            | 19.2        |
------------------------------------------
--------------------------------------------
| reward                   | [-0.93985045] |
| time/                    |               |
|    fps                   | 129           |
|    iterations            | 2             |
|    time_elapsed          | 31            |
|    total_timesteps       | 104448        |
| train/                   |               |
|    approx_kl             | 0.0030280738  |
|    clip_fraction         | 0.00581       |
|    clip_range            | 0.2           |
|    cost_returns          | 262           |
|    cost_value_loss       | 3.91e+03      |
|    cost_values           | 319           |
|    entropy_loss          | -2.91         |
|    explained_variance    | 9.54e-07      |
|    lagrangian_multiplier | 16.2          |
|    learning_rate         | 0.0003        |
|    loss                  | -321          |
|    n_updates             | 500           |
|    policy_gradient_loss  | -0.00216      |
|    std                   | 1.04          |
|    value_loss            | 66.5          |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.7982159] |
| time/                    |              |
|    fps                   | 130          |
|    iterations            | 2            |
|    time_elapsed          | 31           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.00501546   |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 261          |
|    cost_value_loss       | 3.95e+03     |
|    cost_values           | 319          |
|    entropy_loss          | -2.83        |
|    explained_variance    | 2.03e-06     |
|    lagrangian_multiplier | 16.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -320         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00489     |
|    std                   | 0.998        |
|    value_loss            | 59.1         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
Directory already exists: PPOL_New/models/New-PPOL-SpeedLimit=8/model_epoch(0)_timesteps(100000)
------------------------------------
| reward             | [-1.305552] |
| time/              |             |
|    fps             | 135         |
|    iterations      | 1           |
|    time_elapsed    | 15          |
|    total_timesteps | 102400      |
------------------------------------
-------------------------------------------
| reward                   | [-0.9781233] |
| time/                    |              |
|    fps                   | 128          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0042892974 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 275          |
|    cost_value_loss       | 3.22e+03     |
|    cost_values           | 326          |
|    entropy_loss          | -2.92        |
|    explained_variance    | 8.94e-07     |
|    lagrangian_multiplier | 16.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -327         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 1.05         |
|    value_loss            | 139          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.187302]  |
| time/                    |              |
|    fps                   | 129          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0050685713 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 268          |
|    cost_value_loss       | 3.91e+03     |
|    cost_values           | 325          |
|    entropy_loss          | -2.83        |
|    explained_variance    | 1.13e-06     |
|    lagrangian_multiplier | 16.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -326         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00478     |
|    std                   | 0.996        |
|    value_loss            | 94.8         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.85446066] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 46            |
|    time_elapsed          | 846           |
|    total_timesteps       | 94208         |
| train/                   |               |
|    approx_kl             | 0.003919689   |
|    clip_fraction         | 0.0147        |
|    clip_range            | 0.2           |
|    cost_returns          | 231           |
|    cost_value_loss       | 3.38e+03      |
|    cost_values           | 285           |
|    entropy_loss          | -3.03         |
|    explained_variance    | 3.64e-06      |
|    lagrangian_multiplier | 14.4          |
|    learning_rate         | 0.0003        |
|    loss                  | -285          |
|    n_updates             | 450           |
|    policy_gradient_loss  | -0.00559      |
|    std                   | 1.11          |
|    value_loss            | 8.7           |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.4492728] |
| time/                    |              |
|    fps                   | 130          |
|    iterations            | 2            |
|    time_elapsed          | 31           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0031732498 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | 260          |
|    cost_value_loss       | 4.18e+03     |
|    cost_values           | 320          |
|    entropy_loss          | -2.93        |
|    explained_variance    | 4.77e-07     |
|    lagrangian_multiplier | 16.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -321         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 1.04         |
|    value_loss            | 80.4         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3600397] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 4            |
|    time_elapsed          | 64           |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0019252243 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 271          |
|    cost_value_loss       | 4.3e+03      |
|    cost_values           | 332          |
|    entropy_loss          | -2.93        |
|    explained_variance    | 3.22e-06     |
|    lagrangian_multiplier | 16.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -332         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 1.04         |
|    value_loss            | 42.4         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.3863583] |
| time/                    |              |
|    fps                   | 128          |
|    iterations            | 4            |
|    time_elapsed          | 63           |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0039505707 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 271          |
|    cost_value_loss       | 4.25e+03     |
|    cost_values           | 331          |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.000122    |
|    lagrangian_multiplier | 16.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -331         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 1            |
|    value_loss            | 114          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.70103866] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 47            |
|    time_elapsed          | 864           |
|    total_timesteps       | 96256         |
| train/                   |               |
|    approx_kl             | 0.0039443965  |
|    clip_fraction         | 0.0103        |
|    clip_range            | 0.2           |
|    cost_returns          | 236           |
|    cost_value_loss       | 3.52e+03      |
|    cost_values           | 291           |
|    entropy_loss          | -3.04         |
|    explained_variance    | 8.94e-07      |
|    lagrangian_multiplier | 14.8          |
|    learning_rate         | 0.0003        |
|    loss                  | -292          |
|    n_updates             | 460           |
|    policy_gradient_loss  | -0.00375      |
|    std                   | 1.1           |
|    value_loss            | 9.34          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-2.219057]  |
| time/                    |              |
|    fps                   | 128          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0030338578 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 265          |
|    cost_value_loss       | 4.36e+03     |
|    cost_values           | 326          |
|    entropy_loss          | -2.91        |
|    explained_variance    | 1.67e-06     |
|    lagrangian_multiplier | 16.5         |
|    learning_rate         | 0.0003       |
|    loss                  | -327         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.03         |
|    value_loss            | 30.6         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0921528] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 5            |
|    time_elapsed          | 80           |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.004729909  |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 282          |
|    cost_value_loss       | 3.87e+03     |
|    cost_values           | 338          |
|    entropy_loss          | -2.92        |
|    explained_variance    | 1.37e-06     |
|    lagrangian_multiplier | 17.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -340         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00668     |
|    std                   | 1.04         |
|    value_loss            | 44.1         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.8951069] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 5            |
|    time_elapsed          | 80           |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0051750895 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 277          |
|    cost_value_loss       | 4.4e+03      |
|    cost_values           | 337          |
|    entropy_loss          | -2.84        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 17.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -339         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 1.01         |
|    value_loss            | 139          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.41597223] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 48            |
|    time_elapsed          | 883           |
|    total_timesteps       | 98304         |
| train/                   |               |
|    approx_kl             | 0.0012992946  |
|    clip_fraction         | 0.000977      |
|    clip_range            | 0.2           |
|    cost_returns          | 241           |
|    cost_value_loss       | 3.67e+03      |
|    cost_values           | 297           |
|    entropy_loss          | -3.04         |
|    explained_variance    | 2.5e-06       |
|    lagrangian_multiplier | 15.1          |
|    learning_rate         | 0.0003        |
|    loss                  | -298          |
|    n_updates             | 470           |
|    policy_gradient_loss  | -0.000978     |
|    std                   | 1.11          |
|    value_loss            | 4.75          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.5352992] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 4            |
|    time_elapsed          | 64           |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.005294632  |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 270          |
|    cost_value_loss       | 4.53e+03     |
|    cost_values           | 333          |
|    entropy_loss          | -2.9         |
|    explained_variance    | 4.77e-07     |
|    lagrangian_multiplier | 16.9         |
|    learning_rate         | 0.0003       |
|    loss                  | -333         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 1.03         |
|    value_loss            | 264          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0305346] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 6            |
|    time_elapsed          | 96           |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0014680119 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 288          |
|    cost_value_loss       | 3.93e+03     |
|    cost_values           | 344          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.0074      |
|    lagrangian_multiplier | 17.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -345         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 1.04         |
|    value_loss            | 122          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0440593] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 6            |
|    time_elapsed          | 96           |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0037494004 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 282          |
|    cost_value_loss       | 4.52e+03     |
|    cost_values           | 344          |
|    entropy_loss          | -2.85        |
|    explained_variance    | -7.51e-06    |
|    lagrangian_multiplier | 17.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -344         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 1.01         |
|    value_loss            | 127          |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.7936672] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 49           |
|    time_elapsed          | 901          |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.00223835   |
|    clip_fraction         | 0.00518      |
|    clip_range            | 0.2          |
|    cost_returns          | 246          |
|    cost_value_loss       | 3.82e+03     |
|    cost_values           | 304          |
|    entropy_loss          | -3.03        |
|    explained_variance    | 4.17e-07     |
|    lagrangian_multiplier | 15.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -305         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.1          |
|    value_loss            | 6.95         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9103422] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 5            |
|    time_elapsed          | 80           |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.004531359  |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 276          |
|    cost_value_loss       | 4.64e+03     |
|    cost_values           | 339          |
|    entropy_loss          | -2.89        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 17.2         |
|    learning_rate         | 0.0003       |
|    loss                  | -339         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 1.03         |
|    value_loss            | 81.5         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7635683] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 7            |
|    time_elapsed          | 113          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0029289448 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 286          |
|    cost_value_loss       | 4.87e+03     |
|    cost_values           | 351          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 17.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -351         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 1.04         |
|    value_loss            | 126          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.886934] |
| time/                    |             |
|    fps                   | 127         |
|    iterations            | 7           |
|    time_elapsed          | 112         |
|    total_timesteps       | 114688      |
| train/                   |             |
|    approx_kl             | 0.004499537 |
|    clip_fraction         | 0.0238      |
|    clip_range            | 0.2         |
|    cost_returns          | 286         |
|    cost_value_loss       | 4.77e+03    |
|    cost_values           | 350         |
|    entropy_loss          | -2.85       |
|    explained_variance    | 4.17e-07    |
|    lagrangian_multiplier | 17.7        |
|    learning_rate         | 0.0003      |
|    loss                  | -350        |
|    n_updates             | 550         |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 1.01        |
|    value_loss            | 49.6        |
------------------------------------------
Directory already exists: PPOL_New/models/New-PPOL-SpeedLimit=4/model_epoch(0)_timesteps(100000)
--------------------------------------
| reward             | [-0.64215165] |
| time/              |               |
|    fps             | 118           |
|    iterations      | 1             |
|    time_elapsed    | 17            |
|    total_timesteps | 102400        |
--------------------------------------
------------------------------------------
| reward                   | [-2.382929] |
| time/                    |             |
|    fps                   | 126         |
|    iterations            | 6           |
|    time_elapsed          | 97          |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.002868839 |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 281         |
|    cost_value_loss       | 4.77e+03    |
|    cost_values           | 345         |
|    entropy_loss          | -2.89       |
|    explained_variance    | 2.38e-07    |
|    lagrangian_multiplier | 17.5        |
|    learning_rate         | 0.0003      |
|    loss                  | -346        |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 1.02        |
|    value_loss            | 126         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.249527]  |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 8            |
|    time_elapsed          | 129          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0045060506 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 296          |
|    cost_value_loss       | 4.5e+03      |
|    cost_values           | 357          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -1.91e-06    |
|    lagrangian_multiplier | 18.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -357         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 1.04         |
|    value_loss            | 42.1         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.5451458] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 8            |
|    time_elapsed          | 128          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0023161606 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 291          |
|    cost_value_loss       | 4.99e+03     |
|    cost_values           | 356          |
|    entropy_loss          | -2.86        |
|    explained_variance    | -6.08e-06    |
|    lagrangian_multiplier | 18           |
|    learning_rate         | 0.0003       |
|    loss                  | -357         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 1.01         |
|    value_loss            | 39           |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.8213164]  |
| time/                    |               |
|    fps                   | 115           |
|    iterations            | 2             |
|    time_elapsed          | 35            |
|    total_timesteps       | 104448        |
| train/                   |               |
|    approx_kl             | 0.00045340668 |
|    clip_fraction         | 0.000244      |
|    clip_range            | 0.2           |
|    cost_returns          | 257           |
|    cost_value_loss       | 4.12e+03      |
|    cost_values           | 316           |
|    entropy_loss          | -3.01         |
|    explained_variance    | -1.67e-06     |
|    lagrangian_multiplier | 16            |
|    learning_rate         | 0.0003        |
|    loss                  | -317          |
|    n_updates             | 500           |
|    policy_gradient_loss  | -0.000907     |
|    std                   | 1.09          |
|    value_loss            | 3.36          |
--------------------------------------------
-------------------------------------------
| reward                   | [-2.853293]  |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 7            |
|    time_elapsed          | 113          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0037609837 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 286          |
|    cost_value_loss       | 4.93e+03     |
|    cost_values           | 351          |
|    entropy_loss          | -2.88        |
|    explained_variance    | -7.03e-06    |
|    lagrangian_multiplier | 17.8         |
|    learning_rate         | 0.0003       |
|    loss                  | -352         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 1.02         |
|    value_loss            | 135          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.84952164] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 9             |
|    time_elapsed          | 145           |
|    total_timesteps       | 118784        |
| train/                   |               |
|    approx_kl             | 0.0024573843  |
|    clip_fraction         | 0.00513       |
|    clip_range            | 0.2           |
|    cost_returns          | 297           |
|    cost_value_loss       | 5.15e+03      |
|    cost_values           | 363           |
|    entropy_loss          | -2.92         |
|    explained_variance    | 7.15e-07      |
|    lagrangian_multiplier | 18.4          |
|    learning_rate         | 0.0003        |
|    loss                  | -364          |
|    n_updates             | 570           |
|    policy_gradient_loss  | -0.00286      |
|    std                   | 1.04          |
|    value_loss            | 44            |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.7109724] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 9            |
|    time_elapsed          | 145          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.006360579  |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | 296          |
|    cost_value_loss       | 5.18e+03     |
|    cost_values           | 362          |
|    entropy_loss          | -2.86        |
|    explained_variance    | 1.43e-06     |
|    lagrangian_multiplier | 18.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -362         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00611     |
|    std                   | 1.02         |
|    value_loss            | 56.3         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8529748] |
| time/                    |              |
|    fps                   | 114          |
|    iterations            | 3            |
|    time_elapsed          | 53           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0023120234 |
|    clip_fraction         | 0.00327      |
|    clip_range            | 0.2          |
|    cost_returns          | 262          |
|    cost_value_loss       | 4.28e+03     |
|    cost_values           | 322          |
|    entropy_loss          | -3           |
|    explained_variance    | 2.15e-06     |
|    lagrangian_multiplier | 16.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -323         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 1.08         |
|    value_loss            | 4.06         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.79359174] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 8             |
|    time_elapsed          | 129           |
|    total_timesteps       | 116736        |
| train/                   |               |
|    approx_kl             | 0.0044765305  |
|    clip_fraction         | 0.0222        |
|    clip_range            | 0.2           |
|    cost_returns          | 291           |
|    cost_value_loss       | 5.13e+03      |
|    cost_values           | 358           |
|    entropy_loss          | -2.89         |
|    explained_variance    | 1.07e-06      |
|    lagrangian_multiplier | 18.1          |
|    learning_rate         | 0.0003        |
|    loss                  | -358          |
|    n_updates             | 560           |
|    policy_gradient_loss  | -0.00373      |
|    std                   | 1.03          |
|    value_loss            | 313           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1422379] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 10           |
|    time_elapsed          | 162          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0013248347 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 307          |
|    cost_value_loss       | 5.15e+03     |
|    cost_values           | 369          |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 18.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -371         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 1.04         |
|    value_loss            | 212          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1817603] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 10           |
|    time_elapsed          | 161          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0043977154 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 301          |
|    cost_value_loss       | 5.42e+03     |
|    cost_values           | 369          |
|    entropy_loss          | -2.88        |
|    explained_variance    | 1.19e-06     |
|    lagrangian_multiplier | 18.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -368         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 1.02         |
|    value_loss            | 83.9         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.27330554] |
| time/                    |               |
|    fps                   | 113           |
|    iterations            | 4             |
|    time_elapsed          | 72            |
|    total_timesteps       | 108544        |
| train/                   |               |
|    approx_kl             | 0.0013217558  |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 267           |
|    cost_value_loss       | 4.44e+03      |
|    cost_values           | 329           |
|    entropy_loss          | -2.99         |
|    explained_variance    | 4.17e-07      |
|    lagrangian_multiplier | 16.7          |
|    learning_rate         | 0.0003        |
|    loss                  | -330          |
|    n_updates             | 520           |
|    policy_gradient_loss  | -0.000752     |
|    std                   | 1.08          |
|    value_loss            | 7.68          |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.8139662] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 9            |
|    time_elapsed          | 146          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0033743249 |
|    clip_fraction         | 0.00884      |
|    clip_range            | 0.2          |
|    cost_returns          | 298          |
|    cost_value_loss       | 5.14e+03     |
|    cost_values           | 364          |
|    entropy_loss          | -2.88        |
|    explained_variance    | 5.36e-07     |
|    lagrangian_multiplier | 18.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -363         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 1.02         |
|    value_loss            | 89.6         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1640075] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 11           |
|    time_elapsed          | 178          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0017305538 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 313          |
|    cost_value_loss       | 4.78e+03     |
|    cost_values           | 376          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 19           |
|    learning_rate         | 0.0003       |
|    loss                  | -376         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 1.03         |
|    value_loss            | 56.6         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8330702] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 11           |
|    time_elapsed          | 177          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0037695162 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 307          |
|    cost_value_loss       | 5.44e+03     |
|    cost_values           | 375          |
|    entropy_loss          | -2.89        |
|    explained_variance    | 1.19e-06     |
|    lagrangian_multiplier | 19           |
|    learning_rate         | 0.0003       |
|    loss                  | -374         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 1.03         |
|    value_loss            | 38.3         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.7643875] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 10           |
|    time_elapsed          | 162          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0033425328 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 301          |
|    cost_value_loss       | 5.5e+03      |
|    cost_values           | 370          |
|    entropy_loss          | -2.88        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 18.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -370         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 1.02         |
|    value_loss            | 122          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7715821] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 12           |
|    time_elapsed          | 195          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0014621725 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | 314          |
|    cost_value_loss       | 5.52e+03     |
|    cost_values           | 382          |
|    entropy_loss          | -2.9         |
|    explained_variance    | 5.96e-07     |
|    lagrangian_multiplier | 19.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -382         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 1.03         |
|    value_loss            | 37.7         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7393245] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 12           |
|    time_elapsed          | 194          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.004050885  |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 313          |
|    cost_value_loss       | 5.58e+03     |
|    cost_values           | 381          |
|    entropy_loss          | -2.89        |
|    explained_variance    | 4.35e-06     |
|    lagrangian_multiplier | 19.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -382         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00387     |
|    std                   | 1.03         |
|    value_loss            | 33           |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.56215864] |
| time/                    |               |
|    fps                   | 113           |
|    iterations            | 5             |
|    time_elapsed          | 90            |
|    total_timesteps       | 110592        |
| train/                   |               |
|    approx_kl             | 0.0011831006  |
|    clip_fraction         | 0.000195      |
|    clip_range            | 0.2           |
|    cost_returns          | 272           |
|    cost_value_loss       | 4.61e+03      |
|    cost_values           | 335           |
|    entropy_loss          | -2.99         |
|    explained_variance    | 3.04e-06      |
|    lagrangian_multiplier | 17            |
|    learning_rate         | 0.0003        |
|    loss                  | -334          |
|    n_updates             | 530           |
|    policy_gradient_loss  | -0.00113      |
|    std                   | 1.08          |
|    value_loss            | 7.16          |
--------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.8268527] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 11           |
|    time_elapsed          | 179          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0049905414 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 307          |
|    cost_value_loss       | 5.64e+03     |
|    cost_values           | 376          |
|    entropy_loss          | -2.89        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 19.1         |
|    learning_rate         | 0.0003       |
|    loss                  | -377         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 1.03         |
|    value_loss            | 93.9         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.2429328] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 13           |
|    time_elapsed          | 211          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0022172292 |
|    clip_fraction         | 0.00361      |
|    clip_range            | 0.2          |
|    cost_returns          | 318          |
|    cost_value_loss       | 5.78e+03     |
|    cost_values           | 388          |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 19.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -389         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 1.03         |
|    value_loss            | 40.8         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.2344882] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 13           |
|    time_elapsed          | 210          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0023626783 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 316          |
|    cost_value_loss       | 6.02e+03     |
|    cost_values           | 387          |
|    entropy_loss          | -2.89        |
|    explained_variance    | 1.85e-06     |
|    lagrangian_multiplier | 19.6         |
|    learning_rate         | 0.0003       |
|    loss                  | -388         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 1.03         |
|    value_loss            | 31.4         |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.5893243] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 6            |
|    time_elapsed          | 109          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0030094846 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 277          |
|    cost_value_loss       | 4.78e+03     |
|    cost_values           | 341          |
|    entropy_loss          | -2.98        |
|    explained_variance    | 1.97e-06     |
|    lagrangian_multiplier | 17.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -342         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 1.07         |
|    value_loss            | 2.16         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.2526841] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 12           |
|    time_elapsed          | 195          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0035006227 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 311          |
|    cost_value_loss       | 5.9e+03      |
|    cost_values           | 383          |
|    entropy_loss          | -2.9         |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 19.4         |
|    learning_rate         | 0.0003       |
|    loss                  | -382         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 1.03         |
|    value_loss            | 84.3         |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.4397006] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 14           |
|    time_elapsed          | 227          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.004325499  |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 328          |
|    cost_value_loss       | 5.34e+03     |
|    cost_values           | 394          |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 20           |
|    learning_rate         | 0.0003       |
|    loss                  | -395         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00488     |
|    std                   | 1.04         |
|    value_loss            | 61.4         |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6860557] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 14           |
|    time_elapsed          | 226          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.004314945  |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 322          |
|    cost_value_loss       | 6.08e+03     |
|    cost_values           | 394          |
|    entropy_loss          | -2.91        |
|    explained_variance    | -7.03e-06    |
|    lagrangian_multiplier | 19.9         |
|    learning_rate         | 0.0003       |
|    loss                  | -394         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00429     |
|    std                   | 1.04         |
|    value_loss            | 45.4         |
-------------------------------------------
srun: Job 114555 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.44368318] |
| time/                    |               |
|    fps                   | 112           |
|    iterations            | 7             |
|    time_elapsed          | 127           |
|    total_timesteps       | 114688        |
| train/                   |               |
|    approx_kl             | 0.00044837987 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 282           |
|    cost_value_loss       | 4.95e+03      |
|    cost_values           | 347           |
|    entropy_loss          | -2.97         |
|    explained_variance    | 7.15e-07      |
|    lagrangian_multiplier | 17.6          |
|    learning_rate         | 0.0003        |
|    loss                  | -348          |
|    n_updates             | 550           |
|    policy_gradient_loss  | -0.000541     |
|    std                   | 1.07          |
|    value_loss            | 5.07          |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.2296455] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 13           |
|    time_elapsed          | 212          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0020091385 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | 317          |
|    cost_value_loss       | 5.99e+03     |
|    cost_values           | 389          |
|    entropy_loss          | -2.91        |
|    explained_variance    | 1.01e-06     |
|    lagrangian_multiplier | 19.7         |
|    learning_rate         | 0.0003       |
|    loss                  | -389         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 1.04         |
|    value_loss            | 119          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.1513956] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 15           |
|    time_elapsed          | 243          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0015196118 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 337          |
|    cost_value_loss       | 5.07e+03     |
|    cost_values           | 401          |
|    entropy_loss          | -2.92        |
|    explained_variance    | 5.96e-07     |
|    lagrangian_multiplier | 20.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -402         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 1.04         |
|    value_loss            | 197          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6577346] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 15           |
|    time_elapsed          | 243          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0020979312 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 326          |
|    cost_value_loss       | 6.32e+03     |
|    cost_values           | 400          |
|    entropy_loss          | -2.9         |
|    explained_variance    | 7.15e-07     |
|    lagrangian_multiplier | 20.3         |
|    learning_rate         | 0.0003       |
|    loss                  | -400         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 1.03         |
|    value_loss            | 46.3         |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.60546184] |
| time/                    |               |
|    fps                   | 112           |
|    iterations            | 8             |
|    time_elapsed          | 146           |
|    total_timesteps       | 116736        |
| train/                   |               |
|    approx_kl             | 0.0037748632  |
|    clip_fraction         | 0.0129        |
|    clip_range            | 0.2           |
|    cost_returns          | 287           |
|    cost_value_loss       | 5.12e+03      |
|    cost_values           | 354           |
|    entropy_loss          | -2.98         |
|    explained_variance    | -4.77e-07     |
|    lagrangian_multiplier | 17.9          |
|    learning_rate         | 0.0003        |
|    loss                  | -355          |
|    n_updates             | 560           |
|    policy_gradient_loss  | -0.00352      |
|    std                   | 1.08          |
|    value_loss            | 3.61          |
--------------------------------------------
slurmstepd: error: *** STEP 114555.3 ON gail.ist.berkeley.edu CANCELLED AT 2023-12-27T19:18:49 ***
slurmstepd: error: *** STEP 114555.2 ON dqn.ist.berkeley.edu CANCELLED AT 2023-12-27T19:18:49 ***
slurmstepd: error: *** STEP 114555.1 ON ddpg.ist.berkeley.edu CANCELLED AT 2023-12-27T19:18:49 ***
slurmstepd: error: *** JOB 114555 ON airl.ist.berkeley.edu CANCELLED AT 2023-12-28T03:18:49 ***
slurmstepd: error: *** STEP 114555.0 ON airl.ist.berkeley.edu CANCELLED AT 2023-12-28T03:18:49 ***
