wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230813_010728-974c757e-cc7c-400f-b5b5-8bd0a3ea7ca5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol_step_per_epoch20000_target_kl0.01-aa30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO/runs/974c757e-cc7c-400f-b5b5-8bd0a3ea7ca5
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
[32;1mLogging data to logs/PPO/parking-v0-cost-10/ppol_step_per_epoch20000_target_kl0.01-aa30/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "batch_size":	256,
    "buffer_size":	100000,
    "constraints":	false,
    "cost_limit":	10,
    "deterministic_eval":	true,
    "device":	"cpu",
    "dual_clip":	null,
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	20,
    "epoch":	600,
    "eps_clip":	0.2,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "lagrangian_pid":	[
        0.05,
        0.0005,
        0.1
    ],
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.0005,
    "max_batchsize":	100000,
    "max_grad_norm":	0.5,
    "name":	"ppol_step_per_epoch20000_target_kl0.01-aa30",
    "norm_adv":	true,
    "prefix":	"ppol",
    "project":	"PPO",
    "recompute_adv":	false,
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "rescaling":	true,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "use_lagrangian":	true,
    "value_clip":	false,
    "verbose":	true,
    "vf_coef":	0.25,
    "worker":	"ShmemVectorEnv"
}
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230812_180729-20a730ae-c328-4a41-a39e-07d1301727c5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol_step_per_epoch20000_target_kl0.01-be0d
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO/runs/20a730ae-c328-4a41-a39e-07d1301727c5
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230812_180729-60ba4661-74ad-43e2-9b08-8fe540c14294
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol_step_per_epoch20000_target_kl0.008-280a
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO/runs/60ba4661-74ad-43e2-9b08-8fe540c14294
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
[32;1mLogging data to logs/PPO/parking-v0-cost-10/ppol_step_per_epoch20000_target_kl0.01-be0d/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "batch_size":	256,
    "buffer_size":	100000,
    "constraints":	false,
    "cost_limit":	10,
    "deterministic_eval":	true,
    "device":	"cpu",
    "dual_clip":	null,
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	20,
    "epoch":	300,
    "eps_clip":	0.2,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "lagrangian_pid":	[
        0.05,
        0.0005,
        0.1
    ],
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.0005,
    "max_batchsize":	100000,
    "max_grad_norm":	0.5,
    "name":	"ppol_step_per_epoch20000_target_kl0.01-be0d",
    "norm_adv":	true,
    "prefix":	"ppol",
    "project":	"PPO",
    "recompute_adv":	false,
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "rescaling":	true,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "use_lagrangian":	true,
    "value_clip":	false,
    "verbose":	true,
    "vf_coef":	0.25,
    "worker":	"ShmemVectorEnv"
}
[32;1mLogging data to logs/PPO/parking-v0-cost-10/ppol_step_per_epoch20000_target_kl0.008-280a/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "batch_size":	256,
    "buffer_size":	100000,
    "constraints":	false,
    "cost_limit":	10,
    "deterministic_eval":	true,
    "device":	"cpu",
    "dual_clip":	null,
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	20,
    "epoch":	600,
    "eps_clip":	0.2,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "lagrangian_pid":	[
        0.05,
        0.0005,
        0.1
    ],
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.0005,
    "max_batchsize":	100000,
    "max_grad_norm":	0.5,
    "name":	"ppol_step_per_epoch20000_target_kl0.008-280a",
    "norm_adv":	true,
    "prefix":	"ppol",
    "project":	"PPO",
    "recompute_adv":	false,
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "rescaling":	true,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.008,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "use_lagrangian":	true,
    "value_clip":	false,
    "verbose":	true,
    "vf_coef":	0.25,
    "worker":	"ShmemVectorEnv"
}
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230812_180730-a62297d2-f800-4ab3-a3d5-b9d25b260001
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol_step_per_epoch20000_target_kl0.005-f4f0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO/runs/a62297d2-f800-4ab3-a3d5-b9d25b260001
[32;1mLogging data to logs/PPO/parking-v0-cost-10/ppol_step_per_epoch20000_target_kl0.005-f4f0/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "batch_size":	256,
    "buffer_size":	100000,
    "constraints":	false,
    "cost_limit":	10,
    "deterministic_eval":	true,
    "device":	"cpu",
    "dual_clip":	null,
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	20,
    "epoch":	300,
    "eps_clip":	0.2,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "lagrangian_pid":	[
        0.05,
        0.0005,
        0.1
    ],
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.0005,
    "max_batchsize":	100000,
    "max_grad_norm":	0.5,
    "name":	"ppol_step_per_epoch20000_target_kl0.005-f4f0",
    "norm_adv":	true,
    "prefix":	"ppol",
    "project":	"PPO",
    "recompute_adv":	false,
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "rescaling":	true,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.005,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "use_lagrangian":	true,
    "value_clip":	false,
    "verbose":	true,
    "vf_coef":	0.25,
    "worker":	"ShmemVectorEnv"
}
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230812_180729-073f598f-72c9-4c95-8a7d-711dd5165f6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol_step_per_epoch20000_target_kl0.008-8f65
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO/runs/073f598f-72c9-4c95-8a7d-711dd5165f6d
[32;1mLogging data to logs/PPO/parking-v0-cost-10/ppol_step_per_epoch20000_target_kl0.008-8f65/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "batch_size":	256,
    "buffer_size":	100000,
    "constraints":	false,
    "cost_limit":	10,
    "deterministic_eval":	true,
    "device":	"cpu",
    "dual_clip":	null,
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	20,
    "epoch":	300,
    "eps_clip":	0.2,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "lagrangian_pid":	[
        0.05,
        0.0005,
        0.1
    ],
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.0005,
    "max_batchsize":	100000,
    "max_grad_norm":	0.5,
    "name":	"ppol_step_per_epoch20000_target_kl0.008-8f65",
    "norm_adv":	true,
    "prefix":	"ppol",
    "project":	"PPO",
    "recompute_adv":	false,
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "rescaling":	true,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.008,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "use_lagrangian":	true,
    "value_clip":	false,
    "verbose":	true,
    "vf_coef":	0.25,
    "worker":	"ShmemVectorEnv"
}
slurmstepd: error: *** STEP 39834.3 ON gan.ist.berkeley.edu CANCELLED AT 2023-08-12T18:07:39 ***
slurmstepd: error: *** STEP 39834.2 ON gail.ist.berkeley.edu CANCELLED AT 2023-08-12T18:07:39 ***
slurmstepd: error: *** STEP 39834.1 ON ddpg.ist.berkeley.edu CANCELLED AT 2023-08-12T18:07:39 ***
slurmstepd: error: *** JOB 39834 ON airl.ist.berkeley.edu CANCELLED AT 2023-08-13T01:07:39 ***
slurmstepd: error: *** STEP 39834.0 ON airl.ist.berkeley.edu CANCELLED AT 2023-08-13T01:07:39 ***
wandb: Waiting for W&B process to finish... (failed 15). Press Control-C to abort syncing.
