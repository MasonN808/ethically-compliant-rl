wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240130_174225-uzbcif3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-wind-71
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/seed-testing
wandb: üöÄ View run at https://wandb.ai/ecrl/seed-testing/runs/uzbcif3k
Using cpu device
------------------------------------
| avg_speed          | 0.114       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.114       |
| reward             | -0.40254623 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.59e+03   |
| time/              |             |
|    fps             | 98          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 0.803        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.803        |
| reward                   | -0.88885176  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.85e+03    |
| time/                    |              |
|    fps                   | 96           |
|    iterations            | 2            |
|    time_elapsed          | 42           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0034414995 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 240          |
|    cost_values           | 0.0235       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00357      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 367          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 1            |
|    value_loss            | 806          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.68         |
| reward                   | -0.926823    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.82e+03    |
| time/                    |              |
|    fps                   | 96           |
|    iterations            | 3            |
|    time_elapsed          | 63           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0061845565 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 227          |
|    cost_values           | -0.193       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0676       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 686          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.01         |
|    value_loss            | 1.43e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.57         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.57         |
| reward                   | -1.2337818   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.75e+03    |
| time/                    |              |
|    fps                   | 96           |
|    iterations            | 4            |
|    time_elapsed          | 85           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0037988627 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.42         |
|    cost_value_loss       | 156          |
|    cost_values           | -0.34        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.11         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 508          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 1.01         |
|    value_loss            | 1.05e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.488        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.488        |
| reward                   | -0.8480502   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.74e+03    |
| time/                    |              |
|    fps                   | 96           |
|    iterations            | 5            |
|    time_elapsed          | 106          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0070569185 |
|    clip_fraction         | 0.053        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 185          |
|    cost_values           | -0.269       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.208        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 374          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 1.01         |
|    value_loss            | 785          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.09        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.09        |
| reward                   | -0.99639636 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.64e+03   |
| time/                    |             |
|    fps                   | 96          |
|    iterations            | 6           |
|    time_elapsed          | 127         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.005834993 |
|    clip_fraction         | 0.0238      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 226         |
|    cost_values           | -0.583      |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.235       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 420         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 1.01        |
|    value_loss            | 864         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.68627906  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.57e+03    |
| time/                    |              |
|    fps                   | 96           |
|    iterations            | 7            |
|    time_elapsed          | 149          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0042045964 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.69         |
|    cost_value_loss       | 87.5         |
|    cost_values           | -0.0428      |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -1.37        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 201          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00536     |
|    std                   | 1.02         |
|    value_loss            | 422          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.204       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.204       |
| reward                   | -0.8342897  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 95          |
|    iterations            | 8           |
|    time_elapsed          | 170         |
|    total_timesteps       | 16384       |
| train/                   |             |
|    approx_kl             | 0.002639722 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.72        |
|    cost_value_loss       | 40.3        |
|    cost_values           | -0.49       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0668      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 170         |
|    n_updates             | 70          |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 1.02        |
|    value_loss            | 369         |
------------------------------------------
slurmstepd: error: *** JOB 124296 ON vae.ist.berkeley.edu CANCELLED AT 2024-01-30T17:45:22 ***
slurmstepd: error: *** STEP 124296.0 ON vae.ist.berkeley.edu CANCELLED AT 2024-01-30T17:45:22 ***
