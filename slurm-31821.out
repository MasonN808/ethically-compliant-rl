wandb: WARNING `resume` will be ignored since W&B syncing is set to `offline`. Starting a new run with run id 6f0ef3c9-e19b-450e-90c8-ab327e5bb2fb.
wandb: Tracking run with wandb version 0.14.2
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
[32;1mLogging data to logs/fast-safe-rl/parking-v0-cost-10/sacl_gamma0.99_step_per_epoch20000-1e67/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "actor_lr":	0.0005,
    "alpha":	0.005,
    "alpha_lr":	0.0003,
    "auto_alpha":	true,
    "batch_size":	256,
    "buffer_size":	100000,
    "conditioned_sigma":	true,
    "cost_limit":	10,
    "critic_lr":	0.001,
    "deterministic_eval":	true,
    "device":	"cuda",
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	2,
    "epoch":	250,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "lagrangian_pid":	[
        0.05,
        0.0005,
        0.1
    ],
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.001,
    "n_step":	2,
    "name":	"sacl_gamma0.99_step_per_epoch20000-1e67",
    "prefix":	"sacl",
    "project":	"fast-safe-rl",
    "render":	null,
    "render_mode":	null,
    "rescaling":	true,
    "resume":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "tau":	0.05,
    "testing_num":	2,
    "thread":	320,
    "training_num":	10,
    "unbounded":	false,
    "update_per_step":	0.2,
    "use_default_cfg":	false,
    "use_lagrangian":	true,
    "verbose":	true,
    "worker":	"ShmemVectorEnv"
}
Epoch #1:   0%|          | 0/20000 [00:00<?, ?it/s]Epoch #1:   8%|7         | 1500/20000 [00:06<01:19, 231.38it/s]Epoch #1:   8%|7         | 1500/20000 [00:06<01:19, 231.27it/s]
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/SAC/train_SAC.py", line 307, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/SAC/train_SAC.py", line 284, in train
    for epoch, epoch_stat, info in trainer:
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 205, in __next__
    self.policy_update_fn(stats_train)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/offpolicy.py", line 104, in policy_update_fn
    self.policy.update(self.batch_size, self.train_collector.buffer)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 361, in update
    batch = self.process_fn(batch, buffer, indices)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/sac_lag.py", line 150, in process_fn
    batch = self.compute_nstep_returns(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 507, in compute_nstep_returns
    target_q_list = target_q_fn(buffer, terminal)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/sac_lag.py", line 143, in _target_q
    target_q, _ = self.critics_old[i].predict(batch.obs_next, act)
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'new_net_class' object has no attribute 'predict'
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/SAC/train_SAC.py", line 307, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/SAC/train_SAC.py", line 284, in train
    for epoch, epoch_stat, info in trainer:
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 205, in __next__
    self.policy_update_fn(stats_train)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/offpolicy.py", line 104, in policy_update_fn
    self.policy.update(self.batch_size, self.train_collector.buffer)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 361, in update
    batch = self.process_fn(batch, buffer, indices)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/sac_lag.py", line 150, in process_fn
    batch = self.compute_nstep_returns(
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/base_policy.py", line 507, in compute_nstep_returns
    target_q_list = target_q_fn(buffer, terminal)
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/policy/sac_lag.py", line 143, in _target_q
    target_q, _ = self.critics_old[i].predict(batch.obs_next, act)
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'new_net_class' object has no attribute 'predict'
wandb: Waiting for W&B process to finish... (failed 1).
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /nas/ucb/mason/ethically-compliant-rl/wandb/offline-run-20230801_182756-6f0ef3c9-e19b-450e-90c8-ab327e5bb2fb
wandb: Find logs at: ./wandb/offline-run-20230801_182756-6f0ef3c9-e19b-450e-90c8-ab327e5bb2fb/logs
srun: error: airl.ist.berkeley.edu: task 0: Exited with exit code 1
