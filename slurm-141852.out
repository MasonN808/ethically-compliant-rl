wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240222_032511-knrahchi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run auspicious-orchid-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/knrahchi
Using cpu device
------------------------------------
| avg_speed          | 1.71        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.71        |
| reward             | -0.80434805 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.37e+03   |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2048        |
------------------------------------
------------------------------------------
| avg_speed                | 4.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.11        |
| reward                   | -0.96760255 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.004496456 |
|    clip_fraction         | 0.0576      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0507      |
|    cost_value_loss       | 0.0369      |
|    cost_values           | 0.0602      |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -0.000195   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 211         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 1           |
|    value_loss            | 495         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.52        |
| reward                   | -0.7211884  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 91          |
|    total_timesteps       | 6144        |
| train/                   |             |
|    approx_kl             | 0.004766916 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.112       |
|    cost_value_loss       | 0.136       |
|    cost_values           | 0.108       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 318         |
|    n_updates             | 20          |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.997       |
|    value_loss            | 668         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.46         |
| reward                   | -1.1144751   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 126          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0038167853 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.192        |
|    cost_value_loss       | 0.205        |
|    cost_values           | 0.188        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 182          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.996        |
|    value_loss            | 386          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.46       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.46       |
| reward                   | -1.0257218 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -1.26e+03  |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 5          |
|    time_elapsed          | 161        |
|    total_timesteps       | 10240      |
| train/                   |            |
|    approx_kl             | 0.00535836 |
|    clip_fraction         | 0.0354     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.502      |
|    cost_value_loss       | 0.729      |
|    cost_values           | 0.479      |
|    entropy               | -2.83      |
|    entropy_loss          | -2.83      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 101        |
|    n_updates             | 40         |
|    policy_gradient_loss  | -0.00216   |
|    std                   | 0.999      |
|    value_loss            | 210        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2202747   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0052352822 |
|    clip_fraction         | 0.0444       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.402        |
|    cost_value_loss       | 0.0186       |
|    cost_values           | 0.411        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 193          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 0.997        |
|    value_loss            | 390          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.59064764  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0016469301 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.376        |
|    cost_value_loss       | 0.096        |
|    cost_values           | 0.38         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 182          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.993        |
|    value_loss            | 374          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.33         |
| reward                   | -1.0966492   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0034170153 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.368        |
|    cost_value_loss       | 0.0777       |
|    cost_values           | 0.369        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 122          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.000979    |
|    std                   | 0.992        |
|    value_loss            | 257          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -2.4657073   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 299          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0042547323 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.337        |
|    cost_value_loss       | 0.0395       |
|    cost_values           | 0.34         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 269          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.995        |
|    value_loss            | 549          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -2.2603016   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0052369502 |
|    clip_fraction         | 0.0601       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.617        |
|    cost_value_loss       | 0.744        |
|    cost_values           | 0.594        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 230          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00444     |
|    std                   | 0.997        |
|    value_loss            | 475          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -2.20581     |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0035896855 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.477        |
|    cost_value_loss       | 0.00406      |
|    cost_values           | 0.489        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 341          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.997        |
|    value_loss            | 694          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.4714636   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 402          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0024794445 |
|    clip_fraction         | 0.00967      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.421        |
|    cost_value_loss       | 0.0225       |
|    cost_values           | 0.428        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 302          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.000643    |
|    std                   | 0.998        |
|    value_loss            | 662          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.35         |
| reward                   | -1.2512845   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0048236204 |
|    clip_fraction         | 0.0582       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.513        |
|    cost_value_loss       | 0.515        |
|    cost_values           | 0.506        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 172          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 0.994        |
|    value_loss            | 378          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42718852  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 471          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0037884593 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.69         |
|    cost_value_loss       | 0.794        |
|    cost_values           | 0.677        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 107          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.989        |
|    value_loss            | 220          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -2.1033502   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 505          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0053911344 |
|    clip_fraction         | 0.0564       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.581        |
|    cost_value_loss       | 0.0234       |
|    cost_values           | 0.592        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 194          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 0.985        |
|    value_loss            | 403          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.284       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.284       |
| reward                   | -0.5211418  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 539         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.003077503 |
|    clip_fraction         | 0.0133      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.511       |
|    cost_value_loss       | 0.039       |
|    cost_values           | 0.518       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 295         |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.982       |
|    value_loss            | 610         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.56        |
| reward                   | -0.5457295  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.002932393 |
|    clip_fraction         | 0.00181     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.422       |
|    cost_value_loss       | 0.00394     |
|    cost_values           | 0.431       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 304         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -6.71e-05   |
|    std                   | 0.983       |
|    value_loss            | 618         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7113546   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 608          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0030661628 |
|    clip_fraction         | 0.0476       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.458        |
|    cost_value_loss       | 0.222        |
|    cost_values           | 0.457        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 128          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.985        |
|    value_loss            | 268          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.6164314  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 642         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.004327625 |
|    clip_fraction         | 0.0374      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.465       |
|    cost_value_loss       | 0.158       |
|    cost_values           | 0.464       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 210         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.985       |
|    value_loss            | 445         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.89912045  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 676          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0043487856 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.462        |
|    cost_value_loss       | 0.144        |
|    cost_values           | 0.462        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 173          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.985        |
|    value_loss            | 340          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.99101585  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 710          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0025408447 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.565        |
|    cost_value_loss       | 0.426        |
|    cost_values           | 0.557        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 139          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.978        |
|    value_loss            | 288          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3530009   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 744          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0030932343 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.599        |
|    cost_value_loss       | 0.256        |
|    cost_values           | 0.598        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 188          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00079     |
|    std                   | 0.975        |
|    value_loss            | 385          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.6898972   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 779          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0016228925 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.587        |
|    cost_value_loss       | 0.212        |
|    cost_values           | 0.588        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 137          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.000732    |
|    std                   | 0.973        |
|    value_loss            | 291          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.9436478   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 813          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0016948209 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.552        |
|    cost_value_loss       | 0.197        |
|    cost_values           | 0.554        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 183          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.000119    |
|    std                   | 0.972        |
|    value_loss            | 387          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.5175114   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 847          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0042290967 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.518        |
|    cost_value_loss       | 0.231        |
|    cost_values           | 0.52         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 205          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.966        |
|    value_loss            | 429          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0301387   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 881          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0032390708 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.607        |
|    cost_value_loss       | 0.293        |
|    cost_values           | 0.601        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 113          |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00079     |
|    std                   | 0.964        |
|    value_loss            | 233          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9578354   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 916          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0046651335 |
|    clip_fraction         | 0.0405       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.576        |
|    cost_value_loss       | 0.105        |
|    cost_values           | 0.58         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 218          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.965        |
|    value_loss            | 427          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.8019103   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 950          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0022703682 |
|    clip_fraction         | 0.0375       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.633        |
|    cost_value_loss       | 0.372        |
|    cost_values           | 0.629        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 152          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.957        |
|    value_loss            | 322          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.58771574  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 985          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0031319559 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.585        |
|    cost_value_loss       | 0.165        |
|    cost_values           | 0.59         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 139          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.000727    |
|    std                   | 0.952        |
|    value_loss            | 281          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.7750621  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 61440       |
| train/                   |             |
|    approx_kl             | 0.003609443 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.513       |
|    cost_value_loss       | 0.0822      |
|    cost_values           | 0.517       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 222         |
|    n_updates             | 290         |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 0.95        |
|    value_loss            | 477         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4744132   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1052         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0035142053 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.474        |
|    cost_value_loss       | 0.134        |
|    cost_values           | 0.476        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 189          |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.95         |
|    value_loss            | 387          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.422272    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1086         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0024730377 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.442        |
|    cost_value_loss       | 0.0782       |
|    cost_values           | 0.443        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.946        |
|    value_loss            | 253          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.146518    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1120         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0028563025 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.408        |
|    cost_value_loss       | 0.0583       |
|    cost_values           | 0.411        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.947        |
|    value_loss            | 326          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.37680036  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1154         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0019461142 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.356        |
|    cost_value_loss       | 0.0224       |
|    cost_values           | 0.359        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 187          |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.000238    |
|    std                   | 0.948        |
|    value_loss            | 388          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.96886057  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1189         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0039603035 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.803        |
|    cost_value_loss       | 1.5          |
|    cost_values           | 0.772        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 145          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.000717    |
|    std                   | 0.95         |
|    value_loss            | 296          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.9143496   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1224         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0033597932 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.863        |
|    cost_value_loss       | 0.301        |
|    cost_values           | 0.863        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.2         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.000439    |
|    std                   | 0.945        |
|    value_loss            | 158          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.8675673  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1258        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.003821495 |
|    clip_fraction         | 0.0135      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.714       |
|    cost_value_loss       | 0.00849     |
|    cost_values           | 0.728       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 171         |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.000993   |
|    std                   | 0.94        |
|    value_loss            | 349         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9876796   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1293         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0047111968 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.731        |
|    cost_value_loss       | 0.283        |
|    cost_values           | 0.73         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.2         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.000778    |
|    std                   | 0.935        |
|    value_loss            | 184          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -2.3172219   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1327         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0037109086 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.658        |
|    cost_value_loss       | 0.0837       |
|    cost_values           | 0.664        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 102          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.000989    |
|    std                   | 0.929        |
|    value_loss            | 229          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -1.886627  |
| rollout/                 |            |
|    ep_len_mean           | 988        |
|    ep_rew_mean           | -1.28e+03  |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 40         |
|    time_elapsed          | 1361       |
|    total_timesteps       | 81920      |
| train/                   |            |
|    approx_kl             | 0.00393732 |
|    clip_fraction         | 0.0413     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.589      |
|    cost_value_loss       | 0.0661     |
|    cost_values           | 0.593      |
|    entropy               | -2.69      |
|    entropy_loss          | -2.69      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 263        |
|    n_updates             | 390        |
|    policy_gradient_loss  | -0.00291   |
|    std                   | 0.927      |
|    value_loss            | 530        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.7224084   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1395         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0036438107 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.636        |
|    cost_value_loss       | 0.356        |
|    cost_values           | 0.632        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 184          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.929        |
|    value_loss            | 395          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7297377   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1429         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0018023823 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.602        |
|    cost_value_loss       | 0.142        |
|    cost_values           | 0.605        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 113          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.000841    |
|    std                   | 0.929        |
|    value_loss            | 239          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.85         |
| reward                   | -0.65712786  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 43           |
|    time_elapsed          | 1464         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0048123295 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.82         |
|    cost_value_loss       | 1.12         |
|    cost_values           | 0.804        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 110          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.928        |
|    value_loss            | 224          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.83871317  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 44           |
|    time_elapsed          | 1498         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0030854156 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.8          |
|    cost_value_loss       | 0.217        |
|    cost_values           | 0.804        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.5         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.922        |
|    value_loss            | 131          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0781001   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 45           |
|    time_elapsed          | 1532         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0052658524 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.905        |
|    cost_value_loss       | 0.855        |
|    cost_values           | 0.898        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.2         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.923        |
|    value_loss            | 140          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7918039   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 46           |
|    time_elapsed          | 1566         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0043635843 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.964        |
|    cost_value_loss       | 0.52         |
|    cost_values           | 0.961        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.6         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.921        |
|    value_loss            | 136          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.88724     |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 47           |
|    time_elapsed          | 1600         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0041260323 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.855        |
|    cost_value_loss       | 0.111        |
|    cost_values           | 0.865        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 171          |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.914        |
|    value_loss            | 353          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.67492545  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 48           |
|    time_elapsed          | 1634         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0036057374 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.84         |
|    cost_value_loss       | 0.319        |
|    cost_values           | 0.841        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.9         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.911        |
|    value_loss            | 146          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.90889245  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 49           |
|    time_elapsed          | 1669         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0051174643 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.977        |
|    cost_value_loss       | 0.867        |
|    cost_values           | 0.823        |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.2         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.905        |
|    value_loss            | 92.7         |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/knrahchi
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -1.1455791 |
| rollout/           |            |
|    ep_len_mean     | 990        |
|    ep_rew_mean     | -1.25e+03  |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7946338   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0029408743 |
|    clip_fraction         | 0.0431       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.801        |
|    cost_value_loss       | 0.229        |
|    cost_values           | 0.866        |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 82.1         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.905        |
|    value_loss            | 173          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1884116   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0043210806 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.764        |
|    cost_value_loss       | 0.194        |
|    cost_values           | 0.794        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 93.3         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.902        |
|    value_loss            | 203          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.943812   |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.005080208 |
|    clip_fraction         | 0.0342      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.747       |
|    cost_value_loss       | 0.318       |
|    cost_values           | 0.754       |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 40.3        |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.895       |
|    value_loss            | 90.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9374732   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0029521114 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.721        |
|    cost_value_loss       | 0.196        |
|    cost_values           | 0.734        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.892        |
|    value_loss            | 213          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.5327718   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0068964465 |
|    clip_fraction         | 0.0599       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.632        |
|    cost_value_loss       | 0.0762       |
|    cost_values           | 0.685        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 100          |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.895        |
|    value_loss            | 212          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4899024   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0037245562 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.585        |
|    cost_value_loss       | 0.0714       |
|    cost_values           | 0.613        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.894        |
|    value_loss            | 224          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.88793015  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0016483247 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.59         |
|    cost_value_loss       | 0.219        |
|    cost_values           | 0.586        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 149          |
|    n_updates             | 560          |
|    policy_gradient_loss  | 3.32e-05     |
|    std                   | 0.895        |
|    value_loss            | 314          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7051964   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0029354992 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.676        |
|    cost_value_loss       | 0.51         |
|    cost_values           | 0.624        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 153          |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.895        |
|    value_loss            | 323          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4780701   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0029445358 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.805        |
|    cost_value_loss       | 0.726        |
|    cost_values           | 0.762        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.896        |
|    value_loss            | 66.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1489491   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0029551687 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.987        |
|    cost_value_loss       | 0.866        |
|    cost_values           | 0.917        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.7         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.000365    |
|    std                   | 0.901        |
|    value_loss            | 66.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.8634957   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0022229317 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.39         |
|    cost_values           | 0.926        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.5         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.000427    |
|    std                   | 0.902        |
|    value_loss            | 79.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9704575   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0014633373 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.791        |
|    cost_value_loss       | 0.0303       |
|    cost_values           | 0.942        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.4         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.902        |
|    value_loss            | 136          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.4495165   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 14           |
|    time_elapsed          | 478          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0054584527 |
|    clip_fraction         | 0.0622       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.928        |
|    cost_value_loss       | 0.712        |
|    cost_values           | 0.89         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.5         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00434     |
|    std                   | 0.883        |
|    value_loss            | 47.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.97139245 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 15          |
|    time_elapsed          | 513         |
|    total_timesteps       | 131072      |
| train/                   |             |
|    approx_kl             | 0.003024392 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.555       |
|    cost_values           | 0.957       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.7        |
|    n_updates             | 630         |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.877       |
|    value_loss            | 87.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.69         |
| reward                   | -0.5379129   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 548          |
|    total_timesteps       | 133120       |
| train/                   |              |
|    approx_kl             | 0.0011513341 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.14         |
|    cost_values           | 0.951        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.6         |
|    n_updates             | 640          |
|    policy_gradient_loss  | -0.000354    |
|    std                   | 0.87         |
|    value_loss            | 36.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.22371982 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 17          |
|    time_elapsed          | 583         |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.004609588 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.886       |
|    cost_value_loss       | 0.238       |
|    cost_values           | 0.865       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 70.1        |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.869       |
|    value_loss            | 144         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5956024   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 618          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0016003365 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 1            |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00028     |
|    std                   | 0.869        |
|    value_loss            | 20.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.77901673  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 652          |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0047574714 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 0.985        |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.9         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.862        |
|    value_loss            | 52.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.7283912  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 686         |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.003601771 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 3.06        |
|    cost_values           | 1.1         |
|    entropy               | -2.52       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.76        |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.000609   |
|    std                   | 0.852       |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.98268515  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 721          |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0037225746 |
|    clip_fraction         | 0.0502       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 0.965        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.2         |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.000579    |
|    std                   | 0.851        |
|    value_loss            | 85           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9585378   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 755          |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0045977896 |
|    clip_fraction         | 0.0503       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.6          |
|    cost_values           | 0.976        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.849        |
|    value_loss            | 40.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.9276298  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 790         |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.002483535 |
|    clip_fraction         | 0.0498      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 1.96        |
|    cost_values           | 0.996       |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.2        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.849       |
|    value_loss            | 65.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89863974  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 824          |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0013200268 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.954        |
|    cost_value_loss       | 0.48         |
|    cost_values           | 0.971        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.5         |
|    n_updates             | 720          |
|    policy_gradient_loss  | 5.07e-05     |
|    std                   | 0.848        |
|    value_loss            | 116          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.71315837 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 858         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.004227221 |
|    clip_fraction         | 0.00854     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.96        |
|    cost_value_loss       | 0.49        |
|    cost_values           | 0.961       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.5        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.000805   |
|    std                   | 0.841       |
|    value_loss            | 57.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.40127972  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 892          |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0025587657 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.925        |
|    cost_value_loss       | 0.328        |
|    cost_values           | 0.95         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.000602    |
|    std                   | 0.839        |
|    value_loss            | 23.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9456597  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 926         |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.004261166 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 3.79        |
|    cost_values           | 1.19        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.36        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.000393   |
|    std                   | 0.829       |
|    value_loss            | 14.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1450664  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 961         |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.005015688 |
|    clip_fraction         | 0.0509      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 1.31        |
|    cost_values           | 1.22        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.1        |
|    n_updates             | 760         |
|    policy_gradient_loss  | 0.00076     |
|    std                   | 0.825       |
|    value_loss            | 29.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.26         |
| reward                   | -0.6962272   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 996          |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0037765708 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.49         |
|    cost_values           | 1.02         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.45        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.826        |
|    value_loss            | 26.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.76         |
| reward                   | -0.7249557   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1031         |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0040892703 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 5.71         |
|    cost_values           | 1.37         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.01         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.000304    |
|    std                   | 0.822        |
|    value_loss            | 4.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.28        |
| reward                   | -0.79674906 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1065        |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.006683376 |
|    clip_fraction         | 0.0985      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 0.0793      |
|    cost_values           | 1.67        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 790         |
|    policy_gradient_loss  | 2.47e-05    |
|    std                   | 0.819       |
|    value_loss            | 34.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.43805584 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1099        |
|    total_timesteps       | 165888      |
| train/                   |             |
|    approx_kl             | 0.004012539 |
|    clip_fraction         | 0.0116      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 0.0368      |
|    cost_values           | 1.07        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 800         |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.818       |
|    value_loss            | 37.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.43096852 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1134        |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.004993646 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.955       |
|    cost_value_loss       | 0.885       |
|    cost_values           | 0.903       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.2        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.822       |
|    value_loss            | 35.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8539713   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1169         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0036146769 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 4.97         |
|    cost_values           | 1.1          |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.53         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.819        |
|    value_loss            | 9.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.9751887  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1204        |
|    total_timesteps       | 172032      |
| train/                   |             |
|    approx_kl             | 0.004277393 |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 2.11        |
|    cost_values           | 1.18        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 830         |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.813       |
|    value_loss            | 20.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.56128514  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1238         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0020775483 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 1.27         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.89         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.000231    |
|    std                   | 0.816        |
|    value_loss            | 9.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.23         |
| reward                   | -0.6682312   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -990         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0043002097 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 0.0598       |
|    cost_values           | 1.45         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.52         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.818        |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.832745   |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -974        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1306        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.010757305 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 0.856       |
|    cost_values           | 1.19        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.1        |
|    n_updates             | 860         |
|    policy_gradient_loss  | 0.00181     |
|    std                   | 0.812       |
|    value_loss            | 60          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.482259    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -959         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1340         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0044677556 |
|    clip_fraction         | 0.133        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.13         |
|    cost_values           | 1.07         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.61         |
|    n_updates             | 870          |
|    policy_gradient_loss  | 0.00632      |
|    std                   | 0.812        |
|    value_loss            | 17.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.80915785  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -952         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1375         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0009948873 |
|    clip_fraction         | 0.0424       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.911        |
|    cost_value_loss       | 0.361        |
|    cost_values           | 0.914        |
|    entropy               | -2.41        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.12         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.808        |
|    value_loss            | 4.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.84532523  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -943         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1410         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0013354633 |
|    clip_fraction         | 0.0847       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.751        |
|    cost_value_loss       | 0.0287       |
|    cost_values           | 0.848        |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 890          |
|    policy_gradient_loss  | 0.00395      |
|    std                   | 0.808        |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.8158304  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -938        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1444        |
|    total_timesteps       | 186368      |
| train/                   |             |
|    approx_kl             | 0.005530432 |
|    clip_fraction         | 0.052       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 2.39        |
|    cost_values           | 1.14        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.41       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 900         |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.805       |
|    value_loss            | 7.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0489588  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -932        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1478        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.004837957 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 0.191       |
|    cost_values           | 1.26        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.23        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00028    |
|    std                   | 0.803       |
|    value_loss            | 15.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75294864  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1513         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0023893553 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.869        |
|    cost_value_loss       | 0.0166       |
|    cost_values           | 0.917        |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.000349    |
|    std                   | 0.804        |
|    value_loss            | 8.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5450209   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -909         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1548         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0010582099 |
|    clip_fraction         | 0.00811      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.8          |
|    cost_values           | 0.957        |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.52         |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.802        |
|    value_loss            | 15           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.61157787 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -900        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1582        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.004897466 |
|    clip_fraction         | 0.0439      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 2.56        |
|    cost_values           | 1.11        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.2        |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.8         |
|    value_loss            | 39.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.6337482   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -882         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1617         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0034084818 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 5.7          |
|    cost_values           | 1.56         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.52         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.8          |
|    value_loss            | 3.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.93416506  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -876         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1652         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0035841165 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.13         |
|    cost_value_loss       | 5.99         |
|    cost_values           | 2.15         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.8          |
|    value_loss            | 33.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.8023603   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -869         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1687         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0023293581 |
|    clip_fraction         | 0.00986      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 1.86         |
|    cost_values           | 2.12         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.799        |
|    value_loss            | 7.45         |
-------------------------------------------
-----------------------------------
| avg_speed          | 2.32       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.32       |
| reward             | -0.8089321 |
| rollout/           |            |
|    ep_len_mean     | 967        |
|    ep_rew_mean     | -851       |
| time/              |            |
|    fps             | 81         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 6.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.68         |
| reward                   | -0.7078452   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -843         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0038820663 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.36         |
|    cost_value_loss       | 8.78         |
|    cost_values           | 2.68         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.6         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.797        |
|    value_loss            | 59.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.71          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.71          |
| reward                   | -0.63807774   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -836          |
| time/                    |               |
|    fps                   | 65            |
|    iterations            | 3             |
|    time_elapsed          | 94            |
|    total_timesteps       | 206848        |
| train/                   |               |
|    approx_kl             | 0.00090846024 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.36          |
|    cost_value_loss       | 0.224         |
|    cost_values           | 2.74          |
|    entropy               | -2.38         |
|    entropy_loss          | -2.38         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.05          |
|    n_updates             | 1000          |
|    policy_gradient_loss  | -0.000122     |
|    std                   | 0.797         |
|    value_loss            | 18.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.0616739   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -826         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0039610732 |
|    clip_fraction         | 0.00698      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 0.846        |
|    cost_values           | 2.3          |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.68         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.000743    |
|    std                   | 0.797        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.7879828   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -812         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 210944       |
| train/                   |              |
|    approx_kl             | 0.0038730898 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 2.17         |
|    cost_values           | 2.14         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.13         |
|    n_updates             | 1020         |
|    policy_gradient_loss  | -0.000959    |
|    std                   | 0.796        |
|    value_loss            | 12.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6277277   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -792         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0072317505 |
|    clip_fraction         | 0.0651       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 0.113        |
|    cost_values           | 2.13         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.18         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | 0.00205      |
|    std                   | 0.795        |
|    value_loss            | 16.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.7547583   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -787         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0064771893 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 2.04         |
|    cost_values           | 1.75         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.794        |
|    value_loss            | 27.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -1.141258     |
| rollout/                 |               |
|    ep_len_mean           | 961           |
|    ep_rew_mean           | -786          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 8             |
|    time_elapsed          | 266           |
|    total_timesteps       | 217088        |
| train/                   |               |
|    approx_kl             | 0.00072920055 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.46          |
|    cost_value_loss       | 0.183         |
|    cost_values           | 1.56          |
|    entropy               | -2.38         |
|    entropy_loss          | -2.38         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4             |
|    n_updates             | 1050          |
|    policy_gradient_loss  | 0.000327      |
|    std                   | 0.795         |
|    value_loss            | 9.29          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0808483   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0012058695 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 2.53         |
|    cost_values           | 1.36         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.64         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.000177    |
|    std                   | 0.795        |
|    value_loss            | 15.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.58        |
| reward                   | -0.40168986 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 221184      |
| train/                   |             |
|    approx_kl             | 0.005122761 |
|    clip_fraction         | 0.0247      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.95        |
|    cost_value_loss       | 3.56        |
|    cost_values           | 1.6         |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.7        |
|    n_updates             | 1070        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.792       |
|    value_loss            | 21.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -1.0597366  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -762        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 223232      |
| train/                   |             |
|    approx_kl             | 0.001702614 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 3.22        |
|    cost_values           | 1.77        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.16        |
|    n_updates             | 1080        |
|    policy_gradient_loss  | 0.000472    |
|    std                   | 0.79        |
|    value_loss            | 7.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.7110648   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0062899464 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 2.08         |
|    cost_values           | 1.75         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.4         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.789        |
|    value_loss            | 34           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.33877018  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 438          |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0026081859 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 2.82         |
|    cost_values           | 1.85         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.92         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.000626    |
|    std                   | 0.787        |
|    value_loss            | 5.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.95801663  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 472          |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0070301336 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 2.92         |
|    cost_values           | 2.13         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.791        |
|    value_loss            | 5.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4610846   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 507          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0030499506 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 2.23         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.9         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | 0.00104      |
|    std                   | 0.789        |
|    value_loss            | 31           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.95         |
| reward                   | -0.93819344  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0022353213 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 4.7          |
|    cost_values           | 2.34         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.96         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.000376    |
|    std                   | 0.79         |
|    value_loss            | 15.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.97          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.97          |
| reward                   | -0.56548965   |
| rollout/                 |               |
|    ep_len_mean           | 948           |
|    ep_rew_mean           | -738          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 17            |
|    time_elapsed          | 576           |
|    total_timesteps       | 235520        |
| train/                   |               |
|    approx_kl             | 0.00049256557 |
|    clip_fraction         | 0.0326        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.51          |
|    cost_value_loss       | 1.65          |
|    cost_values           | 2.46          |
|    entropy               | -2.35         |
|    entropy_loss          | -2.36         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.69          |
|    n_updates             | 1140          |
|    policy_gradient_loss  | -0.00051      |
|    std                   | 0.785         |
|    value_loss            | 15            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.8379121   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0002516434 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.85         |
|    cost_value_loss       | 9.11         |
|    cost_values           | 2.63         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | 0.00154      |
|    std                   | 0.783        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.9507772   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 644          |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0017527584 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.9          |
|    cost_value_loss       | 2.22         |
|    cost_values           | 2.88         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.25         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | 0.000418     |
|    std                   | 0.782        |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.8005651  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -733        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 678         |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.004732389 |
|    clip_fraction         | 0.00522     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 1.63        |
|    cost_values           | 2.78        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.79        |
|    n_updates             | 1170        |
|    policy_gradient_loss  | 0.000539    |
|    std                   | 0.781       |
|    value_loss            | 16.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.57089597  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 712          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0021084496 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 1.26         |
|    cost_values           | 2.59         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.68         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.78         |
|    value_loss            | 14.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3579687   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 746          |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0038145154 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 1.01         |
|    cost_values           | 2.45         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.000514    |
|    std                   | 0.781        |
|    value_loss            | 6.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.302947    |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 781          |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0039460864 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 0.774        |
|    cost_values           | 2.22         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.34         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.000879    |
|    std                   | 0.782        |
|    value_loss            | 18.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.170931   |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -725        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 815         |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.002684631 |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 2.03        |
|    cost_values           | 1.93        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00076    |
|    std                   | 0.781       |
|    value_loss            | 22.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0000788  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 851         |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.003716637 |
|    clip_fraction         | 0.00537     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.6         |
|    cost_value_loss       | 0.178       |
|    cost_values           | 1.77        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.000696   |
|    std                   | 0.78        |
|    value_loss            | 29.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.8275322  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 885         |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.005072618 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 1.17        |
|    cost_values           | 1.54        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.775       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.7         |
| reward                   | -0.57807285 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -732        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 919         |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.002725336 |
|    clip_fraction         | 0.00713     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 3.34        |
|    cost_values           | 1.63        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.73        |
|    n_updates             | 1240        |
|    policy_gradient_loss  | -0.000405   |
|    std                   | 0.774       |
|    value_loss            | 13.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.5         |
| reward                   | -0.58413243 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 28          |
|    time_elapsed          | 953         |
|    total_timesteps       | 258048      |
| train/                   |             |
|    approx_kl             | 0.005035937 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 0.0599      |
|    cost_values           | 1.47        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.47        |
|    n_updates             | 1250        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.772       |
|    value_loss            | 7.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7912205  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 988         |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.001511598 |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.24        |
|    cost_value_loss       | 4.1         |
|    cost_values           | 1.29        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.000263   |
|    std                   | 0.77        |
|    value_loss            | 4.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.3860261   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1022         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0041560913 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.593        |
|    cost_values           | 1.32         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.769        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.89189446 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 31          |
|    time_elapsed          | 1056        |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.005388369 |
|    clip_fraction         | 0.0083      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 2.99        |
|    cost_values           | 1.2         |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.9        |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.768       |
|    value_loss            | 71.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.9281216   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1090         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0061577912 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 2            |
|    cost_values           | 1.25         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.766        |
|    value_loss            | 8.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.2321494   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1125         |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0021721383 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 0.404        |
|    cost_values           | 1.27         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.25         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.77         |
|    value_loss            | 6.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6055352   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1159         |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0029164073 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 3.56         |
|    cost_values           | 1.43         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.769        |
|    value_loss            | 22.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.79146653  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1194         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0034420956 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 1.71         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.73         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.769        |
|    value_loss            | 18.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89830023  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1229         |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0056237183 |
|    clip_fraction         | 0.00947      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 2.69         |
|    cost_values           | 1.62         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.45         |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.000307    |
|    std                   | 0.768        |
|    value_loss            | 3.79         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.010321     |
| rollout/                 |               |
|    ep_len_mean           | 955           |
|    ep_rew_mean           | -718          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 37            |
|    time_elapsed          | 1263          |
|    total_timesteps       | 276480        |
| train/                   |               |
|    approx_kl             | 0.00056871714 |
|    clip_fraction         | 0.0106        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.02          |
|    cost_value_loss       | 1.73          |
|    cost_values           | 1.71          |
|    entropy               | -2.31         |
|    entropy_loss          | -2.31         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.2           |
|    n_updates             | 1340          |
|    policy_gradient_loss  | 0.00126       |
|    std                   | 0.768         |
|    value_loss            | 7.84          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -0.6240775   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1297         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0051301057 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 0.0527       |
|    cost_values           | 1.53         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.34         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.769        |
|    value_loss            | 9.65         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.89       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.89       |
| reward                   | -0.7599283 |
| rollout/                 |            |
|    ep_len_mean           | 955        |
|    ep_rew_mean           | -716       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 39         |
|    time_elapsed          | 1331       |
|    total_timesteps       | 280576     |
| train/                   |            |
|    approx_kl             | 0.00599748 |
|    clip_fraction         | 0.0408     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.57       |
|    cost_value_loss       | 1.95       |
|    cost_values           | 1.21       |
|    entropy               | -2.31      |
|    entropy_loss          | -2.31      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.86       |
|    n_updates             | 1360       |
|    policy_gradient_loss  | -0.00396   |
|    std                   | 0.768      |
|    value_loss            | 12.9       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.04        |
| reward                   | -0.71253824 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1366        |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.004293495 |
|    clip_fraction         | 0.00986     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.963       |
|    cost_value_loss       | 0.124       |
|    cost_values           | 0.994       |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.7         |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.000446   |
|    std                   | 0.768       |
|    value_loss            | 3.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.29        |
| reward                   | -0.73086107 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1400        |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.00321573  |
|    clip_fraction         | 0.0546      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.784       |
|    cost_value_loss       | 0.0212      |
|    cost_values           | 0.85        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 0.765       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8217368  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1435        |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.004641736 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.864       |
|    cost_value_loss       | 0.383       |
|    cost_values           | 0.855       |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.88        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.000803   |
|    std                   | 0.765       |
|    value_loss            | 7.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.464331    |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1470         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0027332064 |
|    clip_fraction         | 0.00356      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.706        |
|    cost_value_loss       | 0.0248       |
|    cost_values           | 0.849        |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00016     |
|    std                   | 0.765        |
|    value_loss            | 39.9         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.88       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.88       |
| reward                   | -0.7965357 |
| rollout/                 |            |
|    ep_len_mean           | 959        |
|    ep_rew_mean           | -728       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 44         |
|    time_elapsed          | 1506       |
|    total_timesteps       | 290816     |
| train/                   |            |
|    approx_kl             | 0.00276563 |
|    clip_fraction         | 0.00146    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.79       |
|    cost_value_loss       | 0.298      |
|    cost_values           | 0.812      |
|    entropy               | -2.3       |
|    entropy_loss          | -2.3       |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.33       |
|    n_updates             | 1410       |
|    policy_gradient_loss  | -0.000851  |
|    std                   | 0.765      |
|    value_loss            | 20.4       |
-----------------------------------------
--------------------------------------------
| avg_speed                | 8.05          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.05          |
| reward                   | -0.67894894   |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -732          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1540          |
|    total_timesteps       | 292864        |
| train/                   |               |
|    approx_kl             | 0.00073866814 |
|    clip_fraction         | 0.0124        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.13          |
|    cost_value_loss       | 1.19          |
|    cost_values           | 1.02          |
|    entropy               | -2.31         |
|    entropy_loss          | -2.3          |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.91          |
|    n_updates             | 1420          |
|    policy_gradient_loss  | -0.000552     |
|    std                   | 0.768         |
|    value_loss            | 2.61          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.5968504   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1575         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0077227955 |
|    clip_fraction         | 0.115        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 4.29         |
|    cost_values           | 1.07         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | 0.00269      |
|    std                   | 0.77         |
|    value_loss            | 38.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.7307745   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1609         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0051263003 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 3.85         |
|    cost_values           | 1.1          |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.48         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.000775    |
|    std                   | 0.77         |
|    value_loss            | 9.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.8138413   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1643         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0057101264 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 2.34         |
|    cost_values           | 1.34         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.61         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.77         |
|    value_loss            | 7.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.4210243   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1678         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0036221957 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 2.13         |
|    cost_values           | 1.71         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.77         |
|    value_loss            | 5.72         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.61116123 |
| rollout/           |             |
|    ep_len_mean     | 959         |
|    ep_rew_mean     | -721        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 303104      |
------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.82978725  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0024208776 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.54         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.2         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.000889    |
|    std                   | 0.768        |
|    value_loss            | 68           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.97          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.97          |
| reward                   | -0.927376     |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -715          |
| time/                    |               |
|    fps                   | 66            |
|    iterations            | 3             |
|    time_elapsed          | 92            |
|    total_timesteps       | 307200        |
| train/                   |               |
|    approx_kl             | 0.00089208595 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.5           |
|    cost_value_loss       | 0.819         |
|    cost_values           | 1.35          |
|    entropy               | -2.3          |
|    entropy_loss          | -2.31         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.53          |
|    n_updates             | 1490          |
|    policy_gradient_loss  | -0.000369     |
|    std                   | 0.767         |
|    value_loss            | 9.24          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.64852303 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.005100617 |
|    clip_fraction         | 0.0127      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.73        |
|    cost_value_loss       | 6.81        |
|    cost_values           | 1.36        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 0.767       |
|    value_loss            | 16.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.86395514  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 161          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0072988076 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.78         |
|    cost_value_loss       | 5.63         |
|    cost_values           | 1.78         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.4         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.767        |
|    value_loss            | 66.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.64        |
| reward                   | -0.486447   |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -706        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 196         |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.003589308 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.56        |
|    cost_value_loss       | 2.41        |
|    cost_values           | 2.18        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.765       |
|    value_loss            | 9.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49168608  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0050337925 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 0.635        |
|    cost_values           | 2.27         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.761        |
|    value_loss            | 33.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -0.8235966    |
| rollout/                 |               |
|    ep_len_mean           | 950           |
|    ep_rew_mean           | -704          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 8             |
|    time_elapsed          | 267           |
|    total_timesteps       | 317440        |
| train/                   |               |
|    approx_kl             | 0.00048648924 |
|    clip_fraction         | 0.00181       |
|    clip_range            | 0.2           |
|    cost_returns          | 1.92          |
|    cost_value_loss       | 0.454         |
|    cost_values           | 1.95          |
|    entropy               | -2.28         |
|    entropy_loss          | -2.28         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 2.42          |
|    n_updates             | 1540          |
|    policy_gradient_loss  | 0.000655      |
|    std                   | 0.759         |
|    value_loss            | 4.29          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.914874    |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0006182925 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 4.19         |
|    cost_values           | 2            |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.04         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | 0.000784     |
|    std                   | 0.759        |
|    value_loss            | 7.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.47727683  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0020484363 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 0.635        |
|    cost_values           | 2.25         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8            |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.000572    |
|    std                   | 0.76         |
|    value_loss            | 17.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.8840026  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 371         |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.004129396 |
|    clip_fraction         | 0.00464     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.03        |
|    cost_value_loss       | 0.779       |
|    cost_values           | 1.95        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.76        |
|    value_loss            | 9.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.090359    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0031100959 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 0.907        |
|    cost_values           | 1.69         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.52         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.000938    |
|    std                   | 0.759        |
|    value_loss            | 13.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.54296017  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0022312466 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 3.2          |
|    cost_values           | 1.56         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.000353    |
|    std                   | 0.759        |
|    value_loss            | 18.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.91979504  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0065640723 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 1.65         |
|    cost_values           | 1.55         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.758        |
|    value_loss            | 35.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.85          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.85          |
| reward                   | -0.5545871    |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -725          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 15            |
|    time_elapsed          | 508           |
|    total_timesteps       | 331776        |
| train/                   |               |
|    approx_kl             | 3.1318632e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.43          |
|    cost_value_loss       | 0.733         |
|    cost_values           | 1.33          |
|    entropy               | -2.28         |
|    entropy_loss          | -2.28         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 23.7          |
|    n_updates             | 1610          |
|    policy_gradient_loss  | 3.44e-05      |
|    std                   | 0.757         |
|    value_loss            | 47.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.2386295   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0010086311 |
|    clip_fraction         | 0.00332      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.994        |
|    cost_value_loss       | 0.0312       |
|    cost_values           | 1.03         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.000149    |
|    std                   | 0.754        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.82884055  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0018913609 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.962        |
|    cost_value_loss       | 0.614        |
|    cost_values           | 0.973        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.54         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.000913    |
|    std                   | 0.757        |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9143899  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 611         |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.002011607 |
|    clip_fraction         | 0.0374      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 6.29        |
|    cost_values           | 1.24        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 1640        |
|    policy_gradient_loss  | 0.000767    |
|    std                   | 0.759       |
|    value_loss            | 24.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.5399538   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0034039395 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 1.56         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3            |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.000856    |
|    std                   | 0.758        |
|    value_loss            | 4.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.8605164   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0061851526 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 2.59         |
|    cost_values           | 1.64         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.759        |
|    value_loss            | 5.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46469143  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 714          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0042493604 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 2.34         |
|    cost_values           | 1.79         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.41         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.76         |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0220644  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 749         |
|    total_timesteps       | 346112      |
| train/                   |             |
|    approx_kl             | 0.002449596 |
|    clip_fraction         | 0.000439    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 0.465       |
|    cost_values           | 1.55        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.96        |
|    n_updates             | 1680        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.759       |
|    value_loss            | 21.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.0258559   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 783          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0010833798 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 9.77         |
|    cost_values           | 1.43         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.51         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.000331    |
|    std                   | 0.759        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9357157  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 817         |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.002947218 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 1.91        |
|    cost_values           | 1.58        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.1         |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.758       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.71        |
| reward                   | -0.7584278  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 852         |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.002036669 |
|    clip_fraction         | 0.00786     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 0.714       |
|    cost_values           | 1.58        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.28       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.48        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.000418   |
|    std                   | 0.754       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0301121   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 886          |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0010517524 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.91         |
|    cost_value_loss       | 8.64         |
|    cost_values           | 1.61         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.03         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | 6.15e-06     |
|    std                   | 0.753        |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.7765235   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 921          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0008570069 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 6.53         |
|    cost_values           | 1.74         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.1         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.0002      |
|    std                   | 0.753        |
|    value_loss            | 38.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7634715   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 955          |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0041515874 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 2.82         |
|    cost_values           | 1.9          |
|    entropy               | -2.24        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.745        |
|    value_loss            | 10.3         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.82       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.82       |
| reward                   | -0.8454743 |
| rollout/                 |            |
|    ep_len_mean           | 972        |
|    ep_rew_mean           | -721       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 29         |
|    time_elapsed          | 989        |
|    total_timesteps       | 360448     |
| train/                   |            |
|    approx_kl             | 0.0049211  |
|    clip_fraction         | 0.0444     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.79       |
|    cost_value_loss       | 0.51       |
|    cost_values           | 1.86       |
|    entropy               | -2.24      |
|    entropy_loss          | -2.24      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.67       |
|    n_updates             | 1750       |
|    policy_gradient_loss  | -0.00239   |
|    std                   | 0.743      |
|    value_loss            | 5.09       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7399138   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1024         |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0056725154 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 0.136        |
|    cost_values           | 1.46         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.15         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.747        |
|    value_loss            | 4.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.5318644   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1058         |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0013840981 |
|    clip_fraction         | 0.00308      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 3.26         |
|    cost_values           | 1.63         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.000338    |
|    std                   | 0.747        |
|    value_loss            | 6.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8545766   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1092         |
|    total_timesteps       | 366592       |
| train/                   |              |
|    approx_kl             | 0.0019890682 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 1.05         |
|    cost_values           | 1.86         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.13         |
|    n_updates             | 1780         |
|    policy_gradient_loss  | 0.00179      |
|    std                   | 0.748        |
|    value_loss            | 11.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.46712336   |
| rollout/                 |               |
|    ep_len_mean           | 966           |
|    ep_rew_mean           | -703          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 33            |
|    time_elapsed          | 1126          |
|    total_timesteps       | 368640        |
| train/                   |               |
|    approx_kl             | 0.00027519782 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.08          |
|    cost_value_loss       | 2.34          |
|    cost_values           | 1.66          |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 30.4          |
|    n_updates             | 1790          |
|    policy_gradient_loss  | -0.000126     |
|    std                   | 0.748         |
|    value_loss            | 35.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.43427733  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1160         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0029563005 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 1.53         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.9          |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.000347    |
|    std                   | 0.748        |
|    value_loss            | 5.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.92031115  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1195         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 8.355902e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 1.62         |
|    cost_values           | 1.43         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | 3.01e-05     |
|    std                   | 0.747        |
|    value_loss            | 6.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.31912848  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1229         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0065183886 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.237        |
|    cost_values           | 1.19         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.22         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.747        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.0795287   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1263         |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0021460436 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.83         |
|    cost_values           | 1.16         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.746        |
|    value_loss            | 5.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.1205983   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1297         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0032723357 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 4.56         |
|    cost_values           | 1.54         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.746        |
|    value_loss            | 7.75         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.85068977   |
| rollout/                 |               |
|    ep_len_mean           | 960           |
|    ep_rew_mean           | -700          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 39            |
|    time_elapsed          | 1332          |
|    total_timesteps       | 380928        |
| train/                   |               |
|    approx_kl             | 0.00020087193 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.42          |
|    cost_value_loss       | 0.0959        |
|    cost_values           | 1.7           |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.4          |
|    n_updates             | 1850          |
|    policy_gradient_loss  | 3.38e-05      |
|    std                   | 0.747         |
|    value_loss            | 33.3          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.90269095   |
| rollout/                 |               |
|    ep_len_mean           | 960           |
|    ep_rew_mean           | -697          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 40            |
|    time_elapsed          | 1366          |
|    total_timesteps       | 382976        |
| train/                   |               |
|    approx_kl             | 0.00031703734 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.04          |
|    cost_value_loss       | 3.05          |
|    cost_values           | 1.6           |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21.1          |
|    n_updates             | 1860          |
|    policy_gradient_loss  | -6.57e-05     |
|    std                   | 0.747         |
|    value_loss            | 33.8          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.97124076 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1401        |
|    total_timesteps       | 385024      |
| train/                   |             |
|    approx_kl             | 0.002289649 |
|    clip_fraction         | 0.000928    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 3.61        |
|    cost_values           | 1.78        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 1870        |
|    policy_gradient_loss  | -0.000343   |
|    std                   | 0.746       |
|    value_loss            | 18.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.5930047   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1435         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0032179262 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 1.79         |
|    cost_values           | 1.73         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.745        |
|    value_loss            | 8.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5266067   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1469         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0032701558 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 1.85         |
|    cost_values           | 1.8          |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.11         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.743        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.5159611   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1504         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0008828229 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 0.109        |
|    cost_values           | 1.87         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.000368    |
|    std                   | 0.742        |
|    value_loss            | 36.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.57832485   |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -699          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1538          |
|    total_timesteps       | 393216        |
| train/                   |               |
|    approx_kl             | 0.00042620767 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.11          |
|    cost_value_loss       | 2.51          |
|    cost_values           | 1.62          |
|    entropy               | -2.23         |
|    entropy_loss          | -2.23         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.6           |
|    n_updates             | 1910          |
|    policy_gradient_loss  | -0.000197     |
|    std                   | 0.742         |
|    value_loss            | 11.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.94976413 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1573        |
|    total_timesteps       | 395264      |
| train/                   |             |
|    approx_kl             | 0.003955502 |
|    clip_fraction         | 0.0209      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.38        |
|    cost_value_loss       | 5.06        |
|    cost_values           | 1.63        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.64        |
|    n_updates             | 1920        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.741       |
|    value_loss            | 8.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.54786646 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -701        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1607        |
|    total_timesteps       | 397312      |
| train/                   |             |
|    approx_kl             | 0.002888562 |
|    clip_fraction         | 0.00127     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.53        |
|    cost_value_loss       | 0.134       |
|    cost_values           | 1.77        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.04        |
|    n_updates             | 1930        |
|    policy_gradient_loss  | -0.000701   |
|    std                   | 0.741       |
|    value_loss            | 17.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.70155853  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1642         |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0022595625 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 3.57         |
|    cost_values           | 1.65         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.04         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | -0.000907    |
|    std                   | 0.741        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9852935   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1676         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0031231556 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 0.0717       |
|    cost_values           | 1.66         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.49         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.741        |
|    value_loss            | 5.23         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -1.0728788 |
| rollout/           |            |
|    ep_len_mean     | 970        |
|    ep_rew_mean     | -713       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 403456     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.9127642   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0011682756 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.889        |
|    cost_values           | 1.25         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.735        |
|    value_loss            | 13.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.1717294   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0008950713 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.0515       |
|    cost_values           | 1.12         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.42         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.000894    |
|    std                   | 0.735        |
|    value_loss            | 8.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.1133407   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0028739735 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.829        |
|    cost_value_loss       | 0.0195       |
|    cost_values           | 0.927        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.39         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.000147    |
|    std                   | 0.735        |
|    value_loss            | 7.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.9687699   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0035821004 |
|    clip_fraction         | 0.00498      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.802        |
|    cost_value_loss       | 0.316        |
|    cost_values           | 0.796        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.000857    |
|    std                   | 0.735        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.645        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.645        |
| reward                   | -0.72647166  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0052716285 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 2.31         |
|    cost_values           | 0.87         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.45         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.735        |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.91        |
| reward                   | -0.8064322  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 232         |
|    total_timesteps       | 415744      |
| train/                   |             |
|    approx_kl             | 0.005216426 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 2.94        |
|    cost_values           | 1.08        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.96        |
|    n_updates             | 2020        |
|    policy_gradient_loss  | -0.000538   |
|    std                   | 0.734       |
|    value_loss            | 3           |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.58861846  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -732         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0023252973 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.0868       |
|    cost_values           | 1.1          |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.15         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00065     |
|    std                   | 0.734        |
|    value_loss            | 2.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.69160587 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -736        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 302         |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.000373061 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 0.768       |
|    cost_values           | 0.988       |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.65        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -5.46e-05   |
|    std                   | 0.733       |
|    value_loss            | 13          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.87770736  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0047824406 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.816        |
|    cost_value_loss       | 0.0208       |
|    cost_values           | 0.931        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.32         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.732        |
|    value_loss            | 5.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.7006321   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 373          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0025162594 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.67         |
|    cost_values           | 1.13         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.72         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.731        |
|    value_loss            | 9.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.9748611   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 408          |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0065053436 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.496        |
|    cost_values           | 1.39         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7            |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.73         |
|    value_loss            | 14.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5623562   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0005210485 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.27         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 1.27         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.000309    |
|    std                   | 0.73         |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9674809   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 477          |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0050470326 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 4.46         |
|    cost_values           | 1.42         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.3         |
|    n_updates             | 2090         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.73         |
|    value_loss            | 38.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.4449346   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0062121404 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 4.73         |
|    cost_values           | 1.74         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.15         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.000714    |
|    std                   | 0.728        |
|    value_loss            | 6.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7145707  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 545         |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.004877166 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 1.29        |
|    cost_values           | 1.96        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.727       |
|    value_loss            | 8.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.50616366  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 580          |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0039498815 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 0.675        |
|    cost_values           | 1.67         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.2         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.727        |
|    value_loss            | 40.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.64917046  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 615          |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0011918906 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 3.39         |
|    cost_values           | 1.56         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.1         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.000374    |
|    std                   | 0.727        |
|    value_loss            | 38.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.98          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.98          |
| reward                   | -0.41385853   |
| rollout/                 |               |
|    ep_len_mean           | 975           |
|    ep_rew_mean           | -714          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 19            |
|    time_elapsed          | 649           |
|    total_timesteps       | 440320        |
| train/                   |               |
|    approx_kl             | 0.00022983833 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.3           |
|    cost_value_loss       | 0.0526        |
|    cost_values           | 1.47          |
|    entropy               | -2.19         |
|    entropy_loss          | -2.19         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.97          |
|    n_updates             | 2140          |
|    policy_gradient_loss  | -3.25e-05     |
|    std                   | 0.727         |
|    value_loss            | 19.1          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.75          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.75          |
| reward                   | -0.71485454   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -711          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 20            |
|    time_elapsed          | 684           |
|    total_timesteps       | 442368        |
| train/                   |               |
|    approx_kl             | 0.00029266358 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.77          |
|    cost_value_loss       | 2.19          |
|    cost_values           | 1.4           |
|    entropy               | -2.19         |
|    entropy_loss          | -2.19         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.05          |
|    n_updates             | 2150          |
|    policy_gradient_loss  | 4.06e-05      |
|    std                   | 0.728         |
|    value_loss            | 7.45          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.60017157  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0047705313 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 0.453        |
|    cost_values           | 1.58         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.5         |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.728        |
|    value_loss            | 52.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4594028   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0029076878 |
|    clip_fraction         | 0.00386      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 0.0418       |
|    cost_values           | 1.24         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.1          |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00049     |
|    std                   | 0.728        |
|    value_loss            | 4.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.4563784  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 787         |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.004442707 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 1.36        |
|    cost_values           | 1.13        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.725       |
|    value_loss            | 4.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.47968918  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 821          |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0030271206 |
|    clip_fraction         | 0.0021       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 1.37         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.724        |
|    value_loss            | 19.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4857638   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 855          |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0017496631 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 1.47         |
|    cost_values           | 1.5          |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.28         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.000663    |
|    std                   | 0.721        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.73447746 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 890         |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.003658581 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 1.48        |
|    cost_values           | 1.47        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3           |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.000847   |
|    std                   | 0.719       |
|    value_loss            | 6.33        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.44404072   |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -697          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 27            |
|    time_elapsed          | 924           |
|    total_timesteps       | 456704        |
| train/                   |               |
|    approx_kl             | 0.00020981504 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.73          |
|    cost_value_loss       | 6.9           |
|    cost_values           | 1.3           |
|    entropy               | -2.17         |
|    entropy_loss          | -2.17         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 41.2          |
|    n_updates             | 2220          |
|    policy_gradient_loss  | -0.000157     |
|    std                   | 0.719         |
|    value_loss            | 97.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.7570278   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0055011073 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 7.05         |
|    cost_values           | 1.33         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.68         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.719        |
|    value_loss            | 8.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91536665  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0018426385 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.49         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.719        |
|    value_loss            | 30.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.88856375  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0008729701 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 1.69         |
|    cost_values           | 1.38         |
|    entropy               | -2.15        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.71         |
|    value_loss            | 8.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9313312   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0017174629 |
|    clip_fraction         | 0.0402       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 4.86         |
|    cost_values           | 1.55         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.98         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | 0.0015       |
|    std                   | 0.707        |
|    value_loss            | 5.19         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.9035125    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -718          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 32            |
|    time_elapsed          | 1096          |
|    total_timesteps       | 466944        |
| train/                   |               |
|    approx_kl             | 0.00037855303 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.57          |
|    cost_value_loss       | 0.342         |
|    cost_values           | 1.7           |
|    entropy               | -2.13         |
|    entropy_loss          | -2.14         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.65          |
|    n_updates             | 2270          |
|    policy_gradient_loss  | 1.5e-05       |
|    std                   | 0.706         |
|    value_loss            | 10.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.49474385  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1131         |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0025718962 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 0.49         |
|    cost_values           | 1.41         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.27         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -1.08e-05    |
|    std                   | 0.707        |
|    value_loss            | 6.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.717589    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1165         |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0028608479 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.514        |
|    cost_values           | 1.21         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | 0.00046      |
|    std                   | 0.707        |
|    value_loss            | 15.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.96088934 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1200        |
|    total_timesteps       | 473088      |
| train/                   |             |
|    approx_kl             | 0.005607025 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 2.03        |
|    cost_values           | 1.04        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 2300        |
|    policy_gradient_loss  | -0.000706   |
|    std                   | 0.708       |
|    value_loss            | 4.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8767785  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -716        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1234        |
|    total_timesteps       | 475136      |
| train/                   |             |
|    approx_kl             | 0.003579848 |
|    clip_fraction         | 0.00356     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 6.81        |
|    cost_values           | 1.11        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.4         |
|    n_updates             | 2310        |
|    policy_gradient_loss  | -0.0006     |
|    std                   | 0.707       |
|    value_loss            | 8.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1231444   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1268         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0014638563 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.0526       |
|    cost_values           | 1.17         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.76         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.000339    |
|    std                   | 0.707        |
|    value_loss            | 8.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.0320351   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1303         |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0036529405 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.845        |
|    cost_value_loss       | 0.0206       |
|    cost_values           | 0.941        |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.86         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.706        |
|    value_loss            | 21.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.76376677  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0063380348 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 1            |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.9         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.706        |
|    value_loss            | 38           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.93847823  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1372         |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0036798986 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 2.72         |
|    cost_values           | 1.09         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.706        |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8855716  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1407        |
|    total_timesteps       | 485376      |
| train/                   |             |
|    approx_kl             | 0.004098159 |
|    clip_fraction         | 0.00776     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.974       |
|    cost_value_loss       | 0.0865      |
|    cost_values           | 1.06        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 2360        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.705       |
|    value_loss            | 28.7        |
------------------------------------------
--------------------------------------------
| avg_speed                | 2.42          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.42          |
| reward                   | -0.80284506   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -721          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 42            |
|    time_elapsed          | 1442          |
|    total_timesteps       | 487424        |
| train/                   |               |
|    approx_kl             | 0.00047892446 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.788         |
|    cost_value_loss       | 0.037         |
|    cost_values           | 0.911         |
|    entropy               | -2.13         |
|    entropy_loss          | -2.13         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.6          |
|    n_updates             | 2370          |
|    policy_gradient_loss  | -5.39e-05     |
|    std                   | 0.705         |
|    value_loss            | 31            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.7          |
| reward                   | -0.7149802   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1476         |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0031205812 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.737        |
|    cost_value_loss       | 0.0166       |
|    cost_values           | 0.771        |
|    entropy               | -2.14        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.000567    |
|    std                   | 0.708        |
|    value_loss            | 46.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.89          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.89          |
| reward                   | -0.7190264    |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -723          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 44            |
|    time_elapsed          | 1511          |
|    total_timesteps       | 491520        |
| train/                   |               |
|    approx_kl             | 0.00075828715 |
|    clip_fraction         | 0.0844        |
|    clip_range            | 0.2           |
|    cost_returns          | 0.813         |
|    cost_value_loss       | 0.502         |
|    cost_values           | 0.76          |
|    entropy               | -2.14         |
|    entropy_loss          | -2.14         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.49          |
|    n_updates             | 2390          |
|    policy_gradient_loss  | 0.00312       |
|    std                   | 0.71          |
|    value_loss            | 18.7          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.6834758    |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -722          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1546          |
|    total_timesteps       | 493568        |
| train/                   |               |
|    approx_kl             | 0.00046722151 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.75          |
|    cost_value_loss       | 3.54          |
|    cost_values           | 0.917         |
|    entropy               | -2.14         |
|    entropy_loss          | -2.14         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.06          |
|    n_updates             | 2400          |
|    policy_gradient_loss  | -6.17e-05     |
|    std                   | 0.71          |
|    value_loss            | 12            |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.26454955 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1581        |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.008673149 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.593       |
|    cost_values           | 1.04        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.27        |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.000214   |
|    std                   | 0.709       |
|    value_loss            | 5.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.98920465  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1615         |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0017422601 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 4.15         |
|    cost_values           | 1.04         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.95         |
|    n_updates             | 2420         |
|    policy_gradient_loss  | 0.0025       |
|    std                   | 0.71         |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.65166426  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1651         |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0051052426 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.903        |
|    cost_value_loss       | 0.0663       |
|    cost_values           | 0.979        |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.16         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.71         |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.31899005  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1685         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0004960554 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.838        |
|    cost_value_loss       | 0.208        |
|    cost_values           | 0.884        |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.9         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -9.39e-05    |
|    std                   | 0.709        |
|    value_loss            | 42.6         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
----------------------------------
| avg_speed          | 8.02      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8.02      |
| reward             | -1.156798 |
| rollout/           |           |
|    ep_len_mean     | 967       |
|    ep_rew_mean     | -726      |
| time/              |           |
|    fps             | 82        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 503808    |
----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6737766   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0013016742 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 8.71         |
|    cost_values           | 1.33         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | 0.000249     |
|    std                   | 0.704        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0137761  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.004900911 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 0.383       |
|    cost_values           | 1.41        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.01        |
|    n_updates             | 2470        |
|    policy_gradient_loss  | 0.000631    |
|    std                   | 0.705       |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.525242    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0033324454 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 3.62         |
|    cost_values           | 1.54         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.704        |
|    value_loss            | 21.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6107624   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0061840573 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 5.08         |
|    cost_values           | 1.9          |
|    entropy               | -2.13        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.83         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.704        |
|    value_loss            | 9.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80408776 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 196         |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.004326139 |
|    clip_fraction         | 0.0293      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.71        |
|    cost_value_loss       | 4.43        |
|    cost_values           | 2.1         |
|    entropy               | -2.12       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.61        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00235    |
|    std                   | 0.704       |
|    value_loss            | 13.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.7880583   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0034293784 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 0.724        |
|    cost_values           | 2.31         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.24         |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.000554    |
|    std                   | 0.704        |
|    value_loss            | 6.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.25814462  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0046383603 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 0.238        |
|    cost_values           | 1.95         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2            |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.705        |
|    value_loss            | 4.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.7160911  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 300         |
|    total_timesteps       | 520192      |
| train/                   |             |
|    approx_kl             | 0.005145606 |
|    clip_fraction         | 0.0342      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 3.67        |
|    cost_values           | 1.88        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.12        |
|    n_updates             | 2530        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.705       |
|    value_loss            | 14.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.69314    |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -723        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 334         |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.004337351 |
|    clip_fraction         | 0.0109      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 1.82        |
|    cost_values           | 2.17        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.704       |
|    value_loss            | 10.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.69749737  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0033794274 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 1.31         |
|    cost_values           | 2.11         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.000447    |
|    std                   | 0.702        |
|    value_loss            | 7.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.94354755  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0048218123 |
|    clip_fraction         | 0.0474       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 4.65         |
|    cost_values           | 2.29         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.3         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.701        |
|    value_loss            | 46.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3066658   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0027718681 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 3.42         |
|    cost_values           | 2.48         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.000125    |
|    std                   | 0.701        |
|    value_loss            | 8.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6364009  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -714        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 471         |
|    total_timesteps       | 530432      |
| train/                   |             |
|    approx_kl             | 0.005326608 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 0.762       |
|    cost_values           | 2.29        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 2580        |
|    policy_gradient_loss  | -0.00238    |
|    std                   | 0.704       |
|    value_loss            | 9.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2253768   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 6.607364e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 4.52         |
|    cost_values           | 2.25         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.83         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | 0.000179     |
|    std                   | 0.704        |
|    value_loss            | 13.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.240106   |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 540         |
|    total_timesteps       | 534528      |
| train/                   |             |
|    approx_kl             | 0.005056738 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 2.59        |
|    cost_values           | 2.23        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.2         |
|    n_updates             | 2600        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.704       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9789106   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 574          |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0045900033 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 2.14         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.706        |
|    value_loss            | 24           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.49         |
| reward                   | -0.77328247  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 609          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0041157827 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 0.0995       |
|    cost_values           | 1.88         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.13        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.25         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.704        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.51        |
| reward                   | -0.834097   |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 643         |
|    total_timesteps       | 540672      |
| train/                   |             |
|    approx_kl             | 0.003106911 |
|    clip_fraction         | 0.00117     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 2.42        |
|    cost_values           | 1.69        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 2630        |
|    policy_gradient_loss  | -0.00024    |
|    std                   | 0.703       |
|    value_loss            | 24.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8032178   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 678          |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0042531495 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 5            |
|    cost_values           | 1.9          |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.79         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.702        |
|    value_loss            | 5.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.35610923 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 712         |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.00509178  |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 2.87        |
|    cost_values           | 2.2         |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.701       |
|    value_loss            | 6.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -1.2652488   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 747          |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0030789585 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 4.52         |
|    cost_values           | 2.34         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.701        |
|    value_loss            | 16.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7369315  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 781         |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.011301285 |
|    clip_fraction         | 0.071       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 1.98        |
|    cost_values           | 2.69        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 36.8        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.701       |
|    value_loss            | 70.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.64975667  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 815          |
|    total_timesteps       | 550912       |
| train/                   |              |
|    approx_kl             | 0.0045539653 |
|    clip_fraction         | 0.0979       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 0.189        |
|    cost_values           | 2.61         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 2680         |
|    policy_gradient_loss  | -0.000418    |
|    std                   | 0.701        |
|    value_loss            | 24.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1052527   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 849          |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0037893779 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.56         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 2.39         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.99         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.7          |
|    value_loss            | 7.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.38         |
| reward                   | -0.63600117  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 884          |
|    total_timesteps       | 555008       |
| train/                   |              |
|    approx_kl             | 0.0011404856 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 0.194        |
|    cost_values           | 2.39         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 2700         |
|    policy_gradient_loss  | -0.000427    |
|    std                   | 0.699        |
|    value_loss            | 40.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9538648   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 918          |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0043774545 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 4.02         |
|    cost_values           | 2.16         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.7          |
|    value_loss            | 40.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3995708   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0012158607 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 0.137        |
|    cost_values           | 2.04         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.000522    |
|    std                   | 0.7          |
|    value_loss            | 31.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40925834 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 29          |
|    time_elapsed          | 986         |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.000183063 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 0.949       |
|    cost_values           | 1.72        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -5.74e-05   |
|    std                   | 0.7         |
|    value_loss            | 30.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -0.8578418   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1021         |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0037106057 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 3.11         |
|    cost_values           | 1.58         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.19         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.699        |
|    value_loss            | 7.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.5345103   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0024554273 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.875        |
|    cost_values           | 1.62         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.7          |
|    value_loss            | 27.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1148149   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0046774116 |
|    clip_fraction         | 0.0609       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 1.22         |
|    cost_values           | 1.52         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.00485     |
|    std                   | 0.7          |
|    value_loss            | 18.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.39         |
| reward                   | -0.5337342   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1123         |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0017951058 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 1.15         |
|    cost_values           | 1.55         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.000903    |
|    std                   | 0.698        |
|    value_loss            | 6.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9732553   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1158         |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0012166249 |
|    clip_fraction         | 0.0608       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 0.456        |
|    cost_values           | 1.45         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | 0.00185      |
|    std                   | 0.697        |
|    value_loss            | 26.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.0048983   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1192         |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0016275691 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 3.18         |
|    cost_values           | 1.25         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21           |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.000386    |
|    std                   | 0.697        |
|    value_loss            | 36.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1196841   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1226         |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0052721165 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 0.494        |
|    cost_values           | 1.13         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.697        |
|    value_loss            | 35.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -0.8982373  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1261        |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.002102999 |
|    clip_fraction         | 0.000244    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.819       |
|    cost_value_loss       | 0.0229      |
|    cost_values           | 0.948       |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.000633   |
|    std                   | 0.697       |
|    value_loss            | 28.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.573        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.573        |
| reward                   | -0.7062223   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1295         |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0025399253 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 1.18         |
|    cost_values           | 0.967        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.45         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.000482    |
|    std                   | 0.697        |
|    value_loss            | 8.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.9         |
| reward                   | -0.538765   |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 39          |
|    time_elapsed          | 1329        |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.004923322 |
|    clip_fraction         | 0.0114      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 4.71        |
|    cost_values           | 1.02        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.05        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.697       |
|    value_loss            | 8.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.07         |
| reward                   | -0.7001578   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1364         |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0009444662 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.919        |
|    cost_value_loss       | 0.0589       |
|    cost_values           | 0.992        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.12         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.000149    |
|    std                   | 0.697        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.67748785  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 41           |
|    time_elapsed          | 1398         |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0062702396 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 2.91         |
|    cost_values           | 0.985        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.698        |
|    value_loss            | 8.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.6345734   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 42           |
|    time_elapsed          | 1433         |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0030293548 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.953        |
|    cost_value_loss       | 0.267        |
|    cost_values           | 0.973        |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.000843    |
|    std                   | 0.698        |
|    value_loss            | 23           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8093706   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1468         |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0059742504 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 1.64         |
|    cost_values           | 1.15         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.697        |
|    value_loss            | 9            |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8167617  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -740        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1503        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.004191747 |
|    clip_fraction         | 0.0248      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 0.134       |
|    cost_values           | 1.09        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.68        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.000394   |
|    std                   | 0.698       |
|    value_loss            | 7.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.53032184  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1538         |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0006488943 |
|    clip_fraction         | 0.0438       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 6.39         |
|    cost_values           | 1.17         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | 0.00184      |
|    std                   | 0.698        |
|    value_loss            | 7.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.75583875  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1573         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0016111423 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.167        |
|    cost_values           | 1.24         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.000173    |
|    std                   | 0.698        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.56340593  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1607         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0041568447 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 0.605        |
|    cost_values           | 1.01         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.11        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.696        |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.819685    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1642         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0010863408 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 3.11         |
|    cost_values           | 1.08         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | 0.00102      |
|    std                   | 0.695        |
|    value_loss            | 23.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.76422715  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1677         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0072403774 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.35         |
|    cost_values           | 1.33         |
|    entropy               | -2.09        |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.47         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.693        |
|    value_loss            | 10           |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.05       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.05       |
| reward             | -0.9803491 |
| rollout/           |            |
|    ep_len_mean     | 972        |
|    ep_rew_mean     | -735       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 604160     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.704602    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0009476219 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 2.19         |
|    cost_values           | 1.86         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.09        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.47         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | 0.000204     |
|    std                   | 0.69         |
|    value_loss            | 15.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.70742154   |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -745          |
| time/                    |               |
|    fps                   | 65            |
|    iterations            | 3             |
|    time_elapsed          | 94            |
|    total_timesteps       | 608256        |
| train/                   |               |
|    approx_kl             | 0.00039817372 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.88          |
|    cost_value_loss       | 1.46          |
|    cost_values           | 1.73          |
|    entropy               | -2.08         |
|    entropy_loss          | -2.08         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 37            |
|    n_updates             | 2960          |
|    policy_gradient_loss  | 5.26e-05      |
|    std                   | 0.69          |
|    value_loss            | 79.7          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.88670385 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.004807912 |
|    clip_fraction         | 0.011       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.7         |
|    cost_value_loss       | 1.49        |
|    cost_values           | 1.53        |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.000143   |
|    std                   | 0.691       |
|    value_loss            | 4.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.71        |
| reward                   | -0.8366119  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.004291133 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 0.0495      |
|    cost_values           | 1.42        |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.88        |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.000991   |
|    std                   | 0.691       |
|    value_loss            | 16.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66520834  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0018068689 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.98         |
|    cost_values           | 1.11         |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.000608    |
|    std                   | 0.691        |
|    value_loss            | 41.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.59035975  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0034679547 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.72         |
|    cost_values           | 1            |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.1          |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.000574    |
|    std                   | 0.691        |
|    value_loss            | 9.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.80096257  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0018494535 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 1.93         |
|    cost_values           | 1            |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.5         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.000521    |
|    std                   | 0.691        |
|    value_loss            | 34.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0447521   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0033849624 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.34         |
|    cost_values           | 1.09         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.000316    |
|    std                   | 0.685        |
|    value_loss            | 5.33         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.56460637   |
| rollout/                 |               |
|    ep_len_mean           | 974           |
|    ep_rew_mean           | -755          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 10            |
|    time_elapsed          | 334           |
|    total_timesteps       | 622592        |
| train/                   |               |
|    approx_kl             | 0.00046093372 |
|    clip_fraction         | 0.0964        |
|    clip_range            | 0.2           |
|    cost_returns          | 0.94          |
|    cost_value_loss       | 0.0213        |
|    cost_values           | 1.03          |
|    entropy               | -2.06         |
|    entropy_loss          | -2.07         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.52          |
|    n_updates             | 3030          |
|    policy_gradient_loss  | 0.00364       |
|    std                   | 0.682         |
|    value_loss            | 10.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9520687   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0031163283 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.791        |
|    cost_value_loss       | 0.0637       |
|    cost_values           | 0.883        |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00086     |
|    std                   | 0.682        |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.574339    |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 402          |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0058570243 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 2.72         |
|    cost_values           | 0.934        |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.681        |
|    value_loss            | 9.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6991002   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0020304439 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 1.12         |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.68         |
|    value_loss            | 18.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.68234456   |
| rollout/                 |               |
|    ep_len_mean           | 974           |
|    ep_rew_mean           | -752          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 14            |
|    time_elapsed          | 471           |
|    total_timesteps       | 630784        |
| train/                   |               |
|    approx_kl             | 0.00015159024 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.74          |
|    cost_value_loss       | 2.42          |
|    cost_values           | 1.27          |
|    entropy               | -2.06         |
|    entropy_loss          | -2.06         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.05          |
|    n_updates             | 3070          |
|    policy_gradient_loss  | 6.69e-06      |
|    std                   | 0.681         |
|    value_loss            | 9.55          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.33141768 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -751        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 506         |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.004312358 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 1.38        |
|    cost_values           | 1.32        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.17        |
|    n_updates             | 3080        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.679       |
|    value_loss            | 5.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.7722105   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 540          |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0012295835 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 2.74         |
|    cost_values           | 1.33         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.52         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | 0.00113      |
|    std                   | 0.677        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36732784 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.004139769 |
|    clip_fraction         | 0.00625     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 2.02        |
|    cost_values           | 1.24        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.678       |
|    value_loss            | 27.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.97787535  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 609          |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0046428456 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 6.37         |
|    cost_values           | 1.17         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.3         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.678        |
|    value_loss            | 36           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4963879  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 644         |
|    total_timesteps       | 641024      |
| train/                   |             |
|    approx_kl             | 0.004328884 |
|    clip_fraction         | 0.00693     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.49        |
|    cost_value_loss       | 6.3         |
|    cost_values           | 1.4         |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.3         |
|    n_updates             | 3120        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 0.679       |
|    value_loss            | 11.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.3524637    |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -758          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 20            |
|    time_elapsed          | 679           |
|    total_timesteps       | 643072        |
| train/                   |               |
|    approx_kl             | 0.00069871556 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.19          |
|    cost_value_loss       | 2.97          |
|    cost_values           | 1.73          |
|    entropy               | -2.05         |
|    entropy_loss          | -2.05         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.93          |
|    n_updates             | 3130          |
|    policy_gradient_loss  | 6.35e-05      |
|    std                   | 0.678         |
|    value_loss            | 9.69          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.7822301    |
| rollout/                 |               |
|    ep_len_mean           | 984           |
|    ep_rew_mean           | -760          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 21            |
|    time_elapsed          | 713           |
|    total_timesteps       | 645120        |
| train/                   |               |
|    approx_kl             | 0.00059463596 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.62          |
|    cost_value_loss       | 4.91          |
|    cost_values           | 1.98          |
|    entropy               | -2.05         |
|    entropy_loss          | -2.05         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 14.6          |
|    n_updates             | 3140          |
|    policy_gradient_loss  | 0.000817      |
|    std                   | 0.678         |
|    value_loss            | 24.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.0199751   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 747          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0030717712 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.84         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 2.05         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.678        |
|    value_loss            | 9.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.98656964 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 781         |
|    total_timesteps       | 649216      |
| train/                   |             |
|    approx_kl             | 0.004015117 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 2.55        |
|    cost_values           | 2.13        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.99        |
|    n_updates             | 3160        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.678       |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5489731   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 815          |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0027096907 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 0.27         |
|    cost_values           | 1.87         |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.97         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.677        |
|    value_loss            | 5.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7913085  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 25          |
|    time_elapsed          | 850         |
|    total_timesteps       | 653312      |
| train/                   |             |
|    approx_kl             | 0.002006936 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 1.45        |
|    cost_values           | 1.57        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.26        |
|    n_updates             | 3180        |
|    policy_gradient_loss  | -0.000114   |
|    std                   | 0.677       |
|    value_loss            | 18.4        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.071132     |
| rollout/                 |               |
|    ep_len_mean           | 987           |
|    ep_rew_mean           | -754          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 26            |
|    time_elapsed          | 884           |
|    total_timesteps       | 655360        |
| train/                   |               |
|    approx_kl             | 0.00095482345 |
|    clip_fraction         | 0.0161        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.96          |
|    cost_value_loss       | 3.55          |
|    cost_values           | 1.65          |
|    entropy               | -2.05         |
|    entropy_loss          | -2.05         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.32          |
|    n_updates             | 3190          |
|    policy_gradient_loss  | -0.000661     |
|    std                   | 0.677         |
|    value_loss            | 6.12          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7956344  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -742        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 918         |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.006863701 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 1.99        |
|    cost_values           | 2           |
|    entropy               | -2.06       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.76        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.682       |
|    value_loss            | 7.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1014626   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 952          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0005828595 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 3.8          |
|    cost_values           | 2.06         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.3         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | 0.0022       |
|    std                   | 0.683        |
|    value_loss            | 42.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.017155    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 987          |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0027052257 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 0.448        |
|    cost_values           | 1.97         |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.96         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | 0.000134     |
|    std                   | 0.681        |
|    value_loss            | 9.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.88167167 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -742        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 663552      |
| train/                   |             |
|    approx_kl             | 0.005511421 |
|    clip_fraction         | 0.02        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 0.275       |
|    cost_values           | 1.75        |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.7         |
|    n_updates             | 3230        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.68        |
|    value_loss            | 18.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.99925554  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1056         |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0021797945 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 3.4          |
|    cost_values           | 1.55         |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.6          |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.679        |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9305928   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1090         |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0039174543 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 2.4          |
|    cost_values           | 1.6          |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.44         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.677        |
|    value_loss            | 11.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.44426477 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 33          |
|    time_elapsed          | 1124        |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.001033553 |
|    clip_fraction         | 0.0118      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 0.447       |
|    cost_values           | 1.54        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.000366   |
|    std                   | 0.675       |
|    value_loss            | 10.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.1061485   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1159         |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0018519806 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 2.54         |
|    cost_values           | 1.43         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.15         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | 0.000892     |
|    std                   | 0.674        |
|    value_loss            | 7.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1048183   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1193         |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0038736705 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 1.5          |
|    cost_values           | 1.35         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.06         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.000798    |
|    std                   | 0.675        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9040946   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1227         |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0021778336 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.0279       |
|    cost_values           | 1.11         |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.00012     |
|    std                   | 0.674        |
|    value_loss            | 8.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1514608  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -736        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 37          |
|    time_elapsed          | 1262        |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.004782476 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 0.544       |
|    cost_values           | 0.995       |
|    entropy               | -2.03       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.66        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.67        |
|    value_loss            | 5           |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.2673596   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 38           |
|    time_elapsed          | 1296         |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0044634105 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.823        |
|    cost_value_loss       | 0.0233       |
|    cost_values           | 0.95         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.09         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.667        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.75         |
| reward                   | -0.60991037  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 39           |
|    time_elapsed          | 1330         |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0007871314 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.723        |
|    cost_value_loss       | 0.0196       |
|    cost_values           | 0.845        |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.000226    |
|    std                   | 0.668        |
|    value_loss            | 23.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.90966034  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 40           |
|    time_elapsed          | 1364         |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0035953827 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.54         |
|    cost_values           | 0.872        |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.000953    |
|    std                   | 0.667        |
|    value_loss            | 8.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0878162  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 41          |
|    time_elapsed          | 1399        |
|    total_timesteps       | 686080      |
| train/                   |             |
|    approx_kl             | 0.006237937 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.91        |
|    cost_value_loss       | 4.74        |
|    cost_values           | 1.1         |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.3        |
|    n_updates             | 3340        |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.668       |
|    value_loss            | 37.1        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.5481766 |
| rollout/                 |            |
|    ep_len_mean           | 971        |
|    ep_rew_mean           | -734       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 42         |
|    time_elapsed          | 1433       |
|    total_timesteps       | 688128     |
| train/                   |            |
|    approx_kl             | 0.00488921 |
|    clip_fraction         | 0.00991    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.13       |
|    cost_value_loss       | 0.311      |
|    cost_values           | 1.15       |
|    entropy               | -2.02      |
|    entropy_loss          | -2.02      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 36.7       |
|    n_updates             | 3350       |
|    policy_gradient_loss  | -0.00114   |
|    std                   | 0.668      |
|    value_loss            | 48.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7434289   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1467         |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0047246004 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.989        |
|    cost_value_loss       | 0.408        |
|    cost_values           | 0.971        |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.58         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.667        |
|    value_loss            | 19.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55197257 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1502        |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.003915592 |
|    clip_fraction         | 0.00356     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.03        |
|    cost_value_loss       | 4.95        |
|    cost_values           | 1.17        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.4        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | 7.16e-05    |
|    std                   | 0.667       |
|    value_loss            | 41.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.3487204  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1536        |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.004800556 |
|    clip_fraction         | 0.00918     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 2.01        |
|    cost_values           | 1.4         |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.667       |
|    value_loss            | 11.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73276234  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1571         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0028900944 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 1.53         |
|    cost_values           | 1.34         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.02        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.000891    |
|    std                   | 0.666        |
|    value_loss            | 49.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7026745  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -726        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1605        |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.006052417 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 5.35        |
|    cost_values           | 1.5         |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.666       |
|    value_loss            | 15.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.85625464 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1640        |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.002564557 |
|    clip_fraction         | 0.000488    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.06        |
|    cost_value_loss       | 2.49        |
|    cost_values           | 1.77        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.75        |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.000411   |
|    std                   | 0.665       |
|    value_loss            | 16.9        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.9053173    |
| rollout/                 |               |
|    ep_len_mean           | 953           |
|    ep_rew_mean           | -715          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 49            |
|    time_elapsed          | 1674          |
|    total_timesteps       | 702464        |
| train/                   |               |
|    approx_kl             | 0.00031339278 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.42          |
|    cost_value_loss       | 3.6           |
|    cost_values           | 1.71          |
|    entropy               | -2.01         |
|    entropy_loss          | -2.01         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 27.7          |
|    n_updates             | 3420          |
|    policy_gradient_loss  | 0.000117      |
|    std                   | 0.665         |
|    value_loss            | 38.5          |
--------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
----------------------------------
| avg_speed          | 8.04      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8.04      |
| reward             | -0.664579 |
| rollout/           |           |
|    ep_len_mean     | 953       |
|    ep_rew_mean     | -717      |
| time/              |           |
|    fps             | 84        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 704512    |
----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.93583745  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0028047864 |
|    clip_fraction         | 0.00796      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 0.78         |
|    cost_values           | 1.53         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.67         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.00054     |
|    std                   | 0.665        |
|    value_loss            | 16           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.06          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.06          |
| reward                   | -1.1585759    |
| rollout/                 |               |
|    ep_len_mean           | 955           |
|    ep_rew_mean           | -719          |
| time/                    |               |
|    fps                   | 66            |
|    iterations            | 3             |
|    time_elapsed          | 92            |
|    total_timesteps       | 708608        |
| train/                   |               |
|    approx_kl             | 0.00077515934 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.93          |
|    cost_value_loss       | 3.27          |
|    cost_values           | 1.32          |
|    entropy               | -2.01         |
|    entropy_loss          | -2.01         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21.9          |
|    n_updates             | 3450          |
|    policy_gradient_loss  | -0.000336     |
|    std                   | 0.665         |
|    value_loss            | 44.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9157849   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0031121776 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 4.14         |
|    cost_values           | 1.41         |
|    entropy               | -2           |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.71         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.663        |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.64351726 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -726        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 161         |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.004313728 |
|    clip_fraction         | 0.0175      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 0.0517      |
|    cost_values           | 1.44        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.000845   |
|    std                   | 0.666       |
|    value_loss            | 4.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.64026576 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -723        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 195         |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.004222456 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.2         |
|    cost_value_loss       | 4           |
|    cost_values           | 1.45        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.86        |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.00293    |
|    std                   | 0.665       |
|    value_loss            | 16.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.42633808 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 229         |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.002348762 |
|    clip_fraction         | 0.000293    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 2.98        |
|    cost_values           | 1.81        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.000404   |
|    std                   | 0.664       |
|    value_loss            | 8.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.54         |
| reward                   | -0.70931846  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 8            |
|    time_elapsed          | 264          |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0026312917 |
|    clip_fraction         | 0.00122      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 0.976        |
|    cost_values           | 1.71         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.45         |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.000861    |
|    std                   | 0.664        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9317416   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 298          |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0024897098 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.0398       |
|    cost_values           | 1.38         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.08         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.000933    |
|    std                   | 0.664        |
|    value_loss            | 4.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7605231   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 332          |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0015022367 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 0.618        |
|    cost_values           | 1.22         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.8          |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.664        |
|    value_loss            | 8.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.42024815  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 367          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0070076715 |
|    clip_fraction         | 0.0645       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.542        |
|    cost_values           | 1.15         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | 0.000709     |
|    std                   | 0.664        |
|    value_loss            | 7.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6406241   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 401          |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0046230415 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.379        |
|    cost_values           | 1            |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.2          |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.661        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.87866     |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 436          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0036912411 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 0.248        |
|    cost_values           | 0.964        |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.66         |
|    value_loss            | 23.3         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.7326517 |
| rollout/                 |            |
|    ep_len_mean           | 953        |
|    ep_rew_mean           | -724       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 14         |
|    time_elapsed          | 471        |
|    total_timesteps       | 731136     |
| train/                   |            |
|    approx_kl             | 0.00639616 |
|    clip_fraction         | 0.0168     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.29       |
|    cost_value_loss       | 2.36       |
|    cost_values           | 0.991      |
|    entropy               | -1.99      |
|    entropy_loss          | -1.99      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.59       |
|    n_updates             | 3560       |
|    policy_gradient_loss  | -0.00161   |
|    std                   | 0.66       |
|    value_loss            | 36.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9340483   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 505          |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0030617141 |
|    clip_fraction         | 0.00449      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 1.3          |
|    cost_values           | 1.09         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.000122    |
|    std                   | 0.659        |
|    value_loss            | 6.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3566095   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 540          |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0041679256 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 4.32         |
|    cost_values           | 1.25         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.24         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.659        |
|    value_loss            | 6.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8235849  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -723        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 575         |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.004588107 |
|    clip_fraction         | 0.00503     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.16        |
|    cost_value_loss       | 3.38        |
|    cost_values           | 1.37        |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.000472   |
|    std                   | 0.659       |
|    value_loss            | 35          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0238      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0238      |
| reward                   | -0.62296474 |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -730        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 610         |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.001815276 |
|    clip_fraction         | 0.0164      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 0.591       |
|    cost_values           | 1.4         |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.3        |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.00099    |
|    std                   | 0.658       |
|    value_loss            | 37.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.18         |
| reward                   | -0.7259736   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0008149961 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 0.376        |
|    cost_values           | 1.24         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.3         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -7.77e-05    |
|    std                   | 0.658        |
|    value_loss            | 50.2         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.715383  |
| rollout/                 |            |
|    ep_len_mean           | 947        |
|    ep_rew_mean           | -727       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 20         |
|    time_elapsed          | 680        |
|    total_timesteps       | 743424     |
| train/                   |            |
|    approx_kl             | 0.00028083 |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 2.41       |
|    cost_value_loss       | 5.46       |
|    cost_values           | 1.06       |
|    entropy               | -1.99      |
|    entropy_loss          | -1.99      |
|    explained_variance    | 5.96e-08   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.94       |
|    n_updates             | 3620       |
|    policy_gradient_loss  | -8.85e-05  |
|    std                   | 0.658      |
|    value_loss            | 13         |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.37916002  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0038165436 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.434        |
|    cost_values           | 1.02         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.83         |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.658        |
|    value_loss            | 9.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.73578966  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0005433257 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.02         |
|    cost_values           | 0.998        |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.000252    |
|    std                   | 0.658        |
|    value_loss            | 39.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.67338586  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -732         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 784          |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0039395075 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.875        |
|    cost_value_loss       | 0.0577       |
|    cost_values           | 0.902        |
|    entropy               | -2           |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.57         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.664        |
|    value_loss            | 4.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0499387   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 819          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0030076287 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.866        |
|    cost_value_loss       | 0.395        |
|    cost_values           | 0.891        |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -2.6e-05     |
|    std                   | 0.665        |
|    value_loss            | 11.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89259285  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 853          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0049597225 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.23         |
|    cost_values           | 1.12         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.5          |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.666        |
|    value_loss            | 8.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53769666  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0049127303 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.596        |
|    cost_values           | 1.32         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.25         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.666        |
|    value_loss            | 6.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8190688  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -735        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 922         |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.003101875 |
|    clip_fraction         | 0.00679     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 2.44        |
|    cost_values           | 1.17        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.53        |
|    n_updates             | 3690        |
|    policy_gradient_loss  | 4.07e-05    |
|    std                   | 0.665       |
|    value_loss            | 16.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.75573033 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -736        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 956         |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.00641717  |
|    clip_fraction         | 0.0216      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 2.71        |
|    cost_values           | 1.23        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.39        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.665       |
|    value_loss            | 14.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7094571   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 990          |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0048514255 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 1.21         |
|    cost_values           | 1.44         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.25         |
|    n_updates             | 3710         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.664        |
|    value_loss            | 5.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.86373967  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0009778641 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 0.951        |
|    cost_values           | 1.32         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.000508    |
|    std                   | 0.664        |
|    value_loss            | 27.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85939956  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1059         |
|    total_timesteps       | 765952       |
| train/                   |              |
|    approx_kl             | 0.0046548164 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 2.73         |
|    cost_values           | 1.14         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 3730         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.663        |
|    value_loss            | 9.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9016634   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1093         |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0023170905 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 0.381        |
|    cost_values           | 1.08         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6            |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.000787    |
|    std                   | 0.662        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.8089204   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1127         |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0042963056 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.884        |
|    cost_value_loss       | 0.0334       |
|    cost_values           | 0.967        |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.74         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.662        |
|    value_loss            | 20.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5012901   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1161         |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0002261003 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.915        |
|    cost_value_loss       | 0.453        |
|    cost_values           | 0.894        |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.3         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -3.24e-05    |
|    std                   | 0.661        |
|    value_loss            | 45.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73023814  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1196         |
|    total_timesteps       | 774144       |
| train/                   |              |
|    approx_kl             | 0.0040605143 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.742        |
|    cost_value_loss       | 0.0245       |
|    cost_values           | 0.882        |
|    entropy               | -1.99        |
|    entropy_loss          | -2           |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.41         |
|    n_updates             | 3770         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.66         |
|    value_loss            | 17           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.2416674   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1230         |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0029662424 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 6.98         |
|    cost_values           | 0.986        |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.77         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.66         |
|    value_loss            | 14.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0715206   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1264         |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0052073644 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 4.02         |
|    cost_values           | 1.3          |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.07         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.659        |
|    value_loss            | 10.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.46421522   |
| rollout/                 |               |
|    ep_len_mean           | 955           |
|    ep_rew_mean           | -749          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1298          |
|    total_timesteps       | 780288        |
| train/                   |               |
|    approx_kl             | 0.00077997654 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.25          |
|    cost_value_loss       | 0.0744        |
|    cost_values           | 1.49          |
|    entropy               | -1.99         |
|    entropy_loss          | -1.99         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 12.7          |
|    n_updates             | 3800          |
|    policy_gradient_loss  | 0.000171      |
|    std                   | 0.659         |
|    value_loss            | 27.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.95166063  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1333         |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 4.646351e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 6.09         |
|    cost_values           | 1.4          |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | 2.53e-05     |
|    std                   | 0.659        |
|    value_loss            | 20.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9226764   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1367         |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0024200794 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 0.579        |
|    cost_values           | 1.49         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.67         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.000668    |
|    std                   | 0.657        |
|    value_loss            | 10.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -1.1402655    |
| rollout/                 |               |
|    ep_len_mean           | 962           |
|    ep_rew_mean           | -751          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1402          |
|    total_timesteps       | 786432        |
| train/                   |               |
|    approx_kl             | 0.00097536866 |
|    clip_fraction         | 0.0239        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.54          |
|    cost_value_loss       | 2.4           |
|    cost_values           | 1.45          |
|    entropy               | -1.96         |
|    entropy_loss          | -1.97         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.01          |
|    n_updates             | 3830          |
|    policy_gradient_loss  | -0.00146      |
|    std                   | 0.648         |
|    value_loss            | 4.11          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8740429  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1436        |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.004427548 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 1.66        |
|    cost_values           | 1.46        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.66        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00014    |
|    std                   | 0.644       |
|    value_loss            | 14.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6080987   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1470         |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0024672034 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 3.29         |
|    cost_values           | 1.54         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 3850         |
|    policy_gradient_loss  | 0.000173     |
|    std                   | 0.644        |
|    value_loss            | 47           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7191908   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1505         |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0046952716 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 5.07         |
|    cost_values           | 1.7          |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25           |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.644        |
|    value_loss            | 48.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80649596 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -747        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1539        |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.005505053 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 6.99        |
|    cost_values           | 1.73        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.92        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.644       |
|    value_loss            | 8.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85669094  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1573         |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0036601014 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 3.8          |
|    cost_values           | 1.86         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.3          |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.644        |
|    value_loss            | 9.58         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1513109  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -750        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1608        |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.004198299 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 5.09        |
|    cost_values           | 2.01        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.6        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.644       |
|    value_loss            | 45.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50753635  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1643         |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0071392814 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 1.17         |
|    cost_values           | 2.13         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.644        |
|    value_loss            | 38.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.5010355   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1679         |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0031460389 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 2.48         |
|    cost_values           | 2.03         |
|    entropy               | -1.94        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.000336    |
|    std                   | 0.643        |
|    value_loss            | 21.1         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.7066688 |
| rollout/           |            |
|    ep_len_mean     | 961        |
|    ep_rew_mean     | -746       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 804864     |
-----------------------------------
-------------------------------------------
| avg_speed                | 5.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.43         |
| reward                   | -0.54377806  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0034037395 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 0.416        |
|    cost_values           | 1.54         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.33         |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.643        |
|    value_loss            | 11.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.0546983    |
| rollout/                 |               |
|    ep_len_mean           | 952           |
|    ep_rew_mean           | -746          |
| time/                    |               |
|    fps                   | 65            |
|    iterations            | 3             |
|    time_elapsed          | 93            |
|    total_timesteps       | 808960        |
| train/                   |               |
|    approx_kl             | 0.00092580414 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.24          |
|    cost_value_loss       | 0.27          |
|    cost_values           | 1.26          |
|    entropy               | -1.95         |
|    entropy_loss          | -1.95         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.9          |
|    n_updates             | 3940          |
|    policy_gradient_loss  | -0.000538     |
|    std                   | 0.644         |
|    value_loss            | 38            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 2.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.95         |
| reward                   | -0.39213148  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0037591795 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.7          |
|    cost_values           | 0.995        |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.000698    |
|    std                   | 0.644        |
|    value_loss            | 60.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.83422554 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -754        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.004137168 |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.826       |
|    cost_value_loss       | 0.0567      |
|    cost_values           | 0.974       |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.41        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.644       |
|    value_loss            | 16.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.93081886 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -761        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 196         |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.003987694 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.837       |
|    cost_value_loss       | 0.119       |
|    cost_values           | 0.87        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.644       |
|    value_loss            | 11.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67923564  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 7            |
|    time_elapsed          | 230          |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0023657926 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.923        |
|    cost_value_loss       | 0.843        |
|    cost_values           | 0.836        |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 3980         |
|    policy_gradient_loss  | 0.00386      |
|    std                   | 0.645        |
|    value_loss            | 38.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.90769666  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0063155056 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.768        |
|    cost_value_loss       | 0.164        |
|    cost_values           | 0.841        |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 3990         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.645        |
|    value_loss            | 22.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4709274   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 299          |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0032013902 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 1.63         |
|    cost_values           | 0.876        |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.000821    |
|    std                   | 0.645        |
|    value_loss            | 30           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6851341   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 333          |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0037185848 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.979        |
|    cost_values           | 0.997        |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9            |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.000569    |
|    std                   | 0.644        |
|    value_loss            | 16.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45232543 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 368         |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.005659813 |
|    clip_fraction         | 0.0421      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.995       |
|    cost_value_loss       | 0.2         |
|    cost_values           | 0.994       |
|    entropy               | -1.92       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.6        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.000759   |
|    std                   | 0.636       |
|    value_loss            | 45.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.51532984  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 402          |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0040760753 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 1.59         |
|    cost_values           | 1            |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.31         |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.000794    |
|    std                   | 0.635        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6724087   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 436          |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0051467866 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.01         |
|    cost_values           | 1            |
|    entropy               | -1.91        |
|    entropy_loss          | -1.92        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 4040         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.634        |
|    value_loss            | 47.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6994516   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -787         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 471          |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0041208514 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.87         |
|    cost_value_loss       | 0.0425       |
|    cost_values           | 0.965        |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.14         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.633        |
|    value_loss            | 9.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9593039   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 505          |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0039283875 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.977        |
|    cost_value_loss       | 0.761        |
|    cost_values           | 0.93         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.633        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8421377   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 539          |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0052698143 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 1.14         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.12         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.000487    |
|    std                   | 0.632        |
|    value_loss            | 16.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.86294913  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 574          |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0030713647 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 1.36         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.91        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.631        |
|    value_loss            | 19.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4455482   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 608          |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0055934363 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 0.64         |
|    cost_values           | 1.42         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.634        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.60639066  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 642          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0035195546 |
|    clip_fraction         | 0.07         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.4          |
|    cost_values           | 1.33         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.53         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.634        |
|    value_loss            | 19.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.1348993    |
| rollout/                 |               |
|    ep_len_mean           | 960           |
|    ep_rew_mean           | -789          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 20            |
|    time_elapsed          | 676           |
|    total_timesteps       | 843776        |
| train/                   |               |
|    approx_kl             | 0.00075215235 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.949         |
|    cost_value_loss       | 0.0169        |
|    cost_values           | 0.999         |
|    entropy               | -1.91         |
|    entropy_loss          | -1.91         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 20.7          |
|    n_updates             | 4110          |
|    policy_gradient_loss  | -0.00033      |
|    std                   | 0.634         |
|    value_loss            | 46.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5739917   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 710          |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0003672678 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.32         |
|    cost_values           | 0.97         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.65         |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -6.52e-05    |
|    std                   | 0.633        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6969616   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 745          |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0034496628 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 3.54         |
|    cost_values           | 1.15         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.634        |
|    value_loss            | 24.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7097662   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 779          |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0010385746 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.452        |
|    cost_values           | 1.35         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 4140         |
|    policy_gradient_loss  | -4.49e-05    |
|    std                   | 0.634        |
|    value_loss            | 33.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7899325   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -797         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 814          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0005468194 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 2.06         |
|    cost_values           | 1.11         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.46         |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.000172    |
|    std                   | 0.634        |
|    value_loss            | 9.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9193927   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -797         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 848          |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0043956144 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.954        |
|    cost_values           | 1.18         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.91        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.31         |
|    n_updates             | 4160         |
|    policy_gradient_loss  | 0.000175     |
|    std                   | 0.63         |
|    value_loss            | 8.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.98717004 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -799        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 883         |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.007523426 |
|    clip_fraction         | 0.0561      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 1.02        |
|    cost_values           | 1.29        |
|    entropy               | -1.89       |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.2         |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.627       |
|    value_loss            | 10          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.620112   |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 918         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.006628273 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 0.411       |
|    cost_values           | 1.28        |
|    entropy               | -1.9        |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.94        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.000506   |
|    std                   | 0.631       |
|    value_loss            | 8.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.5099333   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 953          |
|    total_timesteps       | 860160       |
| train/                   |              |
|    approx_kl             | 0.0025983735 |
|    clip_fraction         | 0.0842       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 4.18         |
|    cost_values           | 1.31         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.1         |
|    n_updates             | 4190         |
|    policy_gradient_loss  | 0.00197      |
|    std                   | 0.631        |
|    value_loss            | 52.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73879737  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 987          |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0048612873 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 1.39         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 4200         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.631        |
|    value_loss            | 24.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.72098255 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 30          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.004468929 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 0.904       |
|    cost_values           | 1.35        |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.37        |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.63        |
|    value_loss            | 13.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7944861   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0037343465 |
|    clip_fraction         | 0.00869      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 1.22         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.9         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | 0.000235     |
|    std                   | 0.63         |
|    value_loss            | 81.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.47002894  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 32           |
|    time_elapsed          | 1090         |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0010769952 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 4.9          |
|    cost_values           | 1.12         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30           |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.000509    |
|    std                   | 0.63         |
|    value_loss            | 50.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.64378375  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -775         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1124         |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0025292933 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.409        |
|    cost_values           | 1.06         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.46         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.63         |
|    value_loss            | 9.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89510465  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1158         |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0024126892 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.911        |
|    cost_value_loss       | 0.247        |
|    cost_values           | 0.962        |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.000362    |
|    std                   | 0.63         |
|    value_loss            | 25.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0580293   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1192         |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0010503081 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.777        |
|    cost_value_loss       | 0.0107       |
|    cost_values           | 0.8          |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.25         |
|    n_updates             | 4260         |
|    policy_gradient_loss  | 0.000168     |
|    std                   | 0.625        |
|    value_loss            | 14.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0296816   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 36           |
|    time_elapsed          | 1227         |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0029424266 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 3.86         |
|    cost_values           | 1.17         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.000646    |
|    std                   | 0.623        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.56         |
| reward                   | -0.7457968   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1262         |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0027918285 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 4.05         |
|    cost_values           | 1.71         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.88         |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.000574    |
|    std                   | 0.623        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.46850565 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -763        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1297        |
|    total_timesteps       | 880640      |
| train/                   |             |
|    approx_kl             | 0.00409925  |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 1.88        |
|    cost_values           | 1.86        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 4290        |
|    policy_gradient_loss  | -0.000397   |
|    std                   | 0.624       |
|    value_loss            | 8.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4122454  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1332        |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.005744228 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.85        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.1        |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.624       |
|    value_loss            | 51.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8393966   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1367         |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0036740564 |
|    clip_fraction         | 0.00215      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.12         |
|    cost_value_loss       | 6.14         |
|    cost_values           | 1.85         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.07         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.624        |
|    value_loss            | 6.72         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.7084973    |
| rollout/                 |               |
|    ep_len_mean           | 942           |
|    ep_rew_mean           | -769          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1402          |
|    total_timesteps       | 886784        |
| train/                   |               |
|    approx_kl             | 0.00045107523 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.15          |
|    cost_value_loss       | 1.75          |
|    cost_values           | 1.98          |
|    entropy               | -1.88         |
|    entropy_loss          | -1.88         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 36.3          |
|    n_updates             | 4320          |
|    policy_gradient_loss  | 2.28e-05      |
|    std                   | 0.623         |
|    value_loss            | 54.4          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5891759  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1436        |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.001992162 |
|    clip_fraction         | 0.00859     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 0.62        |
|    cost_values           | 1.78        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.000226   |
|    std                   | 0.621       |
|    value_loss            | 5.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.278582    |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1470         |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0021448433 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 1.7          |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.22         |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.000449    |
|    std                   | 0.619        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7928185   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1505         |
|    total_timesteps       | 892928       |
| train/                   |              |
|    approx_kl             | 0.0055322675 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 4.38         |
|    cost_values           | 1.77         |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.09         |
|    n_updates             | 4350         |
|    policy_gradient_loss  | -0.00089     |
|    std                   | 0.619        |
|    value_loss            | 13.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.98          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.98          |
| reward                   | -0.6506601    |
| rollout/                 |               |
|    ep_len_mean           | 945           |
|    ep_rew_mean           | -774          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 45            |
|    time_elapsed          | 1539          |
|    total_timesteps       | 894976        |
| train/                   |               |
|    approx_kl             | 0.00088675256 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.83          |
|    cost_value_loss       | 0.599         |
|    cost_values           | 1.99          |
|    entropy               | -1.87         |
|    entropy_loss          | -1.87         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.82          |
|    n_updates             | 4360          |
|    policy_gradient_loss  | -0.000196     |
|    std                   | 0.62          |
|    value_loss            | 7.92          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.89331657  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1573         |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0044608084 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 1.75         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.1         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.618        |
|    value_loss            | 51.8         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.8814274 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -771       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 47         |
|    time_elapsed          | 1608       |
|    total_timesteps       | 899072     |
| train/                   |            |
|    approx_kl             | 0.00569393 |
|    clip_fraction         | 0.0111     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.44       |
|    cost_value_loss       | 4.46       |
|    cost_values           | 1.82       |
|    entropy               | -1.86      |
|    entropy_loss          | -1.86      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.9        |
|    n_updates             | 4380       |
|    policy_gradient_loss  | -0.00114   |
|    std                   | 0.617      |
|    value_loss            | 9.44       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.2600479   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1642         |
|    total_timesteps       | 901120       |
| train/                   |              |
|    approx_kl             | 0.0012040028 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 1.64         |
|    cost_values           | 1.81         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.83         |
|    n_updates             | 4390         |
|    policy_gradient_loss  | -0.00015     |
|    std                   | 0.617        |
|    value_loss            | 6.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.68502855  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1677         |
|    total_timesteps       | 903168       |
| train/                   |              |
|    approx_kl             | 0.0039721234 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 1.68         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.5         |
|    n_updates             | 4400         |
|    policy_gradient_loss  | -0.000772    |
|    std                   | 0.616        |
|    value_loss            | 52.1         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
------------------------------------
| avg_speed          | 3.3         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 3.3         |
| reward             | -0.63179517 |
| rollout/           |             |
|    ep_len_mean     | 942         |
|    ep_rew_mean     | -754        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 905216      |
------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.56253856 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 907264      |
| train/                   |             |
|    approx_kl             | 0.00643532  |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 2.72        |
|    cost_values           | 1.6         |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 4420        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.616       |
|    value_loss            | 39.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.4219589    |
| rollout/                 |               |
|    ep_len_mean           | 942           |
|    ep_rew_mean           | -753          |
| time/                    |               |
|    fps                   | 65            |
|    iterations            | 3             |
|    time_elapsed          | 93            |
|    total_timesteps       | 909312        |
| train/                   |               |
|    approx_kl             | 0.00031097923 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.3           |
|    cost_value_loss       | 0.0539        |
|    cost_values           | 1.43          |
|    entropy               | -1.86         |
|    entropy_loss          | -1.86         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 16.8          |
|    n_updates             | 4430          |
|    policy_gradient_loss  | -8.01e-05     |
|    std                   | 0.616         |
|    value_loss            | 33.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85851467  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 911360       |
| train/                   |              |
|    approx_kl             | 0.0025750464 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 0.961        |
|    cost_values           | 1.15         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.23         |
|    n_updates             | 4440         |
|    policy_gradient_loss  | -0.000284    |
|    std                   | 0.617        |
|    value_loss            | 8.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5160594   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0053113224 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.66         |
|    cost_values           | 1.09         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.71         |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.614        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6793482  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 915456      |
| train/                   |             |
|    approx_kl             | 0.003920401 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 1.58        |
|    cost_values           | 1.11        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 4460        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.612       |
|    value_loss            | 20          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.69120413  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0027082744 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 1.04         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.7         |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.612        |
|    value_loss            | 33.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0472002    |
| rollout/                 |               |
|    ep_len_mean           | 943           |
|    ep_rew_mean           | -758          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 8             |
|    time_elapsed          | 267           |
|    total_timesteps       | 919552        |
| train/                   |               |
|    approx_kl             | 0.00039084707 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.836         |
|    cost_value_loss       | 0.0431        |
|    cost_values           | 0.986         |
|    entropy               | -1.84         |
|    entropy_loss          | -1.84         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 29.1          |
|    n_updates             | 4480          |
|    policy_gradient_loss  | -2.66e-05     |
|    std                   | 0.612         |
|    value_loss            | 63.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.53767926  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0002922592 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.815        |
|    cost_value_loss       | 0.0563       |
|    cost_values           | 0.947        |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.6         |
|    n_updates             | 4490         |
|    policy_gradient_loss  | -0.000133    |
|    std                   | 0.612        |
|    value_loss            | 71.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8878161   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0027173473 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 1            |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.612        |
|    value_loss            | 12.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9897537   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0024411022 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 3.07         |
|    cost_values           | 1.03         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.000619    |
|    std                   | 0.612        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.54958415 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 406         |
|    total_timesteps       | 927744      |
| train/                   |             |
|    approx_kl             | 0.005323126 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.663       |
|    cost_values           | 1.01        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.3        |
|    n_updates             | 4520        |
|    policy_gradient_loss  | -0.000966   |
|    std                   | 0.613       |
|    value_loss            | 50.3        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.2936081    |
| rollout/                 |               |
|    ep_len_mean           | 945           |
|    ep_rew_mean           | -753          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 13            |
|    time_elapsed          | 441           |
|    total_timesteps       | 929792        |
| train/                   |               |
|    approx_kl             | 0.00096715405 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.59          |
|    cost_value_loss       | 2.4           |
|    cost_values           | 1.11          |
|    entropy               | -1.85         |
|    entropy_loss          | -1.84         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.49          |
|    n_updates             | 4530          |
|    policy_gradient_loss  | 0.000644      |
|    std                   | 0.613         |
|    value_loss            | 11.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4168607   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 475          |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0031633605 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 4.8          |
|    cost_values           | 1.35         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -0.000277    |
|    std                   | 0.613        |
|    value_loss            | 17.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.13         |
| reward                   | -0.40741515  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 510          |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0015967416 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.0459       |
|    cost_values           | 1.34         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.84        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.4         |
|    n_updates             | 4550         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.613        |
|    value_loss            | 73.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.52452195 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -750        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 544         |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.006056587 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 0.948       |
|    cost_values           | 1.04        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.613       |
|    value_loss            | 21.5        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.5825796 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -747       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 17         |
|    time_elapsed          | 578        |
|    total_timesteps       | 937984     |
| train/                   |            |
|    approx_kl             | 0.00319335 |
|    clip_fraction         | 0.00234    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.36       |
|    cost_value_loss       | 2.23       |
|    cost_values           | 1.01       |
|    entropy               | -1.84      |
|    entropy_loss          | -1.84      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 3.77       |
|    n_updates             | 4570       |
|    policy_gradient_loss  | -0.000435  |
|    std                   | 0.613      |
|    value_loss            | 6.55       |
-----------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.7290233    |
| rollout/                 |               |
|    ep_len_mean           | 945           |
|    ep_rew_mean           | -743          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 18            |
|    time_elapsed          | 613           |
|    total_timesteps       | 940032        |
| train/                   |               |
|    approx_kl             | 0.00018066968 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.921         |
|    cost_value_loss       | 0.167         |
|    cost_values           | 0.962         |
|    entropy               | -1.84         |
|    entropy_loss          | -1.84         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.3          |
|    n_updates             | 4580          |
|    policy_gradient_loss  | 3.1e-06       |
|    std                   | 0.612         |
|    value_loss            | 37.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8748298   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 647          |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0042737657 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.823        |
|    cost_values           | 0.97         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.09         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.61         |
|    value_loss            | 8.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.677829   |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -741        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 682         |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.004569687 |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.955       |
|    cost_value_loss       | 0.41        |
|    cost_values           | 0.977       |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.61        |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4720042   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 946176       |
| train/                   |              |
|    approx_kl             | 0.0044923504 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.4          |
|    cost_values           | 1.05         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.08         |
|    n_updates             | 4610         |
|    policy_gradient_loss  | -0.000666    |
|    std                   | 0.609        |
|    value_loss            | 13.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.75494605 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 752         |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.006342928 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 0.695       |
|    cost_values           | 1.05        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.18        |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.608       |
|    value_loss            | 15.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9827451   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 950272       |
| train/                   |              |
|    approx_kl             | 0.0059837564 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 2.89         |
|    cost_values           | 1.23         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 4630         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.608        |
|    value_loss            | 22.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7854577   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 822          |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0042428114 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 3.14         |
|    cost_values           | 1.64         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.32         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.607        |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0767479   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 857          |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0063830093 |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 0.751        |
|    cost_values           | 1.68         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.83         |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.602        |
|    value_loss            | 4.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.58792317  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 891          |
|    total_timesteps       | 956416       |
| train/                   |              |
|    approx_kl             | 0.0049145143 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 0.612        |
|    cost_values           | 1.54         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.89         |
|    n_updates             | 4660         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.602        |
|    value_loss            | 5.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8398461   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 925          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0041952506 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 0.865        |
|    cost_values           | 1.35         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.81         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.601        |
|    value_loss            | 7.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9949812   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 960          |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0045721983 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.542        |
|    cost_values           | 1.28         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.17         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -5e-05       |
|    std                   | 0.598        |
|    value_loss            | 8.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0650717   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 994          |
|    total_timesteps       | 962560       |
| train/                   |              |
|    approx_kl             | 0.0047983727 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 2.62         |
|    cost_values           | 1.43         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 4690         |
|    policy_gradient_loss  | 7.95e-05     |
|    std                   | 0.598        |
|    value_loss            | 7.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.77898955  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0051860185 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 2.55         |
|    cost_values           | 1.91         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.000681    |
|    std                   | 0.597        |
|    value_loss            | 24.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6733856   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0048142276 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.91         |
|    cost_value_loss       | 4.02         |
|    cost_values           | 2.23         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.52         |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.597        |
|    value_loss            | 9.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6126401   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1097         |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0050740335 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 2.54         |
|    cost_values           | 2.32         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.4         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00071     |
|    std                   | 0.596        |
|    value_loss            | 42.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.87584656 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -739        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1131        |
|    total_timesteps       | 970752      |
| train/                   |             |
|    approx_kl             | 0.00155051  |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 6.59        |
|    cost_values           | 2.36        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 4730        |
|    policy_gradient_loss  | -0.000715   |
|    std                   | 0.596       |
|    value_loss            | 23.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67059726  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1166         |
|    total_timesteps       | 972800       |
| train/                   |              |
|    approx_kl             | 0.0019558966 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 2.27         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 4740         |
|    policy_gradient_loss  | -0.000781    |
|    std                   | 0.596        |
|    value_loss            | 34.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7718746   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1200         |
|    total_timesteps       | 974848       |
| train/                   |              |
|    approx_kl             | 0.0048170174 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 3.04         |
|    cost_values           | 2.11         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 4750         |
|    policy_gradient_loss  | -0.000945    |
|    std                   | 0.596        |
|    value_loss            | 17.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3547263   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1235         |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0011791524 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 3.03         |
|    cost_values           | 2.19         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.62         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | 0.000107     |
|    std                   | 0.596        |
|    value_loss            | 6.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60256386  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1269         |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0052187527 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 2.46         |
|    cost_values           | 2.25         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.86         |
|    n_updates             | 4770         |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.595        |
|    value_loss            | 8.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.92470366 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -740        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1303        |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.00509329  |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.71        |
|    cost_value_loss       | 4.02        |
|    cost_values           | 2.16        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 0.594       |
|    value_loss            | 5.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.87517965  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1338         |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0038175455 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 2.2          |
|    cost_values           | 2.21         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.78         |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.595        |
|    value_loss            | 3.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0888184   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1372         |
|    total_timesteps       | 985088       |
| train/                   |              |
|    approx_kl             | 0.0017555526 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 1.55         |
|    cost_values           | 2.23         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.56         |
|    n_updates             | 4800         |
|    policy_gradient_loss  | 1.93e-05     |
|    std                   | 0.596        |
|    value_loss            | 12.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.06         |
| reward                   | -0.62328774  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1406         |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 0.0004347849 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 0.602        |
|    cost_values           | 1.96         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.98         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | -0.000101    |
|    std                   | 0.596        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7802708   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1440         |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0011063073 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 0.546        |
|    cost_values           | 1.64         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.5          |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00064     |
|    std                   | 0.596        |
|    value_loss            | 20.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.52252495 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1475        |
|    total_timesteps       | 991232      |
| train/                   |             |
|    approx_kl             | 0.008150686 |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 0.0733      |
|    cost_values           | 1.25        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.78       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.72        |
|    n_updates             | 4830        |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.589       |
|    value_loss            | 5.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.887004    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1510         |
|    total_timesteps       | 993280       |
| train/                   |              |
|    approx_kl             | 0.0031506827 |
|    clip_fraction         | 0.0833       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 1.15         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 4840         |
|    policy_gradient_loss  | -0.000259    |
|    std                   | 0.587        |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.82363766  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1544         |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0038684057 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.902        |
|    cost_value_loss       | 0.0448       |
|    cost_values           | 0.959        |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.58         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.000552    |
|    std                   | 0.587        |
|    value_loss            | 5.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7609425  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -768        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1579        |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.005438542 |
|    clip_fraction         | 0.0186      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.761       |
|    cost_value_loss       | 0.032       |
|    cost_values           | 0.863       |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.96        |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.588       |
|    value_loss            | 4.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42113864  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1614         |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0035592453 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 4.13         |
|    cost_values           | 1.1          |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.79         |
|    n_updates             | 4870         |
|    policy_gradient_loss  | -0.000543    |
|    std                   | 0.587        |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.93415445  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1649         |
|    total_timesteps       | 1001472      |
| train/                   |              |
|    approx_kl             | 0.0038408365 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 1.97         |
|    cost_values           | 1.43         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 4880         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.585        |
|    value_loss            | 6.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.34717333  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1684         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0030813655 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 3.55         |
|    cost_values           | 1.45         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.82         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.000362    |
|    std                   | 0.585        |
|    value_loss            | 8.54         |
-------------------------------------------
---------------------------------
| avg_speed          | 8        |
| cost               | 0        |
| is_success         | 0        |
| max_speed          | 8        |
| reward             | -1.26612 |
| rollout/           |          |
|    ep_len_mean     | 979      |
|    ep_rew_mean     | -768     |
| time/              |          |
|    fps             | 82       |
|    iterations      | 1        |
|    time_elapsed    | 24       |
|    total_timesteps | 1005568  |
---------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7022338   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0034295483 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 4.06         |
|    cost_values           | 1.67         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.586        |
|    value_loss            | 25.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0078404  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -773        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.003836372 |
|    clip_fraction         | 0.00571     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 0.0981      |
|    cost_values           | 1.81        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.586       |
|    value_loss            | 21.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.82        |
| reward                   | -0.37142318 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 1011712     |
| train/                   |             |
|    approx_kl             | 0.005848306 |
|    clip_fraction         | 0.0136      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 0.0391      |
|    cost_values           | 1.41        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.22        |
|    n_updates             | 4930        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.585       |
|    value_loss            | 17.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.533794   |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -764        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.003091426 |
|    clip_fraction         | 0.00112     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 0.892       |
|    cost_values           | 1.09        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.6        |
|    n_updates             | 4940        |
|    policy_gradient_loss  | -0.000405   |
|    std                   | 0.586       |
|    value_loss            | 38.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8315131   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1015808      |
| train/                   |              |
|    approx_kl             | 0.0002279823 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.09         |
|    cost_values           | 0.995        |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.5          |
|    n_updates             | 4950         |
|    policy_gradient_loss  | 0.000105     |
|    std                   | 0.585        |
|    value_loss            | 9.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73947024  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0010825472 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 1.57         |
|    cost_values           | 1.06         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.55         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.586        |
|    value_loss            | 2.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6139847   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 1019904      |
| train/                   |              |
|    approx_kl             | 0.0012070369 |
|    clip_fraction         | 0.0562       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.964        |
|    cost_value_loss       | 0.197        |
|    cost_values           | 0.993        |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.85         |
|    n_updates             | 4970         |
|    policy_gradient_loss  | 0.0017       |
|    std                   | 0.586        |
|    value_loss            | 8.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7849796   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0028989308 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 3.7          |
|    cost_values           | 1.13         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.1          |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -0.00084     |
|    std                   | 0.586        |
|    value_loss            | 15.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.4140631    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -749          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 10            |
|    time_elapsed          | 336           |
|    total_timesteps       | 1024000       |
| train/                   |               |
|    approx_kl             | 0.00036306604 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.33          |
|    cost_value_loss       | 0.744         |
|    cost_values           | 1.32          |
|    entropy               | -1.75         |
|    entropy_loss          | -1.75         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.42          |
|    n_updates             | 4990          |
|    policy_gradient_loss  | -0.000102     |
|    std                   | 0.585         |
|    value_loss            | 8.78          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.7700913   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 1026048      |
| train/                   |              |
|    approx_kl             | 0.0021152247 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 1.48         |
|    cost_values           | 1.2          |
|    entropy               | -1.76        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 5000         |
|    policy_gradient_loss  | -0.000863    |
|    std                   | 0.587        |
|    value_loss            | 40.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0509418  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 405         |
|    total_timesteps       | 1028096     |
| train/                   |             |
|    approx_kl             | 0.007446134 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 2.16        |
|    cost_values           | 1.39        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 5010        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.589       |
|    value_loss            | 6.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52358145  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1030144      |
| train/                   |              |
|    approx_kl             | 0.0029672706 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 0.207        |
|    cost_values           | 1.41         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 5020         |
|    policy_gradient_loss  | 0.000267     |
|    std                   | 0.589        |
|    value_loss            | 13.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48835868  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1032192      |
| train/                   |              |
|    approx_kl             | 0.0024200962 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 3.24         |
|    cost_values           | 1.21         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 5030         |
|    policy_gradient_loss  | -0.00056     |
|    std                   | 0.589        |
|    value_loss            | 8.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0909257   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 509          |
|    total_timesteps       | 1034240      |
| train/                   |              |
|    approx_kl             | 0.0047719255 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 1.07         |
|    cost_values           | 1.14         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 5040         |
|    policy_gradient_loss  | -0.000639    |
|    std                   | 0.589        |
|    value_loss            | 19.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7995228   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 1036288      |
| train/                   |              |
|    approx_kl             | 0.0057279654 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 3.27         |
|    cost_values           | 1.12         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.84         |
|    n_updates             | 5050         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.587        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78426296  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 578          |
|    total_timesteps       | 1038336      |
| train/                   |              |
|    approx_kl             | 0.0028201242 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 0.552        |
|    cost_values           | 1.3          |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.6          |
|    n_updates             | 5060         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.587        |
|    value_loss            | 5.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6652197  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -745        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 612         |
|    total_timesteps       | 1040384     |
| train/                   |             |
|    approx_kl             | 0.004325152 |
|    clip_fraction         | 0.00454     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 2.23        |
|    cost_values           | 1.3         |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.56        |
|    n_updates             | 5070        |
|    policy_gradient_loss  | -0.000745   |
|    std                   | 0.587       |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0166324   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 647          |
|    total_timesteps       | 1042432      |
| train/                   |              |
|    approx_kl             | 0.0021959343 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 2.47         |
|    cost_values           | 1.51         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.6          |
|    n_updates             | 5080         |
|    policy_gradient_loss  | -2.16e-05    |
|    std                   | 0.585        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1660925   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 681          |
|    total_timesteps       | 1044480      |
| train/                   |              |
|    approx_kl             | 0.0041208193 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 0.565        |
|    cost_values           | 1.72         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 5090         |
|    policy_gradient_loss  | 0.000165     |
|    std                   | 0.585        |
|    value_loss            | 25.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9513113  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 715         |
|    total_timesteps       | 1046528     |
| train/                   |             |
|    approx_kl             | 0.003179452 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 1.43        |
|    cost_values           | 1.59        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.99        |
|    n_updates             | 5100        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.585       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8638267   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 1048576      |
| train/                   |              |
|    approx_kl             | 0.0023309197 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 1.37         |
|    cost_values           | 1.63         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 5110         |
|    policy_gradient_loss  | -0.000377    |
|    std                   | 0.586        |
|    value_loss            | 46.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.88994086 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 784         |
|    total_timesteps       | 1050624     |
| train/                   |             |
|    approx_kl             | 0.004325573 |
|    clip_fraction         | 0.00669     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 1.49        |
|    cost_values           | 1.58        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.4         |
|    n_updates             | 5120        |
|    policy_gradient_loss  | -0.00037    |
|    std                   | 0.585       |
|    value_loss            | 5.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8072981   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -754         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 818          |
|    total_timesteps       | 1052672      |
| train/                   |              |
|    approx_kl             | 0.0024881992 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.0611       |
|    cost_values           | 1.52         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.67         |
|    n_updates             | 5130         |
|    policy_gradient_loss  | -0.000133    |
|    std                   | 0.584        |
|    value_loss            | 6.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66550446  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 853          |
|    total_timesteps       | 1054720      |
| train/                   |              |
|    approx_kl             | 0.0048386334 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 1.2          |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.62         |
|    n_updates             | 5140         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.584        |
|    value_loss            | 14.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.1810199   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 1056768      |
| train/                   |              |
|    approx_kl             | 0.0037450534 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.483        |
|    cost_values           | 1.02         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.45         |
|    n_updates             | 5150         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.584        |
|    value_loss            | 6.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1331186   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 921          |
|    total_timesteps       | 1058816      |
| train/                   |              |
|    approx_kl             | 0.0041962774 |
|    clip_fraction         | 0.0471       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 0.119        |
|    cost_values           | 0.981        |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.1         |
|    n_updates             | 5160         |
|    policy_gradient_loss  | 0.000796     |
|    std                   | 0.584        |
|    value_loss            | 99.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3691759   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1060864      |
| train/                   |              |
|    approx_kl             | 0.0036235158 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 1.03         |
|    cost_values           | 0.99         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.01         |
|    n_updates             | 5170         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.584        |
|    value_loss            | 17.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.743       |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 990          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0007535182 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.46         |
|    cost_values           | 0.999        |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 5180         |
|    policy_gradient_loss  | -0.000287    |
|    std                   | 0.584        |
|    value_loss            | 37.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0269434   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 1064960      |
| train/                   |              |
|    approx_kl             | 0.0008809073 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 2.47         |
|    cost_values           | 1.04         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 5190         |
|    policy_gradient_loss  | -7.83e-05    |
|    std                   | 0.584        |
|    value_loss            | 25.8         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.9742379 |
| rollout/                 |            |
|    ep_len_mean           | 972        |
|    ep_rew_mean           | -779       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 31         |
|    time_elapsed          | 1059       |
|    total_timesteps       | 1067008    |
| train/                   |            |
|    approx_kl             | 0.00323876 |
|    clip_fraction         | 0.0184     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.909      |
|    cost_value_loss       | 0.0312     |
|    cost_values           | 0.945      |
|    entropy               | -1.74      |
|    entropy_loss          | -1.74      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.13       |
|    n_updates             | 5200       |
|    policy_gradient_loss  | -0.00122   |
|    std                   | 0.58       |
|    value_loss            | 10.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0154935   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1093         |
|    total_timesteps       | 1069056      |
| train/                   |              |
|    approx_kl             | 0.0018847804 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.857        |
|    cost_value_loss       | 0.373        |
|    cost_values           | 0.927        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 5210         |
|    policy_gradient_loss  | -0.000354    |
|    std                   | 0.577        |
|    value_loss            | 27.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.282284     |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -798          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 33            |
|    time_elapsed          | 1128          |
|    total_timesteps       | 1071104       |
| train/                   |               |
|    approx_kl             | 0.00027743395 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.746         |
|    cost_value_loss       | 0.0232        |
|    cost_values           | 0.88          |
|    entropy               | -1.73         |
|    entropy_loss          | -1.73         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.99          |
|    n_updates             | 5220          |
|    policy_gradient_loss  | 5.76e-05      |
|    std                   | 0.576         |
|    value_loss            | 14.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6523067   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1163         |
|    total_timesteps       | 1073152      |
| train/                   |              |
|    approx_kl             | 0.0012134821 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.703        |
|    cost_value_loss       | 0.023        |
|    cost_values           | 0.823        |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 5230         |
|    policy_gradient_loss  | -0.000585    |
|    std                   | 0.576        |
|    value_loss            | 25.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.211187   |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -800        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1197        |
|    total_timesteps       | 1075200     |
| train/                   |             |
|    approx_kl             | 0.004625227 |
|    clip_fraction         | 0.00654     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 1.23        |
|    cost_values           | 0.838       |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.1        |
|    n_updates             | 5240        |
|    policy_gradient_loss  | -0.000781   |
|    std                   | 0.576       |
|    value_loss            | 50.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5703282  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -804        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1232        |
|    total_timesteps       | 1077248     |
| train/                   |             |
|    approx_kl             | 0.004207644 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 0.832       |
|    cost_values           | 0.971       |
|    entropy               | -1.73       |
|    entropy_loss          | -1.72       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.85        |
|    n_updates             | 5250        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.576       |
|    value_loss            | 13.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1984868   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 1079296      |
| train/                   |              |
|    approx_kl             | 0.0032224292 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 2.15         |
|    cost_values           | 1.15         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.2         |
|    n_updates             | 5260         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.575        |
|    value_loss            | 31.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.4828082    |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -814          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1301          |
|    total_timesteps       | 1081344       |
| train/                   |               |
|    approx_kl             | 0.00059248856 |
|    clip_fraction         | 0.000244      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.23          |
|    cost_value_loss       | 0.298         |
|    cost_values           | 1.33          |
|    entropy               | -1.72         |
|    entropy_loss          | -1.72         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.1          |
|    n_updates             | 5270          |
|    policy_gradient_loss  | 0.00112       |
|    std                   | 0.574         |
|    value_loss            | 27.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7480741   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -812         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1335         |
|    total_timesteps       | 1083392      |
| train/                   |              |
|    approx_kl             | 0.0044246786 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.641        |
|    cost_values           | 1.05         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 5280         |
|    policy_gradient_loss  | -0.000163    |
|    std                   | 0.575        |
|    value_loss            | 22.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2907318  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -806        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1369        |
|    total_timesteps       | 1085440     |
| train/                   |             |
|    approx_kl             | 0.005133529 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 3.11        |
|    cost_values           | 1.09        |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.24        |
|    n_updates             | 5290        |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.575       |
|    value_loss            | 16.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.96433496  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1404         |
|    total_timesteps       | 1087488      |
| train/                   |              |
|    approx_kl             | 0.0024079187 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.53         |
|    cost_values           | 1.18         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.66         |
|    n_updates             | 5300         |
|    policy_gradient_loss  | -0.000199    |
|    std                   | 0.575        |
|    value_loss            | 10.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0184935  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -804        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1438        |
|    total_timesteps       | 1089536     |
| train/                   |             |
|    approx_kl             | 0.006426476 |
|    clip_fraction         | 0.0378      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.133       |
|    cost_values           | 1.1         |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.15        |
|    n_updates             | 5310        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.574       |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6984748   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -802         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1473         |
|    total_timesteps       | 1091584      |
| train/                   |              |
|    approx_kl             | 0.0034802454 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.904        |
|    cost_value_loss       | 0.12         |
|    cost_values           | 0.922        |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.61         |
|    n_updates             | 5320         |
|    policy_gradient_loss  | 0.000156     |
|    std                   | 0.576        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.34349     |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -798         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1507         |
|    total_timesteps       | 1093632      |
| train/                   |              |
|    approx_kl             | 0.0019728104 |
|    clip_fraction         | 0.0832       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 3.28         |
|    cost_values           | 0.998        |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 5330         |
|    policy_gradient_loss  | 0.0024       |
|    std                   | 0.576        |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7363286   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1541         |
|    total_timesteps       | 1095680      |
| train/                   |              |
|    approx_kl             | 0.0045443317 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.766        |
|    cost_values           | 0.995        |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 5340         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.576        |
|    value_loss            | 28.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.19         |
| reward                   | -0.7330216   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -801         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1576         |
|    total_timesteps       | 1097728      |
| train/                   |              |
|    approx_kl             | 0.0055038147 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 3.13         |
|    cost_values           | 1.13         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 5350         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.576        |
|    value_loss            | 18           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30409032 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -802        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1611        |
|    total_timesteps       | 1099776     |
| train/                   |             |
|    approx_kl             | 0.002117889 |
|    clip_fraction         | 0.002       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 0.752       |
|    cost_values           | 1.26        |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 5360        |
|    policy_gradient_loss  | -0.000539   |
|    std                   | 0.576       |
|    value_loss            | 13.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54152113  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1645         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0054765334 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.245        |
|    cost_values           | 1.04         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.72         |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.000208    |
|    std                   | 0.577        |
|    value_loss            | 9.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2879567  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -786        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1680        |
|    total_timesteps       | 1103872     |
| train/                   |             |
|    approx_kl             | 0.001956202 |
|    clip_fraction         | 0.0101      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.986       |
|    cost_value_loss       | 0.489       |
|    cost_values           | 0.971       |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.2        |
|    n_updates             | 5380        |
|    policy_gradient_loss  | -7.57e-05   |
|    std                   | 0.578       |
|    value_loss            | 42.6        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -1.2612246 |
| rollout/           |            |
|    ep_len_mean     | 958        |
|    ep_rew_mean     | -787       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1105920    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6739251   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -793         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 1107968      |
| train/                   |              |
|    approx_kl             | 0.0030399417 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.0266       |
|    cost_values           | 1.12         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.31         |
|    n_updates             | 5400         |
|    policy_gradient_loss  | -0.000708    |
|    std                   | 0.579        |
|    value_loss            | 13.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.92        |
| reward                   | -0.78705305 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -790        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1110016     |
| train/                   |             |
|    approx_kl             | 0.003967257 |
|    clip_fraction         | 0.00444     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 3.77        |
|    cost_values           | 1.04        |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.39        |
|    n_updates             | 5410        |
|    policy_gradient_loss  | -0.000845   |
|    std                   | 0.579       |
|    value_loss            | 13.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89434564  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1112064      |
| train/                   |              |
|    approx_kl             | 0.0013791656 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.926        |
|    cost_value_loss       | 0.0333       |
|    cost_values           | 0.966        |
|    entropy               | -1.76        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.45         |
|    n_updates             | 5420         |
|    policy_gradient_loss  | -0.000414    |
|    std                   | 0.586        |
|    value_loss            | 3.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0418738   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1114112      |
| train/                   |              |
|    approx_kl             | 0.0017801067 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.958        |
|    cost_values           | 1.03         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.3         |
|    n_updates             | 5430         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.589        |
|    value_loss            | 37.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6152247   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -797         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1116160      |
| train/                   |              |
|    approx_kl             | 0.0040607885 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.922        |
|    cost_value_loss       | 0.0638       |
|    cost_values           | 0.993        |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 5440         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.589        |
|    value_loss            | 28.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.75004363 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -800        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 1118208     |
| train/                   |             |
|    approx_kl             | 0.005597255 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.05        |
|    cost_values           | 0.966       |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25          |
|    n_updates             | 5450        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.589       |
|    value_loss            | 51.6        |
------------------------------------------
wandb: Network error (ConnectTimeout), entering retry loop.
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3768275   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1120256      |
| train/                   |              |
|    approx_kl             | 0.0018564377 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.898        |
|    cost_value_loss       | 0.227        |
|    cost_values           | 0.914        |
|    entropy               | -1.75        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.77         |
|    n_updates             | 5460         |
|    policy_gradient_loss  | -0.000778    |
|    std                   | 0.584        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85760134  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 1122304      |
| train/                   |              |
|    approx_kl             | 0.0008241109 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 1.83         |
|    cost_values           | 0.978        |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.07         |
|    n_updates             | 5470         |
|    policy_gradient_loss  | 9.09e-06     |
|    std                   | 0.582        |
|    value_loss            | 13.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5720602    |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -806          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 10            |
|    time_elapsed          | 334           |
|    total_timesteps       | 1124352       |
| train/                   |               |
|    approx_kl             | 0.00073082105 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.73          |
|    cost_value_loss       | 3.33          |
|    cost_values           | 1.02          |
|    entropy               | -1.74         |
|    entropy_loss          | -1.74         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 22.2          |
|    n_updates             | 5480          |
|    policy_gradient_loss  | -0.000173     |
|    std                   | 0.582         |
|    value_loss            | 46.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75528115  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -803         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 1126400      |
| train/                   |              |
|    approx_kl             | 0.0007727367 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.879        |
|    cost_value_loss       | 0.022        |
|    cost_values           | 0.985        |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 5490         |
|    policy_gradient_loss  | -0.000335    |
|    std                   | 0.582        |
|    value_loss            | 18.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.43612224  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -792         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 1128448      |
| train/                   |              |
|    approx_kl             | 0.0039641587 |
|    clip_fraction         | 0.00552      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 3.89         |
|    cost_values           | 1.03         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.93         |
|    n_updates             | 5500         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.582        |
|    value_loss            | 7.12         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.58283395   |
| rollout/                 |               |
|    ep_len_mean           | 961           |
|    ep_rew_mean           | -793          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 13            |
|    time_elapsed          | 438           |
|    total_timesteps       | 1130496       |
| train/                   |               |
|    approx_kl             | 0.00030804085 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.8           |
|    cost_value_loss       | 3.28          |
|    cost_values           | 1.07          |
|    entropy               | -1.74         |
|    entropy_loss          | -1.74         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 26.2          |
|    n_updates             | 5510          |
|    policy_gradient_loss  | -0.000242     |
|    std                   | 0.582         |
|    value_loss            | 49.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3032575   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 1132544      |
| train/                   |              |
|    approx_kl             | 0.0050386363 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 6.2          |
|    cost_values           | 1.25         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 5520         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.582        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4532967   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 507          |
|    total_timesteps       | 1134592      |
| train/                   |              |
|    approx_kl             | 0.0063694124 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.16         |
|    cost_value_loss       | 6.3          |
|    cost_values           | 1.84         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 5530         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.582        |
|    value_loss            | 21.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7769824  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -792        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 542         |
|    total_timesteps       | 1136640     |
| train/                   |             |
|    approx_kl             | 0.002785086 |
|    clip_fraction         | 0.0118      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.18        |
|    cost_value_loss       | 1.69        |
|    cost_values           | 2.13        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 5540        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.586       |
|    value_loss            | 24.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.647872    |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 576          |
|    total_timesteps       | 1138688      |
| train/                   |              |
|    approx_kl             | 0.0026420117 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.276        |
|    cost_values           | 1.93         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 5550         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.585        |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6088112   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -792         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 610          |
|    total_timesteps       | 1140736      |
| train/                   |              |
|    approx_kl             | 0.0043102093 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 3.66         |
|    cost_values           | 1.78         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 5560         |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.584        |
|    value_loss            | 26           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3108649   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1142784      |
| train/                   |              |
|    approx_kl             | 0.0042999154 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 2.11         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 5570         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.583        |
|    value_loss            | 19.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4540123   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -797         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 679          |
|    total_timesteps       | 1144832      |
| train/                   |              |
|    approx_kl             | 0.0021601347 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 0.112        |
|    cost_values           | 2.11         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.71         |
|    n_updates             | 5580         |
|    policy_gradient_loss  | 5.97e-05     |
|    std                   | 0.583        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.69299537  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 713          |
|    total_timesteps       | 1146880      |
| train/                   |              |
|    approx_kl             | 0.0049313623 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 0.869        |
|    cost_values           | 1.73         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 5590         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.582        |
|    value_loss            | 33.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9132081   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -798         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 748          |
|    total_timesteps       | 1148928      |
| train/                   |              |
|    approx_kl             | 0.0021453341 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 0.876        |
|    cost_values           | 1.5          |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 5600         |
|    policy_gradient_loss  | -0.00072     |
|    std                   | 0.582        |
|    value_loss            | 31.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.86314875  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -798         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 782          |
|    total_timesteps       | 1150976      |
| train/                   |              |
|    approx_kl             | 0.0026714327 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 4.62         |
|    cost_values           | 1.38         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.98         |
|    n_updates             | 5610         |
|    policy_gradient_loss  | -0.000521    |
|    std                   | 0.582        |
|    value_loss            | 7.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60974693  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 816          |
|    total_timesteps       | 1153024      |
| train/                   |              |
|    approx_kl             | 0.0037495727 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.0349       |
|    cost_values           | 1.24         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.47         |
|    n_updates             | 5620         |
|    policy_gradient_loss  | -0.000747    |
|    std                   | 0.583        |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.18         |
| reward                   | -0.7486078   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -789         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 851          |
|    total_timesteps       | 1155072      |
| train/                   |              |
|    approx_kl             | 0.0035448084 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 0.604        |
|    cost_values           | 1.03         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 5630         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.582        |
|    value_loss            | 9            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8654327   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 886          |
|    total_timesteps       | 1157120      |
| train/                   |              |
|    approx_kl             | 0.0024887598 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 5.05         |
|    cost_values           | 1.15         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.21         |
|    n_updates             | 5640         |
|    policy_gradient_loss  | 9.4e-05      |
|    std                   | 0.582        |
|    value_loss            | 8.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5639195   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 921          |
|    total_timesteps       | 1159168      |
| train/                   |              |
|    approx_kl             | 0.0026519801 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.02         |
|    cost_values           | 1.32         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 5650         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.581        |
|    value_loss            | 22.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.61635053  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -783         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1161216      |
| train/                   |              |
|    approx_kl             | 0.0021735458 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 0.0328       |
|    cost_values           | 1.21         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.02         |
|    n_updates             | 5660         |
|    policy_gradient_loss  | -0.000415    |
|    std                   | 0.581        |
|    value_loss            | 6.61         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.6157546    |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -782          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 29            |
|    time_elapsed          | 991           |
|    total_timesteps       | 1163264       |
| train/                   |               |
|    approx_kl             | 0.00032212783 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.54          |
|    cost_value_loss       | 7.14          |
|    cost_values           | 1.01          |
|    entropy               | -1.74         |
|    entropy_loss          | -1.74         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 46.9          |
|    n_updates             | 5670          |
|    policy_gradient_loss  | -0.000183     |
|    std                   | 0.581         |
|    value_loss            | 65.8          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47587654 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -778        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1026        |
|    total_timesteps       | 1165312     |
| train/                   |             |
|    approx_kl             | 0.004346435 |
|    clip_fraction         | 0.0153      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.625       |
|    cost_values           | 0.996       |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 5680        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.582       |
|    value_loss            | 23.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7010239   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1061         |
|    total_timesteps       | 1167360      |
| train/                   |              |
|    approx_kl             | 0.0038544447 |
|    clip_fraction         | 0.00337      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 1.37         |
|    cost_values           | 1            |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.58         |
|    n_updates             | 5690         |
|    policy_gradient_loss  | -0.000807    |
|    std                   | 0.582        |
|    value_loss            | 7.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0085324   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1096         |
|    total_timesteps       | 1169408      |
| train/                   |              |
|    approx_kl             | 0.0027606229 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.895        |
|    cost_value_loss       | 0.122        |
|    cost_values           | 0.904        |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.72         |
|    n_updates             | 5700         |
|    policy_gradient_loss  | -0.000218    |
|    std                   | 0.582        |
|    value_loss            | 3.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7438925   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -781         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1130         |
|    total_timesteps       | 1171456      |
| train/                   |              |
|    approx_kl             | 0.0028268679 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.82         |
|    cost_values           | 0.978        |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 5710         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.581        |
|    value_loss            | 23.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40891108  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1165         |
|    total_timesteps       | 1173504      |
| train/                   |              |
|    approx_kl             | 0.0003198521 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 1.64         |
|    cost_values           | 1.04         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.69         |
|    n_updates             | 5720         |
|    policy_gradient_loss  | 0.000108     |
|    std                   | 0.581        |
|    value_loss            | 6.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.38549593  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1199         |
|    total_timesteps       | 1175552      |
| train/                   |              |
|    approx_kl             | 0.0015999431 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 1.96         |
|    cost_values           | 1.03         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.75         |
|    n_updates             | 5730         |
|    policy_gradient_loss  | -0.000465    |
|    std                   | 0.58         |
|    value_loss            | 18           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0777307   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1233         |
|    total_timesteps       | 1177600      |
| train/                   |              |
|    approx_kl             | 0.0017018542 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.33         |
|    cost_values           | 0.997        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 5740         |
|    policy_gradient_loss  | -0.000906    |
|    std                   | 0.58         |
|    value_loss            | 23           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87188715  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1267         |
|    total_timesteps       | 1179648      |
| train/                   |              |
|    approx_kl             | 0.0049179955 |
|    clip_fraction         | 0.0374       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.895        |
|    cost_value_loss       | 0.0937       |
|    cost_values           | 0.967        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 5750         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.58         |
|    value_loss            | 26.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8406469   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1302         |
|    total_timesteps       | 1181696      |
| train/                   |              |
|    approx_kl             | 0.0037231697 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.764        |
|    cost_value_loss       | 0.0178       |
|    cost_values           | 0.869        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.92         |
|    n_updates             | 5760         |
|    policy_gradient_loss  | -0.000504    |
|    std                   | 0.58         |
|    value_loss            | 9.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8395506   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1336         |
|    total_timesteps       | 1183744      |
| train/                   |              |
|    approx_kl             | 0.0029386806 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.652        |
|    cost_value_loss       | 0.0145       |
|    cost_values           | 0.754        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.33         |
|    n_updates             | 5770         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.58         |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7694744   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1370         |
|    total_timesteps       | 1185792      |
| train/                   |              |
|    approx_kl             | 0.0053303977 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.608        |
|    cost_value_loss       | 0.0136       |
|    cost_values           | 0.62         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.48         |
|    n_updates             | 5780         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.577        |
|    value_loss            | 3.02         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.87376785   |
| rollout/                 |               |
|    ep_len_mean           | 973           |
|    ep_rew_mean           | -768          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1405          |
|    total_timesteps       | 1187840       |
| train/                   |               |
|    approx_kl             | 0.00055701396 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.16          |
|    cost_value_loss       | 3.5           |
|    cost_values           | 0.687         |
|    entropy               | -1.72         |
|    entropy_loss          | -1.72         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.57          |
|    n_updates             | 5790          |
|    policy_gradient_loss  | -0.000168     |
|    std                   | 0.576         |
|    value_loss            | 14.5          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.4834161  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -773        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1440        |
|    total_timesteps       | 1189888     |
| train/                   |             |
|    approx_kl             | 0.003289268 |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.667       |
|    cost_value_loss       | 0.0193      |
|    cost_values           | 0.783       |
|    entropy               | -1.73       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.62        |
|    n_updates             | 5800        |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.578       |
|    value_loss            | 3.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3709986   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1475         |
|    total_timesteps       | 1191936      |
| train/                   |              |
|    approx_kl             | 0.0024184843 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.865        |
|    cost_value_loss       | 1.22         |
|    cost_values           | 0.682        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 5810         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.578        |
|    value_loss            | 26.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.6          |
| reward                   | -0.7356392   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1509         |
|    total_timesteps       | 1193984      |
| train/                   |              |
|    approx_kl             | 0.0023039293 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.913        |
|    cost_value_loss       | 1.39         |
|    cost_values           | 0.768        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 5820         |
|    policy_gradient_loss  | -0.000682    |
|    std                   | 0.578        |
|    value_loss            | 24.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7827568  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -779        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1544        |
|    total_timesteps       | 1196032     |
| train/                   |             |
|    approx_kl             | 3.74346e-05 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 2.05        |
|    cost_values           | 0.902       |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 5830        |
|    policy_gradient_loss  | 0.000101    |
|    std                   | 0.578       |
|    value_loss            | 22.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0010332   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1580         |
|    total_timesteps       | 1198080      |
| train/                   |              |
|    approx_kl             | 0.0014397979 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.808        |
|    cost_value_loss       | 0.0358       |
|    cost_values           | 0.981        |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.74         |
|    n_updates             | 5840         |
|    policy_gradient_loss  | -0.00046     |
|    std                   | 0.578        |
|    value_loss            | 19.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.62035275 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -781        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1615        |
|    total_timesteps       | 1200128     |
| train/                   |             |
|    approx_kl             | 0.004412309 |
|    clip_fraction         | 0.00884     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 4.46        |
|    cost_values           | 1.09        |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.41        |
|    n_updates             | 5850        |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.578       |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45276213  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -789         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1650         |
|    total_timesteps       | 1202176      |
| train/                   |              |
|    approx_kl             | 0.0005080646 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 6.44         |
|    cost_values           | 1.27         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.03         |
|    n_updates             | 5860         |
|    policy_gradient_loss  | -0.000309    |
|    std                   | 0.578        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.83153087  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -781         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1685         |
|    total_timesteps       | 1204224      |
| train/                   |              |
|    approx_kl             | 0.0032162196 |
|    clip_fraction         | 0.00332      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 0.903        |
|    cost_values           | 1.26         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.83         |
|    n_updates             | 5870         |
|    policy_gradient_loss  | -0.000202    |
|    std                   | 0.578        |
|    value_loss            | 7.18         |
-------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.46398404 |
| rollout/           |             |
|    ep_len_mean     | 986         |
|    ep_rew_mean     | -775        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1206272     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.49497846 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 1208320     |
| train/                   |             |
|    approx_kl             | 0.005036886 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.04        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 1.02        |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.7        |
|    n_updates             | 5890        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.578       |
|    value_loss            | 43.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.25778922  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -775         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1210368      |
| train/                   |              |
|    approx_kl             | 0.0009949302 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 1.05         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.78         |
|    n_updates             | 5900         |
|    policy_gradient_loss  | -0.000107    |
|    std                   | 0.578        |
|    value_loss            | 5.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.237219   |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 127         |
|    total_timesteps       | 1212416     |
| train/                   |             |
|    approx_kl             | 0.003921055 |
|    clip_fraction         | 0.00278     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 3.49        |
|    cost_values           | 1.08        |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.85        |
|    n_updates             | 5910        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.577       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0430491   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 1214464      |
| train/                   |              |
|    approx_kl             | 0.0040436867 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 1.43         |
|    cost_values           | 1.09         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.36         |
|    n_updates             | 5920         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.576        |
|    value_loss            | 10           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.32365525  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1216512      |
| train/                   |              |
|    approx_kl             | 0.0030138711 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 3.64         |
|    cost_values           | 1.33         |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 5930         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.575        |
|    value_loss            | 29           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0514485   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1218560      |
| train/                   |              |
|    approx_kl             | 0.0047718924 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 3.19         |
|    cost_values           | 1.62         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.29         |
|    n_updates             | 5940         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 0.575        |
|    value_loss            | 11.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48275635 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 267         |
|    total_timesteps       | 1220608     |
| train/                   |             |
|    approx_kl             | 0.007939469 |
|    clip_fraction         | 0.0737      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 3.88        |
|    cost_values           | 1.78        |
|    entropy               | -1.71       |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.7        |
|    n_updates             | 5950        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.574       |
|    value_loss            | 36.3        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.81251824   |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -751          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 9             |
|    time_elapsed          | 302           |
|    total_timesteps       | 1222656       |
| train/                   |               |
|    approx_kl             | 0.00028037393 |
|    clip_fraction         | 0.0225        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.15          |
|    cost_value_loss       | 1.2           |
|    cost_values           | 2.09          |
|    entropy               | -1.7          |
|    entropy_loss          | -1.71         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.09          |
|    n_updates             | 5960          |
|    policy_gradient_loss  | 0.000201      |
|    std                   | 0.572         |
|    value_loss            | 9.37          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1126456  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 336         |
|    total_timesteps       | 1224704     |
| train/                   |             |
|    approx_kl             | 0.002356749 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 2.21        |
|    cost_values           | 2.15        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.01        |
|    n_updates             | 5970        |
|    policy_gradient_loss  | -0.000732   |
|    std                   | 0.571       |
|    value_loss            | 15.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.640759    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 1226752      |
| train/                   |              |
|    approx_kl             | 0.0030127293 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 2.18         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.45         |
|    n_updates             | 5980         |
|    policy_gradient_loss  | -0.000253    |
|    std                   | 0.57         |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3097893  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -764        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 405         |
|    total_timesteps       | 1228800     |
| train/                   |             |
|    approx_kl             | 0.003582922 |
|    clip_fraction         | 0.0419      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 0.0656      |
|    cost_values           | 1.82        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.13        |
|    n_updates             | 5990        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.569       |
|    value_loss            | 7.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42892015  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -765         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 1230848      |
| train/                   |              |
|    approx_kl             | 0.0038737645 |
|    clip_fraction         | 0.0248       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 2.09         |
|    cost_values           | 1.66         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.27         |
|    n_updates             | 6000         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.568        |
|    value_loss            | 13.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9468373   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1232896      |
| train/                   |              |
|    approx_kl             | 0.0027778922 |
|    clip_fraction         | 0.0559       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 5.03         |
|    cost_values           | 1.95         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.9         |
|    n_updates             | 6010         |
|    policy_gradient_loss  | 8.24e-05     |
|    std                   | 0.568        |
|    value_loss            | 46.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7256997   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1234944      |
| train/                   |              |
|    approx_kl             | 0.0031115343 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 1.69         |
|    cost_values           | 2.02         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.15         |
|    n_updates             | 6020         |
|    policy_gradient_loss  | -0.000713    |
|    std                   | 0.568        |
|    value_loss            | 9.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.86765504  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 1236992      |
| train/                   |              |
|    approx_kl             | 0.0028349417 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 0.0824       |
|    cost_values           | 1.86         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.8          |
|    n_updates             | 6030         |
|    policy_gradient_loss  | -0.000722    |
|    std                   | 0.567        |
|    value_loss            | 4.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.481852    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 577          |
|    total_timesteps       | 1239040      |
| train/                   |              |
|    approx_kl             | 0.0041470136 |
|    clip_fraction         | 0.00718      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 0.698        |
|    cost_values           | 1.49         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.5         |
|    n_updates             | 6040         |
|    policy_gradient_loss  | -0.000151    |
|    std                   | 0.567        |
|    value_loss            | 59.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.820509    |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 612          |
|    total_timesteps       | 1241088      |
| train/                   |              |
|    approx_kl             | 0.0014837572 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 2.74         |
|    cost_values           | 1.4          |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 6050         |
|    policy_gradient_loss  | -0.000436    |
|    std                   | 0.567        |
|    value_loss            | 45.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9207624  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 19          |
|    time_elapsed          | 646         |
|    total_timesteps       | 1243136     |
| train/                   |             |
|    approx_kl             | 0.005281211 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 5.45        |
|    cost_values           | 1.53        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.5        |
|    n_updates             | 6060        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.566       |
|    value_loss            | 39.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.69491524  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 1245184      |
| train/                   |              |
|    approx_kl             | 0.0022644904 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 3.25         |
|    cost_values           | 1.74         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.06         |
|    n_updates             | 6070         |
|    policy_gradient_loss  | -0.000307    |
|    std                   | 0.567        |
|    value_loss            | 6.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8537142   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 1247232      |
| train/                   |              |
|    approx_kl             | 0.0037389484 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 0.113        |
|    cost_values           | 1.73         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.72         |
|    n_updates             | 6080         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.567        |
|    value_loss            | 3.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6631873   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 749          |
|    total_timesteps       | 1249280      |
| train/                   |              |
|    approx_kl             | 0.0029337169 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.501        |
|    cost_values           | 1.39         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.42         |
|    n_updates             | 6090         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.566        |
|    value_loss            | 4.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.7081817  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -734        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 783         |
|    total_timesteps       | 1251328     |
| train/                   |             |
|    approx_kl             | 0.006573608 |
|    clip_fraction         | 0.0392      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.0256      |
|    cost_values           | 1.11        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.68       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.23        |
|    n_updates             | 6100        |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.562       |
|    value_loss            | 2.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.592364   |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -739        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 818         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.002343068 |
|    clip_fraction         | 0.000537    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 1.77        |
|    cost_values           | 1.23        |
|    entropy               | -1.66       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23          |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.000124   |
|    std                   | 0.558       |
|    value_loss            | 32          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5793924   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 852          |
|    total_timesteps       | 1255424      |
| train/                   |              |
|    approx_kl             | 0.0027012425 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.516        |
|    cost_values           | 1.34         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.91         |
|    n_updates             | 6120         |
|    policy_gradient_loss  | -0.00065     |
|    std                   | 0.555        |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1847863   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 887          |
|    total_timesteps       | 1257472      |
| train/                   |              |
|    approx_kl             | 0.0013636342 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 7.95         |
|    cost_values           | 1.34         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.1         |
|    n_updates             | 6130         |
|    policy_gradient_loss  | -0.000274    |
|    std                   | 0.555        |
|    value_loss            | 40.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5720103    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -741          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 27            |
|    time_elapsed          | 921           |
|    total_timesteps       | 1259520       |
| train/                   |               |
|    approx_kl             | 0.00034724598 |
|    clip_fraction         | 0.000635      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.4           |
|    cost_value_loss       | 0.198         |
|    cost_values           | 1.45          |
|    entropy               | -1.65         |
|    entropy_loss          | -1.65         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.22          |
|    n_updates             | 6140          |
|    policy_gradient_loss  | 0.00014       |
|    std                   | 0.554         |
|    value_loss            | 11.5          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.42142615   |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -738          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 28            |
|    time_elapsed          | 956           |
|    total_timesteps       | 1261568       |
| train/                   |               |
|    approx_kl             | 0.00062729174 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.11          |
|    cost_value_loss       | 0.0618        |
|    cost_values           | 1.19          |
|    entropy               | -1.65         |
|    entropy_loss          | -1.65         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.03          |
|    n_updates             | 6150          |
|    policy_gradient_loss  | 0.000508      |
|    std                   | 0.555         |
|    value_loss            | 9.14          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.4820158    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -738          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 29            |
|    time_elapsed          | 990           |
|    total_timesteps       | 1263616       |
| train/                   |               |
|    approx_kl             | 0.00034076287 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.74          |
|    cost_value_loss       | 2.92          |
|    cost_values           | 1.01          |
|    entropy               | -1.65         |
|    entropy_loss          | -1.65         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.73          |
|    n_updates             | 6160          |
|    policy_gradient_loss  | 0.000127      |
|    std                   | 0.555         |
|    value_loss            | 12.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.20077416  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1024         |
|    total_timesteps       | 1265664      |
| train/                   |              |
|    approx_kl             | 0.0023284531 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.84         |
|    cost_value_loss       | 0.0234       |
|    cost_values           | 0.967        |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 6170         |
|    policy_gradient_loss  | -0.000703    |
|    std                   | 0.555        |
|    value_loss            | 28           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6606158  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -734        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 1267712     |
| train/                   |             |
|    approx_kl             | 0.003959012 |
|    clip_fraction         | 0.0197      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.44        |
|    cost_value_loss       | 2.31        |
|    cost_values           | 1.14        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26          |
|    n_updates             | 6180        |
|    policy_gradient_loss  | -0.000762   |
|    std                   | 0.554       |
|    value_loss            | 46.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.43818548  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1093         |
|    total_timesteps       | 1269760      |
| train/                   |              |
|    approx_kl             | 0.0063186893 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 2.35         |
|    cost_values           | 1.33         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.08         |
|    n_updates             | 6190         |
|    policy_gradient_loss  | -0.00323     |
|    std                   | 0.554        |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9275646  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -725        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1127        |
|    total_timesteps       | 1271808     |
| train/                   |             |
|    approx_kl             | 0.002520102 |
|    clip_fraction         | 0.000732    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 2.13        |
|    cost_values           | 1.17        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.5        |
|    n_updates             | 6200        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.555       |
|    value_loss            | 36.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5273168  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -726        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1162        |
|    total_timesteps       | 1273856     |
| train/                   |             |
|    approx_kl             | 0.004351086 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.12        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 6210        |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.555       |
|    value_loss            | 6.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7250565   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1196         |
|    total_timesteps       | 1275904      |
| train/                   |              |
|    approx_kl             | 0.0060853926 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 1.54         |
|    cost_values           | 1.35         |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.22         |
|    n_updates             | 6220         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.553        |
|    value_loss            | 11.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1337667  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1230        |
|    total_timesteps       | 1277952     |
| train/                   |             |
|    approx_kl             | 0.008403856 |
|    clip_fraction         | 0.067       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 0.221       |
|    cost_values           | 1.29        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.01        |
|    n_updates             | 6230        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.552       |
|    value_loss            | 1.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.715775    |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1265         |
|    total_timesteps       | 1280000      |
| train/                   |              |
|    approx_kl             | 0.0020519737 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.784        |
|    cost_values           | 1.18         |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.2          |
|    n_updates             | 6240         |
|    policy_gradient_loss  | 0.000529     |
|    std                   | 0.551        |
|    value_loss            | 6.56         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5532191 |
| rollout/                 |            |
|    ep_len_mean           | 965        |
|    ep_rew_mean           | -726       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 38         |
|    time_elapsed          | 1299       |
|    total_timesteps       | 1282048    |
| train/                   |            |
|    approx_kl             | 0.00467808 |
|    clip_fraction         | 0.012      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.35       |
|    cost_value_loss       | 6.41       |
|    cost_values           | 1.25       |
|    entropy               | -1.64      |
|    entropy_loss          | -1.64      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.2        |
|    n_updates             | 6250       |
|    policy_gradient_loss  | -0.00115   |
|    std                   | 0.552      |
|    value_loss            | 10.9       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0403929   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1334         |
|    total_timesteps       | 1284096      |
| train/                   |              |
|    approx_kl             | 0.0015657344 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 1.6          |
|    entropy               | -1.63        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3            |
|    n_updates             | 6260         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.55         |
|    value_loss            | 4.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5676816   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1368         |
|    total_timesteps       | 1286144      |
| train/                   |              |
|    approx_kl             | 0.0022933227 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 1.16         |
|    cost_values           | 1.71         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.79         |
|    n_updates             | 6270         |
|    policy_gradient_loss  | -0.000873    |
|    std                   | 0.547        |
|    value_loss            | 4.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4580314  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1402        |
|    total_timesteps       | 1288192     |
| train/                   |             |
|    approx_kl             | 0.002156962 |
|    clip_fraction         | 0.000586    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 2.56        |
|    cost_values           | 1.72        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 6280        |
|    policy_gradient_loss  | -0.000187   |
|    std                   | 0.547       |
|    value_loss            | 19.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.681557    |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1437         |
|    total_timesteps       | 1290240      |
| train/                   |              |
|    approx_kl             | 7.233891e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 6.34         |
|    cost_values           | 1.57         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.68         |
|    n_updates             | 6290         |
|    policy_gradient_loss  | 3.65e-06     |
|    std                   | 0.547        |
|    value_loss            | 14.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5155229   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1471         |
|    total_timesteps       | 1292288      |
| train/                   |              |
|    approx_kl             | 0.0020056386 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 5.27         |
|    cost_values           | 1.55         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.43         |
|    n_updates             | 6300         |
|    policy_gradient_loss  | -0.000576    |
|    std                   | 0.547        |
|    value_loss            | 12.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6058095   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1506         |
|    total_timesteps       | 1294336      |
| train/                   |              |
|    approx_kl             | 0.0038648741 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 0.425        |
|    cost_values           | 1.46         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.32         |
|    n_updates             | 6310         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.546        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.94583416  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1541         |
|    total_timesteps       | 1296384      |
| train/                   |              |
|    approx_kl             | 0.0032504583 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 5.55         |
|    cost_values           | 1.48         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 6320         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.547        |
|    value_loss            | 37           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7905948  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1575        |
|    total_timesteps       | 1298432     |
| train/                   |             |
|    approx_kl             | 0.005990432 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.98        |
|    cost_value_loss       | 2.57        |
|    cost_values           | 1.82        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 6330        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.547       |
|    value_loss            | 7.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.39128742  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1610         |
|    total_timesteps       | 1300480      |
| train/                   |              |
|    approx_kl             | 0.0062260176 |
|    clip_fraction         | 0.0854       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 0.119        |
|    cost_values           | 1.76         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 6340         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.547        |
|    value_loss            | 28.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7721704   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1644         |
|    total_timesteps       | 1302528      |
| train/                   |              |
|    approx_kl             | 0.0019693763 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 0.529        |
|    cost_values           | 1.46         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.48         |
|    n_updates             | 6350         |
|    policy_gradient_loss  | -0.00055     |
|    std                   | 0.547        |
|    value_loss            | 8.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21826108 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1679        |
|    total_timesteps       | 1304576     |
| train/                   |             |
|    approx_kl             | 0.005090039 |
|    clip_fraction         | 0.0109      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 2.16        |
|    cost_values           | 1.26        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 6360        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.547       |
|    value_loss            | 7.59        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
-----------------------------------
| avg_speed          | 1.6        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.6        |
| reward             | -0.7107293 |
| rollout/           |            |
|    ep_len_mean     | 960        |
|    ep_rew_mean     | -706       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1306624    |
-----------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.76138383   |
| rollout/                 |               |
|    ep_len_mean           | 960           |
|    ep_rew_mean           | -705          |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 2             |
|    time_elapsed          | 59            |
|    total_timesteps       | 1308672       |
| train/                   |               |
|    approx_kl             | 0.00037924873 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.53          |
|    cost_value_loss       | 1.96          |
|    cost_values           | 1.16          |
|    entropy               | -1.62         |
|    entropy_loss          | -1.62         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.47          |
|    n_updates             | 6380          |
|    policy_gradient_loss  | -0.000121     |
|    std                   | 0.547         |
|    value_loss            | 32.5          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.79639536 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1310720     |
| train/                   |             |
|    approx_kl             | 0.006228297 |
|    clip_fraction         | 0.0472      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.888       |
|    cost_value_loss       | 0.0143      |
|    cost_values           | 0.926       |
|    entropy               | -1.61       |
|    entropy_loss          | -1.62       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 6390        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.543       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48622367  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1312768      |
| train/                   |              |
|    approx_kl             | 0.0023762882 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 2.23         |
|    cost_values           | 0.959        |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.1         |
|    n_updates             | 6400         |
|    policy_gradient_loss  | 0.000195     |
|    std                   | 0.542        |
|    value_loss            | 38.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6462638   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 1314816      |
| train/                   |              |
|    approx_kl             | 0.0021046167 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 4.45         |
|    cost_values           | 1.04         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.01         |
|    n_updates             | 6410         |
|    policy_gradient_loss  | -0.000459    |
|    std                   | 0.541        |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7979693   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 196          |
|    total_timesteps       | 1316864      |
| train/                   |              |
|    approx_kl             | 0.0049092756 |
|    clip_fraction         | 0.00986      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 3.31         |
|    cost_values           | 1.15         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 6420         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.541        |
|    value_loss            | 5.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.79229605  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 1318912      |
| train/                   |              |
|    approx_kl             | 0.0003251779 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 2.75         |
|    cost_values           | 1.13         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 6430         |
|    policy_gradient_loss  | -3.56e-05    |
|    std                   | 0.541        |
|    value_loss            | 9.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.64546686  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1320960      |
| train/                   |              |
|    approx_kl             | 0.0053004557 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 7.38         |
|    cost_values           | 1.26         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.55         |
|    n_updates             | 6440         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.54         |
|    value_loss            | 4.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49171904  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 300          |
|    total_timesteps       | 1323008      |
| train/                   |              |
|    approx_kl             | 0.0008754729 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 0.339        |
|    cost_values           | 1.25         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 6450         |
|    policy_gradient_loss  | -0.000694    |
|    std                   | 0.537        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7087322  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -682        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 334         |
|    total_timesteps       | 1325056     |
| train/                   |             |
|    approx_kl             | 0.003934518 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 0.763       |
|    cost_values           | 1.23        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 6460        |
|    policy_gradient_loss  | -0.000746   |
|    std                   | 0.537       |
|    value_loss            | 3.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8803184  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -682        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 369         |
|    total_timesteps       | 1327104     |
| train/                   |             |
|    approx_kl             | 0.003043082 |
|    clip_fraction         | 0.0153      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 9.54        |
|    cost_values           | 1.42        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 6470        |
|    policy_gradient_loss  | 0.000114    |
|    std                   | 0.538       |
|    value_loss            | 33.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.30864298  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 403          |
|    total_timesteps       | 1329152      |
| train/                   |              |
|    approx_kl             | 0.0010427095 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 3.84         |
|    cost_values           | 1.62         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 6480         |
|    policy_gradient_loss  | -0.000421    |
|    std                   | 0.538        |
|    value_loss            | 8.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.34265575  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 437          |
|    total_timesteps       | 1331200      |
| train/                   |              |
|    approx_kl             | 0.0040844847 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 0.657        |
|    cost_values           | 1.53         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 6490         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.538        |
|    value_loss            | 35.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4937131  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -671        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 472         |
|    total_timesteps       | 1333248     |
| train/                   |             |
|    approx_kl             | 0.002164899 |
|    clip_fraction         | 0.000293    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 2.92        |
|    cost_values           | 1.36        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 6500        |
|    policy_gradient_loss  | -0.000617   |
|    std                   | 0.537       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5035064   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 1335296      |
| train/                   |              |
|    approx_kl             | 0.0009500275 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 5            |
|    cost_values           | 1.27         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 6510         |
|    policy_gradient_loss  | -0.000494    |
|    std                   | 0.537        |
|    value_loss            | 14.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.2          |
| reward                   | -0.714039    |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 541          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0024419334 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 1.18         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 6520         |
|    policy_gradient_loss  | -0.000686    |
|    std                   | 0.538        |
|    value_loss            | 31.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7529889   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 575          |
|    total_timesteps       | 1339392      |
| train/                   |              |
|    approx_kl             | 0.0008137006 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 6.86         |
|    cost_values           | 1.14         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 6530         |
|    policy_gradient_loss  | -0.00015     |
|    std                   | 0.537        |
|    value_loss            | 30.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.75250155 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -669        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 611         |
|    total_timesteps       | 1341440     |
| train/                   |             |
|    approx_kl             | 0.005254836 |
|    clip_fraction         | 0.0287      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 2.8         |
|    cost_values           | 1.48        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.76        |
|    n_updates             | 6540        |
|    policy_gradient_loss  | -0.000922   |
|    std                   | 0.535       |
|    value_loss            | 2.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7298206   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1343488      |
| train/                   |              |
|    approx_kl             | 0.0013294539 |
|    clip_fraction         | 0.0439       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 5.57         |
|    cost_values           | 1.6          |
|    entropy               | -1.57        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.05         |
|    n_updates             | 6550         |
|    policy_gradient_loss  | 0.00185      |
|    std                   | 0.533        |
|    value_loss            | 6.27         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.4174239    |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -670          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 20            |
|    time_elapsed          | 680           |
|    total_timesteps       | 1345536       |
| train/                   |               |
|    approx_kl             | 0.00031261714 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.36          |
|    cost_value_loss       | 0.0617        |
|    cost_values           | 1.46          |
|    entropy               | -1.58         |
|    entropy_loss          | -1.57         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.17          |
|    n_updates             | 6560          |
|    policy_gradient_loss  | 0.000111      |
|    std                   | 0.534         |
|    value_loss            | 6.97          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.84286505 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -666        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 715         |
|    total_timesteps       | 1347584     |
| train/                   |             |
|    approx_kl             | 0.002515971 |
|    clip_fraction         | 0.0175      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 0.829       |
|    cost_values           | 1.16        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 6570        |
|    policy_gradient_loss  | 0.000469    |
|    std                   | 0.534       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74404925 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -666        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 22          |
|    time_elapsed          | 750         |
|    total_timesteps       | 1349632     |
| train/                   |             |
|    approx_kl             | 0.004999792 |
|    clip_fraction         | 0.00835     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.5         |
|    cost_value_loss       | 8.12        |
|    cost_values           | 1.06        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.25        |
|    n_updates             | 6580        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.534       |
|    value_loss            | 7.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60038614  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 785          |
|    total_timesteps       | 1351680      |
| train/                   |              |
|    approx_kl             | 0.0067065237 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 2.41         |
|    cost_values           | 1.16         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 6590         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.534        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8922672   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 820          |
|    total_timesteps       | 1353728      |
| train/                   |              |
|    approx_kl             | 0.0037984233 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 5.69         |
|    cost_values           | 1.24         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.35         |
|    n_updates             | 6600         |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.533        |
|    value_loss            | 8.08         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.6907786    |
| rollout/                 |               |
|    ep_len_mean           | 955           |
|    ep_rew_mean           | -656          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 25            |
|    time_elapsed          | 855           |
|    total_timesteps       | 1355776       |
| train/                   |               |
|    approx_kl             | 0.00017598271 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.77          |
|    cost_value_loss       | 6.32          |
|    cost_values           | 1.67          |
|    entropy               | -1.57         |
|    entropy_loss          | -1.57         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 20.9          |
|    n_updates             | 6610          |
|    policy_gradient_loss  | -4.06e-05     |
|    std                   | 0.532         |
|    value_loss            | 29.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8267051   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 890          |
|    total_timesteps       | 1357824      |
| train/                   |              |
|    approx_kl             | 0.0045181178 |
|    clip_fraction         | 0.0064       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 0.0939       |
|    cost_values           | 1.75         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.76         |
|    n_updates             | 6620         |
|    policy_gradient_loss  | -0.000668    |
|    std                   | 0.531        |
|    value_loss            | 5.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.51902354 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -651        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 924         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.009053978 |
|    clip_fraction         | 0.0509      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.24        |
|    cost_value_loss       | 4.51        |
|    cost_values           | 1.65        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.57       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 0.53        |
|    value_loss            | 4.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53308547  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -652         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 1361920      |
| train/                   |              |
|    approx_kl             | 0.0010352444 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.39         |
|    cost_value_loss       | 8.39         |
|    cost_values           | 2.08         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 6640         |
|    policy_gradient_loss  | 0.00011      |
|    std                   | 0.529        |
|    value_loss            | 14.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6334577   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -655         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 1363968      |
| train/                   |              |
|    approx_kl             | 0.0028239605 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 0.0937       |
|    cost_values           | 1.99         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 6650         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.528        |
|    value_loss            | 7.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.956759    |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -659         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 1366016      |
| train/                   |              |
|    approx_kl             | 0.0034083598 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 4.5          |
|    cost_values           | 1.86         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.87         |
|    n_updates             | 6660         |
|    policy_gradient_loss  | -0.000794    |
|    std                   | 0.528        |
|    value_loss            | 6.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9895012  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -663        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1062        |
|    total_timesteps       | 1368064     |
| train/                   |             |
|    approx_kl             | 0.005175465 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 0.949       |
|    cost_values           | 2.04        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 6670        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.529       |
|    value_loss            | 5.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5334004  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1097        |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.004413263 |
|    clip_fraction         | 0.00537     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 0.783       |
|    cost_values           | 1.85        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 6680        |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.53        |
|    value_loss            | 8.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4247972   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1132         |
|    total_timesteps       | 1372160      |
| train/                   |              |
|    approx_kl             | 0.0054725064 |
|    clip_fraction         | 0.00923      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 1.61         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 6690         |
|    policy_gradient_loss  | -0.000636    |
|    std                   | 0.529        |
|    value_loss            | 15.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4828798  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -661        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1167        |
|    total_timesteps       | 1374208     |
| train/                   |             |
|    approx_kl             | 0.004661009 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 5.84        |
|    cost_values           | 1.63        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 6700        |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.53        |
|    value_loss            | 4.51        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.98714507   |
| rollout/                 |               |
|    ep_len_mean           | 961           |
|    ep_rew_mean           | -656          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 35            |
|    time_elapsed          | 1201          |
|    total_timesteps       | 1376256       |
| train/                   |               |
|    approx_kl             | 0.00015376788 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.42          |
|    cost_value_loss       | 9.96          |
|    cost_values           | 2.01          |
|    entropy               | -1.56         |
|    entropy_loss          | -1.56         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.54          |
|    n_updates             | 6710          |
|    policy_gradient_loss  | 0.000287      |
|    std                   | 0.53          |
|    value_loss            | 9.83          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5722867  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -654        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1236        |
|    total_timesteps       | 1378304     |
| train/                   |             |
|    approx_kl             | 0.002170038 |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 6.25        |
|    cost_values           | 2.25        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.18        |
|    n_updates             | 6720        |
|    policy_gradient_loss  | -0.000986   |
|    std                   | 0.529       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.84887147  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1270         |
|    total_timesteps       | 1380352      |
| train/                   |              |
|    approx_kl             | 0.0005155385 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 5.75         |
|    cost_values           | 2.64         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.32         |
|    n_updates             | 6730         |
|    policy_gradient_loss  | -1.35e-05    |
|    std                   | 0.528        |
|    value_loss            | 7.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9090433   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -659         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1305         |
|    total_timesteps       | 1382400      |
| train/                   |              |
|    approx_kl             | 0.0036217587 |
|    clip_fraction         | 0.00352      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 2.9          |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.35         |
|    n_updates             | 6740         |
|    policy_gradient_loss  | -0.0003      |
|    std                   | 0.527        |
|    value_loss            | 6.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7533396   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1339         |
|    total_timesteps       | 1384448      |
| train/                   |              |
|    approx_kl             | 0.0025756706 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 0.166        |
|    cost_values           | 2.63         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.91         |
|    n_updates             | 6750         |
|    policy_gradient_loss  | -0.000174    |
|    std                   | 0.526        |
|    value_loss            | 13.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4629909   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1373         |
|    total_timesteps       | 1386496      |
| train/                   |              |
|    approx_kl             | 0.0002706382 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 3.38         |
|    cost_values           | 2.39         |
|    entropy               | -1.54        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.73         |
|    n_updates             | 6760         |
|    policy_gradient_loss  | -3.86e-06    |
|    std                   | 0.526        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7751404   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -663         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1408         |
|    total_timesteps       | 1388544      |
| train/                   |              |
|    approx_kl             | 0.0024359694 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 6.72         |
|    cost_values           | 2.5          |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 6770         |
|    policy_gradient_loss  | -0.00059     |
|    std                   | 0.526        |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.66486377 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -662        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1443        |
|    total_timesteps       | 1390592     |
| train/                   |             |
|    approx_kl             | 0.004449947 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.18        |
|    cost_value_loss       | 0.49        |
|    cost_values           | 2.42        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 6780        |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 0.526       |
|    value_loss            | 6.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.706185   |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -664        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1478        |
|    total_timesteps       | 1392640     |
| train/                   |             |
|    approx_kl             | 0.008250006 |
|    clip_fraction         | 0.0573      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 3.03        |
|    cost_values           | 2.11        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.5        |
|    n_updates             | 6790        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.525       |
|    value_loss            | 36.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6972594  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -655        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1513        |
|    total_timesteps       | 1394688     |
| train/                   |             |
|    approx_kl             | 0.002260867 |
|    clip_fraction         | 0.000635    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.83        |
|    cost_value_loss       | 0.471       |
|    cost_values           | 1.87        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.82        |
|    n_updates             | 6800        |
|    policy_gradient_loss  | -0.000426   |
|    std                   | 0.525       |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.64251435 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -651        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1548        |
|    total_timesteps       | 1396736     |
| train/                   |             |
|    approx_kl             | 0.007481264 |
|    clip_fraction         | 0.0626      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.8         |
|    cost_value_loss       | 6.23        |
|    cost_values           | 1.73        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.3        |
|    n_updates             | 6810        |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 0.525       |
|    value_loss            | 30.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73069733  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1583         |
|    total_timesteps       | 1398784      |
| train/                   |              |
|    approx_kl             | 0.0059506046 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 13.2         |
|    cost_values           | 2            |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 6820         |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.525        |
|    value_loss            | 14.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.83615917  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -658         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1617         |
|    total_timesteps       | 1400832      |
| train/                   |              |
|    approx_kl             | 0.0044360557 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 2.33         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.43         |
|    n_updates             | 6830         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.523        |
|    value_loss            | 2.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7774093  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -661        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1652        |
|    total_timesteps       | 1402880     |
| train/                   |             |
|    approx_kl             | 0.003911336 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.35        |
|    cost_values           | 2.45        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.25        |
|    n_updates             | 6840        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.521       |
|    value_loss            | 2.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8260411   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -662         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1687         |
|    total_timesteps       | 1404928      |
| train/                   |              |
|    approx_kl             | 0.0027826387 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 0.814        |
|    cost_values           | 2.51         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 6850         |
|    policy_gradient_loss  | -0.000242    |
|    std                   | 0.521        |
|    value_loss            | 31.2         |
-------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.41380844 |
| rollout/           |             |
|    ep_len_mean     | 960         |
|    ep_rew_mean     | -668        |
| time/              |             |
|    fps             | 81          |
|    iterations      | 1           |
|    time_elapsed    | 25          |
|    total_timesteps | 1406976     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8842398   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1409024      |
| train/                   |              |
|    approx_kl             | 0.0019156344 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 0.984        |
|    cost_values           | 2.38         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.62         |
|    n_updates             | 6870         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.521        |
|    value_loss            | 6.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.79761887  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 94           |
|    total_timesteps       | 1411072      |
| train/                   |              |
|    approx_kl             | 0.0038499774 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 5.65         |
|    cost_values           | 2.43         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.61         |
|    n_updates             | 6880         |
|    policy_gradient_loss  | -0.000745    |
|    std                   | 0.52         |
|    value_loss            | 7.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.86179423 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -666        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 1413120     |
| train/                   |             |
|    approx_kl             | 0.012629744 |
|    clip_fraction         | 0.0678      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.2         |
|    cost_value_loss       | 0.198       |
|    cost_values           | 2.49        |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.2        |
|    n_updates             | 6890        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.519       |
|    value_loss            | 29.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8610047   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1415168      |
| train/                   |              |
|    approx_kl             | 0.0001637259 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 1.2          |
|    cost_values           | 2.13         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.65         |
|    n_updates             | 6900         |
|    policy_gradient_loss  | -0.000371    |
|    std                   | 0.518        |
|    value_loss            | 5.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75467     |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 199          |
|    total_timesteps       | 1417216      |
| train/                   |              |
|    approx_kl             | 0.0050588283 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 0.687        |
|    cost_values           | 2.09         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 6910         |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.517        |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6140737   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 234          |
|    total_timesteps       | 1419264      |
| train/                   |              |
|    approx_kl             | 0.0039492035 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 0.0511       |
|    cost_values           | 1.66         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.49         |
|    n_updates             | 6920         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.516        |
|    value_loss            | 2.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.77343893  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 8            |
|    time_elapsed          | 269          |
|    total_timesteps       | 1421312      |
| train/                   |              |
|    approx_kl             | 0.0012739274 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 4.47         |
|    cost_values           | 1.68         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 6930         |
|    policy_gradient_loss  | 0.000505     |
|    std                   | 0.516        |
|    value_loss            | 8.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.69597185 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 303         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.00259034  |
|    clip_fraction         | 0.00952     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 6.09        |
|    cost_values           | 2.13        |
|    entropy               | -1.5        |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.000831   |
|    std                   | 0.514       |
|    value_loss            | 1.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7716995   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 337          |
|    total_timesteps       | 1425408      |
| train/                   |              |
|    approx_kl             | 0.0055557946 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 2.27         |
|    cost_values           | 2.42         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 6950         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.512        |
|    value_loss            | 22.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.17139395  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 372          |
|    total_timesteps       | 1427456      |
| train/                   |              |
|    approx_kl             | 0.0011200174 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 1.03         |
|    cost_values           | 2.18         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.46         |
|    n_updates             | 6960         |
|    policy_gradient_loss  | 4.61e-05     |
|    std                   | 0.512        |
|    value_loss            | 1.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8310624   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 407          |
|    total_timesteps       | 1429504      |
| train/                   |              |
|    approx_kl             | 0.0030736949 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 0.457        |
|    cost_values           | 1.9          |
|    entropy               | -1.48        |
|    entropy_loss          | -1.49        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.79         |
|    n_updates             | 6970         |
|    policy_gradient_loss  | -0.000672    |
|    std                   | 0.51         |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6123394   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 1431552      |
| train/                   |              |
|    approx_kl             | 0.0037705046 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.06         |
|    cost_value_loss       | 7.62         |
|    cost_values           | 1.87         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27           |
|    n_updates             | 6980         |
|    policy_gradient_loss  | -0.000617    |
|    std                   | 0.508        |
|    value_loss            | 45.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4251907   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 477          |
|    total_timesteps       | 1433600      |
| train/                   |              |
|    approx_kl             | 0.0019578682 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 0.173        |
|    cost_values           | 2.02         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 6990         |
|    policy_gradient_loss  | -0.000565    |
|    std                   | 0.508        |
|    value_loss            | 19.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49728212  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 1435648      |
| train/                   |              |
|    approx_kl             | 0.0043011094 |
|    clip_fraction         | 0.00562      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 2.31         |
|    cost_values           | 1.75         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.41         |
|    n_updates             | 7000         |
|    policy_gradient_loss  | -0.000814    |
|    std                   | 0.508        |
|    value_loss            | 7.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57623893  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 546          |
|    total_timesteps       | 1437696      |
| train/                   |              |
|    approx_kl             | 0.0032825293 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 1.79         |
|    cost_values           | 1.58         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.15         |
|    n_updates             | 7010         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.509        |
|    value_loss            | 9.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.60359067 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 17          |
|    time_elapsed          | 580         |
|    total_timesteps       | 1439744     |
| train/                   |             |
|    approx_kl             | 0.003366456 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.63        |
|    cost_value_loss       | 12          |
|    cost_values           | 1.64        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 7020        |
|    policy_gradient_loss  | -0.000997   |
|    std                   | 0.509       |
|    value_loss            | 9.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9074201  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 615         |
|    total_timesteps       | 1441792     |
| train/                   |             |
|    approx_kl             | 0.004608036 |
|    clip_fraction         | 0.0294      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 1.51        |
|    cost_values           | 1.79        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.15        |
|    n_updates             | 7030        |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.508       |
|    value_loss            | 5.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.85179913 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -694        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 649         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.003396214 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 7.67        |
|    cost_values           | 1.88        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.93        |
|    n_updates             | 7040        |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.507       |
|    value_loss            | 5.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8821616  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 684         |
|    total_timesteps       | 1445888     |
| train/                   |             |
|    approx_kl             | 0.005254378 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 0.127       |
|    cost_values           | 1.95        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.41        |
|    n_updates             | 7050        |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.506       |
|    value_loss            | 7.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.36726582  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 1447936      |
| train/                   |              |
|    approx_kl             | 0.0027644306 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 0.0422       |
|    cost_values           | 1.48         |
|    entropy               | -1.44        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.15         |
|    n_updates             | 7060         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.499        |
|    value_loss            | 6.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6349284   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1449984      |
| train/                   |              |
|    approx_kl             | 0.0026448858 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 1.56         |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.09         |
|    n_updates             | 7070         |
|    policy_gradient_loss  | 0.000446     |
|    std                   | 0.497        |
|    value_loss            | 7.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5262543   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 1452032      |
| train/                   |              |
|    approx_kl             | 0.0051848963 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 1.79         |
|    cost_values           | 1.96         |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 7080         |
|    policy_gradient_loss  | -0.000629    |
|    std                   | 0.496        |
|    value_loss            | 31.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7782367  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 822         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.002705535 |
|    clip_fraction         | 0.0492      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 6.03        |
|    cost_values           | 2           |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.32        |
|    n_updates             | 7090        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.496       |
|    value_loss            | 14.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4280905   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 856          |
|    total_timesteps       | 1456128      |
| train/                   |              |
|    approx_kl             | 0.0021700105 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 4.26         |
|    cost_values           | 2            |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.68         |
|    n_updates             | 7100         |
|    policy_gradient_loss  | -0.000512    |
|    std                   | 0.495        |
|    value_loss            | 4.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6026161   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 890          |
|    total_timesteps       | 1458176      |
| train/                   |              |
|    approx_kl             | 0.0050003333 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 2.26         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.59         |
|    n_updates             | 7110         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.496        |
|    value_loss            | 3.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5221073   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 924          |
|    total_timesteps       | 1460224      |
| train/                   |              |
|    approx_kl             | 0.0037752406 |
|    clip_fraction         | 0.00952      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.12         |
|    cost_value_loss       | 4.93         |
|    cost_values           | 2.64         |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.37         |
|    n_updates             | 7120         |
|    policy_gradient_loss  | -0.000591    |
|    std                   | 0.496        |
|    value_loss            | 14.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7564765  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 959         |
|    total_timesteps       | 1462272     |
| train/                   |             |
|    approx_kl             | 0.003095577 |
|    clip_fraction         | 0.00718     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 1.69        |
|    cost_values           | 2.72        |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 7130        |
|    policy_gradient_loss  | -0.000872   |
|    std                   | 0.497       |
|    value_loss            | 7.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.74048626  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 1464320      |
| train/                   |              |
|    approx_kl             | 0.0028372034 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 1.58         |
|    cost_values           | 2.49         |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.23         |
|    n_updates             | 7140         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.496        |
|    value_loss            | 9.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2185596   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 1466368      |
| train/                   |              |
|    approx_kl             | 0.0047929045 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.71         |
|    cost_value_loss       | 4.09         |
|    cost_values           | 2.35         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4            |
|    n_updates             | 7150         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.496        |
|    value_loss            | 4.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.79         |
| reward                   | -0.83607745  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 1468416      |
| train/                   |              |
|    approx_kl             | 0.0027727555 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 4.56         |
|    cost_values           | 2.32         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.21         |
|    n_updates             | 7160         |
|    policy_gradient_loss  | -0.00082     |
|    std                   | 0.495        |
|    value_loss            | 5.95         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5895868    |
| rollout/                 |               |
|    ep_len_mean           | 978           |
|    ep_rew_mean           | -684          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 32            |
|    time_elapsed          | 1098          |
|    total_timesteps       | 1470464       |
| train/                   |               |
|    approx_kl             | 0.00092547445 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.66          |
|    cost_value_loss       | 3.33          |
|    cost_values           | 2.27          |
|    entropy               | -1.42         |
|    entropy_loss          | -1.42         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.53          |
|    n_updates             | 7170          |
|    policy_gradient_loss  | -6.74e-05     |
|    std                   | 0.495         |
|    value_loss            | 6.29          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5333517   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1132         |
|    total_timesteps       | 1472512      |
| train/                   |              |
|    approx_kl             | 0.0015514705 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 0.0869       |
|    cost_values           | 2.02         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.46         |
|    n_updates             | 7180         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.495        |
|    value_loss            | 5.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.77451426 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1167        |
|    total_timesteps       | 1474560     |
| train/                   |             |
|    approx_kl             | 0.003053715 |
|    clip_fraction         | 0.00112     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 4.03        |
|    cost_values           | 1.69        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.51        |
|    n_updates             | 7190        |
|    policy_gradient_loss  | 0.000204    |
|    std                   | 0.495       |
|    value_loss            | 7.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5571165   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1202         |
|    total_timesteps       | 1476608      |
| train/                   |              |
|    approx_kl             | 0.0045294305 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.0417       |
|    cost_values           | 1.44         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.42        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.33         |
|    n_updates             | 7200         |
|    policy_gradient_loss  | -0.000817    |
|    std                   | 0.493        |
|    value_loss            | 6.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.38579607  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 1478656      |
| train/                   |              |
|    approx_kl             | 0.0015105956 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 2.31         |
|    cost_values           | 1.33         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.78         |
|    n_updates             | 7210         |
|    policy_gradient_loss  | -0.000909    |
|    std                   | 0.491        |
|    value_loss            | 3.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60508007  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1271         |
|    total_timesteps       | 1480704      |
| train/                   |              |
|    approx_kl             | 0.0052582915 |
|    clip_fraction         | 0.0064       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 1.42         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 7220         |
|    policy_gradient_loss  | -0.000872    |
|    std                   | 0.49         |
|    value_loss            | 23.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6834957   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1307         |
|    total_timesteps       | 1482752      |
| train/                   |              |
|    approx_kl             | 0.0011493214 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 7.12         |
|    cost_values           | 1.29         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.86         |
|    n_updates             | 7230         |
|    policy_gradient_loss  | -0.000194    |
|    std                   | 0.49         |
|    value_loss            | 14.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5061113  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1342        |
|    total_timesteps       | 1484800     |
| train/                   |             |
|    approx_kl             | 0.003604871 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.0306      |
|    cost_values           | 1.17        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.832       |
|    n_updates             | 7240        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.491       |
|    value_loss            | 1.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.41677493 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1376        |
|    total_timesteps       | 1486848     |
| train/                   |             |
|    approx_kl             | 0.003524226 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.42        |
|    cost_values           | 1.08        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 7250        |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.491       |
|    value_loss            | 3.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6669822   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1411         |
|    total_timesteps       | 1488896      |
| train/                   |              |
|    approx_kl             | 0.0012747265 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 0.474        |
|    cost_values           | 1.06         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.15         |
|    n_updates             | 7260         |
|    policy_gradient_loss  | 0.000626     |
|    std                   | 0.491        |
|    value_loss            | 6.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.584216    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 1490944      |
| train/                   |              |
|    approx_kl             | 0.0026086422 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.894        |
|    cost_value_loss       | 0.357        |
|    cost_values           | 0.913        |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 7270         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.491        |
|    value_loss            | 8.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.457648    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1480         |
|    total_timesteps       | 1492992      |
| train/                   |              |
|    approx_kl             | 0.0043148263 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.743        |
|    cost_value_loss       | 0.0343       |
|    cost_values           | 0.861        |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.42         |
|    n_updates             | 7280         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.491        |
|    value_loss            | 6.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74775445 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1515        |
|    total_timesteps       | 1495040     |
| train/                   |             |
|    approx_kl             | 0.002644832 |
|    clip_fraction         | 0.00859     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.68        |
|    cost_value_loss       | 0.0163      |
|    cost_values           | 0.712       |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.783       |
|    n_updates             | 7290        |
|    policy_gradient_loss  | 0.00013     |
|    std                   | 0.49        |
|    value_loss            | 1.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.63179415 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1550        |
|    total_timesteps       | 1497088     |
| train/                   |             |
|    approx_kl             | 0.004671089 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 0.948       |
|    entropy               | -1.39       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 7300        |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.489       |
|    value_loss            | 3.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7811645  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -668        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1585        |
|    total_timesteps       | 1499136     |
| train/                   |             |
|    approx_kl             | 0.001997681 |
|    clip_fraction         | 0.000928    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 9.64        |
|    cost_values           | 1.6         |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.05        |
|    n_updates             | 7310        |
|    policy_gradient_loss  | -0.000443   |
|    std                   | 0.489       |
|    value_loss            | 6.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7145332  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1620        |
|    total_timesteps       | 1501184     |
| train/                   |             |
|    approx_kl             | 0.006377276 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 1.34        |
|    cost_values           | 1.99        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 7320        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.489       |
|    value_loss            | 3.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42694     |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1655         |
|    total_timesteps       | 1503232      |
| train/                   |              |
|    approx_kl             | 0.0009471748 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 0.0689       |
|    cost_values           | 1.77         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.29         |
|    n_updates             | 7330         |
|    policy_gradient_loss  | -2.06e-05    |
|    std                   | 0.486        |
|    value_loss            | 6.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0244083   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1689         |
|    total_timesteps       | 1505280      |
| train/                   |              |
|    approx_kl             | 0.0037359598 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 0.983        |
|    cost_values           | 1.51         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.47         |
|    n_updates             | 7340         |
|    policy_gradient_loss  | -6.61e-05    |
|    std                   | 0.486        |
|    value_loss            | 11.4         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.5647927 |
| rollout/           |            |
|    ep_len_mean     | 990        |
|    ep_rew_mean     | -672       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1507328    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67608666  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1509376      |
| train/                   |              |
|    approx_kl             | 0.0034829648 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 2            |
|    cost_values           | 1.12         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.14         |
|    n_updates             | 7360         |
|    policy_gradient_loss  | -0.000942    |
|    std                   | 0.485        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7094361   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1511424      |
| train/                   |              |
|    approx_kl             | 0.0036588856 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 6.03         |
|    cost_values           | 1.2          |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.96         |
|    n_updates             | 7370         |
|    policy_gradient_loss  | -0.000977    |
|    std                   | 0.485        |
|    value_loss            | 2.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45507976  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1513472      |
| train/                   |              |
|    approx_kl             | 0.0029789698 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.0446       |
|    cost_values           | 1.27         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.05         |
|    n_updates             | 7380         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.487        |
|    value_loss            | 2.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8653183   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 1515520      |
| train/                   |              |
|    approx_kl             | 0.0034127627 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 4.55         |
|    cost_values           | 1.23         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.01         |
|    n_updates             | 7390         |
|    policy_gradient_loss  | -0.000849    |
|    std                   | 0.488        |
|    value_loss            | 1.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6104773   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1517568      |
| train/                   |              |
|    approx_kl             | 0.0036140908 |
|    clip_fraction         | 0.00488      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 3.33         |
|    cost_values           | 1.53         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.17         |
|    n_updates             | 7400         |
|    policy_gradient_loss  | -0.000789    |
|    std                   | 0.488        |
|    value_loss            | 6.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1931486   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 231          |
|    total_timesteps       | 1519616      |
| train/                   |              |
|    approx_kl             | 0.0072085587 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 0.928        |
|    cost_values           | 1.48         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 7410         |
|    policy_gradient_loss  | -0.000628    |
|    std                   | 0.488        |
|    value_loss            | 34.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8969771   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1521664      |
| train/                   |              |
|    approx_kl             | 0.0010720352 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 0.087        |
|    cost_values           | 1.31         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.56         |
|    n_updates             | 7420         |
|    policy_gradient_loss  | 0.000156     |
|    std                   | 0.487        |
|    value_loss            | 7.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.14        |
| reward                   | -0.43456134 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 299         |
|    total_timesteps       | 1523712     |
| train/                   |             |
|    approx_kl             | 0.00422824  |
|    clip_fraction         | 0.00444     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 0.0907      |
|    cost_values           | 1.03        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.41        |
|    n_updates             | 7430        |
|    policy_gradient_loss  | -0.000664   |
|    std                   | 0.487       |
|    value_loss            | 3.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65230924  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -661         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 10           |
|    time_elapsed          | 334          |
|    total_timesteps       | 1525760      |
| train/                   |              |
|    approx_kl             | 0.0018005286 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.792        |
|    cost_value_loss       | 0.0157       |
|    cost_values           | 0.831        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.54         |
|    n_updates             | 7440         |
|    policy_gradient_loss  | -0.000813    |
|    std                   | 0.487        |
|    value_loss            | 5.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72985107  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 11           |
|    time_elapsed          | 368          |
|    total_timesteps       | 1527808      |
| train/                   |              |
|    approx_kl             | 0.0034139715 |
|    clip_fraction         | 0.00503      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 8.16         |
|    cost_values           | 1.03         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.3          |
|    n_updates             | 7450         |
|    policy_gradient_loss  | -0.000719    |
|    std                   | 0.487        |
|    value_loss            | 6.45         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.758088  |
| rollout/                 |            |
|    ep_len_mean           | 994        |
|    ep_rew_mean           | -665       |
| time/                    |            |
|    fps                   | 60         |
|    iterations            | 12         |
|    time_elapsed          | 403        |
|    total_timesteps       | 1529856    |
| train/                   |            |
|    approx_kl             | 0.00595209 |
|    clip_fraction         | 0.0202     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.04       |
|    cost_value_loss       | 0.0396     |
|    cost_values           | 1.19       |
|    entropy               | -1.39      |
|    entropy_loss          | -1.39      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.07       |
|    n_updates             | 7460       |
|    policy_gradient_loss  | -0.00189   |
|    std                   | 0.487      |
|    value_loss            | 3          |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5528774  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 437         |
|    total_timesteps       | 1531904     |
| train/                   |             |
|    approx_kl             | 0.003924473 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.998       |
|    cost_value_loss       | 0.324       |
|    cost_values           | 0.972       |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 7470        |
|    policy_gradient_loss  | -0.000977   |
|    std                   | 0.486       |
|    value_loss            | 3.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6262283   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 471          |
|    total_timesteps       | 1533952      |
| train/                   |              |
|    approx_kl             | 0.0029565566 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 0.908        |
|    cost_values           | 1            |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.69         |
|    n_updates             | 7480         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.486        |
|    value_loss            | 5.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8933558   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 506          |
|    total_timesteps       | 1536000      |
| train/                   |              |
|    approx_kl             | 0.0040689246 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.83         |
|    cost_value_loss       | 0.0231       |
|    cost_values           | 0.933        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.19         |
|    n_updates             | 7490         |
|    policy_gradient_loss  | -0.000768    |
|    std                   | 0.487        |
|    value_loss            | 6.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8771576   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -659         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 540          |
|    total_timesteps       | 1538048      |
| train/                   |              |
|    approx_kl             | 0.0031523046 |
|    clip_fraction         | 0.00586      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 7.29         |
|    cost_values           | 0.941        |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.5         |
|    n_updates             | 7500         |
|    policy_gradient_loss  | 0.000109     |
|    std                   | 0.487        |
|    value_loss            | 65.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9029526  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -663        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 1540096     |
| train/                   |             |
|    approx_kl             | 0.003332049 |
|    clip_fraction         | 0.00171     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 1.6         |
|    cost_values           | 1.2         |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.06        |
|    n_updates             | 7510        |
|    policy_gradient_loss  | -0.000191   |
|    std                   | 0.488       |
|    value_loss            | 6.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35370976 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -661        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 608         |
|    total_timesteps       | 1542144     |
| train/                   |             |
|    approx_kl             | 0.002119753 |
|    clip_fraction         | 0.00083     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 3.16        |
|    cost_values           | 1.37        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 7520        |
|    policy_gradient_loss  | -0.00035    |
|    std                   | 0.488       |
|    value_loss            | 7.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7902412   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 643          |
|    total_timesteps       | 1544192      |
| train/                   |              |
|    approx_kl             | 0.0044110534 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 1.72         |
|    cost_values           | 1.36         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.4          |
|    n_updates             | 7530         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.488        |
|    value_loss            | 13.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.55694336   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -656          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 20            |
|    time_elapsed          | 677           |
|    total_timesteps       | 1546240       |
| train/                   |               |
|    approx_kl             | 0.00078651286 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.93          |
|    cost_value_loss       | 3.99          |
|    cost_values           | 1.38          |
|    entropy               | -1.39         |
|    entropy_loss          | -1.39         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.62          |
|    n_updates             | 7540          |
|    policy_gradient_loss  | -0.00031      |
|    std                   | 0.487         |
|    value_loss            | 9.57          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3469065   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -652         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 712          |
|    total_timesteps       | 1548288      |
| train/                   |              |
|    approx_kl             | 0.0032651115 |
|    clip_fraction         | 0.00547      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 5.26         |
|    cost_values           | 1.49         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 7550         |
|    policy_gradient_loss  | -0.000449    |
|    std                   | 0.488        |
|    value_loss            | 5.24         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.63799185   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -653          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 22            |
|    time_elapsed          | 746           |
|    total_timesteps       | 1550336       |
| train/                   |               |
|    approx_kl             | 0.00034919026 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.61          |
|    cost_value_loss       | 11.9          |
|    cost_values           | 1.82          |
|    entropy               | -1.4          |
|    entropy_loss          | -1.39         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.18          |
|    n_updates             | 7560          |
|    policy_gradient_loss  | -0.000147     |
|    std                   | 0.488         |
|    value_loss            | 8.3           |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.937678   |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -657        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 781         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.005970049 |
|    clip_fraction         | 0.0143      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.72        |
|    cost_value_loss       | 5.32        |
|    cost_values           | 2.2         |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.86        |
|    n_updates             | 7570        |
|    policy_gradient_loss  | -0.000847   |
|    std                   | 0.489       |
|    value_loss            | 2.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89688396  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 24           |
|    time_elapsed          | 815          |
|    total_timesteps       | 1554432      |
| train/                   |              |
|    approx_kl             | 0.0017826799 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 2.54         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.78         |
|    n_updates             | 7580         |
|    policy_gradient_loss  | 0.000403     |
|    std                   | 0.489        |
|    value_loss            | 9.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7879806   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -658         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 850          |
|    total_timesteps       | 1556480      |
| train/                   |              |
|    approx_kl             | 0.0043156254 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 0.132        |
|    cost_values           | 2.37         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.65         |
|    n_updates             | 7590         |
|    policy_gradient_loss  | -0.000803    |
|    std                   | 0.488        |
|    value_loss            | 7.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8244358  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -658        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 26          |
|    time_elapsed          | 884         |
|    total_timesteps       | 1558528     |
| train/                   |             |
|    approx_kl             | 0.003843648 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 0.093       |
|    cost_values           | 1.85        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.84        |
|    n_updates             | 7600        |
|    policy_gradient_loss  | -0.000471   |
|    std                   | 0.489       |
|    value_loss            | 5.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8841133   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -661         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 27           |
|    time_elapsed          | 918          |
|    total_timesteps       | 1560576      |
| train/                   |              |
|    approx_kl             | 0.0021860453 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 1.59         |
|    cost_values           | 1.58         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.4          |
|    n_updates             | 7610         |
|    policy_gradient_loss  | -0.00019     |
|    std                   | 0.491        |
|    value_loss            | 8.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.93225104  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -663         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 28           |
|    time_elapsed          | 953          |
|    total_timesteps       | 1562624      |
| train/                   |              |
|    approx_kl             | 0.0037865043 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.162        |
|    cost_values           | 1.33         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1            |
|    n_updates             | 7620         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.491        |
|    value_loss            | 2.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9392941   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 29           |
|    time_elapsed          | 987          |
|    total_timesteps       | 1564672      |
| train/                   |              |
|    approx_kl             | 0.0046886634 |
|    clip_fraction         | 0.0474       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 1.27         |
|    cost_values           | 1.2          |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.97         |
|    n_updates             | 7630         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.491        |
|    value_loss            | 6.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75128883  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 30           |
|    time_elapsed          | 1022         |
|    total_timesteps       | 1566720      |
| train/                   |              |
|    approx_kl             | 0.0045261113 |
|    clip_fraction         | 0.00874      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.0795       |
|    cost_values           | 1.18         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.23         |
|    n_updates             | 7640         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.491        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1687659   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 31           |
|    time_elapsed          | 1056         |
|    total_timesteps       | 1568768      |
| train/                   |              |
|    approx_kl             | 0.0027200065 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.858        |
|    cost_value_loss       | 0.0171       |
|    cost_values           | 0.918        |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.86         |
|    n_updates             | 7650         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.491        |
|    value_loss            | 6.34         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.78463197   |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -683          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 32            |
|    time_elapsed          | 1090          |
|    total_timesteps       | 1570816       |
| train/                   |               |
|    approx_kl             | 0.00010253923 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.702         |
|    cost_value_loss       | 0.0224        |
|    cost_values           | 0.837         |
|    entropy               | -1.41         |
|    entropy_loss          | -1.41         |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.8          |
|    n_updates             | 7660          |
|    policy_gradient_loss  | 0.000373      |
|    std                   | 0.491         |
|    value_loss            | 28.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.5736549   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 33           |
|    time_elapsed          | 1125         |
|    total_timesteps       | 1572864      |
| train/                   |              |
|    approx_kl             | 0.0009416266 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 1.08         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 7670         |
|    policy_gradient_loss  | -0.000424    |
|    std                   | 0.492        |
|    value_loss            | 18.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.71851987  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 34           |
|    time_elapsed          | 1159         |
|    total_timesteps       | 1574912      |
| train/                   |              |
|    approx_kl             | 0.0028047068 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 6.41         |
|    cost_values           | 1.38         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.98         |
|    n_updates             | 7680         |
|    policy_gradient_loss  | 0.000129     |
|    std                   | 0.492        |
|    value_loss            | 6.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6430505   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 35           |
|    time_elapsed          | 1194         |
|    total_timesteps       | 1576960      |
| train/                   |              |
|    approx_kl             | 0.0012295096 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 0.0599       |
|    cost_values           | 1.45         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.61         |
|    n_updates             | 7690         |
|    policy_gradient_loss  | -0.000179    |
|    std                   | 0.492        |
|    value_loss            | 4.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.60272896  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1228         |
|    total_timesteps       | 1579008      |
| train/                   |              |
|    approx_kl             | 0.0028117825 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.294        |
|    cost_values           | 1.14         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.41        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.49         |
|    n_updates             | 7700         |
|    policy_gradient_loss  | -0.000127    |
|    std                   | 0.49         |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.74157614  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1263         |
|    total_timesteps       | 1581056      |
| train/                   |              |
|    approx_kl             | 0.0035200608 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 2.6          |
|    cost_values           | 1.19         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.82         |
|    n_updates             | 7710         |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 0.489        |
|    value_loss            | 3.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6163646   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1297         |
|    total_timesteps       | 1583104      |
| train/                   |              |
|    approx_kl             | 0.0030427696 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 1.63         |
|    cost_values           | 1.26         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.17         |
|    n_updates             | 7720         |
|    policy_gradient_loss  | -0.000639    |
|    std                   | 0.489        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8270174   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1331         |
|    total_timesteps       | 1585152      |
| train/                   |              |
|    approx_kl             | 0.0034219492 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.214        |
|    cost_values           | 1.09         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 7730         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.49         |
|    value_loss            | 8.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6079424  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -680        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1366        |
|    total_timesteps       | 1587200     |
| train/                   |             |
|    approx_kl             | 0.001878233 |
|    clip_fraction         | 0.000439    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.16        |
|    cost_value_loss       | 6.16        |
|    cost_values           | 1.12        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.8        |
|    n_updates             | 7740        |
|    policy_gradient_loss  | 0.000507    |
|    std                   | 0.49        |
|    value_loss            | 36.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7413565  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1400        |
|    total_timesteps       | 1589248     |
| train/                   |             |
|    approx_kl             | 0.008485962 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 1.33        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.12        |
|    n_updates             | 7750        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.489       |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87968534  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1435         |
|    total_timesteps       | 1591296      |
| train/                   |              |
|    approx_kl             | 0.0046771644 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 4.07         |
|    cost_values           | 1.29         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.96         |
|    n_updates             | 7760         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.489        |
|    value_loss            | 9            |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.7702716    |
| rollout/                 |               |
|    ep_len_mean           | 978           |
|    ep_rew_mean           | -687          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 43            |
|    time_elapsed          | 1470          |
|    total_timesteps       | 1593344       |
| train/                   |               |
|    approx_kl             | 0.00047707328 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.17          |
|    cost_value_loss       | 0.302         |
|    cost_values           | 1.15          |
|    entropy               | -1.4          |
|    entropy_loss          | -1.4          |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 1.63          |
|    n_updates             | 7770          |
|    policy_gradient_loss  | -0.000207     |
|    std                   | 0.489         |
|    value_loss            | 3.88          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8215063   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1504         |
|    total_timesteps       | 1595392      |
| train/                   |              |
|    approx_kl             | 0.0046603703 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.911        |
|    cost_value_loss       | 0.0968       |
|    cost_values           | 0.944        |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.09         |
|    n_updates             | 7780         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.489        |
|    value_loss            | 6.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7844925  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1538        |
|    total_timesteps       | 1597440     |
| train/                   |             |
|    approx_kl             | 0.005672878 |
|    clip_fraction         | 0.053       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.75        |
|    cost_value_loss       | 0.0179      |
|    cost_values           | 0.856       |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 7790        |
|    policy_gradient_loss  | -0.00455    |
|    std                   | 0.489       |
|    value_loss            | 4.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7084253   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1573         |
|    total_timesteps       | 1599488      |
| train/                   |              |
|    approx_kl             | 0.0037346138 |
|    clip_fraction         | 0.00977      |
|    clip_range            | 0.2          |
|    cost_returns          | 1            |
|    cost_value_loss       | 2.12         |
|    cost_values           | 0.913        |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 7800         |
|    policy_gradient_loss  | -0.000239    |
|    std                   | 0.489        |
|    value_loss            | 7.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.815627    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1607         |
|    total_timesteps       | 1601536      |
| train/                   |              |
|    approx_kl             | 0.0027427538 |
|    clip_fraction         | 0.0482       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.761        |
|    cost_values           | 1.01         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.67         |
|    n_updates             | 7810         |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.484        |
|    value_loss            | 4.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67006123  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1642         |
|    total_timesteps       | 1603584      |
| train/                   |              |
|    approx_kl             | 0.0061451127 |
|    clip_fraction         | 0.0592       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.881        |
|    cost_value_loss       | 0.145        |
|    cost_values           | 0.959        |
|    entropy               | -1.37        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.61         |
|    n_updates             | 7820         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.483        |
|    value_loss            | 6.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67272496  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1676         |
|    total_timesteps       | 1605632      |
| train/                   |              |
|    approx_kl             | 0.0023582734 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.821        |
|    cost_value_loss       | 0.16         |
|    cost_values           | 0.897        |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.52         |
|    n_updates             | 7830         |
|    policy_gradient_loss  | -0.0006      |
|    std                   | 0.483        |
|    value_loss            | 13.7         |
-------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.41890165 |
| rollout/           |             |
|    ep_len_mean     | 978         |
|    ep_rew_mean     | -699        |
| time/              |             |
|    fps             | 84          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1607680     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6357523   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 1609728      |
| train/                   |              |
|    approx_kl             | 0.0014034946 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 3.49         |
|    cost_values           | 1.63         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 7850         |
|    policy_gradient_loss  | -0.000224    |
|    std                   | 0.483        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5274093   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 1611776      |
| train/                   |              |
|    approx_kl             | 0.0028220192 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 3.58         |
|    cost_values           | 1.81         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.45         |
|    n_updates             | 7860         |
|    policy_gradient_loss  | -0.000513    |
|    std                   | 0.483        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47572762  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1613824      |
| train/                   |              |
|    approx_kl             | 0.0040408736 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 0.151        |
|    cost_values           | 1.96         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.29         |
|    n_updates             | 7870         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.483        |
|    value_loss            | 13.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7516428  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 1615872     |
| train/                   |             |
|    approx_kl             | 0.001640862 |
|    clip_fraction         | 0.00186     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 1.92        |
|    cost_values           | 1.74        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.05        |
|    n_updates             | 7880        |
|    policy_gradient_loss  | -0.00037    |
|    std                   | 0.485       |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0300744   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1617920      |
| train/                   |              |
|    approx_kl             | 0.0044640857 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 2.82         |
|    cost_values           | 1.88         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 7890         |
|    policy_gradient_loss  | -0.000513    |
|    std                   | 0.486        |
|    value_loss            | 30.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.58309186 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 232         |
|    total_timesteps       | 1619968     |
| train/                   |             |
|    approx_kl             | 0.005051135 |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 4.78        |
|    cost_values           | 2           |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.1        |
|    n_updates             | 7900        |
|    policy_gradient_loss  | -0.000639   |
|    std                   | 0.486       |
|    value_loss            | 38          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8757374   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 266          |
|    total_timesteps       | 1622016      |
| train/                   |              |
|    approx_kl             | 0.0007638509 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.2          |
|    cost_value_loss       | 8.22         |
|    cost_values           | 2.12         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.96         |
|    n_updates             | 7910         |
|    policy_gradient_loss  | -0.000184    |
|    std                   | 0.486        |
|    value_loss            | 9.36         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 5.6           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.6           |
| reward                   | -0.6590199    |
| rollout/                 |               |
|    ep_len_mean           | 973           |
|    ep_rew_mean           | -699          |
| time/                    |               |
|    fps                   | 61            |
|    iterations            | 9             |
|    time_elapsed          | 301           |
|    total_timesteps       | 1624064       |
| train/                   |               |
|    approx_kl             | 0.00015042978 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.01          |
|    cost_value_loss       | 0.56          |
|    cost_values           | 2.11          |
|    entropy               | -1.39         |
|    entropy_loss          | -1.39         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.76          |
|    n_updates             | 7920          |
|    policy_gradient_loss  | 4.36e-05      |
|    std                   | 0.487         |
|    value_loss            | 7.9           |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7744359  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 1626112     |
| train/                   |             |
|    approx_kl             | 0.002637647 |
|    clip_fraction         | 0.00083     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 3.52        |
|    cost_values           | 1.9         |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 7930        |
|    policy_gradient_loss  | -0.000585   |
|    std                   | 0.487       |
|    value_loss            | 8.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.88679796  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 1628160      |
| train/                   |              |
|    approx_kl             | 0.0034307898 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 4.89         |
|    cost_values           | 2.02         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 7940         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.487        |
|    value_loss            | 3.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7399495   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 404          |
|    total_timesteps       | 1630208      |
| train/                   |              |
|    approx_kl             | 0.0032085988 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 3.66         |
|    cost_values           | 2.3          |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.48         |
|    n_updates             | 7950         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.486        |
|    value_loss            | 5.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38275114 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 438         |
|    total_timesteps       | 1632256     |
| train/                   |             |
|    approx_kl             | 0.005254707 |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 3.04        |
|    cost_values           | 2.44        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 36.3        |
|    n_updates             | 7960        |
|    policy_gradient_loss  | -0.000957   |
|    std                   | 0.486       |
|    value_loss            | 43.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9569395   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 1634304      |
| train/                   |              |
|    approx_kl             | 0.0027630301 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 4.62         |
|    cost_values           | 2.6          |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.32         |
|    n_updates             | 7970         |
|    policy_gradient_loss  | -0.000941    |
|    std                   | 0.485        |
|    value_loss            | 2.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6092353  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 508         |
|    total_timesteps       | 1636352     |
| train/                   |             |
|    approx_kl             | 0.003852978 |
|    clip_fraction         | 0.00952     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.6         |
|    cost_value_loss       | 5.37        |
|    cost_values           | 2.92        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.82        |
|    n_updates             | 7980        |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.485       |
|    value_loss            | 8.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50626945  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 1638400      |
| train/                   |              |
|    approx_kl             | 0.0031786938 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 1.85         |
|    cost_values           | 2.91         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.19         |
|    n_updates             | 7990         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.485        |
|    value_loss            | 15.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8752473   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 576          |
|    total_timesteps       | 1640448      |
| train/                   |              |
|    approx_kl             | 0.0036610314 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.04         |
|    cost_value_loss       | 3.47         |
|    cost_values           | 2.72         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.37         |
|    n_updates             | 8000         |
|    policy_gradient_loss  | -0.000822    |
|    std                   | 0.485        |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6890172  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 611         |
|    total_timesteps       | 1642496     |
| train/                   |             |
|    approx_kl             | 0.004006049 |
|    clip_fraction         | 0.0182      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 3.87        |
|    cost_values           | 2.65        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.76        |
|    n_updates             | 8010        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.485       |
|    value_loss            | 8.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47493708  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1644544      |
| train/                   |              |
|    approx_kl             | 0.0016777535 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 9.97         |
|    cost_values           | 2.78         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.23         |
|    n_updates             | 8020         |
|    policy_gradient_loss  | -0.00021     |
|    std                   | 0.485        |
|    value_loss            | 3.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9593641   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 680          |
|    total_timesteps       | 1646592      |
| train/                   |              |
|    approx_kl             | 0.0052949092 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 2.85         |
|    cost_values           | 2.95         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 8030         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.485        |
|    value_loss            | 37.2         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.329691     |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -703          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 21            |
|    time_elapsed          | 714           |
|    total_timesteps       | 1648640       |
| train/                   |               |
|    approx_kl             | 0.00086430344 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.28          |
|    cost_value_loss       | 9.15          |
|    cost_values           | 2.96          |
|    entropy               | -1.39         |
|    entropy_loss          | -1.38         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0.00186       |
|    learning_rate         | 0.0003        |
|    loss                  | 6.66          |
|    n_updates             | 8040          |
|    policy_gradient_loss  | -7.61e-05     |
|    std                   | 0.486         |
|    value_loss            | 10.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5862847   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 748          |
|    total_timesteps       | 1650688      |
| train/                   |              |
|    approx_kl             | 6.120131e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 2.13         |
|    cost_values           | 2.88         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.55         |
|    n_updates             | 8050         |
|    policy_gradient_loss  | 3.48e-05     |
|    std                   | 0.486        |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4657048   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 783          |
|    total_timesteps       | 1652736      |
| train/                   |              |
|    approx_kl             | 0.0053729294 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 0.285        |
|    cost_values           | 2.55         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 8060         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.486        |
|    value_loss            | 7.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.84801364 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 24          |
|    time_elapsed          | 817         |
|    total_timesteps       | 1654784     |
| train/                   |             |
|    approx_kl             | 0.005957927 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 2.39        |
|    cost_values           | 2.22        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 8070        |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 0.487       |
|    value_loss            | 22.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.6736647   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 25           |
|    time_elapsed          | 851          |
|    total_timesteps       | 1656832      |
| train/                   |              |
|    approx_kl             | 0.0016852597 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 0.0951       |
|    cost_values           | 2.05         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.54         |
|    n_updates             | 8080         |
|    policy_gradient_loss  | -0.000178    |
|    std                   | 0.486        |
|    value_loss            | 5.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9094801   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 26           |
|    time_elapsed          | 886          |
|    total_timesteps       | 1658880      |
| train/                   |              |
|    approx_kl             | 0.0033445505 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 1.19         |
|    cost_values           | 1.69         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.39        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 8090         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.485        |
|    value_loss            | 16.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27806756 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 27          |
|    time_elapsed          | 921         |
|    total_timesteps       | 1660928     |
| train/                   |             |
|    approx_kl             | 0.00471817  |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 0.597       |
|    cost_values           | 1.49        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.9        |
|    n_updates             | 8100        |
|    policy_gradient_loss  | -0.00106    |
|    std                   | 0.484       |
|    value_loss            | 35.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6292386  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 956         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.003160948 |
|    clip_fraction         | 0.00156     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 6.93        |
|    cost_values           | 1.48        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.49        |
|    n_updates             | 8110        |
|    policy_gradient_loss  | -0.000705   |
|    std                   | 0.484       |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81052     |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 990          |
|    total_timesteps       | 1665024      |
| train/                   |              |
|    approx_kl             | 0.0035136533 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 1.09         |
|    cost_values           | 1.68         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 8120         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.485        |
|    value_loss            | 8.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.104015    |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 1667072      |
| train/                   |              |
|    approx_kl             | 0.0014175221 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 3.11         |
|    cost_values           | 1.5          |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 8130         |
|    policy_gradient_loss  | -0.000641    |
|    std                   | 0.484        |
|    value_loss            | 17.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5496453  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 1669120     |
| train/                   |             |
|    approx_kl             | 0.002381945 |
|    clip_fraction         | 0.0136      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 3.37        |
|    cost_values           | 1.44        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.35        |
|    n_updates             | 8140        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.484       |
|    value_loss            | 12          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9827895   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1094         |
|    total_timesteps       | 1671168      |
| train/                   |              |
|    approx_kl             | 0.0038768132 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 4.92         |
|    cost_values           | 1.56         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.88         |
|    n_updates             | 8150         |
|    policy_gradient_loss  | -0.000146    |
|    std                   | 0.485        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50780296  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1128         |
|    total_timesteps       | 1673216      |
| train/                   |              |
|    approx_kl             | 0.0012263822 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 1.87         |
|    cost_values           | 1.87         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 8160         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.482        |
|    value_loss            | 9.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54553604  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1162         |
|    total_timesteps       | 1675264      |
| train/                   |              |
|    approx_kl             | 0.0043571265 |
|    clip_fraction         | 0.163        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 2.04         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.46         |
|    n_updates             | 8170         |
|    policy_gradient_loss  | 0.00295      |
|    std                   | 0.481        |
|    value_loss            | 16           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.52759796 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -680        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1197        |
|    total_timesteps       | 1677312     |
| train/                   |             |
|    approx_kl             | 0.003322077 |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.5         |
|    cost_value_loss       | 3.68        |
|    cost_values           | 2.01        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 8180        |
|    policy_gradient_loss  | -0.000837   |
|    std                   | 0.48        |
|    value_loss            | 30.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.64765424  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1232         |
|    total_timesteps       | 1679360      |
| train/                   |              |
|    approx_kl             | 0.0041503552 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 5.68         |
|    cost_values           | 2.06         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.4         |
|    n_updates             | 8190         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.481        |
|    value_loss            | 35.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.76894295 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -687        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1267        |
|    total_timesteps       | 1681408     |
| train/                   |             |
|    approx_kl             | 0.002631715 |
|    clip_fraction         | 0.00815     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 0.105       |
|    cost_values           | 2.01        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 8200        |
|    policy_gradient_loss  | -0.00066    |
|    std                   | 0.481       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.560612    |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1301         |
|    total_timesteps       | 1683456      |
| train/                   |              |
|    approx_kl             | 0.0029500306 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.0785       |
|    cost_values           | 1.59         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 8210         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.481        |
|    value_loss            | 9.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.65944785 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1336        |
|    total_timesteps       | 1685504     |
| train/                   |             |
|    approx_kl             | 0.004547422 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.96        |
|    cost_value_loss       | 3.86        |
|    cost_values           | 1.52        |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.04        |
|    n_updates             | 8220        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.482       |
|    value_loss            | 8.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.96026313  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1370         |
|    total_timesteps       | 1687552      |
| train/                   |              |
|    approx_kl             | 0.0015930824 |
|    clip_fraction         | 0.0506       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 3.27         |
|    cost_values           | 1.92         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 8230         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.481        |
|    value_loss            | 2.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0323182   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1405         |
|    total_timesteps       | 1689600      |
| train/                   |              |
|    approx_kl             | 0.0032841861 |
|    clip_fraction         | 0.0525       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 7.07         |
|    cost_values           | 2.19         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.91         |
|    n_updates             | 8240         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.482        |
|    value_loss            | 13.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5487      |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1439         |
|    total_timesteps       | 1691648      |
| train/                   |              |
|    approx_kl             | 5.360684e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 0.694        |
|    cost_values           | 2.31         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.32         |
|    n_updates             | 8250         |
|    policy_gradient_loss  | -9.95e-06    |
|    std                   | 0.482        |
|    value_loss            | 10.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9300148   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1474         |
|    total_timesteps       | 1693696      |
| train/                   |              |
|    approx_kl             | 0.0026642783 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 5.65         |
|    cost_values           | 2.16         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.16         |
|    n_updates             | 8260         |
|    policy_gradient_loss  | -0.000401    |
|    std                   | 0.482        |
|    value_loss            | 11.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6290689  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -688        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1508        |
|    total_timesteps       | 1695744     |
| train/                   |             |
|    approx_kl             | 0.004809413 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.36        |
|    cost_value_loss       | 2.63        |
|    cost_values           | 2.18        |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 8270        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.482       |
|    value_loss            | 5.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6957206   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1542         |
|    total_timesteps       | 1697792      |
| train/                   |              |
|    approx_kl             | 0.0046484796 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 0.078        |
|    cost_values           | 1.92         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.2          |
|    n_updates             | 8280         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.482        |
|    value_loss            | 9.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74530524 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1577        |
|    total_timesteps       | 1699840     |
| train/                   |             |
|    approx_kl             | 0.004626437 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.99        |
|    cost_value_loss       | 1.81        |
|    cost_values           | 1.6         |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 8290        |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 0.482       |
|    value_loss            | 3.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.71973974 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -681        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 47          |
|    time_elapsed          | 1611        |
|    total_timesteps       | 1701888     |
| train/                   |             |
|    approx_kl             | 0.006925676 |
|    clip_fraction         | 0.0276      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 1.8         |
|    cost_values           | 1.5         |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 8300        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.482       |
|    value_loss            | 3.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5669061   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1646         |
|    total_timesteps       | 1703936      |
| train/                   |              |
|    approx_kl             | 0.0067278026 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 1.49         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.72         |
|    n_updates             | 8310         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.481        |
|    value_loss            | 6.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.56478     |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1680         |
|    total_timesteps       | 1705984      |
| train/                   |              |
|    approx_kl             | 0.0052998723 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 0.0516       |
|    cost_values           | 1.42         |
|    entropy               | -1.35        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.07         |
|    n_updates             | 8320         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.479        |
|    value_loss            | 4.74         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.75647795 |
| rollout/           |             |
|    ep_len_mean     | 966         |
|    ep_rew_mean     | -683        |
| time/              |             |
|    fps             | 82          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 1708032     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.89903355 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 1710080     |
| train/                   |             |
|    approx_kl             | 0.005211858 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.955       |
|    cost_value_loss       | 0.568       |
|    cost_values           | 0.987       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.58        |
|    n_updates             | 8340        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.475       |
|    value_loss            | 3.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6614528  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1712128     |
| train/                   |             |
|    approx_kl             | 0.003389805 |
|    clip_fraction         | 0.0228      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.94        |
|    cost_values           | 1.06        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.76        |
|    n_updates             | 8350        |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.475       |
|    value_loss            | 3.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.80586195  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 1714176      |
| train/                   |              |
|    approx_kl             | 0.0036982945 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.173        |
|    cost_values           | 1.03         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.74         |
|    n_updates             | 8360         |
|    policy_gradient_loss  | 0.000183     |
|    std                   | 0.473        |
|    value_loss            | 5.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8091039   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 1716224      |
| train/                   |              |
|    approx_kl             | 0.0040846313 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.84         |
|    cost_value_loss       | 0.0289       |
|    cost_values           | 0.929        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.81         |
|    n_updates             | 8370         |
|    policy_gradient_loss  | -0.000546    |
|    std                   | 0.474        |
|    value_loss            | 6            |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.72387207 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 1718272     |
| train/                   |             |
|    approx_kl             | 0.002946778 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.703       |
|    cost_value_loss       | 0.00989     |
|    cost_values           | 0.751       |
|    entropy               | -1.33       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.11        |
|    n_updates             | 8380        |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.473       |
|    value_loss            | 2.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0697458   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1720320      |
| train/                   |              |
|    approx_kl             | 0.0015244561 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.86         |
|    cost_value_loss       | 0.618        |
|    cost_values           | 0.739        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 8390         |
|    policy_gradient_loss  | -0.000103    |
|    std                   | 0.473        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6624447   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 1722368      |
| train/                   |              |
|    approx_kl             | 0.0022170516 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 5.89         |
|    cost_values           | 0.953        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.52         |
|    n_updates             | 8400         |
|    policy_gradient_loss  | -0.000483    |
|    std                   | 0.472        |
|    value_loss            | 11.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80043334 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 302         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.004351682 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.201       |
|    cost_values           | 1.02        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.39        |
|    n_updates             | 8410        |
|    policy_gradient_loss  | -0.00176    |
|    std                   | 0.472       |
|    value_loss            | 3.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.93046206  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 1726464      |
| train/                   |              |
|    approx_kl             | 0.0017639612 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 7.53         |
|    cost_values           | 1.1          |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 8420         |
|    policy_gradient_loss  | -7.73e-05    |
|    std                   | 0.472        |
|    value_loss            | 33.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0192225   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 1728512      |
| train/                   |              |
|    approx_kl             | 0.0033493936 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 0.943        |
|    cost_values           | 1.19         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.84         |
|    n_updates             | 8430         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.473        |
|    value_loss            | 8.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8999663   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 1730560      |
| train/                   |              |
|    approx_kl             | 0.0016774359 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.365        |
|    cost_values           | 1.05         |
|    entropy               | -1.34        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 8440         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.475        |
|    value_loss            | 8.57         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9300325  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 440         |
|    total_timesteps       | 1732608     |
| train/                   |             |
|    approx_kl             | 0.006227852 |
|    clip_fraction         | 0.0731      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.826       |
|    cost_value_loss       | 0.052       |
|    cost_values           | 0.948       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.9        |
|    n_updates             | 8450        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.476       |
|    value_loss            | 37.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7879191   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1734656      |
| train/                   |              |
|    approx_kl             | 0.0022460904 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.844        |
|    cost_value_loss       | 0.296        |
|    cost_values           | 0.849        |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.36         |
|    n_updates             | 8460         |
|    policy_gradient_loss  | -0.000196    |
|    std                   | 0.476        |
|    value_loss            | 5.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1833463  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 509         |
|    total_timesteps       | 1736704     |
| train/                   |             |
|    approx_kl             | 0.003283798 |
|    clip_fraction         | 0.00259     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.688       |
|    cost_value_loss       | 0.0224      |
|    cost_values           | 0.823       |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 8470        |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.475       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47684878  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 544          |
|    total_timesteps       | 1738752      |
| train/                   |              |
|    approx_kl             | 0.0048480565 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.51         |
|    cost_values           | 0.941        |
|    entropy               | -1.33        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 8480         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.473        |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.74849534  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 579          |
|    total_timesteps       | 1740800      |
| train/                   |              |
|    approx_kl             | 0.0040238234 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 3.48         |
|    cost_values           | 1.07         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 8490         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.473        |
|    value_loss            | 18.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.43078586 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 614         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.006545176 |
|    clip_fraction         | 0.0228      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 0.0728      |
|    cost_values           | 1.08        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 8500        |
|    policy_gradient_loss  | -0.000759   |
|    std                   | 0.475       |
|    value_loss            | 4.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7652382  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 649         |
|    total_timesteps       | 1744896     |
| train/                   |             |
|    approx_kl             | 0.005474633 |
|    clip_fraction         | 0.0476      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.19        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 8510        |
|    policy_gradient_loss  | -0.000685   |
|    std                   | 0.476       |
|    value_loss            | 21.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91711074  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 684          |
|    total_timesteps       | 1746944      |
| train/                   |              |
|    approx_kl             | 0.0056227986 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 6.4          |
|    cost_values           | 1.52         |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 8520         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.476        |
|    value_loss            | 9.49         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.7033663 |
| rollout/                 |            |
|    ep_len_mean           | 976        |
|    ep_rew_mean           | -709       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 21         |
|    time_elapsed          | 719        |
|    total_timesteps       | 1748992    |
| train/                   |            |
|    approx_kl             | 0.00499118 |
|    clip_fraction         | 0.0525     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.16       |
|    cost_value_loss       | 3.21       |
|    cost_values           | 1.74       |
|    entropy               | -1.34      |
|    entropy_loss          | -1.34      |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 22.7       |
|    n_updates             | 8530       |
|    policy_gradient_loss  | -0.00232   |
|    std                   | 0.475      |
|    value_loss            | 33.7       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7384002  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 755         |
|    total_timesteps       | 1751040     |
| train/                   |             |
|    approx_kl             | 0.002734206 |
|    clip_fraction         | 0.0209      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 0.395       |
|    cost_values           | 1.69        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.63        |
|    n_updates             | 8540        |
|    policy_gradient_loss  | -0.000774   |
|    std                   | 0.475       |
|    value_loss            | 6.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9368701  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 790         |
|    total_timesteps       | 1753088     |
| train/                   |             |
|    approx_kl             | 0.003314111 |
|    clip_fraction         | 0.012       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 2.25        |
|    cost_values           | 1.55        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.16        |
|    n_updates             | 8550        |
|    policy_gradient_loss  | -0.000809   |
|    std                   | 0.475       |
|    value_loss            | 7.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1137118  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 825         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.004144152 |
|    clip_fraction         | 0.00957     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 2.47        |
|    cost_values           | 1.57        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 8560        |
|    policy_gradient_loss  | -0.00106    |
|    std                   | 0.473       |
|    value_loss            | 7.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45153096 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 860         |
|    total_timesteps       | 1757184     |
| train/                   |             |
|    approx_kl             | 0.002190647 |
|    clip_fraction         | 0.000342    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 0.0805      |
|    cost_values           | 1.64        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 8570        |
|    policy_gradient_loss  | -0.00101    |
|    std                   | 0.472       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.839615    |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 896          |
|    total_timesteps       | 1759232      |
| train/                   |              |
|    approx_kl             | 0.0029765577 |
|    clip_fraction         | 0.0022       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 5.39         |
|    cost_values           | 1.48         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 8580         |
|    policy_gradient_loss  | -0.000815    |
|    std                   | 0.472        |
|    value_loss            | 23.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.62091637  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 930          |
|    total_timesteps       | 1761280      |
| train/                   |              |
|    approx_kl             | 0.0021228509 |
|    clip_fraction         | 0.00273      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 1.19         |
|    cost_values           | 1.58         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.36         |
|    n_updates             | 8590         |
|    policy_gradient_loss  | -0.000619    |
|    std                   | 0.471        |
|    value_loss            | 3.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67094666  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 965          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 7.231001e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.77         |
|    cost_value_loss       | 8.63         |
|    cost_values           | 1.63         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.35         |
|    n_updates             | 8600         |
|    policy_gradient_loss  | 0.000244     |
|    std                   | 0.47         |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65529007  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 1000         |
|    total_timesteps       | 1765376      |
| train/                   |              |
|    approx_kl             | 0.0037417137 |
|    clip_fraction         | 0.00449      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 0.0653       |
|    cost_values           | 1.47         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.34         |
|    n_updates             | 8610         |
|    policy_gradient_loss  | 3.72e-05     |
|    std                   | 0.47         |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9868007   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1036         |
|    total_timesteps       | 1767424      |
| train/                   |              |
|    approx_kl             | 0.0011132739 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 6.03         |
|    cost_values           | 1.25         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 8620         |
|    policy_gradient_loss  | 0.00012      |
|    std                   | 0.469        |
|    value_loss            | 45.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.68981963 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1070        |
|    total_timesteps       | 1769472     |
| train/                   |             |
|    approx_kl             | 0.004700984 |
|    clip_fraction         | 0.0223      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.0252      |
|    cost_values           | 1.09        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.56        |
|    n_updates             | 8630        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.468       |
|    value_loss            | 3.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6576816  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -701        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1106        |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.002192218 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 2.33        |
|    cost_values           | 1.03        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.85        |
|    n_updates             | 8640        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.469       |
|    value_loss            | 6.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5953109  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1141        |
|    total_timesteps       | 1773568     |
| train/                   |             |
|    approx_kl             | 0.005925154 |
|    clip_fraction         | 0.0681      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 2.38        |
|    cost_values           | 1.27        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.31       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 8650        |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 0.467       |
|    value_loss            | 35.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.72771704 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1175        |
|    total_timesteps       | 1775616     |
| train/                   |             |
|    approx_kl             | 0.004971636 |
|    clip_fraction         | 0.034       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 3.48        |
|    cost_values           | 1.53        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 8660        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.466       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55559474 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1210        |
|    total_timesteps       | 1777664     |
| train/                   |             |
|    approx_kl             | 0.004916887 |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 6.09        |
|    cost_values           | 1.71        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.15        |
|    n_updates             | 8670        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.467       |
|    value_loss            | 6.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.22671089  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1245         |
|    total_timesteps       | 1779712      |
| train/                   |              |
|    approx_kl             | 0.0008460436 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 4.79         |
|    cost_values           | 1.88         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.22         |
|    n_updates             | 8680         |
|    policy_gradient_loss  | -0.000235    |
|    std                   | 0.467        |
|    value_loss            | 6.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7676558   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1279         |
|    total_timesteps       | 1781760      |
| train/                   |              |
|    approx_kl             | 0.0028991408 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.77         |
|    cost_value_loss       | 5.53         |
|    cost_values           | 2.02         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.87         |
|    n_updates             | 8690         |
|    policy_gradient_loss  | -0.000705    |
|    std                   | 0.467        |
|    value_loss            | 12.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.8193113    |
| rollout/                 |               |
|    ep_len_mean           | 971           |
|    ep_rew_mean           | -697          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1313          |
|    total_timesteps       | 1783808       |
| train/                   |               |
|    approx_kl             | 0.00013914962 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.54          |
|    cost_value_loss       | 2.32          |
|    cost_values           | 2.31          |
|    entropy               | -1.3          |
|    entropy_loss          | -1.3          |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.11          |
|    n_updates             | 8700          |
|    policy_gradient_loss  | -7.59e-05     |
|    std                   | 0.467         |
|    value_loss            | 6.42          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6325019   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1348         |
|    total_timesteps       | 1785856      |
| train/                   |              |
|    approx_kl             | 0.0047614314 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 0.0909       |
|    cost_values           | 2.02         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.06         |
|    n_updates             | 8710         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.467        |
|    value_loss            | 4.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0507741   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1382         |
|    total_timesteps       | 1787904      |
| train/                   |              |
|    approx_kl             | 0.0019887683 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 2.44         |
|    cost_values           | 1.78         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.68         |
|    n_updates             | 8720         |
|    policy_gradient_loss  | -0.000979    |
|    std                   | 0.467        |
|    value_loss            | 9.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72632766  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1417         |
|    total_timesteps       | 1789952      |
| train/                   |              |
|    approx_kl             | 0.0029506986 |
|    clip_fraction         | 0.00654      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 0.159        |
|    cost_values           | 1.9          |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.91         |
|    n_updates             | 8730         |
|    policy_gradient_loss  | -0.000906    |
|    std                   | 0.467        |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.73002297 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1451        |
|    total_timesteps       | 1792000     |
| train/                   |             |
|    approx_kl             | 0.010091514 |
|    clip_fraction         | 0.0891      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 3.72        |
|    cost_values           | 1.63        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 8740        |
|    policy_gradient_loss  | -0.00605    |
|    std                   | 0.467       |
|    value_loss            | 26.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.036068    |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1486         |
|    total_timesteps       | 1794048      |
| train/                   |              |
|    approx_kl             | 0.0023242282 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 3.67         |
|    cost_values           | 1.54         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 8750         |
|    policy_gradient_loss  | -0.000468    |
|    std                   | 0.467        |
|    value_loss            | 27.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.894889   |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1520        |
|    total_timesteps       | 1796096     |
| train/                   |             |
|    approx_kl             | 0.002409415 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 0.816       |
|    cost_values           | 1.41        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.86        |
|    n_updates             | 8760        |
|    policy_gradient_loss  | -0.000909   |
|    std                   | 0.467       |
|    value_loss            | 25.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5310561  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1556        |
|    total_timesteps       | 1798144     |
| train/                   |             |
|    approx_kl             | 0.004514078 |
|    clip_fraction         | 0.0218      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 0.0439      |
|    cost_values           | 1.29        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.47        |
|    n_updates             | 8770        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.467       |
|    value_loss            | 11.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50381297  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1590         |
|    total_timesteps       | 1800192      |
| train/                   |              |
|    approx_kl             | 0.0047505777 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 1.26         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.3         |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 8780         |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 0.468        |
|    value_loss            | 6.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7296595   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1625         |
|    total_timesteps       | 1802240      |
| train/                   |              |
|    approx_kl             | 0.0008830372 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.2          |
|    cost_value_loss       | 9.62         |
|    cost_values           | 1.62         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.5          |
|    n_updates             | 8790         |
|    policy_gradient_loss  | -0.000194    |
|    std                   | 0.468        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8390362   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1660         |
|    total_timesteps       | 1804288      |
| train/                   |              |
|    approx_kl             | 0.0059992685 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 1.69         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.04         |
|    n_updates             | 8800         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.468        |
|    value_loss            | 5.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80495113 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -677        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1695        |
|    total_timesteps       | 1806336     |
| train/                   |             |
|    approx_kl             | 0.005228277 |
|    clip_fraction         | 0.00747     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 0.0491      |
|    cost_values           | 1.48        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.69        |
|    n_updates             | 8810        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.467       |
|    value_loss            | 9.55        |
------------------------------------------
----------------------------------
| avg_speed          | 8         |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8         |
| reward             | -0.821113 |
| rollout/           |           |
|    ep_len_mean     | 957       |
|    ep_rew_mean     | -674      |
| time/              |           |
|    fps             | 82        |
|    iterations      | 1         |
|    time_elapsed    | 24        |
|    total_timesteps | 1808384   |
----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7575137   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 1810432      |
| train/                   |              |
|    approx_kl             | 0.0007408891 |
|    clip_fraction         | 0.00596      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 5.85         |
|    cost_values           | 1.22         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.11         |
|    n_updates             | 8830         |
|    policy_gradient_loss  | 0.000696     |
|    std                   | 0.466        |
|    value_loss            | 6.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91840494  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 95           |
|    total_timesteps       | 1812480      |
| train/                   |              |
|    approx_kl             | 0.0022056878 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 0.723        |
|    cost_values           | 1.48         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.3         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1            |
|    n_updates             | 8840         |
|    policy_gradient_loss  | -0.000319    |
|    std                   | 0.465        |
|    value_loss            | 1.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8325873   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 4            |
|    time_elapsed          | 130          |
|    total_timesteps       | 1814528      |
| train/                   |              |
|    approx_kl             | 0.0033736248 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 1.37         |
|    cost_values           | 1.46         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.3         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 8850         |
|    policy_gradient_loss  | -0.000965    |
|    std                   | 0.469        |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46103296  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 5            |
|    time_elapsed          | 165          |
|    total_timesteps       | 1816576      |
| train/                   |              |
|    approx_kl             | 0.0043914244 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 7.04         |
|    cost_values           | 1.6          |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.8         |
|    n_updates             | 8860         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.47         |
|    value_loss            | 32.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.70069355  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 200          |
|    total_timesteps       | 1818624      |
| train/                   |              |
|    approx_kl             | 0.0046589556 |
|    clip_fraction         | 0.0062       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 1.91         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 8870         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.469        |
|    value_loss            | 8.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87701786  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 7            |
|    time_elapsed          | 235          |
|    total_timesteps       | 1820672      |
| train/                   |              |
|    approx_kl             | 0.0037421107 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 4.84         |
|    cost_values           | 2.3          |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.54         |
|    n_updates             | 8880         |
|    policy_gradient_loss  | -0.000788    |
|    std                   | 0.469        |
|    value_loss            | 13.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.7769488    |
| rollout/                 |               |
|    ep_len_mean           | 951           |
|    ep_rew_mean           | -674          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 8             |
|    time_elapsed          | 269           |
|    total_timesteps       | 1822720       |
| train/                   |               |
|    approx_kl             | 5.2860938e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.56          |
|    cost_value_loss       | 2.9           |
|    cost_values           | 2.27          |
|    entropy               | -1.31         |
|    entropy_loss          | -1.31         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 9.28          |
|    n_updates             | 8890          |
|    policy_gradient_loss  | -1.94e-06     |
|    std                   | 0.468         |
|    value_loss            | 18.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5748904   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 304          |
|    total_timesteps       | 1824768      |
| train/                   |              |
|    approx_kl             | 0.0035922327 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 0.856        |
|    cost_values           | 2.06         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.16         |
|    n_updates             | 8900         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.468        |
|    value_loss            | 4.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7811142   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 339          |
|    total_timesteps       | 1826816      |
| train/                   |              |
|    approx_kl             | 0.0066942726 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 1.61         |
|    cost_values           | 1.84         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 8910         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.466        |
|    value_loss            | 6.88         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.6687422    |
| rollout/                 |               |
|    ep_len_mean           | 954           |
|    ep_rew_mean           | -669          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 11            |
|    time_elapsed          | 373           |
|    total_timesteps       | 1828864       |
| train/                   |               |
|    approx_kl             | 0.00083916704 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.67          |
|    cost_value_loss       | 5.89          |
|    cost_values           | 1.83          |
|    entropy               | -1.29         |
|    entropy_loss          | -1.29         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 16.1          |
|    n_updates             | 8920          |
|    policy_gradient_loss  | 0.0005        |
|    std                   | 0.464         |
|    value_loss            | 30.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6075233   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 408          |
|    total_timesteps       | 1830912      |
| train/                   |              |
|    approx_kl             | 0.0060478835 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.0706       |
|    cost_values           | 1.7          |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 8930         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.464        |
|    value_loss            | 22.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8530811  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -663        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 442         |
|    total_timesteps       | 1832960     |
| train/                   |             |
|    approx_kl             | 0.003631556 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.237       |
|    cost_values           | 1.37        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.29       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.3         |
|    n_updates             | 8940        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.463       |
|    value_loss            | 17.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5610041   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 1835008      |
| train/                   |              |
|    approx_kl             | 0.0031705215 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 1.53         |
|    cost_values           | 1.32         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.28        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.24         |
|    n_updates             | 8950         |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 0.458        |
|    value_loss            | 8.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.99907005  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 1837056      |
| train/                   |              |
|    approx_kl             | 0.0063716276 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 0.622        |
|    cost_values           | 1.37         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 8960         |
|    policy_gradient_loss  | -0.000898    |
|    std                   | 0.456        |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7715016   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 1839104      |
| train/                   |              |
|    approx_kl             | 0.0050596837 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.521        |
|    cost_values           | 1.16         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 8970         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.457        |
|    value_loss            | 8.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5866196   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 17           |
|    time_elapsed          | 580          |
|    total_timesteps       | 1841152      |
| train/                   |              |
|    approx_kl             | 0.0016762819 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.979        |
|    cost_value_loss       | 0.424        |
|    cost_values           | 0.991        |
|    entropy               | -1.25        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.49         |
|    n_updates             | 8980         |
|    policy_gradient_loss  | -0.00077     |
|    std                   | 0.455        |
|    value_loss            | 6.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4664921   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 615          |
|    total_timesteps       | 1843200      |
| train/                   |              |
|    approx_kl             | 0.0041809585 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.834        |
|    cost_value_loss       | 0.0456       |
|    cost_values           | 0.91         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.01         |
|    n_updates             | 8990         |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.452        |
|    value_loss            | 2.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.44097316 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -664        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 19          |
|    time_elapsed          | 649         |
|    total_timesteps       | 1845248     |
| train/                   |             |
|    approx_kl             | 0.003931639 |
|    clip_fraction         | 0.0216      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.95        |
|    cost_value_loss       | 6.66        |
|    cost_values           | 1.05        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.9        |
|    n_updates             | 9000        |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.451       |
|    value_loss            | 35          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.73313946 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -664        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 684         |
|    total_timesteps       | 1847296     |
| train/                   |             |
|    approx_kl             | 0.004523308 |
|    clip_fraction         | 0.00908     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 0.25        |
|    cost_values           | 1.26        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.01        |
|    n_updates             | 9010        |
|    policy_gradient_loss  | -0.000674   |
|    std                   | 0.451       |
|    value_loss            | 5.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.39133894  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -662         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 718          |
|    total_timesteps       | 1849344      |
| train/                   |              |
|    approx_kl             | 0.0053272936 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.553        |
|    cost_values           | 1.03         |
|    entropy               | -1.25        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.16         |
|    n_updates             | 9020         |
|    policy_gradient_loss  | -0.000278    |
|    std                   | 0.454        |
|    value_loss            | 5.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41864714  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -648         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 753          |
|    total_timesteps       | 1851392      |
| train/                   |              |
|    approx_kl             | 0.0040094433 |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.371        |
|    cost_values           | 1            |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.82         |
|    n_updates             | 9030         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.454        |
|    value_loss            | 5.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6118705  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -643        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 787         |
|    total_timesteps       | 1853440     |
| train/                   |             |
|    approx_kl             | 0.000698338 |
|    clip_fraction         | 0.01        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 2.54        |
|    cost_values           | 1.01        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.7        |
|    n_updates             | 9040        |
|    policy_gradient_loss  | 0.00228     |
|    std                   | 0.455       |
|    value_loss            | 57          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0116658  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -641        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 822         |
|    total_timesteps       | 1855488     |
| train/                   |             |
|    approx_kl             | 0.006442262 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 7.05        |
|    cost_values           | 1.02        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 9050        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.455       |
|    value_loss            | 29.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4237286  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -640        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 857         |
|    total_timesteps       | 1857536     |
| train/                   |             |
|    approx_kl             | 0.004073756 |
|    clip_fraction         | 0.00962     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.306       |
|    cost_values           | 1.01        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 9060        |
|    policy_gradient_loss  | -0.000729   |
|    std                   | 0.454       |
|    value_loss            | 8.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8086594   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -644         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 891          |
|    total_timesteps       | 1859584      |
| train/                   |              |
|    approx_kl             | 0.0035257759 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.972        |
|    cost_values           | 1.02         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 9070         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.451        |
|    value_loss            | 35.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40280366  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -645         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 926          |
|    total_timesteps       | 1861632      |
| train/                   |              |
|    approx_kl             | 0.0037417803 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 0.838        |
|    cost_values           | 1.03         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.05         |
|    n_updates             | 9080         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.45         |
|    value_loss            | 8.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8261642   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -641         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 961          |
|    total_timesteps       | 1863680      |
| train/                   |              |
|    approx_kl             | 0.0053731897 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 5.89         |
|    cost_values           | 1.18         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.64         |
|    n_updates             | 9090         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.45         |
|    value_loss            | 8.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.92568237 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -651        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1865728     |
| train/                   |             |
|    approx_kl             | 0.003591719 |
|    clip_fraction         | 0.00957     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 1.77        |
|    cost_values           | 1.6         |
|    entropy               | -1.24       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.19        |
|    n_updates             | 9100        |
|    policy_gradient_loss  | 4.6e-05     |
|    std                   | 0.451       |
|    value_loss            | 8.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.936284   |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -653        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1030        |
|    total_timesteps       | 1867776     |
| train/                   |             |
|    approx_kl             | 0.004445119 |
|    clip_fraction         | 0.0435      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 2.99        |
|    cost_values           | 1.55        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 9110        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.451       |
|    value_loss            | 8.35        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0099158    |
| rollout/                 |               |
|    ep_len_mean           | 952           |
|    ep_rew_mean           | -658          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 31            |
|    time_elapsed          | 1065          |
|    total_timesteps       | 1869824       |
| train/                   |               |
|    approx_kl             | 0.00010319926 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.34          |
|    cost_value_loss       | 0.255         |
|    cost_values           | 1.38          |
|    entropy               | -1.24         |
|    entropy_loss          | -1.24         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.7           |
|    n_updates             | 9120          |
|    policy_gradient_loss  | 4.4e-05       |
|    std                   | 0.451         |
|    value_loss            | 13.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8222662  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -657        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1100        |
|    total_timesteps       | 1871872     |
| train/                   |             |
|    approx_kl             | 0.005425229 |
|    clip_fraction         | 0.0133      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 0.668       |
|    cost_values           | 1.08        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.85        |
|    n_updates             | 9130        |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.451       |
|    value_loss            | 21.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48925892 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -654        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 33          |
|    time_elapsed          | 1135        |
|    total_timesteps       | 1873920     |
| train/                   |             |
|    approx_kl             | 0.006860396 |
|    clip_fraction         | 0.0296      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.67        |
|    cost_values           | 1.08        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.2        |
|    n_updates             | 9140        |
|    policy_gradient_loss  | -0.000461   |
|    std                   | 0.453       |
|    value_loss            | 36.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8936482   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1170         |
|    total_timesteps       | 1875968      |
| train/                   |              |
|    approx_kl             | 0.0051951697 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.21         |
|    cost_values           | 1.04         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 9150         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.452        |
|    value_loss            | 31.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7430258   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1204         |
|    total_timesteps       | 1878016      |
| train/                   |              |
|    approx_kl             | 0.0015039257 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.999        |
|    cost_value_loss       | 0.445        |
|    cost_values           | 0.988        |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 9160         |
|    policy_gradient_loss  | -0.000156    |
|    std                   | 0.451        |
|    value_loss            | 44.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.50039506  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1239         |
|    total_timesteps       | 1880064      |
| train/                   |              |
|    approx_kl             | 0.0006689718 |
|    clip_fraction         | 0.00366      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 1.04         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.19         |
|    n_updates             | 9170         |
|    policy_gradient_loss  | 0.000247     |
|    std                   | 0.451        |
|    value_loss            | 5.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.84057736 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -655        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1274        |
|    total_timesteps       | 1882112     |
| train/                   |             |
|    approx_kl             | 0.004663296 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.53        |
|    cost_value_loss       | 2.59        |
|    cost_values           | 1.09        |
|    entropy               | -1.23       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.8        |
|    n_updates             | 9180        |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.451       |
|    value_loss            | 29.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8456818  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1308        |
|    total_timesteps       | 1884160     |
| train/                   |             |
|    approx_kl             | 0.004804508 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.44        |
|    cost_value_loss       | 1.5         |
|    cost_values           | 1.17        |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.1         |
|    n_updates             | 9190        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.45        |
|    value_loss            | 8.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9349541   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1343         |
|    total_timesteps       | 1886208      |
| train/                   |              |
|    approx_kl             | 0.0021923892 |
|    clip_fraction         | 0.0021       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.245        |
|    cost_values           | 1.24         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.1         |
|    n_updates             | 9200         |
|    policy_gradient_loss  | -0.000114    |
|    std                   | 0.449        |
|    value_loss            | 97.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.46857896 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 40          |
|    time_elapsed          | 1377        |
|    total_timesteps       | 1888256     |
| train/                   |             |
|    approx_kl             | 0.003132198 |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 1           |
|    cost_value_loss       | 0.159       |
|    cost_values           | 1.01        |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 9210        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.449       |
|    value_loss            | 7.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85421795  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -669         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1412         |
|    total_timesteps       | 1890304      |
| train/                   |              |
|    approx_kl             | 0.0018209094 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 4.32         |
|    cost_values           | 1.06         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.46         |
|    n_updates             | 9220         |
|    policy_gradient_loss  | 6.07e-05     |
|    std                   | 0.45         |
|    value_loss            | 7.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7974342   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1447         |
|    total_timesteps       | 1892352      |
| train/                   |              |
|    approx_kl             | 0.0028686095 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 3.75         |
|    cost_values           | 1.18         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 9230         |
|    policy_gradient_loss  | -0.000593    |
|    std                   | 0.45         |
|    value_loss            | 25.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0006942  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -677        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 43          |
|    time_elapsed          | 1482        |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.003810123 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.21        |
|    cost_value_loss       | 5.14        |
|    cost_values           | 1.49        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.23        |
|    n_updates             | 9240        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.449       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1448898   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1517         |
|    total_timesteps       | 1896448      |
| train/                   |              |
|    approx_kl             | 0.0035781302 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 0.31         |
|    cost_values           | 1.69         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.35         |
|    n_updates             | 9250         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.448        |
|    value_loss            | 4.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.59618807  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1552         |
|    total_timesteps       | 1898496      |
| train/                   |              |
|    approx_kl             | 0.0037593655 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 5.82         |
|    cost_values           | 1.49         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 9260         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.447        |
|    value_loss            | 24           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.70644695 |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1587        |
|    total_timesteps       | 1900544     |
| train/                   |             |
|    approx_kl             | 0.004160344 |
|    clip_fraction         | 0.00981     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 3.18        |
|    cost_values           | 1.63        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.6        |
|    n_updates             | 9270        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.448       |
|    value_loss            | 53.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52779037  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1621         |
|    total_timesteps       | 1902592      |
| train/                   |              |
|    approx_kl             | 0.0048703477 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.85         |
|    cost_value_loss       | 7.06         |
|    cost_values           | 1.78         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.18         |
|    n_updates             | 9280         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.448        |
|    value_loss            | 8.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.95518756  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1655         |
|    total_timesteps       | 1904640      |
| train/                   |              |
|    approx_kl             | 0.0010393778 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 0.194        |
|    cost_values           | 1.83         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 9290         |
|    policy_gradient_loss  | -0.000328    |
|    std                   | 0.448        |
|    value_loss            | 14.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24863327 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -694        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1690        |
|    total_timesteps       | 1906688     |
| train/                   |             |
|    approx_kl             | 0.007234034 |
|    clip_fraction         | 0.0501      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 1.27        |
|    cost_values           | 1.52        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 9300        |
|    policy_gradient_loss  | -0.00394    |
|    std                   | 0.449       |
|    value_loss            | 4.54        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
-----------------------------------
| avg_speed          | 7.8        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.8        |
| reward             | -0.5603211 |
| rollout/           |            |
|    ep_len_mean     | 928        |
|    ep_rew_mean     | -689       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 1908736    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85524637  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 1910784      |
| train/                   |              |
|    approx_kl             | 0.0021488622 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 1.58         |
|    cost_values           | 1.04         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 9320         |
|    policy_gradient_loss  | -0.000587    |
|    std                   | 0.449        |
|    value_loss            | 21.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32023183 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 94          |
|    total_timesteps       | 1912832     |
| train/                   |             |
|    approx_kl             | 0.005730367 |
|    clip_fraction         | 0.0164      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 3.25        |
|    cost_values           | 1.04        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 9330        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.448       |
|    value_loss            | 20.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75330585  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 1914880      |
| train/                   |              |
|    approx_kl             | 0.0054784184 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 3.18         |
|    cost_values           | 1.23         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 9340         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.447        |
|    value_loss            | 24.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.81695503 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 1916928     |
| train/                   |             |
|    approx_kl             | 0.004849217 |
|    clip_fraction         | 0.0083      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 1           |
|    cost_values           | 1.38        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.91        |
|    n_updates             | 9350        |
|    policy_gradient_loss  | -0.000421   |
|    std                   | 0.447       |
|    value_loss            | 10          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33509737 |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 197         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.002818326 |
|    clip_fraction         | 0.0105      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 4.59        |
|    cost_values           | 1.38        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 9360        |
|    policy_gradient_loss  | -0.000803   |
|    std                   | 0.447       |
|    value_loss            | 3.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8103708   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1921024      |
| train/                   |              |
|    approx_kl             | 0.0051545585 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 5.28         |
|    cost_values           | 1.67         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 9370         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.448        |
|    value_loss            | 40.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0747136  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 1923072     |
| train/                   |             |
|    approx_kl             | 0.003040898 |
|    clip_fraction         | 0.00288     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 1.37        |
|    cost_values           | 1.69        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.9         |
|    n_updates             | 9380        |
|    policy_gradient_loss  | -0.000493   |
|    std                   | 0.447       |
|    value_loss            | 14.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6038225   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 1925120      |
| train/                   |              |
|    approx_kl             | 0.0034094898 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.0743       |
|    cost_values           | 1.41         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.39         |
|    n_updates             | 9390         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.448        |
|    value_loss            | 5.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.68734753 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 335         |
|    total_timesteps       | 1927168     |
| train/                   |             |
|    approx_kl             | 0.002001977 |
|    clip_fraction         | 0.0102      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 3.42        |
|    cost_values           | 1.32        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.61        |
|    n_updates             | 9400        |
|    policy_gradient_loss  | -0.000514   |
|    std                   | 0.447       |
|    value_loss            | 9.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.600465    |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 1929216      |
| train/                   |              |
|    approx_kl             | 0.0039677084 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 2.55         |
|    cost_values           | 1.58         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.34         |
|    n_updates             | 9410         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.447        |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6322806   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 1931264      |
| train/                   |              |
|    approx_kl             | 0.0051813987 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 3            |
|    cost_values           | 1.67         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.51         |
|    n_updates             | 9420         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.445        |
|    value_loss            | 7.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.29779038  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 1933312      |
| train/                   |              |
|    approx_kl             | 0.0045384425 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 2.78         |
|    cost_values           | 1.96         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.54         |
|    n_updates             | 9430         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.444        |
|    value_loss            | 8.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7655197   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 474          |
|    total_timesteps       | 1935360      |
| train/                   |              |
|    approx_kl             | 0.0059468225 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.41         |
|    cost_value_loss       | 8.31         |
|    cost_values           | 2.16         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.85         |
|    n_updates             | 9440         |
|    policy_gradient_loss  | -0.000855    |
|    std                   | 0.444        |
|    value_loss            | 8.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7831335   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 509          |
|    total_timesteps       | 1937408      |
| train/                   |              |
|    approx_kl             | 0.0045958254 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 2.54         |
|    cost_values           | 2.4          |
|    entropy               | -1.21        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.26         |
|    n_updates             | 9450         |
|    policy_gradient_loss  | 0.00028      |
|    std                   | 0.445        |
|    value_loss            | 6.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4154951   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 544          |
|    total_timesteps       | 1939456      |
| train/                   |              |
|    approx_kl             | 0.0033658005 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 7.99         |
|    cost_values           | 2.46         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 9460         |
|    policy_gradient_loss  | 0.000943     |
|    std                   | 0.445        |
|    value_loss            | 15.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.90052646 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 578         |
|    total_timesteps       | 1941504     |
| train/                   |             |
|    approx_kl             | 0.004209117 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 1.1         |
|    cost_values           | 2.46        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 9470        |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 0.444       |
|    value_loss            | 5.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87455726  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -694         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 613          |
|    total_timesteps       | 1943552      |
| train/                   |              |
|    approx_kl             | 0.0063895285 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.14         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.46         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 9480         |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.444        |
|    value_loss            | 8.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5587877   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 647          |
|    total_timesteps       | 1945600      |
| train/                   |              |
|    approx_kl             | 0.0051854476 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.28         |
|    cost_value_loss       | 8.34         |
|    cost_values           | 2.91         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.53         |
|    n_updates             | 9490         |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.444        |
|    value_loss            | 4.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9482094   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 1947648      |
| train/                   |              |
|    approx_kl             | 0.0028831959 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.86         |
|    cost_value_loss       | 4.22         |
|    cost_values           | 3            |
|    entropy               | -1.21        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0.00622      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.31         |
|    n_updates             | 9500         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.445        |
|    value_loss            | 33.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6459653   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 1949696      |
| train/                   |              |
|    approx_kl             | 0.0044879187 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.96         |
|    cost_value_loss       | 2.83         |
|    cost_values           | 2.93         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 9510         |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.445        |
|    value_loss            | 35           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5099041  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 751         |
|    total_timesteps       | 1951744     |
| train/                   |             |
|    approx_kl             | 0.004651018 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 3.21        |
|    cost_values           | 2.77        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 9520        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.444       |
|    value_loss            | 6.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8138099   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 786          |
|    total_timesteps       | 1953792      |
| train/                   |              |
|    approx_kl             | 0.0055617914 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.4          |
|    cost_value_loss       | 3.99         |
|    cost_values           | 2.88         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.01         |
|    n_updates             | 9530         |
|    policy_gradient_loss  | -0.000331    |
|    std                   | 0.443        |
|    value_loss            | 7.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.070801   |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 820         |
|    total_timesteps       | 1955840     |
| train/                   |             |
|    approx_kl             | 0.005888098 |
|    clip_fraction         | 0.0198      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 1.25        |
|    cost_values           | 2.85        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.1         |
|    n_updates             | 9540        |
|    policy_gradient_loss  | -0.000877   |
|    std                   | 0.445       |
|    value_loss            | 4.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1589276  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 854         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.002761525 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.36        |
|    cost_value_loss       | 0.359       |
|    cost_values           | 2.63        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.62        |
|    n_updates             | 9550        |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.445       |
|    value_loss            | 14.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6302415   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 889          |
|    total_timesteps       | 1959936      |
| train/                   |              |
|    approx_kl             | 0.0011540267 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 0.892        |
|    cost_values           | 2.29         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.01         |
|    n_updates             | 9560         |
|    policy_gradient_loss  | -0.000144    |
|    std                   | 0.445        |
|    value_loss            | 15.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.53228533 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -716        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 923         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.008092552 |
|    clip_fraction         | 0.0357      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 2.11        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.21       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 9570        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.445       |
|    value_loss            | 45.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72270256  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 958          |
|    total_timesteps       | 1964032      |
| train/                   |              |
|    approx_kl             | 0.0052787177 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 2.05         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.34         |
|    n_updates             | 9580         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.443        |
|    value_loss            | 5.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66672355  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 1966080      |
| train/                   |              |
|    approx_kl             | 0.0030976704 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.69         |
|    cost_value_loss       | 4.24         |
|    cost_values           | 2.06         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.26         |
|    n_updates             | 9590         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.442        |
|    value_loss            | 6.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6549975   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 1968128      |
| train/                   |              |
|    approx_kl             | 0.0058439197 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 1.71         |
|    cost_values           | 2.06         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.2         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 9600         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.442        |
|    value_loss            | 21.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54263943  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 1970176      |
| train/                   |              |
|    approx_kl             | 0.0034453073 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 0.92         |
|    cost_values           | 1.8          |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.41         |
|    n_updates             | 9610         |
|    policy_gradient_loss  | -0.000645    |
|    std                   | 0.441        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47441033 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1096        |
|    total_timesteps       | 1972224     |
| train/                   |             |
|    approx_kl             | 0.00681562  |
|    clip_fraction         | 0.0273      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 2.04        |
|    cost_values           | 1.69        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 9620        |
|    policy_gradient_loss  | -0.00043    |
|    std                   | 0.441       |
|    value_loss            | 8.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5596801   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1131         |
|    total_timesteps       | 1974272      |
| train/                   |              |
|    approx_kl             | 0.0015001455 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.81         |
|    cost_value_loss       | 5.21         |
|    cost_values           | 1.66         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 9630         |
|    policy_gradient_loss  | -0.000269    |
|    std                   | 0.441        |
|    value_loss            | 11.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.7394479    |
| rollout/                 |               |
|    ep_len_mean           | 963           |
|    ep_rew_mean           | -714          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 34            |
|    time_elapsed          | 1166          |
|    total_timesteps       | 1976320       |
| train/                   |               |
|    approx_kl             | 0.00023826295 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.49          |
|    cost_value_loss       | 4.24          |
|    cost_values           | 1.83          |
|    entropy               | -1.19         |
|    entropy_loss          | -1.19         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.02          |
|    n_updates             | 9640          |
|    policy_gradient_loss  | -9.83e-06     |
|    std                   | 0.442         |
|    value_loss            | 6.24          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.83025926  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1201         |
|    total_timesteps       | 1978368      |
| train/                   |              |
|    approx_kl             | 0.0027123704 |
|    clip_fraction         | 0.00757      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 1.31         |
|    cost_values           | 1.91         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.42         |
|    n_updates             | 9650         |
|    policy_gradient_loss  | -0.000275    |
|    std                   | 0.442        |
|    value_loss            | 5.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.70053893  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 1980416      |
| train/                   |              |
|    approx_kl             | 0.0018148673 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 2.2          |
|    cost_values           | 1.84         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.66         |
|    n_updates             | 9660         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.444        |
|    value_loss            | 6.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85968345  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1274         |
|    total_timesteps       | 1982464      |
| train/                   |              |
|    approx_kl             | 0.0032939287 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 0.709        |
|    cost_values           | 1.86         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.96         |
|    n_updates             | 9670         |
|    policy_gradient_loss  | -0.000993    |
|    std                   | 0.444        |
|    value_loss            | 19.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9515469  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1309        |
|    total_timesteps       | 1984512     |
| train/                   |             |
|    approx_kl             | 0.007049891 |
|    clip_fraction         | 0.0545      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.7         |
|    cost_value_loss       | 4.04        |
|    cost_values           | 1.7         |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.46        |
|    n_updates             | 9680        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.444       |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.99158794  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1344         |
|    total_timesteps       | 1986560      |
| train/                   |              |
|    approx_kl             | 0.0064191315 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 0.0789       |
|    cost_values           | 1.62         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 9690         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.444        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5418275   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1380         |
|    total_timesteps       | 1988608      |
| train/                   |              |
|    approx_kl             | 0.0062852046 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.0297       |
|    cost_values           | 1.21         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.09         |
|    n_updates             | 9700         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.446        |
|    value_loss            | 6.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.39599454  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1415         |
|    total_timesteps       | 1990656      |
| train/                   |              |
|    approx_kl             | 0.0039575743 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.925        |
|    cost_value_loss       | 0.0493       |
|    cost_values           | 1.03         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.62         |
|    n_updates             | 9710         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.447        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6227234   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1450         |
|    total_timesteps       | 1992704      |
| train/                   |              |
|    approx_kl             | 0.0022025383 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 8.71         |
|    cost_values           | 1.09         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 9720         |
|    policy_gradient_loss  | -0.000372    |
|    std                   | 0.447        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.58484465  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1485         |
|    total_timesteps       | 1994752      |
| train/                   |              |
|    approx_kl             | 0.0024951203 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 1.15         |
|    cost_values           | 1.34         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.72         |
|    n_updates             | 9730         |
|    policy_gradient_loss  | -0.000431    |
|    std                   | 0.447        |
|    value_loss            | 4.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.675974   |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1520        |
|    total_timesteps       | 1996800     |
| train/                   |             |
|    approx_kl             | 0.003281243 |
|    clip_fraction         | 0.0323      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 0.0757      |
|    cost_values           | 1.29        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.88        |
|    n_updates             | 9740        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.448       |
|    value_loss            | 17.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.69237363  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1555         |
|    total_timesteps       | 1998848      |
| train/                   |              |
|    approx_kl             | 0.0006615776 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 1.97         |
|    cost_values           | 1.08         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 9750         |
|    policy_gradient_loss  | -0.00035     |
|    std                   | 0.448        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7624389   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1589         |
|    total_timesteps       | 2000896      |
| train/                   |              |
|    approx_kl             | 0.0015736712 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2.4          |
|    cost_values           | 1.17         |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.71         |
|    n_updates             | 9760         |
|    policy_gradient_loss  | -0.000746    |
|    std                   | 0.446        |
|    value_loss            | 4.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55225396  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1624         |
|    total_timesteps       | 2002944      |
| train/                   |              |
|    approx_kl             | 0.0059364466 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 0.522        |
|    cost_values           | 1.2          |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.78         |
|    n_updates             | 9770         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.448        |
|    value_loss            | 5.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0012769   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1658         |
|    total_timesteps       | 2004992      |
| train/                   |              |
|    approx_kl             | 0.0028855158 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 8.03         |
|    cost_values           | 1.26         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 9780         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.448        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.22499903  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1693         |
|    total_timesteps       | 2007040      |
| train/                   |              |
|    approx_kl             | 0.0050124777 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 7.33         |
|    cost_values           | 1.53         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.76         |
|    n_updates             | 9790         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.448        |
|    value_loss            | 12.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.7990294 |
| rollout/           |            |
|    ep_len_mean     | 990        |
|    ep_rew_mean     | -716       |
| time/              |            |
|    fps             | 80         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 2009088    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9165565   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 2011136      |
| train/                   |              |
|    approx_kl             | 0.0056752176 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 3.22         |
|    cost_values           | 1.34         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.42         |
|    n_updates             | 9810         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.449        |
|    value_loss            | 9.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.64608496  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 95           |
|    total_timesteps       | 2013184      |
| train/                   |              |
|    approx_kl             | 0.0018846957 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.9          |
|    cost_value_loss       | 9.25         |
|    cost_values           | 1.37         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 9820         |
|    policy_gradient_loss  | -0.000267    |
|    std                   | 0.449        |
|    value_loss            | 14.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.67937607 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 4           |
|    time_elapsed          | 130         |
|    total_timesteps       | 2015232     |
| train/                   |             |
|    approx_kl             | 0.00676056  |
|    clip_fraction         | 0.0339      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 3           |
|    cost_values           | 1.71        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.29        |
|    n_updates             | 9830        |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.446       |
|    value_loss            | 5.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66723067  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 5            |
|    time_elapsed          | 165          |
|    total_timesteps       | 2017280      |
| train/                   |              |
|    approx_kl             | 0.0038216333 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 0.0889       |
|    cost_values           | 1.82         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.51         |
|    n_updates             | 9840         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.444        |
|    value_loss            | 5.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47482482  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 201          |
|    total_timesteps       | 2019328      |
| train/                   |              |
|    approx_kl             | 0.0023504707 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 7.65         |
|    cost_values           | 1.56         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.32         |
|    n_updates             | 9850         |
|    policy_gradient_loss  | -0.000557    |
|    std                   | 0.444        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80973834 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 7           |
|    time_elapsed          | 236         |
|    total_timesteps       | 2021376     |
| train/                   |             |
|    approx_kl             | 0.005548383 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.88        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 1.73        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.7        |
|    n_updates             | 9860        |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 0.444       |
|    value_loss            | 19.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.73901653 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 8           |
|    time_elapsed          | 270         |
|    total_timesteps       | 2023424     |
| train/                   |             |
|    approx_kl             | 0.005305195 |
|    clip_fraction         | 0.00732     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.39        |
|    cost_value_loss       | 6.76        |
|    cost_values           | 2.03        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 9870        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.444       |
|    value_loss            | 3.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.516811    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 305          |
|    total_timesteps       | 2025472      |
| train/                   |              |
|    approx_kl             | 0.0035845852 |
|    clip_fraction         | 0.00269      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 0.158        |
|    cost_values           | 2.18         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 9880         |
|    policy_gradient_loss  | -0.000939    |
|    std                   | 0.443        |
|    value_loss            | 11.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.74984354  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 340          |
|    total_timesteps       | 2027520      |
| train/                   |              |
|    approx_kl             | 0.0034476602 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 2.63         |
|    cost_values           | 1.99         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 9890         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.443        |
|    value_loss            | 29.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.87828994 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 374         |
|    total_timesteps       | 2029568     |
| train/                   |             |
|    approx_kl             | 0.00737492  |
|    clip_fraction         | 0.084       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 4.61        |
|    cost_values           | 2.26        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 9900        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.443       |
|    value_loss            | 30.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.32364255  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 409          |
|    total_timesteps       | 2031616      |
| train/                   |              |
|    approx_kl             | 0.0021552257 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 5.16         |
|    cost_values           | 2.68         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 9910         |
|    policy_gradient_loss  | -0.000544    |
|    std                   | 0.444        |
|    value_loss            | 17.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.2          |
| reward                   | -0.72789526  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 443          |
|    total_timesteps       | 2033664      |
| train/                   |              |
|    approx_kl             | 0.0045672003 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 2.28         |
|    cost_values           | 2.82         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.4         |
|    n_updates             | 9920         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.444        |
|    value_loss            | 77.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.49939808 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 14          |
|    time_elapsed          | 478         |
|    total_timesteps       | 2035712     |
| train/                   |             |
|    approx_kl             | 0.00301438  |
|    clip_fraction         | 0.00269     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 1.56        |
|    cost_values           | 2.59        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.3        |
|    n_updates             | 9930        |
|    policy_gradient_loss  | -0.000477   |
|    std                   | 0.444       |
|    value_loss            | 27.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85084134  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 15           |
|    time_elapsed          | 512          |
|    total_timesteps       | 2037760      |
| train/                   |              |
|    approx_kl             | 0.0063481256 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 0.127        |
|    cost_values           | 2.27         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.76         |
|    n_updates             | 9940         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.444        |
|    value_loss            | 20.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.49595815 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 16          |
|    time_elapsed          | 547         |
|    total_timesteps       | 2039808     |
| train/                   |             |
|    approx_kl             | 0.003487938 |
|    clip_fraction         | 0.00205     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 1.91        |
|    cost_values           | 1.95        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.2        |
|    n_updates             | 9950        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.444       |
|    value_loss            | 35.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33111748 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -701        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 17          |
|    time_elapsed          | 581         |
|    total_timesteps       | 2041856     |
| train/                   |             |
|    approx_kl             | 0.006930054 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 0.504       |
|    cost_values           | 1.7         |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.3        |
|    n_updates             | 9960        |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.444       |
|    value_loss            | 34.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8036875   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 18           |
|    time_elapsed          | 616          |
|    total_timesteps       | 2043904      |
| train/                   |              |
|    approx_kl             | 0.0060675116 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.387        |
|    cost_values           | 1.41         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.59         |
|    n_updates             | 9970         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.443        |
|    value_loss            | 3.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.75864166  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 650          |
|    total_timesteps       | 2045952      |
| train/                   |              |
|    approx_kl             | 0.0038738449 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 0.679        |
|    cost_values           | 1.32         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 9980         |
|    policy_gradient_loss  | -0.000391    |
|    std                   | 0.443        |
|    value_loss            | 7.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72169405  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 685          |
|    total_timesteps       | 2048000      |
| train/                   |              |
|    approx_kl             | 0.0021274833 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.188        |
|    cost_values           | 1.27         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.28         |
|    n_updates             | 9990         |
|    policy_gradient_loss  | -6.39e-05    |
|    std                   | 0.441        |
|    value_loss            | 2.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.69366485  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 719          |
|    total_timesteps       | 2050048      |
| train/                   |              |
|    approx_kl             | 0.0007397799 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 1.09         |
|    cost_values           | 1.06         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.79         |
|    n_updates             | 10000        |
|    policy_gradient_loss  | 0.000218     |
|    std                   | 0.44         |
|    value_loss            | 2.86         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.7151026 |
| rollout/                 |            |
|    ep_len_mean           | 964        |
|    ep_rew_mean           | -697       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 22         |
|    time_elapsed          | 754        |
|    total_timesteps       | 2052096    |
| train/                   |            |
|    approx_kl             | 0.00493127 |
|    clip_fraction         | 0.0083     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.948      |
|    cost_value_loss       | 0.19       |
|    cost_values           | 0.974      |
|    entropy               | -1.19      |
|    entropy_loss          | -1.19      |
|    explained_variance    | 1.19e-07   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 4.95       |
|    n_updates             | 10010      |
|    policy_gradient_loss  | -0.001     |
|    std                   | 0.439      |
|    value_loss            | 11.7       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.80265373  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 788          |
|    total_timesteps       | 2054144      |
| train/                   |              |
|    approx_kl             | 0.0045050546 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 4.16         |
|    cost_values           | 1.1          |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.81         |
|    n_updates             | 10020        |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.439        |
|    value_loss            | 6.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6615951   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 824          |
|    total_timesteps       | 2056192      |
| train/                   |              |
|    approx_kl             | 0.0032296497 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.0351       |
|    cost_values           | 1.15         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.78         |
|    n_updates             | 10030        |
|    policy_gradient_loss  | -0.000711    |
|    std                   | 0.439        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.73842615  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 859          |
|    total_timesteps       | 2058240      |
| train/                   |              |
|    approx_kl             | 0.0032069082 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 5.26         |
|    cost_values           | 1.14         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.91         |
|    n_updates             | 10040        |
|    policy_gradient_loss  | -0.000268    |
|    std                   | 0.438        |
|    value_loss            | 10.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7612034  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 893         |
|    total_timesteps       | 2060288     |
| train/                   |             |
|    approx_kl             | 0.005977387 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 5.11        |
|    cost_values           | 1.49        |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.45        |
|    n_updates             | 10050       |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.438       |
|    value_loss            | 14.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1135459  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -706        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 928         |
|    total_timesteps       | 2062336     |
| train/                   |             |
|    approx_kl             | 0.004563702 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 1.33        |
|    cost_values           | 1.47        |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.5        |
|    n_updates             | 10060       |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.438       |
|    value_loss            | 30.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8579342   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 963          |
|    total_timesteps       | 2064384      |
| train/                   |              |
|    approx_kl             | 0.0045676483 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 1.38         |
|    cost_values           | 1.24         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 10070        |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.437        |
|    value_loss            | 10.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.9287699    |
| rollout/                 |               |
|    ep_len_mean           | 969           |
|    ep_rew_mean           | -706          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 29            |
|    time_elapsed          | 998           |
|    total_timesteps       | 2066432       |
| train/                   |               |
|    approx_kl             | 0.00040042843 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.14          |
|    cost_value_loss       | 0.913         |
|    cost_values           | 1.03          |
|    entropy               | -1.18         |
|    entropy_loss          | -1.18         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.39          |
|    n_updates             | 10080         |
|    policy_gradient_loss  | -4.33e-05     |
|    std                   | 0.437         |
|    value_loss            | 8.41          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6949362  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1032        |
|    total_timesteps       | 2068480     |
| train/                   |             |
|    approx_kl             | 0.005471584 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.841       |
|    cost_value_loss       | 0.0469      |
|    cost_values           | 0.897       |
|    entropy               | -1.16       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 10090       |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.434       |
|    value_loss            | 7.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5918021  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -714        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1067        |
|    total_timesteps       | 2070528     |
| train/                   |             |
|    approx_kl             | 0.003810148 |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.832       |
|    cost_value_loss       | 0.354       |
|    cost_values           | 0.839       |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.02        |
|    n_updates             | 10100       |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.432       |
|    value_loss            | 2.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6115078   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1101         |
|    total_timesteps       | 2072576      |
| train/                   |              |
|    approx_kl             | 0.0036045774 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 3.54         |
|    cost_values           | 0.958        |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.09         |
|    n_updates             | 10110        |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.432        |
|    value_loss            | 5.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.74628353  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1136         |
|    total_timesteps       | 2074624      |
| train/                   |              |
|    approx_kl             | 0.0022828928 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.911        |
|    cost_value_loss       | 0.128        |
|    cost_values           | 0.933        |
|    entropy               | -1.13        |
|    entropy_loss          | -1.15        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.68         |
|    n_updates             | 10120        |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.425        |
|    value_loss            | 8.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.43757442  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1171         |
|    total_timesteps       | 2076672      |
| train/                   |              |
|    approx_kl             | 0.0032679942 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 9.06         |
|    cost_values           | 1.09         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.06         |
|    n_updates             | 10130        |
|    policy_gradient_loss  | -0.000949    |
|    std                   | 0.423        |
|    value_loss            | 9.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.43222573 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1205        |
|    total_timesteps       | 2078720     |
| train/                   |             |
|    approx_kl             | 0.006070941 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.033       |
|    cost_values           | 1.14        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.9         |
|    n_updates             | 10140       |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.423       |
|    value_loss            | 13.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7354618   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 2080768      |
| train/                   |              |
|    approx_kl             | 0.0013073655 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 1.45         |
|    cost_values           | 0.97         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 10150        |
|    policy_gradient_loss  | -0.000335    |
|    std                   | 0.423        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5362456   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1275         |
|    total_timesteps       | 2082816      |
| train/                   |              |
|    approx_kl             | 0.0014803766 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 2.24         |
|    cost_values           | 1            |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.04         |
|    n_updates             | 10160        |
|    policy_gradient_loss  | -0.000361    |
|    std                   | 0.423        |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44253546  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1310         |
|    total_timesteps       | 2084864      |
| train/                   |              |
|    approx_kl             | 0.0021968589 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 8.31         |
|    cost_values           | 1.08         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.57         |
|    n_updates             | 10170        |
|    policy_gradient_loss  | -0.00062     |
|    std                   | 0.423        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81405395  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1345         |
|    total_timesteps       | 2086912      |
| train/                   |              |
|    approx_kl             | 0.0043298304 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 8.79         |
|    cost_values           | 1.33         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.35         |
|    n_updates             | 10180        |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.423        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59520113  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1379         |
|    total_timesteps       | 2088960      |
| train/                   |              |
|    approx_kl             | 0.0021894565 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 7.66         |
|    cost_values           | 1.59         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.05         |
|    n_updates             | 10190        |
|    policy_gradient_loss  | -0.000607    |
|    std                   | 0.423        |
|    value_loss            | 9.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.93846416  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1413         |
|    total_timesteps       | 2091008      |
| train/                   |              |
|    approx_kl             | 0.0054860935 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.0815       |
|    cost_values           | 1.6          |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.42         |
|    n_updates             | 10200        |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.423        |
|    value_loss            | 6.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9290459   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1448         |
|    total_timesteps       | 2093056      |
| train/                   |              |
|    approx_kl             | 0.0052341437 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 1.43         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.62         |
|    n_updates             | 10210        |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.423        |
|    value_loss            | 5.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.64796776  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1483         |
|    total_timesteps       | 2095104      |
| train/                   |              |
|    approx_kl             | 0.0025511226 |
|    clip_fraction         | 0.00352      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 0.294        |
|    cost_values           | 1.5          |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.05         |
|    n_updates             | 10220        |
|    policy_gradient_loss  | -0.00033     |
|    std                   | 0.423        |
|    value_loss            | 9.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.530858    |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1518         |
|    total_timesteps       | 2097152      |
| train/                   |              |
|    approx_kl             | 0.0021449996 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 0.195        |
|    cost_values           | 1.19         |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.09         |
|    n_updates             | 10230        |
|    policy_gradient_loss  | -0.000982    |
|    std                   | 0.422        |
|    value_loss            | 6.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.77342385 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 45          |
|    time_elapsed          | 1553        |
|    total_timesteps       | 2099200     |
| train/                   |             |
|    approx_kl             | 0.004384035 |
|    clip_fraction         | 0.0255      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.965       |
|    cost_value_loss       | 0.345       |
|    cost_values           | 0.967       |
|    entropy               | -1.08       |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.64        |
|    n_updates             | 10240       |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 0.414       |
|    value_loss            | 7.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9677371   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1587         |
|    total_timesteps       | 2101248      |
| train/                   |              |
|    approx_kl             | 0.0054672724 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 6.87         |
|    cost_values           | 1.2          |
|    entropy               | -1.06        |
|    entropy_loss          | -1.07        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.25         |
|    n_updates             | 10250        |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.412        |
|    value_loss            | 8.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.84268844  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1622         |
|    total_timesteps       | 2103296      |
| train/                   |              |
|    approx_kl             | 0.0036436133 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 0.363        |
|    cost_values           | 1.48         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.88         |
|    n_updates             | 10260        |
|    policy_gradient_loss  | -0.000513    |
|    std                   | 0.412        |
|    value_loss            | 7.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.99560964 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 48          |
|    time_elapsed          | 1656        |
|    total_timesteps       | 2105344     |
| train/                   |             |
|    approx_kl             | 0.006032438 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 2.19        |
|    cost_values           | 1.2         |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.2         |
|    n_updates             | 10270       |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.412       |
|    value_loss            | 8.09        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0718791    |
| rollout/                 |               |
|    ep_len_mean           | 969           |
|    ep_rew_mean           | -710          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 49            |
|    time_elapsed          | 1691          |
|    total_timesteps       | 2107392       |
| train/                   |               |
|    approx_kl             | 0.00051478285 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.898         |
|    cost_value_loss       | 0.0176        |
|    cost_values           | 0.982         |
|    entropy               | -1.06         |
|    entropy_loss          | -1.06         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.12          |
|    n_updates             | 10280         |
|    policy_gradient_loss  | -4.93e-05     |
|    std                   | 0.412         |
|    value_loss            | 10.1          |
--------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.7080714 |
| rollout/           |            |
|    ep_len_mean     | 969        |
|    ep_rew_mean     | -709       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2109440    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.73851687 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 2111488     |
| train/                   |             |
|    approx_kl             | 0.005246236 |
|    clip_fraction         | 0.0336      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.722       |
|    cost_value_loss       | 0.0153      |
|    cost_values           | 0.817       |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.66        |
|    n_updates             | 10300       |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.412       |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8561207  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.003212472 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 3.11        |
|    cost_values           | 0.834       |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 10310       |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.412       |
|    value_loss            | 9.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1410484   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2115584      |
| train/                   |              |
|    approx_kl             | 0.0044369455 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 0.859        |
|    cost_values           | 1            |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.23         |
|    n_updates             | 10320        |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.412        |
|    value_loss            | 7.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.68376553  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 2117632      |
| train/                   |              |
|    approx_kl             | 0.0037865664 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 1.47         |
|    cost_values           | 1.14         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.75         |
|    n_updates             | 10330        |
|    policy_gradient_loss  | -0.000328    |
|    std                   | 0.41         |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.8          |
| reward                   | -0.8522319   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2119680      |
| train/                   |              |
|    approx_kl             | 0.0026357947 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.78         |
|    cost_value_loss       | 7.94         |
|    cost_values           | 1.3          |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 10340        |
|    policy_gradient_loss  | 0.000636     |
|    std                   | 0.409        |
|    value_loss            | 15.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78022563  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 2121728      |
| train/                   |              |
|    approx_kl             | 0.0033440108 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 1.23         |
|    cost_values           | 1.32         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.78         |
|    n_updates             | 10350        |
|    policy_gradient_loss  | -0.000731    |
|    std                   | 0.409        |
|    value_loss            | 4.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5748496  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 267         |
|    total_timesteps       | 2123776     |
| train/                   |             |
|    approx_kl             | 0.002704789 |
|    clip_fraction         | 0.00366     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 4.61        |
|    cost_values           | 1.4         |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.57        |
|    n_updates             | 10360       |
|    policy_gradient_loss  | -0.000375   |
|    std                   | 0.41        |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47275794  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 2125824      |
| train/                   |              |
|    approx_kl             | 0.0028537218 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.586        |
|    cost_values           | 1.5          |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.47         |
|    n_updates             | 10370        |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.41         |
|    value_loss            | 2.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6065166   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 336          |
|    total_timesteps       | 2127872      |
| train/                   |              |
|    approx_kl             | 0.0035678227 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.0325       |
|    cost_values           | 1.2          |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.44         |
|    n_updates             | 10380        |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.409        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.56125873  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 370          |
|    total_timesteps       | 2129920      |
| train/                   |              |
|    approx_kl             | 0.0042223204 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 4.77         |
|    cost_values           | 1.03         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 10390        |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.409        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48370835  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 405          |
|    total_timesteps       | 2131968      |
| train/                   |              |
|    approx_kl             | 0.0040048677 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.887        |
|    cost_value_loss       | 0.0548       |
|    cost_values           | 0.961        |
|    entropy               | -1.04        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.73         |
|    n_updates             | 10400        |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.408        |
|    value_loss            | 7.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48897502  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 2134016      |
| train/                   |              |
|    approx_kl             | 0.0017789991 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 2.89         |
|    cost_values           | 1.18         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.45         |
|    n_updates             | 10410        |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.408        |
|    value_loss            | 9.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7094724  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 474         |
|    total_timesteps       | 2136064     |
| train/                   |             |
|    approx_kl             | 0.004363184 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 0.171       |
|    cost_values           | 1.38        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.47        |
|    n_updates             | 10420       |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.408       |
|    value_loss            | 3.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8841087  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 509         |
|    total_timesteps       | 2138112     |
| train/                   |             |
|    approx_kl             | 0.005928155 |
|    clip_fraction         | 0.0342      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 7.51        |
|    cost_values           | 1.33        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.3        |
|    n_updates             | 10430       |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.408       |
|    value_loss            | 37.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.49034494 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 16          |
|    time_elapsed          | 543         |
|    total_timesteps       | 2140160     |
| train/                   |             |
|    approx_kl             | 0.003778499 |
|    clip_fraction         | 0.0165      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 0.0803      |
|    cost_values           | 1.54        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.23        |
|    n_updates             | 10440       |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.408       |
|    value_loss            | 9.88        |
------------------------------------------
--------------------------------------------
| avg_speed                | 5.2           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.2           |
| reward                   | -0.58527976   |
| rollout/                 |               |
|    ep_len_mean           | 996           |
|    ep_rew_mean           | -720          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 17            |
|    time_elapsed          | 578           |
|    total_timesteps       | 2142208       |
| train/                   |               |
|    approx_kl             | 0.00090780115 |
|    clip_fraction         | 0.0189        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.65          |
|    cost_value_loss       | 2.86          |
|    cost_values           | 1.43          |
|    entropy               | -1.04         |
|    entropy_loss          | -1.04         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.8           |
|    n_updates             | 10450         |
|    policy_gradient_loss  | -0.000226     |
|    std                   | 0.406         |
|    value_loss            | 8.69          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5157141    |
| rollout/                 |               |
|    ep_len_mean           | 996           |
|    ep_rew_mean           | -719          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 18            |
|    time_elapsed          | 613           |
|    total_timesteps       | 2144256       |
| train/                   |               |
|    approx_kl             | 0.00035314704 |
|    clip_fraction         | 0.0391        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.99          |
|    cost_value_loss       | 6.14          |
|    cost_values           | 1.76          |
|    entropy               | -1.03         |
|    entropy_loss          | -1.03         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.91          |
|    n_updates             | 10460         |
|    policy_gradient_loss  | 0.000972      |
|    std                   | 0.406         |
|    value_loss            | 4.66          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.9434916    |
| rollout/                 |               |
|    ep_len_mean           | 996           |
|    ep_rew_mean           | -715          |
| time/                    |               |
|    fps                   | 60            |
|    iterations            | 19            |
|    time_elapsed          | 648           |
|    total_timesteps       | 2146304       |
| train/                   |               |
|    approx_kl             | 0.00081601867 |
|    clip_fraction         | 0.0189        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.07          |
|    cost_value_loss       | 1.25          |
|    cost_values           | 2.03          |
|    entropy               | -1.04         |
|    entropy_loss          | -1.03         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 3.2           |
|    n_updates             | 10470         |
|    policy_gradient_loss  | -0.00114      |
|    std                   | 0.406         |
|    value_loss            | 5.11          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5250399   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 683          |
|    total_timesteps       | 2148352      |
| train/                   |              |
|    approx_kl             | 0.0033900212 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 1.96         |
|    cost_values           | 1.95         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.29         |
|    n_updates             | 10480        |
|    policy_gradient_loss  | -0.000238    |
|    std                   | 0.407        |
|    value_loss            | 5.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49335796  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 2150400      |
| train/                   |              |
|    approx_kl             | 0.0026634117 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 1.46         |
|    cost_values           | 1.73         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.07         |
|    n_updates             | 10490        |
|    policy_gradient_loss  | -0.000257    |
|    std                   | 0.408        |
|    value_loss            | 18.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8554792   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 752          |
|    total_timesteps       | 2152448      |
| train/                   |              |
|    approx_kl             | 0.0064352993 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 1.53         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.81         |
|    n_updates             | 10500        |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.408        |
|    value_loss            | 9.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8595224   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 787          |
|    total_timesteps       | 2154496      |
| train/                   |              |
|    approx_kl             | 0.0005004589 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 20.3         |
|    cost_values           | 1.68         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 10510        |
|    policy_gradient_loss  | -0.000182    |
|    std                   | 0.408        |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.65161145 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 821         |
|    total_timesteps       | 2156544     |
| train/                   |             |
|    approx_kl             | 0.005195641 |
|    clip_fraction         | 0.00566     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 0.0844      |
|    cost_values           | 1.77        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.24        |
|    n_updates             | 10520       |
|    policy_gradient_loss  | -0.000108   |
|    std                   | 0.407       |
|    value_loss            | 6.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7138037   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 856          |
|    total_timesteps       | 2158592      |
| train/                   |              |
|    approx_kl             | 0.0029007138 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 3.64         |
|    cost_values           | 1.62         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.64         |
|    n_updates             | 10530        |
|    policy_gradient_loss  | -0.000887    |
|    std                   | 0.406        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8421057   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 891          |
|    total_timesteps       | 2160640      |
| train/                   |              |
|    approx_kl             | 0.0054468676 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 4.64         |
|    cost_values           | 2.11         |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.7          |
|    n_updates             | 10540        |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 0.405        |
|    value_loss            | 3.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5392688   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 925          |
|    total_timesteps       | 2162688      |
| train/                   |              |
|    approx_kl             | 0.0032985187 |
|    clip_fraction         | 0.0286       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 3.63         |
|    cost_values           | 2.57         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.14         |
|    n_updates             | 10550        |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.403        |
|    value_loss            | 6.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48394752  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 960          |
|    total_timesteps       | 2164736      |
| train/                   |              |
|    approx_kl             | 0.0041394457 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 0.22         |
|    cost_values           | 2.67         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.05         |
|    n_updates             | 10560        |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.402        |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8927277   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 994          |
|    total_timesteps       | 2166784      |
| train/                   |              |
|    approx_kl             | 0.0032989625 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 4.87         |
|    cost_values           | 2.55         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 10570        |
|    policy_gradient_loss  | -0.000651    |
|    std                   | 0.402        |
|    value_loss            | 9.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.76089203 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 30          |
|    time_elapsed          | 1029        |
|    total_timesteps       | 2168832     |
| train/                   |             |
|    approx_kl             | 0.006273065 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.92        |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0.000256    |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 10580       |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 0.402       |
|    value_loss            | 13.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66486347  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 2170880      |
| train/                   |              |
|    approx_kl             | 0.0045896233 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 0.187        |
|    cost_values           | 2.75         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.9          |
|    n_updates             | 10590        |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.401        |
|    value_loss            | 7.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40718937  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1099         |
|    total_timesteps       | 2172928      |
| train/                   |              |
|    approx_kl             | 0.0055952617 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 0.179        |
|    cost_values           | 2.19         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.11         |
|    n_updates             | 10600        |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.401        |
|    value_loss            | 2.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.39014706  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1134         |
|    total_timesteps       | 2174976      |
| train/                   |              |
|    approx_kl             | 0.0073157516 |
|    clip_fraction         | 0.0678       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 1.53         |
|    cost_values           | 1.91         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 10610        |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.401        |
|    value_loss            | 6.98         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.9253138    |
| rollout/                 |               |
|    ep_len_mean           | 994           |
|    ep_rew_mean           | -698          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 34            |
|    time_elapsed          | 1169          |
|    total_timesteps       | 2177024       |
| train/                   |               |
|    approx_kl             | 0.00093883194 |
|    clip_fraction         | 0.0324        |
|    clip_range            | 0.2           |
|    cost_returns          | 2.49          |
|    cost_value_loss       | 6.41          |
|    cost_values           | 1.89          |
|    entropy               | -1.01         |
|    entropy_loss          | -1.01         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 5.06          |
|    n_updates             | 10620         |
|    policy_gradient_loss  | 0.00108       |
|    std                   | 0.401         |
|    value_loss            | 5.48          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 4.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.6          |
| reward                   | -0.66703665  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1205         |
|    total_timesteps       | 2179072      |
| train/                   |              |
|    approx_kl             | 0.0053205937 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 3.98         |
|    cost_values           | 1.87         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.8         |
|    n_updates             | 10630        |
|    policy_gradient_loss  | -0.000814    |
|    std                   | 0.4          |
|    value_loss            | 35.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6527839   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 2181120      |
| train/                   |              |
|    approx_kl             | 0.0023834254 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 3.93         |
|    cost_values           | 1.87         |
|    entropy               | -1           |
|    entropy_loss          | -1.01        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.31         |
|    n_updates             | 10640        |
|    policy_gradient_loss  | -0.000554    |
|    std                   | 0.4          |
|    value_loss            | 2.82         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.80820936   |
| rollout/                 |               |
|    ep_len_mean           | 994           |
|    ep_rew_mean           | -702          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 37            |
|    time_elapsed          | 1275          |
|    total_timesteps       | 2183168       |
| train/                   |               |
|    approx_kl             | 0.00075326365 |
|    clip_fraction         | 0.00122       |
|    clip_range            | 0.2           |
|    cost_returns          | 4.9           |
|    cost_value_loss       | 18.3          |
|    cost_values           | 2.12          |
|    entropy               | -1            |
|    entropy_loss          | -1            |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.1          |
|    n_updates             | 10650         |
|    policy_gradient_loss  | 0.000846      |
|    std                   | 0.4           |
|    value_loss            | 6.42          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7528412  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 38          |
|    time_elapsed          | 1310        |
|    total_timesteps       | 2185216     |
| train/                   |             |
|    approx_kl             | 0.004245008 |
|    clip_fraction         | 0.0134      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.12        |
|    cost_value_loss       | 0.45        |
|    cost_values           | 2.28        |
|    entropy               | -1          |
|    entropy_loss          | -1          |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.61        |
|    n_updates             | 10660       |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 0.399       |
|    value_loss            | 9.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.68970925  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1345         |
|    total_timesteps       | 2187264      |
| train/                   |              |
|    approx_kl             | 0.0043828203 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 4.64         |
|    cost_values           | 2.1          |
|    entropy               | -0.999       |
|    entropy_loss          | -0.999       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.85         |
|    n_updates             | 10670        |
|    policy_gradient_loss  | -0.000661    |
|    std                   | 0.399        |
|    value_loss            | 3.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8232465   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1380         |
|    total_timesteps       | 2189312      |
| train/                   |              |
|    approx_kl             | 0.0009970705 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 8.26         |
|    cost_values           | 2.23         |
|    entropy               | -0.997       |
|    entropy_loss          | -0.998       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 10680        |
|    policy_gradient_loss  | -3.23e-05    |
|    std                   | 0.399        |
|    value_loss            | 35.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7731918   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -702         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1415         |
|    total_timesteps       | 2191360      |
| train/                   |              |
|    approx_kl             | 0.0029164073 |
|    clip_fraction         | 0.0286       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 1.41         |
|    cost_values           | 2.19         |
|    entropy               | -0.998       |
|    entropy_loss          | -0.997       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.37         |
|    n_updates             | 10690        |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.399        |
|    value_loss            | 3.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8578726   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1450         |
|    total_timesteps       | 2193408      |
| train/                   |              |
|    approx_kl             | 0.0030482775 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 0.116        |
|    cost_values           | 2.03         |
|    entropy               | -0.998       |
|    entropy_loss          | -0.998       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.2          |
|    n_updates             | 10700        |
|    policy_gradient_loss  | -0.000693    |
|    std                   | 0.399        |
|    value_loss            | 9.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.81834096  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1485         |
|    total_timesteps       | 2195456      |
| train/                   |              |
|    approx_kl             | 0.0056073824 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 0.0509       |
|    cost_values           | 1.65         |
|    entropy               | -0.996       |
|    entropy_loss          | -0.998       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.75         |
|    n_updates             | 10710        |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 0.398        |
|    value_loss            | 7.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49225116  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1520         |
|    total_timesteps       | 2197504      |
| train/                   |              |
|    approx_kl             | 0.0050497083 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 0.393        |
|    cost_values           | 1.32         |
|    entropy               | -0.994       |
|    entropy_loss          | -0.995       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.54         |
|    n_updates             | 10720        |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.398        |
|    value_loss            | 3.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8380436   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1554         |
|    total_timesteps       | 2199552      |
| train/                   |              |
|    approx_kl             | 0.0036859708 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 3.17         |
|    cost_values           | 1.21         |
|    entropy               | -0.992       |
|    entropy_loss          | -0.993       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 10730        |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.397        |
|    value_loss            | 8.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8554724  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1589        |
|    total_timesteps       | 2201600     |
| train/                   |             |
|    approx_kl             | 0.003953337 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.105       |
|    cost_values           | 1.14        |
|    entropy               | -0.988      |
|    entropy_loss          | -0.99       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 10740       |
|    policy_gradient_loss  | -0.000628   |
|    std                   | 0.397       |
|    value_loss            | 4.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.493451    |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1623         |
|    total_timesteps       | 2203648      |
| train/                   |              |
|    approx_kl             | 0.0039465753 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.938        |
|    cost_value_loss       | 0.468        |
|    cost_values           | 0.945        |
|    entropy               | -0.986       |
|    entropy_loss          | -0.987       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.68         |
|    n_updates             | 10750        |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.396        |
|    value_loss            | 4.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4400849   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1657         |
|    total_timesteps       | 2205696      |
| train/                   |              |
|    approx_kl             | 0.0037280584 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.765        |
|    cost_value_loss       | 0.0147       |
|    cost_values           | 0.843        |
|    entropy               | -0.976       |
|    entropy_loss          | -0.982       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.21         |
|    n_updates             | 10760        |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.394        |
|    value_loss            | 6.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6959453   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1692         |
|    total_timesteps       | 2207744      |
| train/                   |              |
|    approx_kl             | 0.0027801145 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.985        |
|    cost_value_loss       | 0.869        |
|    cost_values           | 0.817        |
|    entropy               | -0.972       |
|    entropy_loss          | -0.972       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.62         |
|    n_updates             | 10770        |
|    policy_gradient_loss  | -9.62e-05    |
|    std                   | 0.394        |
|    value_loss            | 3.08         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.5920876 |
| rollout/           |            |
|    ep_len_mean     | 994        |
|    ep_rew_mean     | -685       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2209792    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0297024   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2211840      |
| train/                   |              |
|    approx_kl             | 0.0039304737 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 4.58         |
|    cost_values           | 1.03         |
|    entropy               | -0.967       |
|    entropy_loss          | -0.966       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.36         |
|    n_updates             | 10790        |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.392        |
|    value_loss            | 7.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6136832   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 3            |
|    time_elapsed          | 95           |
|    total_timesteps       | 2213888      |
| train/                   |              |
|    approx_kl             | 0.0029613138 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.852        |
|    cost_values           | 1            |
|    entropy               | -0.963       |
|    entropy_loss          | -0.965       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.3          |
|    n_updates             | 10800        |
|    policy_gradient_loss  | -0.000816    |
|    std                   | 0.392        |
|    value_loss            | 5.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8191488   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 2215936      |
| train/                   |              |
|    approx_kl             | 0.0069763847 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.76         |
|    cost_values           | 0.993        |
|    entropy               | -0.958       |
|    entropy_loss          | -0.96        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.17         |
|    n_updates             | 10810        |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.391        |
|    value_loss            | 8.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1087269   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 164          |
|    total_timesteps       | 2217984      |
| train/                   |              |
|    approx_kl             | 0.0056803105 |
|    clip_fraction         | 0.0687       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 1.16         |
|    cost_values           | 1            |
|    entropy               | -0.953       |
|    entropy_loss          | -0.955       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 10820        |
|    policy_gradient_loss  | -0.00518     |
|    std                   | 0.39         |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.36098525  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2220032      |
| train/                   |              |
|    approx_kl             | 0.0038973573 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.16         |
|    cost_values           | 0.988        |
|    entropy               | -0.952       |
|    entropy_loss          | -0.952       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.49         |
|    n_updates             | 10830        |
|    policy_gradient_loss  | -0.000828    |
|    std                   | 0.389        |
|    value_loss            | 20.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.7106008   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 233          |
|    total_timesteps       | 2222080      |
| train/                   |              |
|    approx_kl             | 0.0022278135 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 1.2          |
|    cost_values           | 1            |
|    entropy               | -0.953       |
|    entropy_loss          | -0.952       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.78         |
|    n_updates             | 10840        |
|    policy_gradient_loss  | -0.000332    |
|    std                   | 0.39         |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6885949   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 2224128      |
| train/                   |              |
|    approx_kl             | 0.0021268057 |
|    clip_fraction         | 0.00659      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 4            |
|    cost_values           | 1.11         |
|    entropy               | -0.958       |
|    entropy_loss          | -0.955       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 10850        |
|    policy_gradient_loss  | -0.00027     |
|    std                   | 0.391        |
|    value_loss            | 6.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6951595   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 2226176      |
| train/                   |              |
|    approx_kl             | 0.0039613475 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.71         |
|    cost_value_loss       | 6.49         |
|    cost_values           | 1.54         |
|    entropy               | -0.957       |
|    entropy_loss          | -0.958       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.14         |
|    n_updates             | 10860        |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.391        |
|    value_loss            | 6.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31460565 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2228224     |
| train/                   |             |
|    approx_kl             | 0.009059604 |
|    clip_fraction         | 0.0293      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 3.91        |
|    cost_values           | 2.12        |
|    entropy               | -0.963      |
|    entropy_loss          | -0.959      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.52        |
|    n_updates             | 10870       |
|    policy_gradient_loss  | -0.000727   |
|    std                   | 0.392       |
|    value_loss            | 2.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6833078   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 371          |
|    total_timesteps       | 2230272      |
| train/                   |              |
|    approx_kl             | 0.0010807513 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 5.14         |
|    cost_values           | 2.36         |
|    entropy               | -0.965       |
|    entropy_loss          | -0.964       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.45         |
|    n_updates             | 10880        |
|    policy_gradient_loss  | 0.000348     |
|    std                   | 0.392        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67004395  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 406          |
|    total_timesteps       | 2232320      |
| train/                   |              |
|    approx_kl             | 0.0061955117 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 1.16         |
|    cost_values           | 2.28         |
|    entropy               | -0.965       |
|    entropy_loss          | -0.965       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 10890        |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.392        |
|    value_loss            | 8.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7761177  |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 441         |
|    total_timesteps       | 2234368     |
| train/                   |             |
|    approx_kl             | 0.003916849 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 1.46        |
|    cost_values           | 2.16        |
|    entropy               | -0.972      |
|    entropy_loss          | -0.969      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.78        |
|    n_updates             | 10900       |
|    policy_gradient_loss  | -0.000453   |
|    std                   | 0.394       |
|    value_loss            | 2.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9887693   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 2236416      |
| train/                   |              |
|    approx_kl             | 0.0030406348 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 0.631        |
|    cost_values           | 2.03         |
|    entropy               | -0.973       |
|    entropy_loss          | -0.973       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.37         |
|    n_updates             | 10910        |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.394        |
|    value_loss            | 17.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37065038 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 510         |
|    total_timesteps       | 2238464     |
| train/                   |             |
|    approx_kl             | 0.001889687 |
|    clip_fraction         | 0.00859     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 0.67        |
|    cost_values           | 1.73        |
|    entropy               | -0.966      |
|    entropy_loss          | -0.971      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.13        |
|    n_updates             | 10920       |
|    policy_gradient_loss  | -0.000674   |
|    std                   | 0.392       |
|    value_loss            | 11.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8737001   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 2240512      |
| train/                   |              |
|    approx_kl             | 0.0035757823 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 0.685        |
|    cost_values           | 1.6          |
|    entropy               | -0.969       |
|    entropy_loss          | -0.966       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 10930        |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.393        |
|    value_loss            | 19.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.84450424 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 579         |
|    total_timesteps       | 2242560     |
| train/                   |             |
|    approx_kl             | 0.006533362 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.05        |
|    cost_value_loss       | 2.75        |
|    cost_values           | 1.56        |
|    entropy               | -0.97       |
|    entropy_loss          | -0.969      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 10940       |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.393       |
|    value_loss            | 33          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65556     |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 18           |
|    time_elapsed          | 614          |
|    total_timesteps       | 2244608      |
| train/                   |              |
|    approx_kl             | 0.0045087263 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 4.98         |
|    cost_values           | 1.61         |
|    entropy               | -0.966       |
|    entropy_loss          | -0.968       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.09         |
|    n_updates             | 10950        |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.392        |
|    value_loss            | 8.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5454586   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 648          |
|    total_timesteps       | 2246656      |
| train/                   |              |
|    approx_kl             | 0.0030199778 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 2.51         |
|    cost_values           | 1.95         |
|    entropy               | -0.96        |
|    entropy_loss          | -0.963       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.26         |
|    n_updates             | 10960        |
|    policy_gradient_loss  | -0.000918    |
|    std                   | 0.391        |
|    value_loss            | 8.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6805954   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 20           |
|    time_elapsed          | 682          |
|    total_timesteps       | 2248704      |
| train/                   |              |
|    approx_kl             | 0.0052801124 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 3.09         |
|    cost_values           | 2.17         |
|    entropy               | -0.958       |
|    entropy_loss          | -0.959       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 10970        |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.391        |
|    value_loss            | 38.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.917318    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 717          |
|    total_timesteps       | 2250752      |
| train/                   |              |
|    approx_kl             | 0.0043797707 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 0.134        |
|    cost_values           | 2.16         |
|    entropy               | -0.959       |
|    entropy_loss          | -0.958       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 10980        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.391        |
|    value_loss            | 13.3         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.48608026   |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -690          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 22            |
|    time_elapsed          | 751           |
|    total_timesteps       | 2252800       |
| train/                   |               |
|    approx_kl             | 0.00041001168 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.66          |
|    cost_value_loss       | 0.106         |
|    cost_values           | 1.79          |
|    entropy               | -0.959        |
|    entropy_loss          | -0.959        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.27          |
|    n_updates             | 10990         |
|    policy_gradient_loss  | -0.000117     |
|    std                   | 0.391         |
|    value_loss            | 16.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.96699923  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 23           |
|    time_elapsed          | 786          |
|    total_timesteps       | 2254848      |
| train/                   |              |
|    approx_kl             | 0.0046052737 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 0.424        |
|    cost_values           | 1.44         |
|    entropy               | -0.96        |
|    entropy_loss          | -0.959       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.68         |
|    n_updates             | 11000        |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.391        |
|    value_loss            | 5.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9768286   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 822          |
|    total_timesteps       | 2256896      |
| train/                   |              |
|    approx_kl             | 0.0032957026 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 6.26         |
|    cost_values           | 1.35         |
|    entropy               | -0.959       |
|    entropy_loss          | -0.96        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.87         |
|    n_updates             | 11010        |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.391        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0132836   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 857          |
|    total_timesteps       | 2258944      |
| train/                   |              |
|    approx_kl             | 0.0021777954 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 7.4          |
|    cost_values           | 1.69         |
|    entropy               | -0.961       |
|    entropy_loss          | -0.959       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 11020        |
|    policy_gradient_loss  | -0.000366    |
|    std                   | 0.391        |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9131961  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 26          |
|    time_elapsed          | 891         |
|    total_timesteps       | 2260992     |
| train/                   |             |
|    approx_kl             | 0.002662437 |
|    clip_fraction         | 0.0233      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.6         |
|    cost_value_loss       | 0.0904      |
|    cost_values           | 1.81        |
|    entropy               | -0.962      |
|    entropy_loss          | -0.962      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 11030       |
|    policy_gradient_loss  | -0.00117    |
|    std                   | 0.392       |
|    value_loss            | 7.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9154597   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 926          |
|    total_timesteps       | 2263040      |
| train/                   |              |
|    approx_kl             | 0.0040600966 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 1.39         |
|    cost_values           | 1.42         |
|    entropy               | -0.961       |
|    entropy_loss          | -0.962       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.5          |
|    n_updates             | 11040        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.391        |
|    value_loss            | 10.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0864625    |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -692          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 28            |
|    time_elapsed          | 960           |
|    total_timesteps       | 2265088       |
| train/                   |               |
|    approx_kl             | 0.00020955682 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.48          |
|    cost_value_loss       | 1.51          |
|    cost_values           | 1.33          |
|    entropy               | -0.964        |
|    entropy_loss          | -0.962        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 4.12          |
|    n_updates             | 11050         |
|    policy_gradient_loss  | 0.000187      |
|    std                   | 0.392         |
|    value_loss            | 6.94          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0485022    |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -692          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 29            |
|    time_elapsed          | 995           |
|    total_timesteps       | 2267136       |
| train/                   |               |
|    approx_kl             | 0.00028073613 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.1           |
|    cost_value_loss       | 0.0425        |
|    cost_values           | 1.25          |
|    entropy               | -0.967        |
|    entropy_loss          | -0.966        |
|    explained_variance    | 5.96e-08      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 7.14          |
|    n_updates             | 11060         |
|    policy_gradient_loss  | 0.000372      |
|    std                   | 0.392         |
|    value_loss            | 16.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5288535   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1029         |
|    total_timesteps       | 2269184      |
| train/                   |              |
|    approx_kl             | 0.0034864566 |
|    clip_fraction         | 0.00439      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 6.85         |
|    cost_values           | 1.22         |
|    entropy               | -0.968       |
|    entropy_loss          | -0.968       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 11070        |
|    policy_gradient_loss  | -0.000229    |
|    std                   | 0.393        |
|    value_loss            | 16.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.6          |
| reward                   | -0.50602525  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1064         |
|    total_timesteps       | 2271232      |
| train/                   |              |
|    approx_kl             | 0.0033258856 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 0.892        |
|    cost_values           | 1.47         |
|    entropy               | -0.966       |
|    entropy_loss          | -0.967       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 11080        |
|    policy_gradient_loss  | -0.00052     |
|    std                   | 0.392        |
|    value_loss            | 22.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48837525  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1099         |
|    total_timesteps       | 2273280      |
| train/                   |              |
|    approx_kl             | 0.0037071656 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.0499       |
|    cost_values           | 1.21         |
|    entropy               | -0.967       |
|    entropy_loss          | -0.966       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 11090        |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.392        |
|    value_loss            | 24.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7554183   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1134         |
|    total_timesteps       | 2275328      |
| train/                   |              |
|    approx_kl             | 0.0044100233 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 4.28         |
|    cost_values           | 1.04         |
|    entropy               | -0.969       |
|    entropy_loss          | -0.968       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.08         |
|    n_updates             | 11100        |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.393        |
|    value_loss            | 11.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.890922   |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 34          |
|    time_elapsed          | 1169        |
|    total_timesteps       | 2277376     |
| train/                   |             |
|    approx_kl             | 0.003864746 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 2.67        |
|    cost_values           | 1.12        |
|    entropy               | -0.968      |
|    entropy_loss          | -0.969      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.41        |
|    n_updates             | 11110       |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 0.393       |
|    value_loss            | 9.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7257567  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 35          |
|    time_elapsed          | 1204        |
|    total_timesteps       | 2279424     |
| train/                   |             |
|    approx_kl             | 0.005208394 |
|    clip_fraction         | 0.0455      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 1.82        |
|    cost_values           | 1.04        |
|    entropy               | -0.967      |
|    entropy_loss          | -0.967      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.65        |
|    n_updates             | 11120       |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 0.392       |
|    value_loss            | 9.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5652956  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 36          |
|    time_elapsed          | 1238        |
|    total_timesteps       | 2281472     |
| train/                   |             |
|    approx_kl             | 0.006298498 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.837       |
|    cost_value_loss       | 0.0242      |
|    cost_values           | 0.968       |
|    entropy               | -0.967      |
|    entropy_loss          | -0.967      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.08        |
|    n_updates             | 11130       |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.392       |
|    value_loss            | 15          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.79919887 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1273        |
|    total_timesteps       | 2283520     |
| train/                   |             |
|    approx_kl             | 0.004308676 |
|    clip_fraction         | 0.0137      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.43        |
|    cost_values           | 0.956       |
|    entropy               | -0.97       |
|    entropy_loss          | -0.968      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.42        |
|    n_updates             | 11140       |
|    policy_gradient_loss  | -0.000896   |
|    std                   | 0.393       |
|    value_loss            | 7.07        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.47576818   |
| rollout/                 |               |
|    ep_len_mean           | 992           |
|    ep_rew_mean           | -711          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 38            |
|    time_elapsed          | 1307          |
|    total_timesteps       | 2285568       |
| train/                   |               |
|    approx_kl             | 0.00076836935 |
|    clip_fraction         | 0.00947       |
|    clip_range            | 0.2           |
|    cost_returns          | 1.16          |
|    cost_value_loss       | 1.32          |
|    cost_values           | 1             |
|    entropy               | -0.963        |
|    entropy_loss          | -0.967        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.79          |
|    n_updates             | 11150         |
|    policy_gradient_loss  | -0.000665     |
|    std                   | 0.392         |
|    value_loss            | 12.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78597695  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1342         |
|    total_timesteps       | 2287616      |
| train/                   |              |
|    approx_kl             | 0.0061196997 |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.896        |
|    cost_value_loss       | 0.133        |
|    cost_values           | 0.941        |
|    entropy               | -0.952       |
|    entropy_loss          | -0.958       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.51         |
|    n_updates             | 11160        |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 0.389        |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67506504  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1376         |
|    total_timesteps       | 2289664      |
| train/                   |              |
|    approx_kl             | 0.0033053681 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 4.68         |
|    cost_values           | 1.17         |
|    entropy               | -0.943       |
|    entropy_loss          | -0.947       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.38         |
|    n_updates             | 11170        |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.388        |
|    value_loss            | 3.1          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.1530389    |
| rollout/                 |               |
|    ep_len_mean           | 992           |
|    ep_rew_mean           | -716          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 41            |
|    time_elapsed          | 1411          |
|    total_timesteps       | 2291712       |
| train/                   |               |
|    approx_kl             | 0.00022023746 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.28          |
|    cost_value_loss       | 0.131         |
|    cost_values           | 1.47          |
|    entropy               | -0.942        |
|    entropy_loss          | -0.942        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 6.08          |
|    n_updates             | 11180         |
|    policy_gradient_loss  | 0.000197      |
|    std                   | 0.388         |
|    value_loss            | 14.1          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7062145  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1446        |
|    total_timesteps       | 2293760     |
| train/                   |             |
|    approx_kl             | 0.002990692 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.0248      |
|    cost_values           | 1.14        |
|    entropy               | -0.943      |
|    entropy_loss          | -0.943      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 11190       |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.388       |
|    value_loss            | 5.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.981355    |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1480         |
|    total_timesteps       | 2295808      |
| train/                   |              |
|    approx_kl             | 0.0051328205 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 2.07         |
|    cost_values           | 1.02         |
|    entropy               | -0.938       |
|    entropy_loss          | -0.941       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.18         |
|    n_updates             | 11200        |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.387        |
|    value_loss            | 13.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.037797    |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 44           |
|    time_elapsed          | 1515         |
|    total_timesteps       | 2297856      |
| train/                   |              |
|    approx_kl             | 0.0030293972 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.877        |
|    cost_value_loss       | 0.0295       |
|    cost_values           | 0.946        |
|    entropy               | -0.951       |
|    entropy_loss          | -0.942       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.38         |
|    n_updates             | 11210        |
|    policy_gradient_loss  | -0.000653    |
|    std                   | 0.39         |
|    value_loss            | 5.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5133596   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1549         |
|    total_timesteps       | 2299904      |
| train/                   |              |
|    approx_kl             | 0.0004182269 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 2.32         |
|    cost_values           | 1.14         |
|    entropy               | -0.955       |
|    entropy_loss          | -0.958       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.48         |
|    n_updates             | 11220        |
|    policy_gradient_loss  | -0.000299    |
|    std                   | 0.39         |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1672854   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 46           |
|    time_elapsed          | 1585         |
|    total_timesteps       | 2301952      |
| train/                   |              |
|    approx_kl             | 0.0056467867 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 1.43         |
|    cost_values           | 1.49         |
|    entropy               | -0.949       |
|    entropy_loss          | -0.951       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 11230        |
|    policy_gradient_loss  | -0.000293    |
|    std                   | 0.389        |
|    value_loss            | 6.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65227324  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1620         |
|    total_timesteps       | 2304000      |
| train/                   |              |
|    approx_kl             | 0.0038533437 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.476        |
|    cost_values           | 1.45         |
|    entropy               | -0.947       |
|    entropy_loss          | -0.949       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25           |
|    n_updates             | 11240        |
|    policy_gradient_loss  | -0.00077     |
|    std                   | 0.389        |
|    value_loss            | 36.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0093361   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1655         |
|    total_timesteps       | 2306048      |
| train/                   |              |
|    approx_kl             | 0.0067317514 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.0472       |
|    cost_values           | 1.16         |
|    entropy               | -0.937       |
|    entropy_loss          | -0.942       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.41         |
|    n_updates             | 11250        |
|    policy_gradient_loss  | -5.06e-05    |
|    std                   | 0.387        |
|    value_loss            | 7.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1319901   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -732         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1690         |
|    total_timesteps       | 2308096      |
| train/                   |              |
|    approx_kl             | 0.0041395957 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.0249       |
|    cost_values           | 0.998        |
|    entropy               | -0.934       |
|    entropy_loss          | -0.935       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.22         |
|    n_updates             | 11260        |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.386        |
|    value_loss            | 19.9         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
-----------------------------------
| avg_speed          | 7.4        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.4        |
| reward             | -0.9165696 |
| rollout/           |            |
|    ep_len_mean     | 991        |
|    ep_rew_mean     | -737       |
| time/              |            |
|    fps             | 82         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2310144    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.58840865  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2312192      |
| train/                   |              |
|    approx_kl             | 0.0035965575 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.74         |
|    cost_value_loss       | 0.0236       |
|    cost_values           | 0.869        |
|    entropy               | -0.932       |
|    entropy_loss          | -0.932       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.46         |
|    n_updates             | 11280        |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.386        |
|    value_loss            | 20.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.43618995 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -739        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.003437277 |
|    clip_fraction         | 0.0163      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 1.13        |
|    cost_values           | 0.877       |
|    entropy               | -0.93       |
|    entropy_loss          | -0.931      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 11290       |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.385       |
|    value_loss            | 7.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.4          |
| reward                   | -0.5900577   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2316288      |
| train/                   |              |
|    approx_kl             | 0.0048141363 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.91         |
|    cost_value_loss       | 0.275        |
|    cost_values           | 0.977        |
|    entropy               | -0.928       |
|    entropy_loss          | -0.929       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.72         |
|    n_updates             | 11300        |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.385        |
|    value_loss            | 6.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.88728625 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -730        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 2318336     |
| train/                   |             |
|    approx_kl             | 0.002260118 |
|    clip_fraction         | 0.000732    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 1.03        |
|    entropy               | -0.929      |
|    entropy_loss          | -0.928      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 11310       |
|    policy_gradient_loss  | -0.000402   |
|    std                   | 0.385       |
|    value_loss            | 35.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87104625  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 2320384      |
| train/                   |              |
|    approx_kl             | 0.0048748436 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.936        |
|    cost_value_loss       | 0.0659       |
|    cost_values           | 0.978        |
|    entropy               | -0.925       |
|    entropy_loss          | -0.928       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.68         |
|    n_updates             | 11320        |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.384        |
|    value_loss            | 3.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.69628227  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 2322432      |
| train/                   |              |
|    approx_kl             | 0.0027923048 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 1.02         |
|    entropy               | -0.924       |
|    entropy_loss          | -0.924       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.14         |
|    n_updates             | 11330        |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.384        |
|    value_loss            | 12.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9008075  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 2324480     |
| train/                   |             |
|    approx_kl             | 0.004135685 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.936       |
|    cost_value_loss       | 0.0573      |
|    cost_values           | 0.986       |
|    entropy               | -0.923      |
|    entropy_loss          | -0.924      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.02        |
|    n_updates             | 11340       |
|    policy_gradient_loss  | -0.00239    |
|    std                   | 0.384       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.78260684 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -751        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 301         |
|    total_timesteps       | 2326528     |
| train/                   |             |
|    approx_kl             | 0.004357743 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.869       |
|    cost_value_loss       | 0.369       |
|    cost_values           | 0.911       |
|    entropy               | -0.922      |
|    entropy_loss          | -0.923      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 11350       |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.384       |
|    value_loss            | 9.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.86594135  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 335          |
|    total_timesteps       | 2328576      |
| train/                   |              |
|    approx_kl             | 0.0036883526 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.833        |
|    cost_value_loss       | 0.139        |
|    cost_values           | 0.883        |
|    entropy               | -0.923       |
|    entropy_loss          | -0.922       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.81         |
|    n_updates             | 11360        |
|    policy_gradient_loss  | -0.000583    |
|    std                   | 0.384        |
|    value_loss            | 19.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.60905975 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 370         |
|    total_timesteps       | 2330624     |
| train/                   |             |
|    approx_kl             | 0.004321373 |
|    clip_fraction         | 0.00439     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 2.21        |
|    cost_values           | 0.953       |
|    entropy               | -0.922      |
|    entropy_loss          | -0.923      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41.4        |
|    n_updates             | 11370       |
|    policy_gradient_loss  | -0.000623   |
|    std                   | 0.384       |
|    value_loss            | 75.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.60937613 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 12          |
|    time_elapsed          | 404         |
|    total_timesteps       | 2332672     |
| train/                   |             |
|    approx_kl             | 0.000840413 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.971       |
|    cost_value_loss       | 0.352       |
|    cost_values           | 0.973       |
|    entropy               | -0.92       |
|    entropy_loss          | -0.921      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.2        |
|    n_updates             | 11380       |
|    policy_gradient_loss  | -0.000195   |
|    std                   | 0.383       |
|    value_loss            | 31.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.70324534  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 439          |
|    total_timesteps       | 2334720      |
| train/                   |              |
|    approx_kl             | 0.0025554593 |
|    clip_fraction         | 0.000879     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 4.4          |
|    cost_values           | 1.03         |
|    entropy               | -0.92        |
|    entropy_loss          | -0.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 11390        |
|    policy_gradient_loss  | -0.000674    |
|    std                   | 0.383        |
|    value_loss            | 19.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6661179   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 473          |
|    total_timesteps       | 2336768      |
| train/                   |              |
|    approx_kl             | 0.0018977688 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 1.22         |
|    entropy               | -0.919       |
|    entropy_loss          | -0.92        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.54         |
|    n_updates             | 11400        |
|    policy_gradient_loss  | -0.00033     |
|    std                   | 0.383        |
|    value_loss            | 5.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.79557234  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -762         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 508          |
|    total_timesteps       | 2338816      |
| train/                   |              |
|    approx_kl             | 0.0027085368 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 1.87         |
|    cost_values           | 1.49         |
|    entropy               | -0.917       |
|    entropy_loss          | -0.918       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 11410        |
|    policy_gradient_loss  | -0.000527    |
|    std                   | 0.383        |
|    value_loss            | 20.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2939407   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 543          |
|    total_timesteps       | 2340864      |
| train/                   |              |
|    approx_kl             | 0.0052628964 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.773        |
|    cost_values           | 1.32         |
|    entropy               | -0.916       |
|    entropy_loss          | -0.916       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 11420        |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.383        |
|    value_loss            | 23.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6754203  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -764        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 577         |
|    total_timesteps       | 2342912     |
| train/                   |             |
|    approx_kl             | 0.004849979 |
|    clip_fraction         | 0.0185      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 2.77        |
|    cost_values           | 1.08        |
|    entropy               | -0.915      |
|    entropy_loss          | -0.916      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.8        |
|    n_updates             | 11430       |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.382       |
|    value_loss            | 21.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80266464 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 612         |
|    total_timesteps       | 2344960     |
| train/                   |             |
|    approx_kl             | 0.005173026 |
|    clip_fraction         | 0.0315      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 2.62        |
|    cost_values           | 1.01        |
|    entropy               | -0.915      |
|    entropy_loss          | -0.915      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.3        |
|    n_updates             | 11440       |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.383       |
|    value_loss            | 58.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87552434  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 646          |
|    total_timesteps       | 2347008      |
| train/                   |              |
|    approx_kl             | 0.0027097785 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 3.45         |
|    cost_values           | 1.22         |
|    entropy               | -0.91        |
|    entropy_loss          | -0.913       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.15         |
|    n_updates             | 11450        |
|    policy_gradient_loss  | -1.41e-05    |
|    std                   | 0.381        |
|    value_loss            | 7.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7928321  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -767        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 681         |
|    total_timesteps       | 2349056     |
| train/                   |             |
|    approx_kl             | 0.003938418 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 0.0452      |
|    cost_values           | 1.3         |
|    entropy               | -0.907      |
|    entropy_loss          | -0.908      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.43        |
|    n_updates             | 11460       |
|    policy_gradient_loss  | -0.000595   |
|    std                   | 0.381       |
|    value_loss            | 3           |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.63167447  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 715          |
|    total_timesteps       | 2351104      |
| train/                   |              |
|    approx_kl             | 0.0067039207 |
|    clip_fraction         | 0.0573       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 2            |
|    cost_values           | 1.35         |
|    entropy               | -0.9         |
|    entropy_loss          | -0.904       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.97         |
|    n_updates             | 11470        |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.38         |
|    value_loss            | 9.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8472032   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 22           |
|    time_elapsed          | 750          |
|    total_timesteps       | 2353152      |
| train/                   |              |
|    approx_kl             | 0.0012681875 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 2.99         |
|    cost_values           | 1.63         |
|    entropy               | -0.896       |
|    entropy_loss          | -0.898       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.13         |
|    n_updates             | 11480        |
|    policy_gradient_loss  | -4.23e-05    |
|    std                   | 0.379        |
|    value_loss            | 15.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4702172  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 23          |
|    time_elapsed          | 784         |
|    total_timesteps       | 2355200     |
| train/                   |             |
|    approx_kl             | 0.002047302 |
|    clip_fraction         | 0.00957     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.32        |
|    cost_value_loss       | 3.63        |
|    cost_values           | 1.87        |
|    entropy               | -0.898      |
|    entropy_loss          | -0.897      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.21        |
|    n_updates             | 11490       |
|    policy_gradient_loss  | -0.000799   |
|    std                   | 0.379       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5942118   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 819          |
|    total_timesteps       | 2357248      |
| train/                   |              |
|    approx_kl             | 0.0046879943 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 1.34         |
|    cost_values           | 2.09         |
|    entropy               | -0.893       |
|    entropy_loss          | -0.897       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.74         |
|    n_updates             | 11500        |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.378        |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6193337   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -779         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 25           |
|    time_elapsed          | 853          |
|    total_timesteps       | 2359296      |
| train/                   |              |
|    approx_kl             | 0.0035274662 |
|    clip_fraction         | 0.0494       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 1.68         |
|    cost_values           | 2.08         |
|    entropy               | -0.874       |
|    entropy_loss          | -0.884       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.4          |
|    n_updates             | 11510        |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.375        |
|    value_loss            | 12.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7355754   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 888          |
|    total_timesteps       | 2361344      |
| train/                   |              |
|    approx_kl             | 0.0050806184 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 2.52         |
|    cost_values           | 2.13         |
|    entropy               | -0.868       |
|    entropy_loss          | -0.87        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 11520        |
|    policy_gradient_loss  | -0.000698    |
|    std                   | 0.374        |
|    value_loss            | 22.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.87365514  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 27           |
|    time_elapsed          | 923          |
|    total_timesteps       | 2363392      |
| train/                   |              |
|    approx_kl             | 0.0027545004 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 0.56         |
|    cost_values           | 2.09         |
|    entropy               | -0.867       |
|    entropy_loss          | -0.867       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.4          |
|    n_updates             | 11530        |
|    policy_gradient_loss  | -0.000879    |
|    std                   | 0.373        |
|    value_loss            | 13.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39342907 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 28          |
|    time_elapsed          | 958         |
|    total_timesteps       | 2365440     |
| train/                   |             |
|    approx_kl             | 0.00397337  |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 0.527       |
|    cost_values           | 1.76        |
|    entropy               | -0.866      |
|    entropy_loss          | -0.866      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 11540       |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.373       |
|    value_loss            | 7.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9831145   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 29           |
|    time_elapsed          | 993          |
|    total_timesteps       | 2367488      |
| train/                   |              |
|    approx_kl             | 0.0055310233 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 1.65         |
|    cost_values           | 1.69         |
|    entropy               | -0.852       |
|    entropy_loss          | -0.861       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.28         |
|    n_updates             | 11550        |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.37         |
|    value_loss            | 12.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49161977  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -768         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 2369536      |
| train/                   |              |
|    approx_kl             | 0.0012598988 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 1.66         |
|    cost_values           | 1.88         |
|    entropy               | -0.845       |
|    entropy_loss          | -0.845       |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 11560        |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.369        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7490343   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 31           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 2371584      |
| train/                   |              |
|    approx_kl             | 0.0041720346 |
|    clip_fraction         | 0.0422       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 1.57         |
|    cost_values           | 1.83         |
|    entropy               | -0.845       |
|    entropy_loss          | -0.845       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 11570        |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.369        |
|    value_loss            | 47.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9891661   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 32           |
|    time_elapsed          | 1097         |
|    total_timesteps       | 2373632      |
| train/                   |              |
|    approx_kl             | 0.0014838821 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 4            |
|    cost_values           | 1.7          |
|    entropy               | -0.845       |
|    entropy_loss          | -0.845       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.45         |
|    n_updates             | 11580        |
|    policy_gradient_loss  | -0.000253    |
|    std                   | 0.369        |
|    value_loss            | 9.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.63839823  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1131         |
|    total_timesteps       | 2375680      |
| train/                   |              |
|    approx_kl             | 0.0029200434 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.823        |
|    cost_values           | 1.63         |
|    entropy               | -0.839       |
|    entropy_loss          | -0.843       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.17         |
|    n_updates             | 11590        |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.368        |
|    value_loss            | 9.63         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.0653528    |
| rollout/                 |               |
|    ep_len_mean           | 968           |
|    ep_rew_mean           | -765          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 34            |
|    time_elapsed          | 1166          |
|    total_timesteps       | 2377728       |
| train/                   |               |
|    approx_kl             | 0.00014498059 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.42          |
|    cost_value_loss       | 0.161         |
|    cost_values           | 1.55          |
|    entropy               | -0.837        |
|    entropy_loss          | -0.837        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.5          |
|    n_updates             | 11600         |
|    policy_gradient_loss  | 0.000296      |
|    std                   | 0.368         |
|    value_loss            | 37.5          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4326186   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1201         |
|    total_timesteps       | 2379776      |
| train/                   |              |
|    approx_kl             | 0.0032421956 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 5.55         |
|    cost_values           | 1.37         |
|    entropy               | -0.837       |
|    entropy_loss          | -0.837       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 11610        |
|    policy_gradient_loss  | -0.000622    |
|    std                   | 0.368        |
|    value_loss            | 11.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.76350385  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1236         |
|    total_timesteps       | 2381824      |
| train/                   |              |
|    approx_kl             | 0.0034143445 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.0403       |
|    cost_values           | 1.28         |
|    entropy               | -0.839       |
|    entropy_loss          | -0.839       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.56         |
|    n_updates             | 11620        |
|    policy_gradient_loss  | -0.000767    |
|    std                   | 0.368        |
|    value_loss            | 9.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74953604 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -765        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 37          |
|    time_elapsed          | 1271        |
|    total_timesteps       | 2383872     |
| train/                   |             |
|    approx_kl             | 0.004443333 |
|    clip_fraction         | 0.0296      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 0.836       |
|    cost_values           | 0.998       |
|    entropy               | -0.836      |
|    entropy_loss          | -0.838      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.83        |
|    n_updates             | 11630       |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.368       |
|    value_loss            | 7.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.17488311  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1306         |
|    total_timesteps       | 2385920      |
| train/                   |              |
|    approx_kl             | 0.0033623737 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 3.84         |
|    cost_values           | 1.12         |
|    entropy               | -0.835       |
|    entropy_loss          | -0.835       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.05         |
|    n_updates             | 11640        |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.368        |
|    value_loss            | 6.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1186973  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -760        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 39          |
|    time_elapsed          | 1340        |
|    total_timesteps       | 2387968     |
| train/                   |             |
|    approx_kl             | 0.003391598 |
|    clip_fraction         | 0.0153      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 3.88        |
|    cost_values           | 1.39        |
|    entropy               | -0.833      |
|    entropy_loss          | -0.834      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.6         |
|    n_updates             | 11650       |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.367       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.81774944  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 40           |
|    time_elapsed          | 1375         |
|    total_timesteps       | 2390016      |
| train/                   |              |
|    approx_kl             | 0.0038148358 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 1.02         |
|    cost_values           | 1.4          |
|    entropy               | -0.833       |
|    entropy_loss          | -0.833       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 11660        |
|    policy_gradient_loss  | -0.000575    |
|    std                   | 0.367        |
|    value_loss            | 9.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4375892  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -760        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 41          |
|    time_elapsed          | 1410        |
|    total_timesteps       | 2392064     |
| train/                   |             |
|    approx_kl             | 0.004422231 |
|    clip_fraction         | 0.00464     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.123       |
|    cost_values           | 1.1         |
|    entropy               | -0.836      |
|    entropy_loss          | -0.835      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 11670       |
|    policy_gradient_loss  | -0.000907   |
|    std                   | 0.368       |
|    value_loss            | 8.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57560253  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 42           |
|    time_elapsed          | 1444         |
|    total_timesteps       | 2394112      |
| train/                   |              |
|    approx_kl             | 0.0021246248 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 1.12         |
|    entropy               | -0.834       |
|    entropy_loss          | -0.836       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 11680        |
|    policy_gradient_loss  | -0.000487    |
|    std                   | 0.367        |
|    value_loss            | 9.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.683745    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 43           |
|    time_elapsed          | 1479         |
|    total_timesteps       | 2396160      |
| train/                   |              |
|    approx_kl             | 0.0067216028 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 2.13         |
|    cost_values           | 1.37         |
|    entropy               | -0.828       |
|    entropy_loss          | -0.831       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.32         |
|    n_updates             | 11690        |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.366        |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.60677016 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -756        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 44          |
|    time_elapsed          | 1513        |
|    total_timesteps       | 2398208     |
| train/                   |             |
|    approx_kl             | 0.004196538 |
|    clip_fraction         | 0.00605     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 4.46        |
|    cost_values           | 1.65        |
|    entropy               | -0.834      |
|    entropy_loss          | -0.83       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.04        |
|    n_updates             | 11700       |
|    policy_gradient_loss  | -0.000537   |
|    std                   | 0.367       |
|    value_loss            | 9.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7094903   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1548         |
|    total_timesteps       | 2400256      |
| train/                   |              |
|    approx_kl             | 0.0022868554 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.77         |
|    cost_value_loss       | 4.52         |
|    cost_values           | 2            |
|    entropy               | -0.837       |
|    entropy_loss          | -0.836       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.22         |
|    n_updates             | 11710        |
|    policy_gradient_loss  | 0.000751     |
|    std                   | 0.368        |
|    value_loss            | 11.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6493834  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1583        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.005227019 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 6           |
|    cost_values           | 2.04        |
|    entropy               | -0.837      |
|    entropy_loss          | -0.837      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 11720       |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.368       |
|    value_loss            | 8.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7314574   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1618         |
|    total_timesteps       | 2404352      |
| train/                   |              |
|    approx_kl             | 0.0035084623 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 2.57         |
|    cost_values           | 2.27         |
|    entropy               | -0.842       |
|    entropy_loss          | -0.839       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.41         |
|    n_updates             | 11730        |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.369        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5698531   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1652         |
|    total_timesteps       | 2406400      |
| train/                   |              |
|    approx_kl             | 0.0005102786 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.17         |
|    cost_value_loss       | 3.92         |
|    cost_values           | 2.77         |
|    entropy               | -0.835       |
|    entropy_loss          | -0.84        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0.00385      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.45         |
|    n_updates             | 11740        |
|    policy_gradient_loss  | 6.11e-05     |
|    std                   | 0.367        |
|    value_loss            | 4.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.51907474 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -736        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 49          |
|    time_elapsed          | 1687        |
|    total_timesteps       | 2408448     |
| train/                   |             |
|    approx_kl             | 0.00454672  |
|    clip_fraction         | 0.0467      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.05        |
|    cost_value_loss       | 6.92        |
|    cost_values           | 2.99        |
|    entropy               | -0.827      |
|    entropy_loss          | -0.83       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0.00826     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.26        |
|    n_updates             | 11750       |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.366       |
|    value_loss            | 2.35        |
------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.9288083 |
| rollout/           |            |
|    ep_len_mean     | 969        |
|    ep_rew_mean     | -733       |
| time/              |            |
|    fps             | 83         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2410496    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2463144  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.003500556 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 2.84        |
|    entropy               | -0.815      |
|    entropy_loss          | -0.819      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0.012       |
|    learning_rate         | 0.0003      |
|    loss                  | 3.25        |
|    n_updates             | 11770       |
|    policy_gradient_loss  | -0.000862   |
|    std                   | 0.364       |
|    value_loss            | 6.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6762902   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 2414592      |
| train/                   |              |
|    approx_kl             | 5.394526e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 0.268        |
|    cost_values           | 2.92         |
|    entropy               | -0.812       |
|    entropy_loss          | -0.812       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.13         |
|    n_updates             | 11780        |
|    policy_gradient_loss  | 5.49e-05     |
|    std                   | 0.363        |
|    value_loss            | 31.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6121671   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 4            |
|    time_elapsed          | 127          |
|    total_timesteps       | 2416640      |
| train/                   |              |
|    approx_kl             | 0.0004239701 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 2.01         |
|    cost_values           | 2.73         |
|    entropy               | -0.811       |
|    entropy_loss          | -0.811       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 11790        |
|    policy_gradient_loss  | -3.23e-05    |
|    std                   | 0.363        |
|    value_loss            | 31.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9033388   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 5            |
|    time_elapsed          | 162          |
|    total_timesteps       | 2418688      |
| train/                   |              |
|    approx_kl             | 0.0024887677 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 0.119        |
|    cost_values           | 2.39         |
|    entropy               | -0.819       |
|    entropy_loss          | -0.814       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.8          |
|    n_updates             | 11800        |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.365        |
|    value_loss            | 9.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.028157    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 197          |
|    total_timesteps       | 2420736      |
| train/                   |              |
|    approx_kl             | 0.0019023808 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 2.66         |
|    cost_values           | 2.02         |
|    entropy               | -0.82        |
|    entropy_loss          | -0.822       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 11810        |
|    policy_gradient_loss  | 0.000515     |
|    std                   | 0.365        |
|    value_loss            | 5.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72431946  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 232          |
|    total_timesteps       | 2422784      |
| train/                   |              |
|    approx_kl             | 0.0030530274 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.08         |
|    cost_value_loss       | 7.24         |
|    cost_values           | 2.18         |
|    entropy               | -0.816       |
|    entropy_loss          | -0.818       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.98         |
|    n_updates             | 11820        |
|    policy_gradient_loss  | -0.000915    |
|    std                   | 0.364        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.94269276  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -738         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 8            |
|    time_elapsed          | 267          |
|    total_timesteps       | 2424832      |
| train/                   |              |
|    approx_kl             | 9.042639e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 3.78         |
|    cost_values           | 2.58         |
|    entropy               | -0.817       |
|    entropy_loss          | -0.817       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.93         |
|    n_updates             | 11830        |
|    policy_gradient_loss  | 0.000298     |
|    std                   | 0.364        |
|    value_loss            | 7.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7898863  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -747        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 302         |
|    total_timesteps       | 2426880     |
| train/                   |             |
|    approx_kl             | 0.004607167 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 2.71        |
|    entropy               | -0.821      |
|    entropy_loss          | -0.819      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 11840       |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.365       |
|    value_loss            | 7.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9884907  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -746        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2428928     |
| train/                   |             |
|    approx_kl             | 0.005729724 |
|    clip_fraction         | 0.0323      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 0.145       |
|    cost_values           | 2.52        |
|    entropy               | -0.822      |
|    entropy_loss          | -0.822      |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.74        |
|    n_updates             | 11850       |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.365       |
|    value_loss            | 3.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0609524  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 372         |
|    total_timesteps       | 2430976     |
| train/                   |             |
|    approx_kl             | 0.004399511 |
|    clip_fraction         | 0.0519      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 0.25        |
|    cost_values           | 2.02        |
|    entropy               | -0.823      |
|    entropy_loss          | -0.823      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.25        |
|    n_updates             | 11860       |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.366       |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46774274  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 407          |
|    total_timesteps       | 2433024      |
| train/                   |              |
|    approx_kl             | 0.0022655472 |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 0.0532       |
|    cost_values           | 1.65         |
|    entropy               | -0.821       |
|    entropy_loss          | -0.822       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.23         |
|    n_updates             | 11870        |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.365        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8918142  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -742        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 13          |
|    time_elapsed          | 441         |
|    total_timesteps       | 2435072     |
| train/                   |             |
|    approx_kl             | 0.008812645 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.84        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 1.52        |
|    entropy               | -0.822      |
|    entropy_loss          | -0.821      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.8        |
|    n_updates             | 11880       |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.365       |
|    value_loss            | 33.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39849412 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -735        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 476         |
|    total_timesteps       | 2437120     |
| train/                   |             |
|    approx_kl             | 0.006336472 |
|    clip_fraction         | 0.01        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 0.0542      |
|    cost_values           | 1.49        |
|    entropy               | -0.806      |
|    entropy_loss          | -0.817      |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.26        |
|    n_updates             | 11890       |
|    policy_gradient_loss  | 0.000153    |
|    std                   | 0.363       |
|    value_loss            | 2.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.918995    |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 2439168      |
| train/                   |              |
|    approx_kl             | 0.0025982761 |
|    clip_fraction         | 0.0894       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 7.59         |
|    cost_values           | 1.29         |
|    entropy               | -0.799       |
|    entropy_loss          | -0.801       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.3         |
|    n_updates             | 11900        |
|    policy_gradient_loss  | 0.00297      |
|    std                   | 0.361        |
|    value_loss            | 42.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8973986   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 16           |
|    time_elapsed          | 546          |
|    total_timesteps       | 2441216      |
| train/                   |              |
|    approx_kl             | 0.0027879048 |
|    clip_fraction         | 0.00659      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 3.91         |
|    cost_values           | 1.51         |
|    entropy               | -0.794       |
|    entropy_loss          | -0.797       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.8          |
|    n_updates             | 11910        |
|    policy_gradient_loss  | -0.000454    |
|    std                   | 0.36         |
|    value_loss            | 16.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7081624  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -734        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 17          |
|    time_elapsed          | 581         |
|    total_timesteps       | 2443264     |
| train/                   |             |
|    approx_kl             | 0.003948574 |
|    clip_fraction         | 0.0151      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 1.29        |
|    cost_values           | 1.78        |
|    entropy               | -0.786      |
|    entropy_loss          | -0.79       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.49        |
|    n_updates             | 11920       |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.359       |
|    value_loss            | 3.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.579624   |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 617         |
|    total_timesteps       | 2445312     |
| train/                   |             |
|    approx_kl             | 0.007298389 |
|    clip_fraction         | 0.0443      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 0.142       |
|    cost_values           | 1.64        |
|    entropy               | -0.783      |
|    entropy_loss          | -0.784      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.19        |
|    n_updates             | 11930       |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.358       |
|    value_loss            | 6.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0892407   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 651          |
|    total_timesteps       | 2447360      |
| train/                   |              |
|    approx_kl             | 0.0035762726 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 3.63         |
|    cost_values           | 1.41         |
|    entropy               | -0.779       |
|    entropy_loss          | -0.781       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.76         |
|    n_updates             | 11940        |
|    policy_gradient_loss  | -0.000629    |
|    std                   | 0.358        |
|    value_loss            | 9.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0670886   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 686          |
|    total_timesteps       | 2449408      |
| train/                   |              |
|    approx_kl             | 0.0054699583 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 2.66         |
|    cost_values           | 1.5          |
|    entropy               | -0.779       |
|    entropy_loss          | -0.779       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.27         |
|    n_updates             | 11950        |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.358        |
|    value_loss            | 14.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.82399434  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 721          |
|    total_timesteps       | 2451456      |
| train/                   |              |
|    approx_kl             | 0.0033251103 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 0.0765       |
|    cost_values           | 1.58         |
|    entropy               | -0.778       |
|    entropy_loss          | -0.779       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.26         |
|    n_updates             | 11960        |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.358        |
|    value_loss            | 18           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7409349   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 755          |
|    total_timesteps       | 2453504      |
| train/                   |              |
|    approx_kl             | 0.0019274907 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 3.28         |
|    cost_values           | 1.49         |
|    entropy               | -0.766       |
|    entropy_loss          | -0.773       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.51         |
|    n_updates             | 11970        |
|    policy_gradient_loss  | -0.000615    |
|    std                   | 0.355        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5165099  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 23          |
|    time_elapsed          | 790         |
|    total_timesteps       | 2455552     |
| train/                   |             |
|    approx_kl             | 0.004507684 |
|    clip_fraction         | 0.0258      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 0.0834      |
|    cost_values           | 1.62        |
|    entropy               | -0.764      |
|    entropy_loss          | -0.764      |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.7         |
|    n_updates             | 11980       |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.355       |
|    value_loss            | 8.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7754416  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 24          |
|    time_elapsed          | 825         |
|    total_timesteps       | 2457600     |
| train/                   |             |
|    approx_kl             | 0.005189561 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.04        |
|    cost_value_loss       | 3.42        |
|    cost_values           | 1.41        |
|    entropy               | -0.768      |
|    entropy_loss          | -0.766      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 11990       |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.356       |
|    value_loss            | 35.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.82321477 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -723        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 25          |
|    time_elapsed          | 860         |
|    total_timesteps       | 2459648     |
| train/                   |             |
|    approx_kl             | 0.003864524 |
|    clip_fraction         | 0.0563      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 0.0431      |
|    cost_values           | 1.33        |
|    entropy               | -0.769      |
|    entropy_loss          | -0.769      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.42        |
|    n_updates             | 12000       |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.356       |
|    value_loss            | 8.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8473783   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 26           |
|    time_elapsed          | 894          |
|    total_timesteps       | 2461696      |
| train/                   |              |
|    approx_kl             | 0.0051468643 |
|    clip_fraction         | 0.0496       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.2          |
|    cost_values           | 1.24         |
|    entropy               | -0.768       |
|    entropy_loss          | -0.769       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 12010        |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.356        |
|    value_loss            | 8.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6370288  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 27          |
|    time_elapsed          | 929         |
|    total_timesteps       | 2463744     |
| train/                   |             |
|    approx_kl             | 0.003226678 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 0.663       |
|    cost_values           | 1.38        |
|    entropy               | -0.765      |
|    entropy_loss          | -0.767      |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.4        |
|    n_updates             | 12020       |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.355       |
|    value_loss            | 36.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55895877  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 28           |
|    time_elapsed          | 963          |
|    total_timesteps       | 2465792      |
| train/                   |              |
|    approx_kl             | 0.0019963307 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 0.366        |
|    cost_values           | 1.17         |
|    entropy               | -0.743       |
|    entropy_loss          | -0.754       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.29         |
|    n_updates             | 12030        |
|    policy_gradient_loss  | -0.000284    |
|    std                   | 0.352        |
|    value_loss            | 2.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7655141  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 29          |
|    time_elapsed          | 998         |
|    total_timesteps       | 2467840     |
| train/                   |             |
|    approx_kl             | 0.004973002 |
|    clip_fraction         | 0.0558      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 1.21        |
|    entropy               | -0.739      |
|    entropy_loss          | -0.74       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.53        |
|    n_updates             | 12040       |
|    policy_gradient_loss  | 0.00235     |
|    std                   | 0.351       |
|    value_loss            | 7.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8470868   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 30           |
|    time_elapsed          | 1033         |
|    total_timesteps       | 2469888      |
| train/                   |              |
|    approx_kl             | 0.0027574282 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 2.66         |
|    cost_values           | 1.38         |
|    entropy               | -0.731       |
|    entropy_loss          | -0.736       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 12050        |
|    policy_gradient_loss  | -0.000398    |
|    std                   | 0.35         |
|    value_loss            | 4.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.593388   |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 31          |
|    time_elapsed          | 1068        |
|    total_timesteps       | 2471936     |
| train/                   |             |
|    approx_kl             | 0.004890286 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 7.29        |
|    cost_values           | 1.72        |
|    entropy               | -0.725      |
|    entropy_loss          | -0.728      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 12060       |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.348       |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.63678885 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 32          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 2473984     |
| train/                   |             |
|    approx_kl             | 0.005603647 |
|    clip_fraction         | 0.0751      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 2.08        |
|    cost_values           | 2.04        |
|    entropy               | -0.723      |
|    entropy_loss          | -0.724      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.7        |
|    n_updates             | 12070       |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 0.348       |
|    value_loss            | 43.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5656492   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 33           |
|    time_elapsed          | 1137         |
|    total_timesteps       | 2476032      |
| train/                   |              |
|    approx_kl             | 0.0032164424 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 0.188        |
|    cost_values           | 1.84         |
|    entropy               | -0.722       |
|    entropy_loss          | -0.722       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.7          |
|    n_updates             | 12080        |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.348        |
|    value_loss            | 6.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.94146544  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 34           |
|    time_elapsed          | 1171         |
|    total_timesteps       | 2478080      |
| train/                   |              |
|    approx_kl             | 0.0036282646 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 0.715        |
|    cost_values           | 1.53         |
|    entropy               | -0.726       |
|    entropy_loss          | -0.723       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.68         |
|    n_updates             | 12090        |
|    policy_gradient_loss  | -0.00042     |
|    std                   | 0.349        |
|    value_loss            | 5.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7695405   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 35           |
|    time_elapsed          | 1206         |
|    total_timesteps       | 2480128      |
| train/                   |              |
|    approx_kl             | 0.0016830233 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 1.33         |
|    cost_values           | 1.33         |
|    entropy               | -0.726       |
|    entropy_loss          | -0.727       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 12100        |
|    policy_gradient_loss  | -0.000131    |
|    std                   | 0.348        |
|    value_loss            | 9.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.24997628  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 36           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 2482176      |
| train/                   |              |
|    approx_kl             | 0.0055347183 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 7.97         |
|    cost_values           | 1.49         |
|    entropy               | -0.726       |
|    entropy_loss          | -0.726       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.71         |
|    n_updates             | 12110        |
|    policy_gradient_loss  | -0.000974    |
|    std                   | 0.349        |
|    value_loss            | 5.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5611217   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 37           |
|    time_elapsed          | 1275         |
|    total_timesteps       | 2484224      |
| train/                   |              |
|    approx_kl             | 0.0015739033 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 4.91         |
|    cost_values           | 1.96         |
|    entropy               | -0.726       |
|    entropy_loss          | -0.726       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 12120        |
|    policy_gradient_loss  | -0.000426    |
|    std                   | 0.349        |
|    value_loss            | 15.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59015566  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 38           |
|    time_elapsed          | 1310         |
|    total_timesteps       | 2486272      |
| train/                   |              |
|    approx_kl             | 0.0046590706 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 1.19         |
|    cost_values           | 2.09         |
|    entropy               | -0.723       |
|    entropy_loss          | -0.725       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 12130        |
|    policy_gradient_loss  | -0.000936    |
|    std                   | 0.348        |
|    value_loss            | 5.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4609581   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 39           |
|    time_elapsed          | 1345         |
|    total_timesteps       | 2488320      |
| train/                   |              |
|    approx_kl             | 0.0042291554 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.56         |
|    cost_value_loss       | 4.64         |
|    cost_values           | 1.92         |
|    entropy               | -0.722       |
|    entropy_loss          | -0.722       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.17         |
|    n_updates             | 12140        |
|    policy_gradient_loss  | -0.000343    |
|    std                   | 0.348        |
|    value_loss            | 11.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.3182217    |
| rollout/                 |               |
|    ep_len_mean           | 975           |
|    ep_rew_mean           | -708          |
| time/                    |               |
|    fps                   | 59            |
|    iterations            | 40            |
|    time_elapsed          | 1379          |
|    total_timesteps       | 2490368       |
| train/                   |               |
|    approx_kl             | 0.00013613726 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.78          |
|    cost_value_loss       | 4.43          |
|    cost_values           | 2.06          |
|    entropy               | -0.721        |
|    entropy_loss          | -0.721        |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 37.1          |
|    n_updates             | 12150         |
|    policy_gradient_loss  | 0.000264      |
|    std                   | 0.348         |
|    value_loss            | 60.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78507566  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 41           |
|    time_elapsed          | 1414         |
|    total_timesteps       | 2492416      |
| train/                   |              |
|    approx_kl             | 0.0050241286 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 0.182        |
|    cost_values           | 2.26         |
|    entropy               | -0.721       |
|    entropy_loss          | -0.721       |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 12160        |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.348        |
|    value_loss            | 29.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0126841  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 42          |
|    time_elapsed          | 1449        |
|    total_timesteps       | 2494464     |
| train/                   |             |
|    approx_kl             | 0.004097488 |
|    clip_fraction         | 0.0216      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.16        |
|    cost_value_loss       | 1.43        |
|    cost_values           | 1.99        |
|    entropy               | -0.722      |
|    entropy_loss          | -0.721      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.25        |
|    n_updates             | 12170       |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.348       |
|    value_loss            | 12.1        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.4        |
| reward                   | -0.7534879 |
| rollout/                 |            |
|    ep_len_mean           | 975        |
|    ep_rew_mean           | -715       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 43         |
|    time_elapsed          | 1484       |
|    total_timesteps       | 2496512    |
| train/                   |            |
|    approx_kl             | 0.00356947 |
|    clip_fraction         | 0.016      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.89       |
|    cost_value_loss       | 5.5        |
|    cost_values           | 2.02       |
|    entropy               | -0.721     |
|    entropy_loss          | -0.722     |
|    explained_variance    | 0          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.37       |
|    n_updates             | 12180      |
|    policy_gradient_loss  | -0.0012    |
|    std                   | 0.348      |
|    value_loss            | 13.6       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.6888493 |
| rollout/                 |            |
|    ep_len_mean           | 975        |
|    ep_rew_mean           | -717       |
| time/                    |            |
|    fps                   | 59         |
|    iterations            | 44         |
|    time_elapsed          | 1518       |
|    total_timesteps       | 2498560    |
| train/                   |            |
|    approx_kl             | 0.0129253  |
|    clip_fraction         | 0.0532     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.02       |
|    cost_value_loss       | 0.5        |
|    cost_values           | 2.08       |
|    entropy               | -0.701     |
|    entropy_loss          | -0.712     |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.27       |
|    n_updates             | 12190      |
|    policy_gradient_loss  | -0.00221   |
|    std                   | 0.344      |
|    value_loss            | 3.83       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.43523663  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 45           |
|    time_elapsed          | 1553         |
|    total_timesteps       | 2500608      |
| train/                   |              |
|    approx_kl             | 0.0031208824 |
|    clip_fraction         | 0.0346       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 0.14         |
|    cost_values           | 1.78         |
|    entropy               | -0.694       |
|    entropy_loss          | -0.696       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 12200        |
|    policy_gradient_loss  | -0.000702    |
|    std                   | 0.343        |
|    value_loss            | 9.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8002512  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 46          |
|    time_elapsed          | 1588        |
|    total_timesteps       | 2502656     |
| train/                   |             |
|    approx_kl             | 0.002144833 |
|    clip_fraction         | 0.0358      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 1           |
|    cost_values           | 1.52        |
|    entropy               | -0.704      |
|    entropy_loss          | -0.697      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.38        |
|    n_updates             | 12210       |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 0.345       |
|    value_loss            | 9.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78048223  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 47           |
|    time_elapsed          | 1623         |
|    total_timesteps       | 2504704      |
| train/                   |              |
|    approx_kl             | 0.0039591505 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.64         |
|    cost_values           | 1.48         |
|    entropy               | -0.7         |
|    entropy_loss          | -0.704       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3            |
|    n_updates             | 12220        |
|    policy_gradient_loss  | 2.27e-06     |
|    std                   | 0.344        |
|    value_loss            | 5.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7632593   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 48           |
|    time_elapsed          | 1657         |
|    total_timesteps       | 2506752      |
| train/                   |              |
|    approx_kl             | 0.0032180788 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.64         |
|    entropy               | -0.697       |
|    entropy_loss          | -0.698       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.69         |
|    n_updates             | 12230        |
|    policy_gradient_loss  | -0.000341    |
|    std                   | 0.344        |
|    value_loss            | 2.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7409465   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 49           |
|    time_elapsed          | 1692         |
|    total_timesteps       | 2508800      |
| train/                   |              |
|    approx_kl             | 0.0041272403 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 0.104        |
|    cost_values           | 1.82         |
|    entropy               | -0.695       |
|    entropy_loss          | -0.696       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.3          |
|    n_updates             | 12240        |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.343        |
|    value_loss            | 3.14         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/knrahchi
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.54766995 |
| rollout/           |             |
|    ep_len_mean     | 975         |
|    ep_rew_mean     | -720        |
| time/              |             |
|    fps             | 83          |
|    iterations      | 1           |
|    time_elapsed    | 24          |
|    total_timesteps | 2510848     |
------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53681463  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 2            |
|    time_elapsed          | 59           |
|    total_timesteps       | 2512896      |
| train/                   |              |
|    approx_kl             | 0.0046102703 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 1.46         |
|    cost_values           | 1.28         |
|    entropy               | -0.669       |
|    entropy_loss          | -0.671       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.65         |
|    n_updates             | 12260        |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.339        |
|    value_loss            | 8.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.78913385  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 3            |
|    time_elapsed          | 93           |
|    total_timesteps       | 2514944      |
| train/                   |              |
|    approx_kl             | 0.0065099834 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 8.63         |
|    cost_values           | 1.27         |
|    entropy               | -0.668       |
|    entropy_loss          | -0.668       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.83         |
|    n_updates             | 12270        |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.339        |
|    value_loss            | 8.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.82649994  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 128          |
|    total_timesteps       | 2516992      |
| train/                   |              |
|    approx_kl             | 0.0047597275 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 0.263        |
|    cost_values           | 1.32         |
|    entropy               | -0.665       |
|    entropy_loss          | -0.667       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3            |
|    n_updates             | 12280        |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.338        |
|    value_loss            | 6.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.62984073  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 5            |
|    time_elapsed          | 163          |
|    total_timesteps       | 2519040      |
| train/                   |              |
|    approx_kl             | 0.0002770995 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 1.1          |
|    cost_values           | 1.08         |
|    entropy               | -0.664       |
|    entropy_loss          | -0.664       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.36         |
|    n_updates             | 12290        |
|    policy_gradient_loss  | 0.000485     |
|    std                   | 0.338        |
|    value_loss            | 6.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.66145146  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 6            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2521088      |
| train/                   |              |
|    approx_kl             | 0.0053987275 |
|    clip_fraction         | 0.0447       |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 5.01         |
|    cost_values           | 1.09         |
|    entropy               | -0.662       |
|    entropy_loss          | -0.664       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.17         |
|    n_updates             | 12300        |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.338        |
|    value_loss            | 8.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6347734   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 7            |
|    time_elapsed          | 233          |
|    total_timesteps       | 2523136      |
| train/                   |              |
|    approx_kl             | 0.0049152323 |
|    clip_fraction         | 0.0416       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 4.91         |
|    cost_values           | 1.29         |
|    entropy               | -0.66        |
|    entropy_loss          | -0.661       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 12310        |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.338        |
|    value_loss            | 16.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27964285 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 267         |
|    total_timesteps       | 2525184     |
| train/                   |             |
|    approx_kl             | 0.003319631 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 1.73        |
|    cost_values           | 1.41        |
|    entropy               | -0.66       |
|    entropy_loss          | -0.66       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 12320       |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.338       |
|    value_loss            | 33.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.22920378  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 302          |
|    total_timesteps       | 2527232      |
| train/                   |              |
|    approx_kl             | 0.0074587762 |
|    clip_fraction         | 0.0757       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 5.58         |
|    cost_values           | 1.56         |
|    entropy               | -0.658       |
|    entropy_loss          | -0.659       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.98         |
|    n_updates             | 12330        |
|    policy_gradient_loss  | -0.00682     |
|    std                   | 0.337        |
|    value_loss            | 9.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47523052  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 10           |
|    time_elapsed          | 338          |
|    total_timesteps       | 2529280      |
| train/                   |              |
|    approx_kl             | 0.0017021107 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 3.58         |
|    cost_values           | 1.83         |
|    entropy               | -0.665       |
|    entropy_loss          | -0.661       |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 12340        |
|    policy_gradient_loss  | -0.000769    |
|    std                   | 0.339        |
|    value_loss            | 21.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9837788   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 373          |
|    total_timesteps       | 2531328      |
| train/                   |              |
|    approx_kl             | 0.0032538339 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.31         |
|    cost_value_loss       | 6.43         |
|    cost_values           | 2.21         |
|    entropy               | -0.671       |
|    entropy_loss          | -0.669       |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 12350        |
|    policy_gradient_loss  | -0.000947    |
|    std                   | 0.34         |
|    value_loss            | 18.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8648414   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 407          |
|    total_timesteps       | 2533376      |
| train/                   |              |
|    approx_kl             | 0.0051372545 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 3.8          |
|    cost_values           | 2.51         |
|    entropy               | -0.678       |
|    entropy_loss          | -0.674       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.88         |
|    n_updates             | 12360        |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.341        |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7209772   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 13           |
|    time_elapsed          | 442          |
|    total_timesteps       | 2535424      |
| train/                   |              |
|    approx_kl             | 0.0075169047 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 0.482        |
|    cost_values           | 2.51         |
|    entropy               | -0.667       |
|    entropy_loss          | -0.676       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 12370        |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.339        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.90930486  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 14           |
|    time_elapsed          | 476          |
|    total_timesteps       | 2537472      |
| train/                   |              |
|    approx_kl             | 0.0012621994 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 0.12         |
|    cost_values           | 2.09         |
|    entropy               | -0.66        |
|    entropy_loss          | -0.662       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.79         |
|    n_updates             | 12380        |
|    policy_gradient_loss  | 1.17e-05     |
|    std                   | 0.338        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33923143  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 15           |
|    time_elapsed          | 511          |
|    total_timesteps       | 2539520      |
| train/                   |              |
|    approx_kl             | 0.0039524855 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 0.0563       |
|    cost_values           | 1.7          |
|    entropy               | -0.657       |
|    entropy_loss          | -0.659       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.21         |
|    n_updates             | 12390        |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.337        |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.61161643  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 545          |
|    total_timesteps       | 2541568      |
| train/                   |              |
|    approx_kl             | 0.0035903996 |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 4.87         |
|    cost_values           | 1.57         |
|    entropy               | -0.656       |
|    entropy_loss          | -0.656       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.77         |
|    n_updates             | 12400        |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.337        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.71650577  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 580          |
|    total_timesteps       | 2543616      |
| train/                   |              |
|    approx_kl             | 0.0040763626 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 1.66         |
|    cost_values           | 1.77         |
|    entropy               | -0.655       |
|    entropy_loss          | -0.655       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 12410        |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.337        |
|    value_loss            | 5.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.8198868  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 615         |
|    total_timesteps       | 2545664     |
| train/                   |             |
|    approx_kl             | 0.002582018 |
|    clip_fraction         | 0.0282      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.24        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 1.9         |
|    entropy               | -0.657      |
|    entropy_loss          | -0.656      |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.29        |
|    n_updates             | 12420       |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.337       |
|    value_loss            | 5.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2951707   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 19           |
|    time_elapsed          | 649          |
|    total_timesteps       | 2547712      |
| train/                   |              |
|    approx_kl             | 0.0042552124 |
|    clip_fraction         | 0.0645       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.8          |
|    cost_value_loss       | 4.83         |
|    cost_values           | 2.11         |
|    entropy               | -0.659       |
|    entropy_loss          | -0.659       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.4         |
|    n_updates             | 12430        |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.338        |
|    value_loss            | 33.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.756219    |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 20           |
|    time_elapsed          | 684          |
|    total_timesteps       | 2549760      |
| train/                   |              |
|    approx_kl             | 0.0042979643 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 5.35         |
|    cost_values           | 2.3          |
|    entropy               | -0.658       |
|    entropy_loss          | -0.659       |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 12440        |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.337        |
|    value_loss            | 51.2         |
-------------------------------------------
slurmstepd: error: *** JOB 141852 ON airl.ist.berkeley.edu CANCELLED AT 2024-02-22T15:22:34 ***
slurmstepd: error: *** STEP 141852.0 ON airl.ist.berkeley.edu CANCELLED AT 2024-02-22T15:22:34 ***
