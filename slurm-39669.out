wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230812_001508-01ac91b4-fb75-4384-ad30-f8394ffe3f14
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol_step_per_epoch20000_target_kl0.01-ce64
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO/runs/01ac91b4-fb75-4384-ad30-f8394ffe3f14
[32;1mLogging data to logs/PPO/parking-v0-cost-10/ppol_step_per_epoch20000_target_kl0.01-ce64/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "batch_size":	256,
    "buffer_size":	100000,
    "cost_limit":	10,
    "deterministic_eval":	true,
    "device":	"cpu",
    "dual_clip":	null,
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoal.txt",
    "episode_per_collect":	20,
    "epoch":	400,
    "eps_clip":	0.2,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "lagrangian_pid":	[
        0.05,
        0.0005,
        0.1
    ],
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.0005,
    "max_batchsize":	100000,
    "max_grad_norm":	0.5,
    "name":	"ppol_step_per_epoch20000_target_kl0.01-ce64",
    "norm_adv":	true,
    "prefix":	"ppol",
    "project":	"PPO",
    "recompute_adv":	false,
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "rescaling":	true,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "use_lagrangian":	true,
    "value_clip":	false,
    "verbose":	true,
    "vf_coef":	0.25,
    "worker":	"ShmemVectorEnv"
}
Epoch #1:   0%|          | 0/20000 [00:00<?, ?it/s]Epoch #1:  50%|#####     | 10000/20000 [00:21<00:21, 473.54it/s]Epoch #1:  50%|#####     | 10000/20000 [00:29<00:21, 473.54it/s, cost=0, length=500, rew=-585]Epoch #1:  50%|#####     | 10000/20000 [00:40<00:21, 473.54it/s, cost=0, length=500, rew=-585]Epoch #1: 100%|##########| 20000/20000 [00:50<00:00, 384.54it/s, cost=0, length=500, rew=-585]Epoch #1: 100%|##########| 20000/20000 [01:01<00:00, 384.54it/s, cost=0, length=500, rew=-544]Epoch #1: 100%|##########| 20000/20000 [01:01<00:00, 322.96it/s, cost=0, length=500, rew=-544]
[32;1mEarly stop at step 2 due to reaching max kl.[0m
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/PPO/train_ppo.py", line 305, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/PPO/train_ppo.py", line 280, in train
    for epoch, epoch_stat, info in trainer:
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 226, in __next__
    if self.perf_is_better(test=True):
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 256, in perf_is_better
    if cost <= self.cost_limit or rew > self.best_perf_rew:
TypeError: '<=' not supported between instances of 'list' and 'int'
Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/PPO/train_ppo.py", line 305, in <module>
    train()
  File "/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/pyrallis/argparsing.py", line 158, in wrapper_inner
    response = fn(cfg, *args, **kwargs)
  File "/nas/ucb/mason/ethically-compliant-rl/PPO/train_ppo.py", line 280, in train
    for epoch, epoch_stat, info in trainer:
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 226, in __next__
    if self.perf_is_better(test=True):
  File "/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/trainer/base_trainer.py", line 256, in perf_is_better
    if cost <= self.cost_limit or rew > self.best_perf_rew:
TypeError: '<=' not supported between instances of 'list' and 'int'
wandb: Waiting for W&B process to finish... (failed 1). Press Control-C to abort syncing.
wandb: - 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: \ 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: | 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: / 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:        loss/actor_rew ‚ñà‚ñÅ
wandb:     loss/actor_safety ‚ñÅ‚ñÅ
wandb:      loss/actor_total ‚ñà‚ñÅ
wandb:          loss/entropy ‚ñÅ‚ñà
wandb:               loss/kl ‚ñà‚ñÅ
wandb:       loss/lagrangian ‚ñÅ‚ñÅ
wandb:        loss/rescaling ‚ñÅ‚ñÅ
wandb:            loss/total ‚ñà‚ñÅ
wandb:              loss/vf0 ‚ñà‚ñÅ
wandb:              loss/vf1 ‚ñà‚ñÅ
wandb:         loss/vf_total ‚ñà‚ñÅ
wandb:            train/cost ‚ñÅ‚ñÅ
wandb:   train/cost_distance ‚ñÅ‚ñÅ
wandb:      train/cost_speed ‚ñÅ‚ñÅ
wandb:          train/length ‚ñÅ‚ñÅ
wandb:          train/reward ‚ñÅ‚ñà
wandb:       update/cum_cost ‚ñÅ‚ñÅ
wandb:        update/episode ‚ñÅ‚ñà
wandb: update/gradient_steps ‚ñÅ‚ñà
wandb: 
wandb: Run summary:
wandb:        loss/actor_rew -0.00019
wandb:     loss/actor_safety 0.0
wandb:      loss/actor_total -0.00019
wandb:          loss/entropy 2.86895
wandb:               loss/kl 0.0087
wandb:       loss/lagrangian 0.0
wandb:        loss/rescaling 1.0
wandb:            loss/total 28.48303
wandb:              loss/vf0 113.9293
wandb:              loss/vf1 0.00357
wandb:         loss/vf_total 113.93287
wandb:            train/cost 0.0
wandb:   train/cost_distance 0.0
wandb:      train/cost_speed 0.0
wandb:          train/length 500.0
wandb:          train/reward -564.47723
wandb:       update/cum_cost 0.0
wandb:        update/episode 30.0
wandb: update/gradient_steps 195.0
wandb: 
wandb: üöÄ View run ppol_step_per_epoch20000_target_kl0.01-ce64 at: https://wandb.ai/ecrl/PPO/runs/01ac91b4-fb75-4384-ad30-f8394ffe3f14
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230812_001508-01ac91b4-fb75-4384-ad30-f8394ffe3f14/logs
srun: error: gail.ist.berkeley.edu: task 0: Exited with exit code 1
