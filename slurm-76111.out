wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_230649-i8y2zioj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-beta(1.0)-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO-Penalty
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO-Penalty/runs/i8y2zioj
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_160649-9qfs6nn8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-beta(0.3)-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO-Penalty
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO-Penalty/runs/9qfs6nn8
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_160649-f1fhmvbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-beta(10.0)-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO-Penalty
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO-Penalty/runs/f1fhmvbe
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_160649-o7ab1779
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-beta(3.0)-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO-Penalty
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO-Penalty/runs/o7ab1779
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2048         |
-------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.443        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0793       |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 159           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -2.13         |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.541        |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 158           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.311        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0434       |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 156           |
|    iterations           | 2             |
|    time_elapsed         | 26            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.818        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.182        |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.791        |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.248        |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 158           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -5.25         |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.95         |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 3             |
|    time_elapsed         | 39            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.444        |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.116        |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 152           |
|    iterations           | 3             |
|    time_elapsed         | 40            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -1.78         |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.626        |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.634       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.216       |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -5.26        |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.89        |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.275       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0853      |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 151          |
|    iterations           | 4            |
|    time_elapsed         | 54           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -1.66        |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.588       |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.331       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.161       |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.5         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.35        |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.162       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0678      |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 151          |
|    iterations           | 5            |
|    time_elapsed         | 67           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.814       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.426       |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 12288        |
-------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.27        |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.399       |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 12288        |
-------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -11.6        |
|    n_updates            | 60           |
|    policy_gradient_loss | -3.52        |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.36        |
|    n_updates            | 70           |
|    policy_gradient_loss | -1.29        |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.463       |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.157       |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.56        |
|    n_updates            | 60           |
|    policy_gradient_loss | -1.09        |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.29        |
|    n_updates            | 80           |
|    policy_gradient_loss | -2.56        |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -34.1        |
|    n_updates            | 70           |
|    policy_gradient_loss | -11.7        |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.978       |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.474       |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -10.2        |
|    n_updates            | 70           |
|    policy_gradient_loss | -3.61        |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.44        |
|    n_updates            | 90           |
|    policy_gradient_loss | -2.17        |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -30.6        |
|    n_updates            | 80           |
|    policy_gradient_loss | -24.1        |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.17        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.887       |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.35        |
|    n_updates            | 80           |
|    policy_gradient_loss | -7.34        |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 22528        |
-------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -31.6        |
|    n_updates            | 90           |
|    policy_gradient_loss | -19.6        |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.25        |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.813       |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.69        |
|    n_updates            | 90           |
|    policy_gradient_loss | -6.05        |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.08        |
|    n_updates            | 110          |
|    policy_gradient_loss | -2.98        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 22528        |
-------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 22528        |
-------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 160          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 22528        |
-------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.75        |
|    n_updates            | 120          |
|    policy_gradient_loss | -4.27        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -47.6        |
|    n_updates            | 110          |
|    policy_gradient_loss | -28.3        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.77        |
|    n_updates            | 110          |
|    policy_gradient_loss | -1.01        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.5        |
|    n_updates            | 110          |
|    policy_gradient_loss | -8.61        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.06        |
|    n_updates            | 130          |
|    policy_gradient_loss | -3.68        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -93.8        |
|    n_updates            | 120          |
|    policy_gradient_loss | -40.5        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.22        |
|    n_updates            | 120          |
|    policy_gradient_loss | -1.45        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.48        |
|    n_updates            | 140          |
|    policy_gradient_loss | -3.11        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -28.4        |
|    n_updates            | 120          |
|    policy_gradient_loss | -12.3        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -86.8        |
|    n_updates            | 130          |
|    policy_gradient_loss | -34.9        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 32768        |
-------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.02        |
|    n_updates            | 130          |
|    policy_gradient_loss | -1.26        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -26.3        |
|    n_updates            | 130          |
|    policy_gradient_loss | -10.6        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -4.38       |
|    n_updates            | 160         |
|    policy_gradient_loss | -2.24       |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -33          |
|    n_updates            | 140          |
|    policy_gradient_loss | -29.1        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 152          |
|    iterations           | 5            |
|    time_elapsed         | 67           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.18        |
|    n_updates            | 140          |
|    policy_gradient_loss | -1.08        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -10          |
|    n_updates            | 140          |
|    policy_gradient_loss | -8.89        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -3.93       |
|    n_updates            | 170         |
|    policy_gradient_loss | -1.65       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 32768        |
-------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 32768        |
-------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 32768        |
-------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.77        |
|    n_updates            | 180          |
|    policy_gradient_loss | -3.14        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -41.6       |
|    n_updates            | 160         |
|    policy_gradient_loss | -21.5       |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 2           |
|    time_elapsed         | 26          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -1.49       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.738      |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -12.7       |
|    n_updates            | 160         |
|    policy_gradient_loss | -6.52       |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.88        |
|    n_updates            | 190          |
|    policy_gradient_loss | -1.58        |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 3           |
|    time_elapsed         | 38          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -37         |
|    n_updates            | 170         |
|    policy_gradient_loss | -14.9       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 153         |
|    iterations           | 3           |
|    time_elapsed         | 40          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -1.36       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.62       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 3           |
|    time_elapsed         | 39          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -11.3       |
|    n_updates            | 170         |
|    policy_gradient_loss | -4.59       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 43008        |
-------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -34.9        |
|    n_updates            | 180          |
|    policy_gradient_loss | -29.2        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.35        |
|    n_updates            | 180          |
|    policy_gradient_loss | -1.11        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.05        |
|    n_updates            | 210          |
|    policy_gradient_loss | -6.43        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -10.7        |
|    n_updates            | 180          |
|    policy_gradient_loss | -8.92        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -56          |
|    n_updates            | 190          |
|    policy_gradient_loss | -14.5        |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 180           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -8.28         |
|    n_updates            | 220           |
|    policy_gradient_loss | -6.04         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.98        |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.578       |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -17          |
|    n_updates            | 190          |
|    policy_gradient_loss | -4.45        |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 43008        |
-------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.6        |
|    n_updates            | 230          |
|    policy_gradient_loss | -5.33        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 43008        |
-------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 43008        |
-------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 5           |
|    time_elapsed         | 57          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -8.33       |
|    n_updates            | 240         |
|    policy_gradient_loss | -4.59       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -76.5        |
|    n_updates            | 210          |
|    policy_gradient_loss | -61.6        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.73        |
|    n_updates            | 210          |
|    policy_gradient_loss | -2.14        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -23.3        |
|    n_updates            | 210          |
|    policy_gradient_loss | -18.7        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 53248        |
-------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 156           |
|    iterations           | 3             |
|    time_elapsed         | 39            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -77.3         |
|    n_updates            | 220           |
|    policy_gradient_loss | -57.3         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.92         |
|    n_updates            | 220           |
|    policy_gradient_loss | -2.05         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 156           |
|    iterations           | 3             |
|    time_elapsed         | 39            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -23.6         |
|    n_updates            | 220           |
|    policy_gradient_loss | -17.4         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.6        |
|    n_updates            | 260          |
|    policy_gradient_loss | -8.88        |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -112         |
|    n_updates            | 230          |
|    policy_gradient_loss | -50.6        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.81        |
|    n_updates            | 230          |
|    policy_gradient_loss | -1.81        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -33.9        |
|    n_updates            | 230          |
|    policy_gradient_loss | -15.4        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.62        |
|    n_updates            | 270          |
|    policy_gradient_loss | -8.49        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 5           |
|    time_elapsed         | 65          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -78.3       |
|    n_updates            | 240         |
|    policy_gradient_loss | -43.7       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 5           |
|    time_elapsed         | 65          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -2.89       |
|    n_updates            | 240         |
|    policy_gradient_loss | -1.55       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 5           |
|    time_elapsed         | 65          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -23.9       |
|    n_updates            | 240         |
|    policy_gradient_loss | -13.3       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.73        |
|    n_updates            | 280          |
|    policy_gradient_loss | -7.6         |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 53248        |
-------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 53248        |
-------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -10.4        |
|    n_updates            | 290          |
|    policy_gradient_loss | -5.85        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 53248        |
-------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -134         |
|    n_updates            | 260          |
|    policy_gradient_loss | -86          |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 63488        |
-------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.23        |
|    n_updates            | 260          |
|    policy_gradient_loss | -2.88        |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -40.4        |
|    n_updates            | 260          |
|    policy_gradient_loss | -26          |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -93.1        |
|    n_updates            | 270          |
|    policy_gradient_loss | -81.9        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -18.6       |
|    n_updates            | 310         |
|    policy_gradient_loss | -10.7       |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.12        |
|    n_updates            | 270          |
|    policy_gradient_loss | -2.78        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -28.2        |
|    n_updates            | 270          |
|    policy_gradient_loss | -24.8        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.2        |
|    n_updates            | 320          |
|    policy_gradient_loss | -8.95        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -83          |
|    n_updates            | 280          |
|    policy_gradient_loss | -67.5        |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.95        |
|    n_updates            | 280          |
|    policy_gradient_loss | -2.94        |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -25.2        |
|    n_updates            | 280          |
|    policy_gradient_loss | -20.9        |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.5        |
|    n_updates            | 330          |
|    policy_gradient_loss | -9.12        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -102         |
|    n_updates            | 290          |
|    policy_gradient_loss | -56.9        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.26        |
|    n_updates            | 290          |
|    policy_gradient_loss | -1.88        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.7        |
|    n_updates            | 290          |
|    policy_gradient_loss | -17.2        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -21.6        |
|    n_updates            | 340          |
|    policy_gradient_loss | -12.8        |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 63488        |
-------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 63488        |
-------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 63488        |
-------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 187         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 73728       |
------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -182        |
|    n_updates            | 310         |
|    policy_gradient_loss | -103        |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -5.9        |
|    n_updates            | 310         |
|    policy_gradient_loss | -3.45       |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -54.9       |
|    n_updates            | 310         |
|    policy_gradient_loss | -31.3       |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -5.41       |
|    n_updates            | 360         |
|    policy_gradient_loss | -5.3        |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -129         |
|    n_updates            | 320          |
|    policy_gradient_loss | -87.4        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.25        |
|    n_updates            | 320          |
|    policy_gradient_loss | -2.84        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -29.5        |
|    n_updates            | 370          |
|    policy_gradient_loss | -12.3        |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -38.9        |
|    n_updates            | 320          |
|    policy_gradient_loss | -26.4        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -141         |
|    n_updates            | 330          |
|    policy_gradient_loss | -88.7        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -13          |
|    n_updates            | 380          |
|    policy_gradient_loss | -12.7        |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.66        |
|    n_updates            | 330          |
|    policy_gradient_loss | -2.93        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -42.6        |
|    n_updates            | 330          |
|    policy_gradient_loss | -26.8        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -210         |
|    n_updates            | 340          |
|    policy_gradient_loss | -124         |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.3        |
|    n_updates            | 390          |
|    policy_gradient_loss | -9.75        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.92        |
|    n_updates            | 340          |
|    policy_gradient_loss | -4.11        |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -63.4        |
|    n_updates            | 340          |
|    policy_gradient_loss | -37.5        |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 83968        |
-------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 164         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 73728       |
------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 163         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 73728       |
------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 165         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 73728       |
------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 2           |
|    time_elapsed         | 23          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -27.2       |
|    n_updates            | 410         |
|    policy_gradient_loss | -16.9       |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -52.3       |
|    n_updates            | 360         |
|    policy_gradient_loss | -50.8       |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -1.77       |
|    n_updates            | 360         |
|    policy_gradient_loss | -1.76       |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 2           |
|    time_elapsed         | 26          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -15.8       |
|    n_updates            | 360         |
|    policy_gradient_loss | -15.4       |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -22.3        |
|    n_updates            | 420          |
|    policy_gradient_loss | -18.2        |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -291         |
|    n_updates            | 370          |
|    policy_gradient_loss | -120         |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.16        |
|    n_updates            | 370          |
|    policy_gradient_loss | -3.95        |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -87.6        |
|    n_updates            | 370          |
|    policy_gradient_loss | -36.3        |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 174           |
|    iterations           | 4             |
|    time_elapsed         | 47            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -29.3         |
|    n_updates            | 430           |
|    policy_gradient_loss | -17.3         |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -128         |
|    n_updates            | 380          |
|    policy_gradient_loss | -124         |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.98        |
|    n_updates            | 380          |
|    policy_gradient_loss | -4.06        |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -38.6        |
|    n_updates            | 380          |
|    policy_gradient_loss | -37.5        |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -18.3        |
|    n_updates            | 440          |
|    policy_gradient_loss | -18.2        |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -129         |
|    n_updates            | 390          |
|    policy_gradient_loss | -94.3        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.25        |
|    n_updates            | 390          |
|    policy_gradient_loss | -3.17        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 94208        |
-------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -39          |
|    n_updates            | 390          |
|    policy_gradient_loss | -28.5        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 83968        |
-------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 83968        |
-------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -16.2       |
|    n_updates            | 460         |
|    policy_gradient_loss | -14.3       |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 83968        |
-------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -268        |
|    n_updates            | 410         |
|    policy_gradient_loss | -166        |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.2        |
|    n_updates            | 470          |
|    policy_gradient_loss | -15.5        |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -8.44       |
|    n_updates            | 410         |
|    policy_gradient_loss | -5.23       |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -80.8       |
|    n_updates            | 410         |
|    policy_gradient_loss | -50.1       |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -220         |
|    n_updates            | 420          |
|    policy_gradient_loss | -178         |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -18.6        |
|    n_updates            | 480          |
|    policy_gradient_loss | -16.8        |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.92        |
|    n_updates            | 420          |
|    policy_gradient_loss | -5.75        |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -66.3        |
|    n_updates            | 420          |
|    policy_gradient_loss | -53.7        |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -16.7        |
|    n_updates            | 490          |
|    policy_gradient_loss | -14.4        |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 4             |
|    time_elapsed         | 52            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -288          |
|    n_updates            | 430           |
|    policy_gradient_loss | -169          |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 156           |
|    iterations           | 4             |
|    time_elapsed         | 52            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -9.14         |
|    n_updates            | 430           |
|    policy_gradient_loss | -5.48         |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 155           |
|    iterations           | 4             |
|    time_elapsed         | 52            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -86.8         |
|    n_updates            | 430           |
|    policy_gradient_loss | -51.1         |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 104448       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -180         |
|    n_updates            | 440          |
|    policy_gradient_loss | -180         |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.71        |
|    n_updates            | 440          |
|    policy_gradient_loss | -5.58        |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -54.2        |
|    n_updates            | 440          |
|    policy_gradient_loss | -54.1        |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.1        |
|    n_updates            | 510          |
|    policy_gradient_loss | -12.9        |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 94208        |
-------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 94208        |
-------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 94208        |
-------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -37          |
|    n_updates            | 520          |
|    policy_gradient_loss | -22.3        |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -159        |
|    n_updates            | 460         |
|    policy_gradient_loss | -139        |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 2           |
|    time_elapsed         | 26          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -5.04       |
|    n_updates            | 460         |
|    policy_gradient_loss | -4.53       |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -23.7        |
|    n_updates            | 530          |
|    policy_gradient_loss | -15.1        |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -47.9       |
|    n_updates            | 460         |
|    policy_gradient_loss | -42         |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -298         |
|    n_updates            | 470          |
|    policy_gradient_loss | -152         |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.4         |
|    n_updates            | 470          |
|    policy_gradient_loss | -4.94        |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -31.4         |
|    n_updates            | 540           |
|    policy_gradient_loss | -22.4         |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -89.6        |
|    n_updates            | 470          |
|    policy_gradient_loss | -45.8        |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -182         |
|    n_updates            | 480          |
|    policy_gradient_loss | -165         |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 114688       |
-------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.9         |
|    n_updates            | 480          |
|    policy_gradient_loss | -5.3         |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -54.9        |
|    n_updates            | 480          |
|    policy_gradient_loss | -49.7        |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -164         |
|    n_updates            | 490          |
|    policy_gradient_loss | -140         |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -20.6        |
|    n_updates            | 560          |
|    policy_gradient_loss | -22.4        |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.22        |
|    n_updates            | 490          |
|    policy_gradient_loss | -4.62        |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -49.5        |
|    n_updates            | 490          |
|    policy_gradient_loss | -42.2        |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.5        |
|    n_updates            | 570          |
|    policy_gradient_loss | -20.9        |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 104448       |
-------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 160          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 104448       |
-------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 104448       |
-------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.2        |
|    n_updates            | 580          |
|    policy_gradient_loss | -18.8        |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -148         |
|    n_updates            | 510          |
|    policy_gradient_loss | -126         |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.72        |
|    n_updates            | 510          |
|    policy_gradient_loss | -4.14        |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -44.7        |
|    n_updates            | 510          |
|    policy_gradient_loss | -38          |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -19          |
|    n_updates            | 590          |
|    policy_gradient_loss | -13.5        |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -366         |
|    n_updates            | 520          |
|    policy_gradient_loss | -219         |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.4        |
|    n_updates            | 520          |
|    policy_gradient_loss | -6.97        |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -110         |
|    n_updates            | 520          |
|    policy_gradient_loss | -66          |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 124928       |
-------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -235         |
|    n_updates            | 530          |
|    policy_gradient_loss | -147         |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.26        |
|    n_updates            | 530          |
|    policy_gradient_loss | -4.84        |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -27.4        |
|    n_updates            | 610          |
|    policy_gradient_loss | -21.8        |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -70.6        |
|    n_updates            | 530          |
|    policy_gradient_loss | -44.5        |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 155           |
|    iterations           | 5             |
|    time_elapsed         | 65            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -310          |
|    n_updates            | 540           |
|    policy_gradient_loss | -220          |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 3          |
|    time_elapsed         | 34         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -29        |
|    n_updates            | 620        |
|    policy_gradient_loss | -23.8      |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 152           |
|    iterations           | 5             |
|    time_elapsed         | 67            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -9.72         |
|    n_updates            | 540           |
|    policy_gradient_loss | -6.98         |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 154           |
|    iterations           | 5             |
|    time_elapsed         | 66            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -93.3         |
|    n_updates            | 540           |
|    policy_gradient_loss | -66.3         |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 114688       |
-------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -42.2        |
|    n_updates            | 630          |
|    policy_gradient_loss | -37.8        |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 114688       |
-------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 114688       |
-------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -201         |
|    n_updates            | 560          |
|    policy_gradient_loss | -220         |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 178           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -28.1         |
|    n_updates            | 640           |
|    policy_gradient_loss | -28.9         |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.6         |
|    n_updates            | 560          |
|    policy_gradient_loss | -7           |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -60.6        |
|    n_updates            | 560          |
|    policy_gradient_loss | -66.3        |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -302         |
|    n_updates            | 570          |
|    policy_gradient_loss | -205         |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.35        |
|    n_updates            | 570          |
|    policy_gradient_loss | -6.57        |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -90.8        |
|    n_updates            | 570          |
|    policy_gradient_loss | -61.9        |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -21          |
|    n_updates            | 660          |
|    policy_gradient_loss | -28.9        |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -300         |
|    n_updates            | 580          |
|    policy_gradient_loss | -184         |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.28        |
|    n_updates            | 580          |
|    policy_gradient_loss | -5.95        |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -90.1        |
|    n_updates            | 580          |
|    policy_gradient_loss | -55.5        |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -55.5        |
|    n_updates            | 670          |
|    policy_gradient_loss | -36.1        |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -185         |
|    n_updates            | 590          |
|    policy_gradient_loss | -132         |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.08        |
|    n_updates            | 590          |
|    policy_gradient_loss | -4.27        |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -53.4        |
|    n_updates            | 680          |
|    policy_gradient_loss | -39          |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -55.8        |
|    n_updates            | 590          |
|    policy_gradient_loss | -39.9        |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 124928       |
-------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 124928       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -16          |
|    n_updates            | 690          |
|    policy_gradient_loss | -14.4        |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 158          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 124928       |
-------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -269         |
|    n_updates            | 610          |
|    policy_gradient_loss | -214         |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 145408       |
-------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -8.58        |
|    n_updates            | 610          |
|    policy_gradient_loss | -6.79        |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -81.2        |
|    n_updates            | 610          |
|    policy_gradient_loss | -64.5        |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 3          |
|    time_elapsed         | 38         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -287       |
|    n_updates            | 620        |
|    policy_gradient_loss | -236       |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -41.3        |
|    n_updates            | 710          |
|    policy_gradient_loss | -39.1        |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 156        |
|    iterations           | 3          |
|    time_elapsed         | 39         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -8.98      |
|    n_updates            | 620        |
|    policy_gradient_loss | -7.37      |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 3          |
|    time_elapsed         | 39         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -86.3      |
|    n_updates            | 620        |
|    policy_gradient_loss | -70.9      |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -417         |
|    n_updates            | 630          |
|    policy_gradient_loss | -375         |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -14.9        |
|    n_updates            | 720          |
|    policy_gradient_loss | -26.6        |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -13          |
|    n_updates            | 630          |
|    policy_gradient_loss | -11.6        |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -126         |
|    n_updates            | 630          |
|    policy_gradient_loss | -113         |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 156           |
|    iterations           | 5             |
|    time_elapsed         | 65            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -277          |
|    n_updates            | 640           |
|    policy_gradient_loss | -286          |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -40.9        |
|    n_updates            | 730          |
|    policy_gradient_loss | -39.9        |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 154           |
|    iterations           | 5             |
|    time_elapsed         | 66            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -8.78         |
|    n_updates            | 640           |
|    policy_gradient_loss | -8.86         |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 153           |
|    iterations           | 5             |
|    time_elapsed         | 66            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -83.3         |
|    n_updates            | 640           |
|    policy_gradient_loss | -86.1         |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 175           |
|    iterations           | 5             |
|    time_elapsed         | 58            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -33.1         |
|    n_updates            | 740           |
|    policy_gradient_loss | -26.6         |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 135168       |
-------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 135168       |
-------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 155648       |
-------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -207         |
|    n_updates            | 660          |
|    policy_gradient_loss | -287         |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -6.48        |
|    n_updates            | 660          |
|    policy_gradient_loss | -8.84        |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -46.9        |
|    n_updates            | 760          |
|    policy_gradient_loss | -34.4        |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -62.4        |
|    n_updates            | 660          |
|    policy_gradient_loss | -86.4        |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -548         |
|    n_updates            | 670          |
|    policy_gradient_loss | -358         |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -17.2        |
|    n_updates            | 670          |
|    policy_gradient_loss | -11          |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -26.7        |
|    n_updates            | 770          |
|    policy_gradient_loss | -29.6        |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -165         |
|    n_updates            | 670          |
|    policy_gradient_loss | -108         |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -532         |
|    n_updates            | 680          |
|    policy_gradient_loss | -386         |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 178        |
|    iterations           | 4          |
|    time_elapsed         | 45         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -28.3      |
|    n_updates            | 780        |
|    policy_gradient_loss | -20.9      |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -16.2        |
|    n_updates            | 680          |
|    policy_gradient_loss | -11.9        |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -160         |
|    n_updates            | 680          |
|    policy_gradient_loss | -116         |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -157         |
|    n_updates            | 690          |
|    policy_gradient_loss | -142         |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -28.5        |
|    n_updates            | 790          |
|    policy_gradient_loss | -24          |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.02        |
|    n_updates            | 690          |
|    policy_gradient_loss | -4.53        |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -47.4        |
|    n_updates            | 690          |
|    policy_gradient_loss | -42.7        |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 160          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 145408       |
-------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 165888       |
-------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 145408       |
-------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 145408       |
-------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -412         |
|    n_updates            | 710          |
|    policy_gradient_loss | -387         |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -27.5        |
|    n_updates            | 810          |
|    policy_gradient_loss | -31.6        |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -12.5        |
|    n_updates            | 710          |
|    policy_gradient_loss | -12          |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -124         |
|    n_updates            | 710          |
|    policy_gradient_loss | -116         |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -35.6        |
|    n_updates            | 820          |
|    policy_gradient_loss | -48.2        |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -148         |
|    n_updates            | 720          |
|    policy_gradient_loss | -261         |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.48        |
|    n_updates            | 720          |
|    policy_gradient_loss | -8.3         |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -47.2       |
|    n_updates            | 830         |
|    policy_gradient_loss | -32         |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -44.5        |
|    n_updates            | 720          |
|    policy_gradient_loss | -78.7        |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -407         |
|    n_updates            | 730          |
|    policy_gradient_loss | -396         |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -12.4        |
|    n_updates            | 730          |
|    policy_gradient_loss | -12.2        |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -74.7        |
|    n_updates            | 840          |
|    policy_gradient_loss | -40          |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -122         |
|    n_updates            | 730          |
|    policy_gradient_loss | -119         |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 155           |
|    iterations           | 5             |
|    time_elapsed         | 65            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -329          |
|    n_updates            | 740           |
|    policy_gradient_loss | -265          |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 155           |
|    iterations           | 5             |
|    time_elapsed         | 65            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -10.1         |
|    n_updates            | 740           |
|    policy_gradient_loss | -8.08         |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 176128       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 154           |
|    iterations           | 5             |
|    time_elapsed         | 66            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -98.8         |
|    n_updates            | 740           |
|    policy_gradient_loss | -79.5         |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 155648       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -34.4        |
|    n_updates            | 860          |
|    policy_gradient_loss | -28.4        |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 155648       |
-------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 155648       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -467         |
|    n_updates            | 760          |
|    policy_gradient_loss | -342         |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -71.9        |
|    n_updates            | 870          |
|    policy_gradient_loss | -59.2        |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -14.3        |
|    n_updates            | 760          |
|    policy_gradient_loss | -10.5        |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -140         |
|    n_updates            | 760          |
|    policy_gradient_loss | -103         |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -264         |
|    n_updates            | 770          |
|    policy_gradient_loss | -294         |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -50          |
|    n_updates            | 880          |
|    policy_gradient_loss | -40.7        |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.17        |
|    n_updates            | 770          |
|    policy_gradient_loss | -9.07        |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -79.5        |
|    n_updates            | 770          |
|    policy_gradient_loss | -88.3        |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 155        |
|    iterations           | 4          |
|    time_elapsed         | 52         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -282       |
|    n_updates            | 780        |
|    policy_gradient_loss | -206       |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -48.4        |
|    n_updates            | 890          |
|    policy_gradient_loss | -57.2        |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 157        |
|    iterations           | 4          |
|    time_elapsed         | 52         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -8.62      |
|    n_updates            | 780        |
|    policy_gradient_loss | -6.47      |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 154        |
|    iterations           | 4          |
|    time_elapsed         | 53         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -84.7      |
|    n_updates            | 780        |
|    policy_gradient_loss | -62        |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 179          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 186368       |
-------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -282         |
|    n_updates            | 790          |
|    policy_gradient_loss | -237         |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.76        |
|    n_updates            | 790          |
|    policy_gradient_loss | -7.39        |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 2           |
|    time_elapsed         | 23          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -114        |
|    n_updates            | 910         |
|    policy_gradient_loss | -75.9       |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -84.9        |
|    n_updates            | 790          |
|    policy_gradient_loss | -71.3        |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 165888       |
-------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 165888       |
-------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -47          |
|    n_updates            | 920          |
|    policy_gradient_loss | -42.8        |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 165888       |
-------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -274         |
|    n_updates            | 810          |
|    policy_gradient_loss | -314         |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -8.33        |
|    n_updates            | 810          |
|    policy_gradient_loss | -9.62        |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 4           |
|    time_elapsed         | 47          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -56.3       |
|    n_updates            | 930         |
|    policy_gradient_loss | -60.9       |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -82.2        |
|    n_updates            | 810          |
|    policy_gradient_loss | -94.3        |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -338         |
|    n_updates            | 820          |
|    policy_gradient_loss | -480         |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -12.1        |
|    n_updates            | 820          |
|    policy_gradient_loss | -14.7        |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -82.6        |
|    n_updates            | 940          |
|    policy_gradient_loss | -62.8        |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -103         |
|    n_updates            | 820          |
|    policy_gradient_loss | -144         |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -469        |
|    n_updates            | 830         |
|    policy_gradient_loss | -317        |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 186           |
|    iterations      | 1             |
|    time_elapsed    | 10            |
|    total_timesteps | 196608        |
--------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -14.3       |
|    n_updates            | 830         |
|    policy_gradient_loss | -9.8        |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -746         |
|    n_updates            | 840          |
|    policy_gradient_loss | -397         |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 153         |
|    iterations           | 4           |
|    time_elapsed         | 53          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -141        |
|    n_updates            | 830         |
|    policy_gradient_loss | -95.3       |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -63.6        |
|    n_updates            | 960          |
|    policy_gradient_loss | -45.5        |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -22.5        |
|    n_updates            | 840          |
|    policy_gradient_loss | -12.2        |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -224         |
|    n_updates            | 840          |
|    policy_gradient_loss | -119         |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -80.4        |
|    n_updates            | 970          |
|    policy_gradient_loss | -69.8        |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -341         |
|    n_updates            | 860          |
|    policy_gradient_loss | -281         |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -61          |
|    n_updates            | 980          |
|    policy_gradient_loss | -90.8        |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -10.5        |
|    n_updates            | 860          |
|    policy_gradient_loss | -8.8         |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -43.5        |
|    n_updates            | 990          |
|    policy_gradient_loss | -37.5        |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -716         |
|    n_updates            | 870          |
|    policy_gradient_loss | -589         |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -103         |
|    n_updates            | 860          |
|    policy_gradient_loss | -84.5        |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -21.8        |
|    n_updates            | 870          |
|    policy_gradient_loss | -18          |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -498         |
|    n_updates            | 880          |
|    policy_gradient_loss | -404         |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -215         |
|    n_updates            | 870          |
|    policy_gradient_loss | -177         |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -15.1        |
|    n_updates            | 880          |
|    policy_gradient_loss | -12.4        |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -248         |
|    n_updates            | 1010         |
|    policy_gradient_loss | -166         |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -484         |
|    n_updates            | 890          |
|    policy_gradient_loss | -569         |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -150         |
|    n_updates            | 880          |
|    policy_gradient_loss | -121         |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.5        |
|    n_updates            | 890          |
|    policy_gradient_loss | -17.4        |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -81.9        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -90.7        |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 186368       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -145         |
|    n_updates            | 890          |
|    policy_gradient_loss | -171         |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -86.4        |
|    n_updates            | 1030         |
|    policy_gradient_loss | -46.7        |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 186368       |
-------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 2           |
|    time_elapsed         | 26          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -1.13e+03   |
|    n_updates            | 910         |
|    policy_gradient_loss | -754        |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 158          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 186368       |
-------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -114         |
|    n_updates            | 1040         |
|    policy_gradient_loss | -59          |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -34.4       |
|    n_updates            | 910         |
|    policy_gradient_loss | -23.2       |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 152          |
|    iterations           | 3            |
|    time_elapsed         | 40           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -458         |
|    n_updates            | 920          |
|    policy_gradient_loss | -425         |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 2           |
|    time_elapsed         | 26          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -340        |
|    n_updates            | 910         |
|    policy_gradient_loss | -227        |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 188         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 217088      |
------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -15          |
|    n_updates            | 920          |
|    policy_gradient_loss | -13.1        |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -28.8         |
|    n_updates            | 1060          |
|    policy_gradient_loss | -48.5         |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -138         |
|    n_updates            | 920          |
|    policy_gradient_loss | -128         |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 151         |
|    iterations           | 4           |
|    time_elapsed         | 54          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -555        |
|    n_updates            | 930         |
|    policy_gradient_loss | -606        |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -17.5       |
|    n_updates            | 930         |
|    policy_gradient_loss | -18.5       |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -125         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -122         |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 4           |
|    time_elapsed         | 53          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -167        |
|    n_updates            | 930         |
|    policy_gradient_loss | -182        |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 150          |
|    iterations           | 5            |
|    time_elapsed         | 67           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -824         |
|    n_updates            | 940          |
|    policy_gradient_loss | -625         |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -24.9        |
|    n_updates            | 940          |
|    policy_gradient_loss | -19.1        |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -81.4        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -65.2        |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -247         |
|    n_updates            | 940          |
|    policy_gradient_loss | -188         |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 160           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 196608        |
--------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 165           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 196608        |
--------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -81.3        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -140         |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 165           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 196608        |
--------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -636         |
|    n_updates            | 960          |
|    policy_gradient_loss | -452         |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -19.1        |
|    n_updates            | 960          |
|    policy_gradient_loss | -13.8        |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 186         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 227328      |
------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -191         |
|    n_updates            | 960          |
|    policy_gradient_loss | -136         |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -804         |
|    n_updates            | 970          |
|    policy_gradient_loss | -696         |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -289         |
|    n_updates            | 1110         |
|    policy_gradient_loss | -219         |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -24.2        |
|    n_updates            | 970          |
|    policy_gradient_loss | -21.1        |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -241         |
|    n_updates            | 970          |
|    policy_gradient_loss | -209         |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -608         |
|    n_updates            | 980          |
|    policy_gradient_loss | -905         |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -173         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -86.1        |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -18.4        |
|    n_updates            | 980          |
|    policy_gradient_loss | -27.4        |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -182         |
|    n_updates            | 980          |
|    policy_gradient_loss | -272         |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -284         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -131         |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -431         |
|    n_updates            | 990          |
|    policy_gradient_loss | -373         |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.4        |
|    n_updates            | 990          |
|    policy_gradient_loss | -11.4        |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -174         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -95.7        |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -130         |
|    n_updates            | 990          |
|    policy_gradient_loss | -112         |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 206848       |
-------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 206848       |
-------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 237568       |
-------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.48e+03    |
|    n_updates            | 1010         |
|    policy_gradient_loss | -1.66e+03    |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -74.6        |
|    n_updates            | 1010         |
|    policy_gradient_loss | -50          |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -637         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -316         |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -745         |
|    n_updates            | 1010         |
|    policy_gradient_loss | -499         |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -815         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -905         |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -24.9        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -27.3        |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.09e+03    |
|    n_updates            | 1170         |
|    policy_gradient_loss | -816         |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -245         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -272         |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -863         |
|    n_updates            | 1030         |
|    policy_gradient_loss | -464         |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -26          |
|    n_updates            | 1030         |
|    policy_gradient_loss | -14.2        |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.15e+03    |
|    n_updates            | 1180         |
|    policy_gradient_loss | -281         |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -259         |
|    n_updates            | 1030         |
|    policy_gradient_loss | -139         |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.14e+03    |
|    n_updates            | 1040         |
|    policy_gradient_loss | -588         |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -353         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -183         |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -34.4        |
|    n_updates            | 1040         |
|    policy_gradient_loss | -17.9        |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -342         |
|    n_updates            | 1040         |
|    policy_gradient_loss | -177         |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 164         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 217088      |
------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 247808       |
-------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 162         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 217088      |
------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 164         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 217088      |
------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -137         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -138         |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 158           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -284          |
|    n_updates            | 1060          |
|    policy_gradient_loss | -482          |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 158           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -8.9          |
|    n_updates            | 1060          |
|    policy_gradient_loss | -14.8         |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -114         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -119         |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 159           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -85.5         |
|    n_updates            | 1060          |
|    policy_gradient_loss | -145          |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.24e+03    |
|    n_updates            | 1070         |
|    policy_gradient_loss | -1.21e+03    |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -37.7        |
|    n_updates            | 1070         |
|    policy_gradient_loss | -36.8        |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -185         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -201         |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -373         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -364         |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -813         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -650         |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -24.5        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -19.7        |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -134         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -194         |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -244         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -195         |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -810         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -1.4e+03     |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -24.6        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -42.2        |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 182          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 258048       |
-------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -243         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -420         |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 162         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 227328      |
------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 165         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 227328      |
------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 175           |
|    iterations           | 2             |
|    time_elapsed         | 23            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -423          |
|    n_updates            | 1260          |
|    policy_gradient_loss | -373          |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 164         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 227328      |
------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -2.88e+03    |
|    n_updates            | 1110         |
|    policy_gradient_loss | -2.18e+03    |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -86.7        |
|    n_updates            | 1110         |
|    policy_gradient_loss | -65.7        |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 175           |
|    iterations           | 3             |
|    time_elapsed         | 35            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.48e+03     |
|    n_updates            | 1270          |
|    policy_gradient_loss | -1.14e+03     |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -866         |
|    n_updates            | 1110         |
|    policy_gradient_loss | -655         |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.73e+03    |
|    n_updates            | 1120         |
|    policy_gradient_loss | -859         |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -306        |
|    n_updates            | 1280        |
|    policy_gradient_loss | -264        |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -52          |
|    n_updates            | 1120         |
|    policy_gradient_loss | -26          |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -518         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -258         |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -716         |
|    n_updates            | 1290         |
|    policy_gradient_loss | -457         |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.84e+03    |
|    n_updates            | 1130         |
|    policy_gradient_loss | -1.31e+03    |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -85.4        |
|    n_updates            | 1130         |
|    policy_gradient_loss | -39.5        |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -852         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -392         |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 268288       |
-------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.74e+03    |
|    n_updates            | 1140         |
|    policy_gradient_loss | -953         |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -52.5        |
|    n_updates            | 1140         |
|    policy_gradient_loss | -29          |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -381        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -315        |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -522         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -286         |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 237568       |
-------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 237568       |
-------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -213        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -189        |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 237568       |
-------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.37e+03    |
|    n_updates            | 1160         |
|    policy_gradient_loss | -3.16e+03    |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -191         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -94.8        |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 4           |
|    time_elapsed         | 45          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -343        |
|    n_updates            | 1330        |
|    policy_gradient_loss | -192        |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.91e+03    |
|    n_updates            | 1160         |
|    policy_gradient_loss | -947         |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.09e+04    |
|    n_updates            | 1170         |
|    policy_gradient_loss | -8.16e+03    |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -326         |
|    n_updates            | 1170         |
|    policy_gradient_loss | -245         |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -366         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -339         |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.26e+03    |
|    n_updates            | 1170         |
|    policy_gradient_loss | -2.45e+03    |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.15e+04    |
|    n_updates            | 1180         |
|    policy_gradient_loss | -2.81e+03    |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
-------------------------------------
| reward             | [-3.7786243] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 278528       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -344         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -84.5        |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.44e+03    |
|    n_updates            | 1180         |
|    policy_gradient_loss | -843         |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.52e+03    |
|    n_updates            | 1190         |
|    policy_gradient_loss | -1.83e+03    |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
------------------------------------------
| reward                  | [-2.9646173] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 336.47464    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.807        |
|    explained_variance   | 0.00696      |
|    learning_rate        | 0.0003       |
|    loss                 | -289         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -270         |
|    std                  | 0.344        |
|    value_loss           | 1.34e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -106         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -55.1        |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.06e+03    |
|    n_updates            | 1190         |
|    policy_gradient_loss | -549         |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.86316013] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 2037.7466     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.835         |
|    explained_variance   | -0.05         |
|    learning_rate        | 0.0003        |
|    loss                 | -2.11e+03     |
|    n_updates            | 1370          |
|    policy_gradient_loss | -1.19e+03     |
|    std                  | 0.349         |
|    value_loss           | 951           |
-------------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 247808       |
-------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 247808       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2530826] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 634.55835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.833        |
|    explained_variance   | 0.00955      |
|    learning_rate        | 0.0003       |
|    loss                 | -738         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -361         |
|    std                  | 0.349        |
|    value_loss           | 1.2e+03      |
------------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 160          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 247808       |
-------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.37e+03    |
|    n_updates            | 1210         |
|    policy_gradient_loss | -1.38e+03    |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -41.1        |
|    n_updates            | 1210         |
|    policy_gradient_loss | -41.6        |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4930831] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 1373.3953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.854        |
|    explained_variance   | -0.105       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.43e+03    |
|    n_updates            | 1390         |
|    policy_gradient_loss | -764         |
|    std                  | 0.347        |
|    value_loss           | 829          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -411         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -414         |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.14e+03    |
|    n_updates            | 1220         |
|    policy_gradient_loss | -1.19e+03    |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -34.4        |
|    n_updates            | 1220         |
|    policy_gradient_loss | -35.9        |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
-------------------------------------
| reward             | [-1.7847402] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 288768       |
-------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -342         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -356         |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.84e+03    |
|    n_updates            | 1230         |
|    policy_gradient_loss | -2e+03       |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -55.5        |
|    n_updates            | 1230         |
|    policy_gradient_loss | -60.4        |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7328235] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 496.2358     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.871        |
|    explained_variance   | -0.00716     |
|    learning_rate        | 0.0003       |
|    loss                 | -528         |
|    n_updates            | 1410         |
|    policy_gradient_loss | -430         |
|    std                  | 0.341        |
|    value_loss           | 1.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -553         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -601         |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.33e+03    |
|    n_updates            | 1240         |
|    policy_gradient_loss | -1.94e+03    |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -40.3        |
|    n_updates            | 1240         |
|    policy_gradient_loss | -58.4        |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3012989] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 831.89606    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.901        |
|    explained_variance   | -0.0602      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.21e+03    |
|    n_updates            | 1420         |
|    policy_gradient_loss | -517         |
|    std                  | 0.34         |
|    value_loss           | 896          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -400         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -583         |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 258048       |
-------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 258048       |
-------------------------------------
-----------------------------------------
| reward                  | [-1.860755] |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 799.6845    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.919       |
|    explained_variance   | -0.0102     |
|    learning_rate        | 0.0003      |
|    loss                 | -648        |
|    n_updates            | 1430        |
|    policy_gradient_loss | -453        |
|    std                  | 0.335       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 258048       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 158           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -4.23e+03     |
|    n_updates            | 1260          |
|    policy_gradient_loss | -3.73e+03     |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.6532316] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 1502.9814    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.943        |
|    explained_variance   | -0.0066      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.06e+03    |
|    n_updates            | 1440         |
|    policy_gradient_loss | -889         |
|    std                  | 0.334        |
|    value_loss           | 964          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 159           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -127          |
|    n_updates            | 1260          |
|    policy_gradient_loss | -112          |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 159           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -1.27e+03     |
|    n_updates            | 1260          |
|    policy_gradient_loss | -1.12e+03     |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 3             |
|    time_elapsed         | 39            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.48e+04     |
|    n_updates            | 1270          |
|    policy_gradient_loss | -1.14e+04     |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
-------------------------------------
| reward             | [-1.9521416] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 299008       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 158           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -744          |
|    n_updates            | 1270          |
|    policy_gradient_loss | -341          |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -7.44e+03     |
|    n_updates            | 1270          |
|    policy_gradient_loss | -3.41e+03     |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.2230222] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 2046.6458    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.968        |
|    explained_variance   | -0.0436      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.04e+03    |
|    n_updates            | 1460         |
|    policy_gradient_loss | -676         |
|    std                  | 0.331        |
|    value_loss           | 596          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -3.06e+03   |
|    n_updates            | 1280        |
|    policy_gradient_loss | -2.64e+03   |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -91.9       |
|    n_updates            | 1280        |
|    policy_gradient_loss | -79.6       |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.44129673] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 1687.8555     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.98          |
|    explained_variance   | -0.0754       |
|    learning_rate        | 0.0003        |
|    loss                 | -1.81e+03     |
|    n_updates            | 1470          |
|    policy_gradient_loss | -877          |
|    std                  | 0.329         |
|    value_loss           | 864           |
-------------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -917        |
|    n_updates            | 1280        |
|    policy_gradient_loss | -792        |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.16e+03    |
|    n_updates            | 1290         |
|    policy_gradient_loss | -4.57e+03    |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -215         |
|    n_updates            | 1290         |
|    policy_gradient_loss | -137         |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.062077] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 1099.2903   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.997       |
|    explained_variance   | -0.0383     |
|    learning_rate        | 0.0003      |
|    loss                 | -852        |
|    n_updates            | 1480        |
|    policy_gradient_loss | -647        |
|    std                  | 0.327       |
|    value_loss           | 938         |
-----------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.15e+03    |
|    n_updates            | 1290         |
|    policy_gradient_loss | -1.37e+03    |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 268288       |
-------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 268288       |
-------------------------------------
------------------------------------------
| reward                  | [-1.5057038] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 1764.5735    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | -0.0299      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.41e+03    |
|    n_updates            | 1490         |
|    policy_gradient_loss | -724         |
|    std                  | 0.326        |
|    value_loss           | 806          |
------------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 268288       |
-------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -3.81e+03   |
|    n_updates            | 1310        |
|    policy_gradient_loss | -3.15e+03   |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -114        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -94.7       |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-1.6954689] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 309248       |
-------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -1.14e+03   |
|    n_updates            | 1310        |
|    policy_gradient_loss | -945        |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 3           |
|    time_elapsed         | 38          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -2.13e+03   |
|    n_updates            | 1320        |
|    policy_gradient_loss | -1.88e+03   |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 3           |
|    time_elapsed         | 39          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -64.1       |
|    n_updates            | 1320        |
|    policy_gradient_loss | -56.9       |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.2569616] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 2666.0024    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | 0.00176      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.77e+03    |
|    n_updates            | 1510         |
|    policy_gradient_loss | -1.31e+03    |
|    std                  | 0.316        |
|    value_loss           | 888          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 3           |
|    time_elapsed         | 38          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -639        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -566        |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 4           |
|    time_elapsed         | 51          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -3.43e+03   |
|    n_updates            | 1330        |
|    policy_gradient_loss | -1.92e+03   |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.9326414] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 2164.9014    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.00968     |
|    learning_rate        | 0.0003       |
|    loss                 | -3.06e+03    |
|    n_updates            | 1520         |
|    policy_gradient_loss | -629         |
|    std                  | 0.318        |
|    value_loss           | 1.21e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 154         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -103        |
|    n_updates            | 1330        |
|    policy_gradient_loss | -57.9       |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 4           |
|    time_elapsed         | 51          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -1.03e+03   |
|    n_updates            | 1330        |
|    policy_gradient_loss | -576        |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.66e+03    |
|    n_updates            | 1340         |
|    policy_gradient_loss | -3.39e+03    |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6199595] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 3188.1294    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.0158      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.38e+03    |
|    n_updates            | 1530         |
|    policy_gradient_loss | -1.76e+03    |
|    std                  | 0.314        |
|    value_loss           | 868          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -110         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -102         |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.1e+03     |
|    n_updates            | 1340         |
|    policy_gradient_loss | -1.02e+03    |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7786243] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 278528       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2143655] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 1703.9617    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | -0.0894      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.84e+03    |
|    n_updates            | 1540         |
|    policy_gradient_loss | -805         |
|    std                  | 0.313        |
|    value_loss           | 763          |
------------------------------------------
-------------------------------------
| reward             | [-3.7786243] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 278528       |
-------------------------------------
-------------------------------------
| reward             | [-3.7786243] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 278528       |
-------------------------------------
------------------------------------------
| reward                  | [-2.9646173] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 336.47464    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.807        |
|    explained_variance   | 0.00696      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.88e+03    |
|    n_updates            | 1360         |
|    policy_gradient_loss | -2.69e+03    |
|    std                  | 0.344        |
|    value_loss           | 1.34e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.5131543] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 319488       |
-------------------------------------
------------------------------------------
| reward                  | [-2.9646173] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 336.47464    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.807        |
|    explained_variance   | 0.00696      |
|    learning_rate        | 0.0003       |
|    loss                 | -87.5        |
|    n_updates            | 1360         |
|    policy_gradient_loss | -81          |
|    std                  | 0.344        |
|    value_loss           | 1.34e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.6689618] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 1401.6238    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.09         |
|    explained_variance   | -0.0797      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.73e+03    |
|    n_updates            | 1560         |
|    policy_gradient_loss | -769         |
|    std                  | 0.309        |
|    value_loss           | 736          |
------------------------------------------
------------------------------------------
| reward                  | [-2.9646173] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 336.47464    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.807        |
|    explained_variance   | 0.00696      |
|    learning_rate        | 0.0003       |
|    loss                 | -865         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -808         |
|    std                  | 0.344        |
|    value_loss           | 1.34e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.86316013] |
| time/                   |               |
|    fps                  | 158           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 2037.7466     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.835         |
|    explained_variance   | -0.05         |
|    learning_rate        | 0.0003        |
|    loss                 | -2.11e+04     |
|    n_updates            | 1370          |
|    policy_gradient_loss | -1.19e+04     |
|    std                  | 0.349         |
|    value_loss           | 951           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.86316013] |
| time/                   |               |
|    fps                  | 153           |
|    iterations           | 3             |
|    time_elapsed         | 40            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 2037.7466     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.835         |
|    explained_variance   | -0.05         |
|    learning_rate        | 0.0003        |
|    loss                 | -634          |
|    n_updates            | 1370          |
|    policy_gradient_loss | -356          |
|    std                  | 0.349         |
|    value_loss           | 951           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.8958263] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 1261.7434    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.12         |
|    explained_variance   | -0.0943      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.41e+03    |
|    n_updates            | 1570         |
|    policy_gradient_loss | -670         |
|    std                  | 0.307        |
|    value_loss           | 895          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.86316013] |
| time/                   |               |
|    fps                  | 154           |
|    iterations           | 3             |
|    time_elapsed         | 39            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 2037.7466     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.835         |
|    explained_variance   | -0.05         |
|    learning_rate        | 0.0003        |
|    loss                 | -6.34e+03     |
|    n_updates            | 1370          |
|    policy_gradient_loss | -3.56e+03     |
|    std                  | 0.349         |
|    value_loss           | 951           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2530826] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 634.55835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.833        |
|    explained_variance   | 0.00955      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.37e+03    |
|    n_updates            | 1380         |
|    policy_gradient_loss | -3.61e+03    |
|    std                  | 0.349        |
|    value_loss           | 1.2e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.2530826] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 4            |
|    time_elapsed         | 53           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 634.55835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.833        |
|    explained_variance   | 0.00955      |
|    learning_rate        | 0.0003       |
|    loss                 | -221         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -108         |
|    std                  | 0.349        |
|    value_loss           | 1.2e+03      |
------------------------------------------
-------------------------------------------
| reward                  | [-0.90219796] |
| time/                   |               |
|    fps                  | 175           |
|    iterations           | 4             |
|    time_elapsed         | 46            |
|    total_timesteps      | 325632        |
| train/                  |               |
|    approx_kl            | 2163.672      |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.13          |
|    explained_variance   | -0.0711       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.2e+03      |
|    n_updates            | 1580          |
|    policy_gradient_loss | -1.08e+03     |
|    std                  | 0.307         |
|    value_loss           | 794           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2530826] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 634.55835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.833        |
|    explained_variance   | 0.00955      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.21e+03    |
|    n_updates            | 1380         |
|    policy_gradient_loss | -1.08e+03    |
|    std                  | 0.349        |
|    value_loss           | 1.2e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.4930831] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 1373.3953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.854        |
|    explained_variance   | -0.105       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.43e+04    |
|    n_updates            | 1390         |
|    policy_gradient_loss | -7.64e+03    |
|    std                  | 0.347        |
|    value_loss           | 829          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4930831] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 1373.3953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.854        |
|    explained_variance   | -0.105       |
|    learning_rate        | 0.0003       |
|    loss                 | -428         |
|    n_updates            | 1390         |
|    policy_gradient_loss | -229         |
|    std                  | 0.347        |
|    value_loss           | 829          |
------------------------------------------
------------------------------------------
| reward                  | [-1.1550593] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 890.99164    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.12         |
|    explained_variance   | -0.0564      |
|    learning_rate        | 0.0003       |
|    loss                 | -881         |
|    n_updates            | 1590         |
|    policy_gradient_loss | -420         |
|    std                  | 0.309        |
|    value_loss           | 694          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4930831] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 1373.3953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.854        |
|    explained_variance   | -0.105       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.28e+03    |
|    n_updates            | 1390         |
|    policy_gradient_loss | -2.29e+03    |
|    std                  | 0.347        |
|    value_loss           | 829          |
------------------------------------------
-------------------------------------
| reward             | [-1.7847402] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 288768       |
-------------------------------------
-------------------------------------
| reward             | [-1.7847402] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 288768       |
-------------------------------------
-------------------------------------
| reward             | [-1.2757176] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 329728       |
-------------------------------------
-------------------------------------
| reward             | [-1.7847402] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 288768       |
-------------------------------------
------------------------------------------
| reward                  | [-1.7328235] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 496.2358     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.871        |
|    explained_variance   | -0.00716     |
|    learning_rate        | 0.0003       |
|    loss                 | -5.28e+03    |
|    n_updates            | 1410         |
|    policy_gradient_loss | -4.3e+03     |
|    std                  | 0.341        |
|    value_loss           | 1.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2780621] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 331776       |
| train/                  |              |
|    approx_kl            | 1132.7843    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.16         |
|    explained_variance   | -0.0658      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.36e+03    |
|    n_updates            | 1610         |
|    policy_gradient_loss | -558         |
|    std                  | 0.304        |
|    value_loss           | 807          |
------------------------------------------
------------------------------------------
| reward                  | [-1.7328235] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 2            |
|    time_elapsed         | 26           |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 496.2358     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.871        |
|    explained_variance   | -0.00716     |
|    learning_rate        | 0.0003       |
|    loss                 | -158         |
|    n_updates            | 1410         |
|    policy_gradient_loss | -129         |
|    std                  | 0.341        |
|    value_loss           | 1.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7328235] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 496.2358     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.871        |
|    explained_variance   | -0.00716     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.58e+03    |
|    n_updates            | 1410         |
|    policy_gradient_loss | -1.29e+03    |
|    std                  | 0.341        |
|    value_loss           | 1.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3012989] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 831.89606    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.901        |
|    explained_variance   | -0.0602      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.21e+04    |
|    n_updates            | 1420         |
|    policy_gradient_loss | -5.17e+03    |
|    std                  | 0.34         |
|    value_loss           | 896          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3508794] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 1526.2327    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | -0.078       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.53e+03    |
|    n_updates            | 1620         |
|    policy_gradient_loss | -1.03e+03    |
|    std                  | 0.303        |
|    value_loss           | 679          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3012989] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 831.89606    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.901        |
|    explained_variance   | -0.0602      |
|    learning_rate        | 0.0003       |
|    loss                 | -363         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -155         |
|    std                  | 0.34         |
|    value_loss           | 896          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3012989] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 831.89606    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.901        |
|    explained_variance   | -0.0602      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.63e+03    |
|    n_updates            | 1420         |
|    policy_gradient_loss | -1.55e+03    |
|    std                  | 0.34         |
|    value_loss           | 896          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.860755] |
| time/                   |             |
|    fps                  | 155         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 799.6845    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.919       |
|    explained_variance   | -0.0102     |
|    learning_rate        | 0.0003      |
|    loss                 | -6.48e+03   |
|    n_updates            | 1430        |
|    policy_gradient_loss | -4.53e+03   |
|    std                  | 0.335       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.5007566] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 993.3564     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.19         |
|    explained_variance   | -0.0657      |
|    learning_rate        | 0.0003       |
|    loss                 | -980         |
|    n_updates            | 1630         |
|    policy_gradient_loss | -728         |
|    std                  | 0.305        |
|    value_loss           | 820          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.860755] |
| time/                   |             |
|    fps                  | 153         |
|    iterations           | 4           |
|    time_elapsed         | 53          |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 799.6845    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.919       |
|    explained_variance   | -0.0102     |
|    learning_rate        | 0.0003      |
|    loss                 | -194        |
|    n_updates            | 1430        |
|    policy_gradient_loss | -136        |
|    std                  | 0.335       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.860755] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 799.6845    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.919       |
|    explained_variance   | -0.0102     |
|    learning_rate        | 0.0003      |
|    loss                 | -1.94e+03   |
|    n_updates            | 1430        |
|    policy_gradient_loss | -1.36e+03   |
|    std                  | 0.335       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.8684181] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 1834.22      |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | -0.0694      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.94e+03    |
|    n_updates            | 1640         |
|    policy_gradient_loss | -1.08e+03    |
|    std                  | 0.306        |
|    value_loss           | 742          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6532316] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 1502.9814    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.943        |
|    explained_variance   | -0.0066      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.06e+04    |
|    n_updates            | 1440         |
|    policy_gradient_loss | -8.89e+03    |
|    std                  | 0.334        |
|    value_loss           | 964          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6532316] |
| time/                   |              |
|    fps                  | 153          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 1502.9814    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.943        |
|    explained_variance   | -0.0066      |
|    learning_rate        | 0.0003       |
|    loss                 | -318         |
|    n_updates            | 1440         |
|    policy_gradient_loss | -267         |
|    std                  | 0.334        |
|    value_loss           | 964          |
------------------------------------------
-------------------------------------
| reward             | [-1.4154465] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 339968       |
-------------------------------------
------------------------------------------
| reward                  | [-1.6532316] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 1502.9814    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.943        |
|    explained_variance   | -0.0066      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.18e+03    |
|    n_updates            | 1440         |
|    policy_gradient_loss | -2.67e+03    |
|    std                  | 0.334        |
|    value_loss           | 964          |
------------------------------------------
-------------------------------------
| reward             | [-1.9521416] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 299008       |
-------------------------------------
-------------------------------------
| reward             | [-1.9521416] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 299008       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0654643] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 342016       |
| train/                  |              |
|    approx_kl            | 817.6089     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.21         |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -816         |
|    n_updates            | 1660         |
|    policy_gradient_loss | -655         |
|    std                  | 0.308        |
|    value_loss           | 756          |
------------------------------------------
-------------------------------------
| reward             | [-1.9521416] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 299008       |
-------------------------------------
------------------------------------------
| reward                  | [-2.2230222] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 2046.6458    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.968        |
|    explained_variance   | -0.0436      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.04e+04    |
|    n_updates            | 1460         |
|    policy_gradient_loss | -6.76e+03    |
|    std                  | 0.331        |
|    value_loss           | 596          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2230222] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 2046.6458    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.968        |
|    explained_variance   | -0.0436      |
|    learning_rate        | 0.0003       |
|    loss                 | -611         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -203         |
|    std                  | 0.331        |
|    value_loss           | 596          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3107834] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 838.7041     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | -0.0723      |
|    learning_rate        | 0.0003       |
|    loss                 | -795         |
|    n_updates            | 1670         |
|    policy_gradient_loss | -721         |
|    std                  | 0.309        |
|    value_loss           | 685          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2230222] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 2046.6458    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.968        |
|    explained_variance   | -0.0436      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.11e+03    |
|    n_updates            | 1460         |
|    policy_gradient_loss | -2.03e+03    |
|    std                  | 0.331        |
|    value_loss           | 596          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.44129673] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 1687.8555     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.98          |
|    explained_variance   | -0.0754       |
|    learning_rate        | 0.0003        |
|    loss                 | -1.81e+04     |
|    n_updates            | 1470          |
|    policy_gradient_loss | -8.77e+03     |
|    std                  | 0.329         |
|    value_loss           | 864           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.29458213] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 4             |
|    time_elapsed         | 46            |
|    total_timesteps      | 346112        |
| train/                  |               |
|    approx_kl            | 2480.199      |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.22          |
|    explained_variance   | -0.0876       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.15e+03     |
|    n_updates            | 1680          |
|    policy_gradient_loss | -1.08e+03     |
|    std                  | 0.309         |
|    value_loss           | 720           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.44129673] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 3             |
|    time_elapsed         | 39            |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 1687.8555     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.98          |
|    explained_variance   | -0.0754       |
|    learning_rate        | 0.0003        |
|    loss                 | -544          |
|    n_updates            | 1470          |
|    policy_gradient_loss | -263          |
|    std                  | 0.329         |
|    value_loss           | 864           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.44129673] |
| time/                   |               |
|    fps                  | 157           |
|    iterations           | 3             |
|    time_elapsed         | 39            |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 1687.8555     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.98          |
|    explained_variance   | -0.0754       |
|    learning_rate        | 0.0003        |
|    loss                 | -5.44e+03     |
|    n_updates            | 1470          |
|    policy_gradient_loss | -2.63e+03     |
|    std                  | 0.329         |
|    value_loss           | 864           |
-------------------------------------------
-----------------------------------------
| reward                  | [-1.062077] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 1099.2903   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.997       |
|    explained_variance   | -0.0383     |
|    learning_rate        | 0.0003      |
|    loss                 | -8.5e+03    |
|    n_updates            | 1480        |
|    policy_gradient_loss | -6.47e+03   |
|    std                  | 0.327       |
|    value_loss           | 938         |
-----------------------------------------
------------------------------------------
| reward                  | [-1.1889738] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 2183.1836    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.23         |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.65e+03    |
|    n_updates            | 1690         |
|    policy_gradient_loss | -1.2e+03     |
|    std                  | 0.31         |
|    value_loss           | 584          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.062077] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 1099.2903   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.997       |
|    explained_variance   | -0.0383     |
|    learning_rate        | 0.0003      |
|    loss                 | -257        |
|    n_updates            | 1480        |
|    policy_gradient_loss | -194        |
|    std                  | 0.327       |
|    value_loss           | 938         |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.062077] |
| time/                   |             |
|    fps                  | 156         |
|    iterations           | 4           |
|    time_elapsed         | 52          |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 1099.2903   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.997       |
|    explained_variance   | -0.0383     |
|    learning_rate        | 0.0003      |
|    loss                 | -2.55e+03   |
|    n_updates            | 1480        |
|    policy_gradient_loss | -1.94e+03   |
|    std                  | 0.327       |
|    value_loss           | 938         |
-----------------------------------------
------------------------------------------
| reward                  | [-1.5057038] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 1764.5735    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | -0.0299      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.41e+04    |
|    n_updates            | 1490         |
|    policy_gradient_loss | -7.23e+03    |
|    std                  | 0.326        |
|    value_loss           | 806          |
------------------------------------------
-------------------------------------
| reward             | [-1.4144108] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 350208       |
-------------------------------------
------------------------------------------
| reward                  | [-1.5057038] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 1764.5735    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | -0.0299      |
|    learning_rate        | 0.0003       |
|    loss                 | -722         |
|    n_updates            | 1490         |
|    policy_gradient_loss | -217         |
|    std                  | 0.326        |
|    value_loss           | 806          |
------------------------------------------
-------------------------------------
| reward             | [-1.6954689] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 309248       |
-------------------------------------
------------------------------------------
| reward                  | [-1.5057038] |
| time/                   |              |
|    fps                  | 154          |
|    iterations           | 5            |
|    time_elapsed         | 66           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 1764.5735    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | -0.0299      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.22e+03    |
|    n_updates            | 1490         |
|    policy_gradient_loss | -2.17e+03    |
|    std                  | 0.326        |
|    value_loss           | 806          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6216848] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 1575.1588    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.5e+03     |
|    n_updates            | 1710         |
|    policy_gradient_loss | -1.05e+03    |
|    std                  | 0.31         |
|    value_loss           | 752          |
------------------------------------------
-------------------------------------
| reward             | [-1.6954689] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 309248       |
-------------------------------------
-------------------------------------
| reward             | [-1.6954689] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 309248       |
-------------------------------------
------------------------------------------
| reward                  | [-1.0997016] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 354304       |
| train/                  |              |
|    approx_kl            | 1413.2979    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.24         |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.45e+03    |
|    n_updates            | 1720         |
|    policy_gradient_loss | -978         |
|    std                  | 0.307        |
|    value_loss           | 660          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2569616] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 2666.0024    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | 0.00176      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.77e+04    |
|    n_updates            | 1510         |
|    policy_gradient_loss | -1.31e+04    |
|    std                  | 0.316        |
|    value_loss           | 888          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2569616] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 2666.0024    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | 0.00176      |
|    learning_rate        | 0.0003       |
|    loss                 | -831         |
|    n_updates            | 1510         |
|    policy_gradient_loss | -394         |
|    std                  | 0.316        |
|    value_loss           | 888          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8927789] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 356352       |
| train/                  |              |
|    approx_kl            | 862.0071     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.25         |
|    explained_variance   | -0.123       |
|    learning_rate        | 0.0003       |
|    loss                 | -905         |
|    n_updates            | 1730         |
|    policy_gradient_loss | -716         |
|    std                  | 0.311        |
|    value_loss           | 815          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2569616] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 2666.0024    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | 0.00176      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.31e+03    |
|    n_updates            | 1510         |
|    policy_gradient_loss | -3.94e+03    |
|    std                  | 0.316        |
|    value_loss           | 888          |
------------------------------------------
------------------------------------------
| reward                  | [-1.9326414] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 2164.9014    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.00968     |
|    learning_rate        | 0.0003       |
|    loss                 | -3.06e+04    |
|    n_updates            | 1520         |
|    policy_gradient_loss | -6.29e+03    |
|    std                  | 0.318        |
|    value_loss           | 1.21e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9326414] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 2164.9014    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.00968     |
|    learning_rate        | 0.0003       |
|    loss                 | -917         |
|    n_updates            | 1520         |
|    policy_gradient_loss | -189         |
|    std                  | 0.318        |
|    value_loss           | 1.21e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9371482] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 2538.542     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.25         |
|    explained_variance   | -0.101       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.71e+03    |
|    n_updates            | 1740         |
|    policy_gradient_loss | -1.44e+03    |
|    std                  | 0.312        |
|    value_loss           | 758          |
------------------------------------------
------------------------------------------
| reward                  | [-1.9326414] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 2164.9014    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.00968     |
|    learning_rate        | 0.0003       |
|    loss                 | -9.17e+03    |
|    n_updates            | 1520         |
|    policy_gradient_loss | -1.89e+03    |
|    std                  | 0.318        |
|    value_loss           | 1.21e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6199595] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 3188.1294    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.0158      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.38e+04    |
|    n_updates            | 1530         |
|    policy_gradient_loss | -1.76e+04    |
|    std                  | 0.314        |
|    value_loss           | 868          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6199595] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 3188.1294    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.0158      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.02e+03    |
|    n_updates            | 1530         |
|    policy_gradient_loss | -527         |
|    std                  | 0.314        |
|    value_loss           | 868          |
------------------------------------------
-------------------------------------
| reward             | [-1.8418007] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 360448       |
-------------------------------------
------------------------------------------
| reward                  | [-1.6199595] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 52           |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 3188.1294    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.0158      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.02e+04    |
|    n_updates            | 1530         |
|    policy_gradient_loss | -5.27e+03    |
|    std                  | 0.314        |
|    value_loss           | 868          |
------------------------------------------
------------------------------------------
| reward                  | [-1.2143655] |
| time/                   |              |
|    fps                  | 155          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 1703.9617    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | -0.0894      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.84e+04    |
|    n_updates            | 1540         |
|    policy_gradient_loss | -8.05e+03    |
|    std                  | 0.313        |
|    value_loss           | 763          |
------------------------------------------
------------------------------------------
| reward                  | [-1.2143655] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 1703.9617    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | -0.0894      |
|    learning_rate        | 0.0003       |
|    loss                 | -552         |
|    n_updates            | 1540         |
|    policy_gradient_loss | -242         |
|    std                  | 0.313        |
|    value_loss           | 763          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4384053] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 362496       |
| train/                  |              |
|    approx_kl            | 4687.436     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.28         |
|    explained_variance   | -0.101       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.27e+03    |
|    n_updates            | 1760         |
|    policy_gradient_loss | -2.95e+03    |
|    std                  | 0.308        |
|    value_loss           | 784          |
------------------------------------------
------------------------------------------
| reward                  | [-1.2143655] |
| time/                   |              |
|    fps                  | 156          |
|    iterations           | 5            |
|    time_elapsed         | 65           |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 1703.9617    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | -0.0894      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.52e+03    |
|    n_updates            | 1540         |
|    policy_gradient_loss | -2.42e+03    |
|    std                  | 0.313        |
|    value_loss           | 763          |
------------------------------------------
-------------------------------------
| reward             | [-1.5131543] |
| time/              |              |
|    fps             | 165          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 319488       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0021868] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 364544       |
| train/                  |              |
|    approx_kl            | 3880.2742    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.29         |
|    explained_variance   | -0.0969      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.45e+03    |
|    n_updates            | 1770         |
|    policy_gradient_loss | -1.54e+03    |
|    std                  | 0.305        |
|    value_loss           | 815          |
------------------------------------------
-------------------------------------
| reward             | [-1.5131543] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 319488       |
-------------------------------------
-------------------------------------
| reward             | [-1.5131543] |
| time/              |              |
|    fps             | 164          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 319488       |
-------------------------------------
------------------------------------------
| reward                  | [-2.6689618] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 1401.6238    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.09         |
|    explained_variance   | -0.0797      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.73e+04    |
|    n_updates            | 1560         |
|    policy_gradient_loss | -7.69e+03    |
|    std                  | 0.309        |
|    value_loss           | 736          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3571217] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 366592       |
| train/                  |              |
|    approx_kl            | 3811.5308    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.31         |
|    explained_variance   | -0.00791     |
|    learning_rate        | 0.0003       |
|    loss                 | -3.6e+03     |
|    n_updates            | 1780         |
|    policy_gradient_loss | -1.45e+03    |
|    std                  | 0.306        |
|    value_loss           | 921          |
------------------------------------------
------------------------------------------
| reward                  | [-2.6689618] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 1401.6238    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.09         |
|    explained_variance   | -0.0797      |
|    learning_rate        | 0.0003       |
|    loss                 | -520         |
|    n_updates            | 1560         |
|    policy_gradient_loss | -231         |
|    std                  | 0.309        |
|    value_loss           | 736          |
------------------------------------------
------------------------------------------
| reward                  | [-2.6689618] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 1401.6238    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.09         |
|    explained_variance   | -0.0797      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.2e+03     |
|    n_updates            | 1560         |
|    policy_gradient_loss | -2.31e+03    |
|    std                  | 0.309        |
|    value_loss           | 736          |
------------------------------------------
------------------------------------------
| reward                  | [-2.8958263] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 3            |
|    time_elapsed         | 39           |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 1261.7434    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.12         |
|    explained_variance   | -0.0943      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.41e+04    |
|    n_updates            | 1570         |
|    policy_gradient_loss | -6.69e+03    |
|    std                  | 0.307        |
|    value_loss           | 895          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.98641926] |
| time/                   |               |
|    fps                  | 176           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 368640        |
| train/                  |               |
|    approx_kl            | 1643.5664     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.33          |
|    explained_variance   | -0.12         |
|    learning_rate        | 0.0003        |
|    loss                 | -1.52e+03     |
|    n_updates            | 1790          |
|    policy_gradient_loss | -1.06e+03     |
|    std                  | 0.303         |
|    value_loss           | 740           |
-------------------------------------------
slurmstepd: error: *** STEP 76111.3 ON gail.ist.berkeley.edu CANCELLED AT 2023-10-17T16:41:48 ***
slurmstepd: error: *** STEP 76111.2 ON dqn.ist.berkeley.edu CANCELLED AT 2023-10-17T16:41:48 ***
slurmstepd: error: *** JOB 76111 ON airl.ist.berkeley.edu CANCELLED AT 2023-10-17T23:41:48 ***
slurmstepd: error: *** STEP 76111.1 ON ddpg.ist.berkeley.edu CANCELLED AT 2023-10-17T16:41:48 ***
slurmstepd: error: *** STEP 76111.0 ON airl.ist.berkeley.edu CANCELLED AT 2023-10-17T23:41:48 ***
