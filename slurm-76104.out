wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_222434-ixngho2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: â­ï¸ View project at https://wandb.ai/ecrl/PPO
wandb: ðŸš€ View run at https://wandb.ai/ecrl/PPO/runs/ixngho2u
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_152434-ynivpqbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: â­ï¸ View project at https://wandb.ai/ecrl/PPO
wandb: ðŸš€ View run at https://wandb.ai/ecrl/PPO/runs/ynivpqbs
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_222435-a6lzf1ly
wandb: Run `wandb offline` to turn off syncing.
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_152434-5ozvklhs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: â­ï¸ View project at https://wandb.ai/ecrl/PPO
wandb: ðŸš€ View run at https://wandb.ai/ecrl/PPO/runs/a6lzf1ly
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: â­ï¸ View project at https://wandb.ai/ecrl/PPO
wandb: ðŸš€ View run at https://wandb.ai/ecrl/PPO/runs/5ozvklhs
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 2048         |
-------------------------------------
Using cuda device
-------------------------------------
| reward             | [-0.5640039] |
| time/              |              |
|    fps             | 170          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 2048         |
-------------------------------------
Using cuda device
-------------------------------------
| reward             | [-0.5640039] |
| time/              |              |
|    fps             | 166          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2048         |
-------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -2.13         |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.541        |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.311        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0434       |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
------------------------------------------
| reward                  | [-0.4830056] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.094922215  |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | 0.0942       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.226       |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.106       |
|    std                  | 1.01         |
|    value_loss           | 160          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48300558] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.09492223    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.85         |
|    explained_variance   | 0.0942        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.049        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0491       |
|    std                  | 1.01          |
|    value_loss           | 160           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -5.25         |
|    n_updates            | 20            |
|    policy_gradient_loss | -1.95         |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.444        |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.116        |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.1538985] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.11541857   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0104       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.445       |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.144       |
|    std                  | 1.01         |
|    value_loss           | 625          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.153896] |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 3           |
|    time_elapsed         | 38          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.11541881  |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.0104      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.186      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0596     |
|    std                  | 1.01        |
|    value_loss           | 625         |
-----------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -5.26        |
|    n_updates            | 30           |
|    policy_gradient_loss | -1.89        |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.275       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0853      |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-2.6212974] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.06942722   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | -0.0122      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.228       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0725      |
|    std                  | 1            |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.6212268] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.06937348   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | -0.0122      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0569      |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0331      |
|    std                  | 1            |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.5         |
|    n_updates            | 40           |
|    policy_gradient_loss | -1.35        |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/save_util.py:283: UserWarning: Path 'PPO_penalty/models/10.0' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.162       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0678      |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/save_util.py:283: UserWarning: Path 'PPO_penalty/models/0.3' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
------------------------------------------
| reward                  | [-3.2562778] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.5236391    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.00946      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.85        |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.574       |
|    std                  | 1.02         |
|    value_loss           | 2.1e+03      |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/save_util.py:283: UserWarning: Path 'PPO_penalty/models/3.0' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
-----------------------------------------
| reward                  | [-3.256111] |
| time/                   |             |
|    fps                  | 158         |
|    iterations           | 5           |
|    time_elapsed         | 64          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.52337277  |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.00946     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.898      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.217      |
|    std                  | 1.02        |
|    value_loss           | 2.1e+03     |
-----------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/save_util.py:283: UserWarning: Path 'PPO_penalty/models/1.0' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-3.9111745] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-3.8846962] |
| time/              |              |
|    fps             | 170          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 12288        |
-------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -11.6        |
|    n_updates            | 60           |
|    policy_gradient_loss | -3.52        |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.463       |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.157       |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.3049574] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.6402833    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0279       |
|    learning_rate        | 0.0003       |
|    loss                 | -7.03        |
|    n_updates            | 60           |
|    policy_gradient_loss | -2.12        |
|    std                  | 1.01         |
|    value_loss           | 3.38e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.483775] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 1.1637082   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.0276      |
|    learning_rate        | 0.0003      |
|    loss                 | -1.51       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.585      |
|    std                  | 1.01        |
|    value_loss           | 3.38e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -34.1        |
|    n_updates            | 70           |
|    policy_gradient_loss | -11.7        |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.978       |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.474       |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.6292953] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.2459025    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.56        |
|    n_updates            | 70           |
|    policy_gradient_loss | -2.48        |
|    std                  | 1.01         |
|    value_loss           | 3.32e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.6850843] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 1.4541783    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0243       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.2         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.536       |
|    std                  | 1.01         |
|    value_loss           | 3.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -30.6        |
|    n_updates            | 80           |
|    policy_gradient_loss | -24.1        |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.17        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.887       |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.8069754] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 2.8601832    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0263       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.8         |
|    n_updates            | 80           |
|    policy_gradient_loss | -4.1         |
|    std                  | 0.992        |
|    value_loss           | 3.77e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -31.6        |
|    n_updates            | 90           |
|    policy_gradient_loss | -19.6        |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.7033916] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 1.7364526    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0285       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.93        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.637       |
|    std                  | 1.01         |
|    value_loss           | 3.83e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.25        |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.813       |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.9336812] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.684393     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.029        |
|    learning_rate        | 0.0003       |
|    loss                 | -17.4        |
|    n_updates            | 90           |
|    policy_gradient_loss | -8.08        |
|    std                  | 0.967        |
|    value_loss           | 3.58e+03     |
------------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 22528        |
-------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 22528        |
-------------------------------------
------------------------------------------
| reward                  | [-3.7710004] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 3.7510333    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | 0.00872      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.63        |
|    n_updates            | 90           |
|    policy_gradient_loss | -1.43        |
|    std                  | 1            |
|    value_loss           | 2.63e+03     |
------------------------------------------
------------------------------------
| reward             | [-0.641781] |
| time/              |             |
|    fps             | 176         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 22528       |
------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -47.6        |
|    n_updates            | 110          |
|    policy_gradient_loss | -28.3        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.77        |
|    n_updates            | 110          |
|    policy_gradient_loss | -1.01        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.7004713] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 22528        |
-------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -93.8        |
|    n_updates            | 120          |
|    policy_gradient_loss | -40.5        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3899173] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 6.169423     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | -0.0265      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.2        |
|    n_updates            | 110          |
|    policy_gradient_loss | -8.3         |
|    std                  | 0.952        |
|    value_loss           | 2.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.22        |
|    n_updates            | 120          |
|    policy_gradient_loss | -1.45        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0880268] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.310428     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00599      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.18        |
|    n_updates            | 110          |
|    policy_gradient_loss | -3.73        |
|    std                  | 0.992        |
|    value_loss           | 2.92e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -86.8        |
|    n_updates            | 130          |
|    policy_gradient_loss | -34.9        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.02        |
|    n_updates            | 130          |
|    policy_gradient_loss | -1.26        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7972231] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 3.2659848    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.74        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -10.1        |
|    n_updates            | 120          |
|    policy_gradient_loss | -4.86        |
|    std                  | 0.948        |
|    value_loss           | 2.99e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7263199] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 6.078926     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.0181       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.49        |
|    n_updates            | 120          |
|    policy_gradient_loss | -3.36        |
|    std                  | 0.984        |
|    value_loss           | 2.7e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -33          |
|    n_updates            | 140          |
|    policy_gradient_loss | -29.1        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.18        |
|    n_updates            | 140          |
|    policy_gradient_loss | -1.08        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0131261] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 4.1690865    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | -0.0257      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.9        |
|    n_updates            | 130          |
|    policy_gradient_loss | -4.51        |
|    std                  | 0.939        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5884455] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 5.916591     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | -0.00506     |
|    learning_rate        | 0.0003       |
|    loss                 | -6.94        |
|    n_updates            | 130          |
|    policy_gradient_loss | -1.92        |
|    std                  | 0.967        |
|    value_loss           | 1.66e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 32768        |
-------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 32768        |
-------------------------------------
------------------------------------------
| reward                  | [-2.3279715] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 5            |
|    time_elapsed         | 61           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 7.6754103    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.71        |
|    explained_variance   | -0.0365      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.9        |
|    n_updates            | 140          |
|    policy_gradient_loss | -15.8        |
|    std                  | 0.938        |
|    value_loss           | 2.29e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.590965] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 5           |
|    time_elapsed         | 63          |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 11.864141   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.75       |
|    explained_variance   | -0.033      |
|    learning_rate        | 0.0003      |
|    loss                 | -12.6       |
|    n_updates            | 140         |
|    policy_gradient_loss | -6.25       |
|    std                  | 0.949       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -41.6       |
|    n_updates            | 160         |
|    policy_gradient_loss | -21.5       |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -1.49       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.738      |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
------------------------------------
| reward             | [-2.471163] |
| time/              |             |
|    fps             | 176         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 32768       |
------------------------------------
------------------------------------
| reward             | [-2.885056] |
| time/              |             |
|    fps             | 173         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 32768       |
------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -37         |
|    n_updates            | 170         |
|    policy_gradient_loss | -14.9       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -1.36       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.62       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-3.1464353] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 12.66841     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.68        |
|    explained_variance   | -0.038       |
|    learning_rate        | 0.0003       |
|    loss                 | -53.9        |
|    n_updates            | 160          |
|    policy_gradient_loss | -15.5        |
|    std                  | 0.922        |
|    value_loss           | 2e+03        |
------------------------------------------
------------------------------------------
| reward                  | [-3.3654208] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 5.7706428    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.0211       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.57        |
|    n_updates            | 160          |
|    policy_gradient_loss | -3.29        |
|    std                  | 0.912        |
|    value_loss           | 1.9e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -34.9        |
|    n_updates            | 180          |
|    policy_gradient_loss | -29.2        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.35        |
|    n_updates            | 180          |
|    policy_gradient_loss | -1.11        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.6896093] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 11.153001    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | -0.0414      |
|    learning_rate        | 0.0003       |
|    loss                 | -25.2        |
|    n_updates            | 170          |
|    policy_gradient_loss | -26.6        |
|    std                  | 0.901        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2365603] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 7.453274     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.64        |
|    explained_variance   | -0.0054      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.17        |
|    n_updates            | 170          |
|    policy_gradient_loss | -5.24        |
|    std                  | 0.899        |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -56          |
|    n_updates            | 190          |
|    policy_gradient_loss | -14.5        |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.98        |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.578       |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8704584] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 11.927754    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.62        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -36.8        |
|    n_updates            | 180          |
|    policy_gradient_loss | -25.4        |
|    std                  | 0.89         |
|    value_loss           | 2.14e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 43008        |
-------------------------------------
------------------------------------------
| reward                  | [-3.5802398] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 6.829602     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | -0.000333    |
|    learning_rate        | 0.0003       |
|    loss                 | -7.78        |
|    n_updates            | 180          |
|    policy_gradient_loss | -4.82        |
|    std                  | 0.888        |
|    value_loss           | 1.84e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 43008        |
-------------------------------------
------------------------------------------
| reward                  | [-3.9747608] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 15.073423    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | -0.0373      |
|    learning_rate        | 0.0003       |
|    loss                 | -57          |
|    n_updates            | 190          |
|    policy_gradient_loss | -31.4        |
|    std                  | 0.875        |
|    value_loss           | 2.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -76.5        |
|    n_updates            | 210          |
|    policy_gradient_loss | -61.6        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.202526] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 5           |
|    time_elapsed         | 63          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 11.111057   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.59       |
|    explained_variance   | 0.00624     |
|    learning_rate        | 0.0003      |
|    loss                 | -15.1       |
|    n_updates            | 190         |
|    policy_gradient_loss | -6.25       |
|    std                  | 0.874       |
|    value_loss           | 1.95e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.73        |
|    n_updates            | 210          |
|    policy_gradient_loss | -2.14        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
------------------------------------
| reward             | [-0.504515] |
| time/              |             |
|    fps             | 177         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 43008       |
------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 176           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -77.3         |
|    n_updates            | 220           |
|    policy_gradient_loss | -57.3         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.92         |
|    n_updates            | 220           |
|    policy_gradient_loss | -2.05         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
------------------------------------
| reward             | [-0.504515] |
| time/              |             |
|    fps             | 172         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 43008       |
------------------------------------
------------------------------------------
| reward                  | [-0.9213489] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 14.327866    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | -0.0385      |
|    learning_rate        | 0.0003       |
|    loss                 | -27          |
|    n_updates            | 210          |
|    policy_gradient_loss | -32.8        |
|    std                  | 0.852        |
|    value_loss           | 2.33e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -112         |
|    n_updates            | 230          |
|    policy_gradient_loss | -50.6        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.81        |
|    n_updates            | 230          |
|    policy_gradient_loss | -1.81        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7824407] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 12.65394     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | -0.0145      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.9        |
|    n_updates            | 210          |
|    policy_gradient_loss | -8.26        |
|    std                  | 0.841        |
|    value_loss           | 2.27e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4068387] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 17.578575    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | -0.0392      |
|    learning_rate        | 0.0003       |
|    loss                 | -71.2        |
|    n_updates            | 220          |
|    policy_gradient_loss | -37.3        |
|    std                  | 0.85         |
|    value_loss           | 2.13e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 5           |
|    time_elapsed         | 58          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -78.3       |
|    n_updates            | 240         |
|    policy_gradient_loss | -43.7       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 173         |
|    iterations           | 5           |
|    time_elapsed         | 58          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -2.89       |
|    n_updates            | 240         |
|    policy_gradient_loss | -1.55       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.2001625] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 12.718302    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.00388      |
|    learning_rate        | 0.0003       |
|    loss                 | -14          |
|    n_updates            | 220          |
|    policy_gradient_loss | -8.64        |
|    std                  | 0.834        |
|    value_loss           | 1.93e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6888704] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 17.328632    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | -0.0397      |
|    learning_rate        | 0.0003       |
|    loss                 | -51.5        |
|    n_updates            | 230          |
|    policy_gradient_loss | -33.5        |
|    std                  | 0.829        |
|    value_loss           | 1.93e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 53248        |
-------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 53248        |
-------------------------------------
------------------------------------------
| reward                  | [-1.1245387] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.083958     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.0399       |
|    learning_rate        | 0.0003       |
|    loss                 | -8.17        |
|    n_updates            | 230          |
|    policy_gradient_loss | -6           |
|    std                  | 0.815        |
|    value_loss           | 1.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -134         |
|    n_updates            | 260          |
|    policy_gradient_loss | -86          |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2624052] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 13.995142    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | -0.035       |
|    learning_rate        | 0.0003       |
|    loss                 | -36.9        |
|    n_updates            | 240          |
|    policy_gradient_loss | -32.5        |
|    std                  | 0.814        |
|    value_loss           | 1.93e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.23        |
|    n_updates            | 260          |
|    policy_gradient_loss | -2.88        |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7839156] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 3.8191137    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.045        |
|    learning_rate        | 0.0003       |
|    loss                 | -6.25        |
|    n_updates            | 240          |
|    policy_gradient_loss | -1.18        |
|    std                  | 0.809        |
|    value_loss           | 1.2e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -93.1        |
|    n_updates            | 270          |
|    policy_gradient_loss | -81.9        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.4090486] |
| time/              |              |
|    fps             | 173          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 53248        |
-------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.12        |
|    n_updates            | 270          |
|    policy_gradient_loss | -2.78        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.3731763] |
| time/              |              |
|    fps             | 167          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 53248        |
-------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -83          |
|    n_updates            | 280          |
|    policy_gradient_loss | -67.5        |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.933221] |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 10.931383   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | -0.0433     |
|    learning_rate        | 0.0003      |
|    loss                 | -33.5       |
|    n_updates            | 260         |
|    policy_gradient_loss | -29         |
|    std                  | 0.781       |
|    value_loss           | 2.21e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.95        |
|    n_updates            | 280          |
|    policy_gradient_loss | -2.94        |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5468013] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 6.145095     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.0284       |
|    learning_rate        | 0.0003       |
|    loss                 | -19.3        |
|    n_updates            | 260          |
|    policy_gradient_loss | -4.56        |
|    std                  | 0.767        |
|    value_loss           | 1.54e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -102         |
|    n_updates            | 290          |
|    policy_gradient_loss | -56.9        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.5067427] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 13.253141    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | -0.0398      |
|    learning_rate        | 0.0003       |
|    loss                 | -44.8        |
|    n_updates            | 270          |
|    policy_gradient_loss | -33.7        |
|    std                  | 0.768        |
|    value_loss           | 2.25e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.26        |
|    n_updates            | 290          |
|    policy_gradient_loss | -1.88        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 63488        |
-------------------------------------
----------------------------------------
| reward                  | [-2.70485] |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 3          |
|    time_elapsed         | 38         |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 7.386668   |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.28      |
|    explained_variance   | 0.0516     |
|    learning_rate        | 0.0003     |
|    loss                 | -12.4      |
|    n_updates            | 270        |
|    policy_gradient_loss | -6         |
|    std                  | 0.757      |
|    value_loss           | 1.44e+03   |
----------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 63488        |
-------------------------------------
------------------------------------------
| reward                  | [-3.9269423] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 14.764171    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0291      |
|    learning_rate        | 0.0003       |
|    loss                 | -33.5        |
|    n_updates            | 280          |
|    policy_gradient_loss | -33.4        |
|    std                  | 0.75         |
|    value_loss           | 2.51e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -182        |
|    n_updates            | 310         |
|    policy_gradient_loss | -103        |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
----------------------------------------
| reward                  | [-2.77428] |
| time/                   |            |
|    fps                  | 159        |
|    iterations           | 4          |
|    time_elapsed         | 51         |
|    total_timesteps      | 59392      |
| train/                  |            |
|    approx_kl            | 6.55002    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.25      |
|    explained_variance   | 0.056      |
|    learning_rate        | 0.0003     |
|    loss                 | -6.74      |
|    n_updates            | 280        |
|    policy_gradient_loss | -4.24      |
|    std                  | 0.743      |
|    value_loss           | 1.26e+03   |
----------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -5.9        |
|    n_updates            | 310         |
|    policy_gradient_loss | -3.45       |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.021211] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 14.216991   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | -0.0286     |
|    learning_rate        | 0.0003      |
|    loss                 | -66.9       |
|    n_updates            | 290         |
|    policy_gradient_loss | -34.8       |
|    std                  | 0.736       |
|    value_loss           | 2.14e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -129         |
|    n_updates            | 320          |
|    policy_gradient_loss | -87.4        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1665008] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 5            |
|    time_elapsed         | 64           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 4.9664097    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.0606       |
|    learning_rate        | 0.0003       |
|    loss                 | -7.3         |
|    n_updates            | 290          |
|    policy_gradient_loss | -3.2         |
|    std                  | 0.727        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.25        |
|    n_updates            | 320          |
|    policy_gradient_loss | -2.84        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------
| reward             | [-4.407244] |
| time/              |             |
|    fps             | 176         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 63488       |
------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -141         |
|    n_updates            | 330          |
|    policy_gradient_loss | -88.7        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.9519663] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 63488        |
-------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.66        |
|    n_updates            | 330          |
|    policy_gradient_loss | -2.93        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5679788] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 15.616434    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | -0.035       |
|    learning_rate        | 0.0003       |
|    loss                 | -42          |
|    n_updates            | 310          |
|    policy_gradient_loss | -34.8        |
|    std                  | 0.71         |
|    value_loss           | 2.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -210         |
|    n_updates            | 340          |
|    policy_gradient_loss | -124         |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.92        |
|    n_updates            | 340          |
|    policy_gradient_loss | -4.11        |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.8405134] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 2.3213165    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.0852       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.46        |
|    n_updates            | 310          |
|    policy_gradient_loss | -1.7         |
|    std                  | 0.693        |
|    value_loss           | 1.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0727842] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 17.369162    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | -0.0315      |
|    learning_rate        | 0.0003       |
|    loss                 | -45          |
|    n_updates            | 320          |
|    policy_gradient_loss | -35.3        |
|    std                  | 0.7          |
|    value_loss           | 2.15e+03     |
------------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 184         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 73728       |
------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 184         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 73728       |
------------------------------------
------------------------------------------
| reward                  | [-1.2843888] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 2.9813147    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.079        |
|    learning_rate        | 0.0003       |
|    loss                 | -2.76        |
|    n_updates            | 320          |
|    policy_gradient_loss | -1.95        |
|    std                  | 0.687        |
|    value_loss           | 1.36e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.168324] |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 4           |
|    time_elapsed         | 49          |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 15.422986   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | -0.025      |
|    learning_rate        | 0.0003      |
|    loss                 | -42.3       |
|    n_updates            | 330         |
|    policy_gradient_loss | -32         |
|    std                  | 0.697       |
|    value_loss           | 1.97e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -52.3       |
|    n_updates            | 360         |
|    policy_gradient_loss | -50.8       |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -1.77       |
|    n_updates            | 360         |
|    policy_gradient_loss | -1.76       |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.4231841] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 4.2337685    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.0758       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.78        |
|    n_updates            | 330          |
|    policy_gradient_loss | -2.38        |
|    std                  | 0.681        |
|    value_loss           | 1.27e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6092161] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 24.237415    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | -0.0251      |
|    learning_rate        | 0.0003       |
|    loss                 | -64.6        |
|    n_updates            | 340          |
|    policy_gradient_loss | -60.4        |
|    std                  | 0.69         |
|    value_loss           | 983          |
------------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -291         |
|    n_updates            | 370          |
|    policy_gradient_loss | -120         |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.16        |
|    n_updates            | 370          |
|    policy_gradient_loss | -3.95        |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0433595] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 5            |
|    time_elapsed         | 64           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 14.594057    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.109        |
|    learning_rate        | 0.0003       |
|    loss                 | -15.2        |
|    n_updates            | 340          |
|    policy_gradient_loss | -9.64        |
|    std                  | 0.675        |
|    value_loss           | 601          |
------------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -128         |
|    n_updates            | 380          |
|    policy_gradient_loss | -124         |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.9376808] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 73728        |
-------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.98        |
|    n_updates            | 380          |
|    policy_gradient_loss | -4.06        |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3068751] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 73728        |
-------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -129         |
|    n_updates            | 390          |
|    policy_gradient_loss | -94.3        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.260013] |
| time/                   |             |
|    fps                  | 169         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 28.682014   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -0.0419     |
|    learning_rate        | 0.0003      |
|    loss                 | -46.7       |
|    n_updates            | 360         |
|    policy_gradient_loss | -63.6       |
|    std                  | 0.649       |
|    value_loss           | 1.01e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.25        |
|    n_updates            | 390          |
|    policy_gradient_loss | -3.17        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 83968        |
-------------------------------------
------------------------------------------
| reward                  | [-1.9387783] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 10.141265    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.0751       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.28        |
|    n_updates            | 360          |
|    policy_gradient_loss | -7.08        |
|    std                  | 0.643        |
|    value_loss           | 744          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.347942] |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 3           |
|    time_elapsed         | 36          |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 19.994303   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -0.041      |
|    learning_rate        | 0.0003      |
|    loss                 | -60.3       |
|    n_updates            | 370         |
|    policy_gradient_loss | -40.8       |
|    std                  | 0.642       |
|    value_loss           | 1.38e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 182          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 83968        |
-------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -268        |
|    n_updates            | 410         |
|    policy_gradient_loss | -166        |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.9844785] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 9.976055     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.0728       |
|    learning_rate        | 0.0003       |
|    loss                 | -11.4        |
|    n_updates            | 370          |
|    policy_gradient_loss | -6.32        |
|    std                  | 0.63         |
|    value_loss           | 924          |
------------------------------------------
------------------------------------------
| reward                  | [-3.1097689] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 16.157642    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | -0.0487      |
|    learning_rate        | 0.0003       |
|    loss                 | -40.8        |
|    n_updates            | 380          |
|    policy_gradient_loss | -37.2        |
|    std                  | 0.621        |
|    value_loss           | 1.25e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 2           |
|    time_elapsed         | 23          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -8.44       |
|    n_updates            | 410         |
|    policy_gradient_loss | -5.23       |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -220         |
|    n_updates            | 420          |
|    policy_gradient_loss | -178         |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6912304] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 4.871605     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.0778       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.52        |
|    n_updates            | 380          |
|    policy_gradient_loss | -3.41        |
|    std                  | 0.619        |
|    value_loss           | 808          |
------------------------------------------
------------------------------------------
| reward                  | [-3.5121868] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 5            |
|    time_elapsed         | 61           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 16.636742    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0367      |
|    learning_rate        | 0.0003       |
|    loss                 | -47.1        |
|    n_updates            | 390          |
|    policy_gradient_loss | -45.6        |
|    std                  | 0.611        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.92        |
|    n_updates            | 420          |
|    policy_gradient_loss | -5.75        |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 4             |
|    time_elapsed         | 45            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -288          |
|    n_updates            | 430           |
|    policy_gradient_loss | -169          |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.1149142] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 15.624599    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.83        |
|    explained_variance   | 0.103        |
|    learning_rate        | 0.0003       |
|    loss                 | -16.3        |
|    n_updates            | 390          |
|    policy_gradient_loss | -10.7        |
|    std                  | 0.604        |
|    value_loss           | 465          |
------------------------------------------
-------------------------------------
| reward             | [-3.3650484] |
| time/              |              |
|    fps             | 177          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 83968        |
-------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 174           |
|    iterations           | 4             |
|    time_elapsed         | 46            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -9.14         |
|    n_updates            | 430           |
|    policy_gradient_loss | -5.48         |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -180         |
|    n_updates            | 440          |
|    policy_gradient_loss | -180         |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.7000338] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 83968        |
-------------------------------------
-------------------------------------------
| reward                  | [-0.40460238] |
| time/                   |               |
|    fps                  | 170           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 22.188478     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.79         |
|    explained_variance   | -0.0491       |
|    learning_rate        | 0.0003        |
|    loss                 | -62.2         |
|    n_updates            | 410           |
|    policy_gradient_loss | -45.4         |
|    std                  | 0.586         |
|    value_loss           | 1.38e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 5            |
|    time_elapsed         | 59           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.71        |
|    n_updates            | 440          |
|    policy_gradient_loss | -5.58        |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 94208        |
-------------------------------------
------------------------------------------
| reward                  | [-0.5069671] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 13.567049    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.0623       |
|    learning_rate        | 0.0003       |
|    loss                 | -13.7        |
|    n_updates            | 410          |
|    policy_gradient_loss | -11          |
|    std                  | 0.578        |
|    value_loss           | 165          |
------------------------------------------
------------------------------------------
| reward                  | [-0.9120159] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 15.884604    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.74        |
|    explained_variance   | -0.0417      |
|    learning_rate        | 0.0003       |
|    loss                 | -70.2        |
|    n_updates            | 420          |
|    policy_gradient_loss | -44.6        |
|    std                  | 0.57         |
|    value_loss           | 1.33e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 94208        |
-------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -159        |
|    n_updates            | 460         |
|    policy_gradient_loss | -139        |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -5.04       |
|    n_updates            | 460         |
|    policy_gradient_loss | -4.53       |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.3354069] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 90112        |
| train/                  |              |
|    approx_kl            | 10.249743    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.7         |
|    explained_variance   | -0.0389      |
|    learning_rate        | 0.0003       |
|    loss                 | -31.6        |
|    n_updates            | 430          |
|    policy_gradient_loss | -27          |
|    std                  | 0.565        |
|    value_loss           | 984          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.31339088] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 19.99268      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.68         |
|    explained_variance   | 0.109         |
|    learning_rate        | 0.0003        |
|    loss                 | -21.7         |
|    n_updates            | 420           |
|    policy_gradient_loss | -16           |
|    std                  | 0.564         |
|    value_loss           | 296           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -298         |
|    n_updates            | 470          |
|    policy_gradient_loss | -152         |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.4         |
|    n_updates            | 470          |
|    policy_gradient_loss | -4.94        |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3028623] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 5            |
|    time_elapsed         | 61           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 19.733112    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | -0.0421      |
|    learning_rate        | 0.0003       |
|    loss                 | -81.5        |
|    n_updates            | 440          |
|    policy_gradient_loss | -42.8        |
|    std                  | 0.559        |
|    value_loss           | 1.27e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.62695354] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 17.578941     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.65         |
|    explained_variance   | 0.117         |
|    learning_rate        | 0.0003        |
|    loss                 | -18.3         |
|    n_updates            | 430           |
|    policy_gradient_loss | -12.9         |
|    std                  | 0.561         |
|    value_loss           | 198           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -182         |
|    n_updates            | 480          |
|    policy_gradient_loss | -165         |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.9         |
|    n_updates            | 480          |
|    policy_gradient_loss | -5.3         |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
--------------------------------------
| reward             | [-0.91202253] |
| time/              |               |
|    fps             | 174           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 94208         |
--------------------------------------
------------------------------------------
| reward                  | [-0.9899591] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 10.92287     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.119        |
|    learning_rate        | 0.0003       |
|    loss                 | -10.7        |
|    n_updates            | 440          |
|    policy_gradient_loss | -8.25        |
|    std                  | 0.552        |
|    value_loss           | 411          |
------------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -164         |
|    n_updates            | 490          |
|    policy_gradient_loss | -140         |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.22        |
|    n_updates            | 490          |
|    policy_gradient_loss | -4.62        |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5886182] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 11.521524    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -0.0259      |
|    learning_rate        | 0.0003       |
|    loss                 | -51          |
|    n_updates            | 460          |
|    policy_gradient_loss | -38.6        |
|    std                  | 0.542        |
|    value_loss           | 428          |
------------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 104448       |
-------------------------------------
-------------------------------------
| reward             | [-0.8048717] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 94208        |
-------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 104448       |
-------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -148         |
|    n_updates            | 510          |
|    policy_gradient_loss | -126         |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2488267] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 16.468967    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.59        |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -56.1        |
|    n_updates            | 470          |
|    policy_gradient_loss | -41.5        |
|    std                  | 0.535        |
|    value_loss           | 832          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3432128] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 8.1230135    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.00336      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.49        |
|    n_updates            | 460          |
|    policy_gradient_loss | -5.53        |
|    std                  | 0.539        |
|    value_loss           | 438          |
------------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -4.72        |
|    n_updates            | 510          |
|    policy_gradient_loss | -4.14        |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -366         |
|    n_updates            | 520          |
|    policy_gradient_loss | -219         |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8938593] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 11.654386    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.55        |
|    explained_variance   | -0.00333     |
|    learning_rate        | 0.0003       |
|    loss                 | -33.2        |
|    n_updates            | 480          |
|    policy_gradient_loss | -30          |
|    std                  | 0.517        |
|    value_loss           | 641          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8513719] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 9.632156     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.53        |
|    explained_variance   | 0.0506       |
|    learning_rate        | 0.0003       |
|    loss                 | -10.8        |
|    n_updates            | 470          |
|    policy_gradient_loss | -7.55        |
|    std                  | 0.529        |
|    value_loss           | 572          |
------------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.4        |
|    n_updates            | 520          |
|    policy_gradient_loss | -6.97        |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -235         |
|    n_updates            | 530          |
|    policy_gradient_loss | -147         |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4693774] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 5            |
|    time_elapsed         | 61           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 10.53932     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.49        |
|    explained_variance   | -0.0303      |
|    learning_rate        | 0.0003       |
|    loss                 | -39.7        |
|    n_updates            | 490          |
|    policy_gradient_loss | -31.4        |
|    std                  | 0.502        |
|    value_loss           | 935          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.71028095] |
| time/                   |               |
|    fps                  | 161           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 11.19893      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.46         |
|    explained_variance   | 0.0102        |
|    learning_rate        | 0.0003        |
|    loss                 | -12.6         |
|    n_updates            | 480           |
|    policy_gradient_loss | -9.26         |
|    std                  | 0.508         |
|    value_loss           | 343           |
-------------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.26        |
|    n_updates            | 530          |
|    policy_gradient_loss | -4.84        |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 178           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -310          |
|    n_updates            | 540           |
|    policy_gradient_loss | -220          |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
------------------------------------
| reward             | [-2.632796] |
| time/              |             |
|    fps             | 176         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 104448      |
------------------------------------
-----------------------------------------
| reward                  | [-1.604351] |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 5           |
|    time_elapsed         | 63          |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 13.913856   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.0971      |
|    learning_rate        | 0.0003      |
|    loss                 | -15.2       |
|    n_updates            | 490         |
|    policy_gradient_loss | -11.5       |
|    std                  | 0.494       |
|    value_loss           | 500         |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 174           |
|    iterations           | 5             |
|    time_elapsed         | 58            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -9.72         |
|    n_updates            | 540           |
|    policy_gradient_loss | -6.98         |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 114688       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4922426] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 16.230824    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.41        |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -41.8        |
|    n_updates            | 510          |
|    policy_gradient_loss | -34          |
|    std                  | 0.487        |
|    value_loss           | 960          |
------------------------------------------
-------------------------------------
| reward             | [-2.7194948] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 104448       |
-------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 114688       |
-------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -201         |
|    n_updates            | 560          |
|    policy_gradient_loss | -220         |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7149894] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 15.181426    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.37        |
|    explained_variance   | -0.0122      |
|    learning_rate        | 0.0003       |
|    loss                 | -39.3        |
|    n_updates            | 520          |
|    policy_gradient_loss | -39.5        |
|    std                  | 0.481        |
|    value_loss           | 759          |
------------------------------------------
----------------------------------------
| reward                  | [-2.80404] |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 2          |
|    time_elapsed         | 25         |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 18.72711   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.3       |
|    explained_variance   | 0.0766     |
|    learning_rate        | 0.0003     |
|    loss                 | -17.8      |
|    n_updates            | 510        |
|    policy_gradient_loss | -13.8      |
|    std                  | 0.478      |
|    value_loss           | 869        |
----------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.6         |
|    n_updates            | 560          |
|    policy_gradient_loss | -7           |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -302         |
|    n_updates            | 570          |
|    policy_gradient_loss | -205         |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.9385597] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.617958    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0147      |
|    learning_rate        | 0.0003       |
|    loss                 | -74.6        |
|    n_updates            | 530          |
|    policy_gradient_loss | -38.8        |
|    std                  | 0.47         |
|    value_loss           | 965          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48277327] |
| time/                   |               |
|    fps                  | 161           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 17.541775     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.26         |
|    explained_variance   | 0.0895        |
|    learning_rate        | 0.0003        |
|    loss                 | -17.5         |
|    n_updates            | 520           |
|    policy_gradient_loss | -13.1         |
|    std                  | 0.471         |
|    value_loss           | 553           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.35        |
|    n_updates            | 570          |
|    policy_gradient_loss | -6.57        |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -300         |
|    n_updates            | 580          |
|    policy_gradient_loss | -184         |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3185405] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 9.800533     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -0.0144      |
|    learning_rate        | 0.0003       |
|    loss                 | -27.3        |
|    n_updates            | 540          |
|    policy_gradient_loss | -30.4        |
|    std                  | 0.464        |
|    value_loss           | 546          |
------------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.28        |
|    n_updates            | 580          |
|    policy_gradient_loss | -5.95        |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5282567] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 12.507125    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.23        |
|    explained_variance   | 0.0792       |
|    learning_rate        | 0.0003       |
|    loss                 | -17.6        |
|    n_updates            | 530          |
|    policy_gradient_loss | -10.4        |
|    std                  | 0.466        |
|    value_loss           | 709          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -185         |
|    n_updates            | 590          |
|    policy_gradient_loss | -132         |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.8660786] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 114688       |
-------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.08        |
|    n_updates            | 590          |
|    policy_gradient_loss | -4.27        |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 180          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 124928       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.31671664] |
| time/                   |               |
|    fps                  | 160           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 12.554815     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.19         |
|    explained_variance   | 0.0991        |
|    learning_rate        | 0.0003        |
|    loss                 | -22.6         |
|    n_updates            | 540           |
|    policy_gradient_loss | -11           |
|    std                  | 0.458         |
|    value_loss           | 433           |
-------------------------------------------
----------------------------------------
| reward                  | [-2.05239] |
| time/                   |            |
|    fps                  | 167        |
|    iterations           | 2          |
|    time_elapsed         | 24         |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 22.66473   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.21      |
|    explained_variance   | -0.0138    |
|    learning_rate        | 0.0003     |
|    loss                 | -86.8      |
|    n_updates            | 560        |
|    policy_gradient_loss | -49.5      |
|    std                  | 0.445      |
|    value_loss           | 960        |
----------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 180          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 124928       |
-------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -269         |
|    n_updates            | 610          |
|    policy_gradient_loss | -214         |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3172163] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 114688       |
-------------------------------------
-----------------------------------------
| reward                  | [-2.198088] |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 32.007423   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0254     |
|    learning_rate        | 0.0003      |
|    loss                 | -65.7       |
|    n_updates            | 570         |
|    policy_gradient_loss | -78.6       |
|    std                  | 0.432       |
|    value_loss           | 1.15e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -8.58        |
|    n_updates            | 610          |
|    policy_gradient_loss | -6.79        |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 3          |
|    time_elapsed         | 35         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -287       |
|    n_updates            | 620        |
|    policy_gradient_loss | -236       |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
-------------------------------------------
| reward                  | [-0.60897666] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 116736        |
| train/                  |               |
|    approx_kl            | 23.887133     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.12         |
|    explained_variance   | 0.0857        |
|    learning_rate        | 0.0003        |
|    loss                 | -24.8         |
|    n_updates            | 560           |
|    policy_gradient_loss | -20.9         |
|    std                  | 0.446         |
|    value_loss           | 439           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.5257442] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 17.223454    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -37          |
|    n_updates            | 580          |
|    policy_gradient_loss | -44.8        |
|    std                  | 0.421        |
|    value_loss           | 1.04e+03     |
------------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 175        |
|    iterations           | 3          |
|    time_elapsed         | 35         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -8.98      |
|    n_updates            | 620        |
|    policy_gradient_loss | -7.37      |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 4            |
|    time_elapsed         | 47           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -417         |
|    n_updates            | 630          |
|    policy_gradient_loss | -375         |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7640867] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 30.74097     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0844       |
|    learning_rate        | 0.0003       |
|    loss                 | -23.9        |
|    n_updates            | 570          |
|    policy_gradient_loss | -25.1        |
|    std                  | 0.435        |
|    value_loss           | 659          |
------------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -13          |
|    n_updates            | 630          |
|    policy_gradient_loss | -11.6        |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
----------------------------------------
| reward                  | [-2.57632] |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 5          |
|    time_elapsed         | 62         |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 17.911133  |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | -0.0206    |
|    learning_rate        | 0.0003     |
|    loss                 | -79.2      |
|    n_updates            | 590        |
|    policy_gradient_loss | -45.6      |
|    std                  | 0.411      |
|    value_loss           | 1.11e+03   |
----------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 172           |
|    iterations           | 5             |
|    time_elapsed         | 59            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -277          |
|    n_updates            | 640           |
|    policy_gradient_loss | -286          |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.66464335] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 120832        |
| train/                  |               |
|    approx_kl            | 26.949306     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.03         |
|    explained_variance   | 0.0827        |
|    learning_rate        | 0.0003        |
|    loss                 | -26.4         |
|    n_updates            | 580           |
|    policy_gradient_loss | -19.7         |
|    std                  | 0.424         |
|    value_loss           | 306           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 173           |
|    iterations           | 5             |
|    time_elapsed         | 58            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -8.78         |
|    n_updates            | 640           |
|    policy_gradient_loss | -8.86         |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
------------------------------------
| reward             | [-2.615175] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 124928      |
------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 182          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------------
| reward                  | [-0.5497661] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 19.899132    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.993       |
|    explained_variance   | 0.097        |
|    learning_rate        | 0.0003       |
|    loss                 | -23.8        |
|    n_updates            | 590          |
|    policy_gradient_loss | -16.2        |
|    std                  | 0.418        |
|    value_loss           | 606          |
------------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -207         |
|    n_updates            | 660          |
|    policy_gradient_loss | -287         |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
------------------------------------------
| reward                  | [-2.9760742] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 28.97602     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.998       |
|    explained_variance   | -0.0193      |
|    learning_rate        | 0.0003       |
|    loss                 | -65.9        |
|    n_updates            | 610          |
|    policy_gradient_loss | -74.6        |
|    std                  | 0.404        |
|    value_loss           | 1.16e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.9637582] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 124928       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -6.48        |
|    n_updates            | 660          |
|    policy_gradient_loss | -8.84        |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -548         |
|    n_updates            | 670          |
|    policy_gradient_loss | -358         |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
-----------------------------------------
| reward                  | [-0.415749] |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 3           |
|    time_elapsed         | 36          |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 18.829689   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.98       |
|    explained_variance   | -0.0217     |
|    learning_rate        | 0.0003      |
|    loss                 | -41.7       |
|    n_updates            | 620         |
|    policy_gradient_loss | -43.6       |
|    std                  | 0.402       |
|    value_loss           | 1e+03       |
-----------------------------------------
------------------------------------------
| reward                  | [-3.1143267] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 12.0007105   |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.911       |
|    explained_variance   | 0.0602       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.64        |
|    n_updates            | 610          |
|    policy_gradient_loss | -9.19        |
|    std                  | 0.406        |
|    value_loss           | 967          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -17.2        |
|    n_updates            | 670          |
|    policy_gradient_loss | -11          |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -532         |
|    n_updates            | 680          |
|    policy_gradient_loss | -386         |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
------------------------------------------
| reward                  | [-1.0469946] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 28.812054    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.963       |
|    explained_variance   | -0.0258      |
|    learning_rate        | 0.0003       |
|    loss                 | -92.2        |
|    n_updates            | 630          |
|    policy_gradient_loss | -70.7        |
|    std                  | 0.397        |
|    value_loss           | 1.22e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5486923] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 17.024405    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.874       |
|    explained_variance   | 0.0607       |
|    learning_rate        | 0.0003       |
|    loss                 | -12          |
|    n_updates            | 620          |
|    policy_gradient_loss | -12.5        |
|    std                  | 0.398        |
|    value_loss           | 847          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -16.2        |
|    n_updates            | 680          |
|    policy_gradient_loss | -11.9        |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -157         |
|    n_updates            | 690          |
|    policy_gradient_loss | -142         |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
------------------------------------------
| reward                  | [-1.1350309] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 34.38217     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.917       |
|    explained_variance   | -0.0264      |
|    learning_rate        | 0.0003       |
|    loss                 | -89.8        |
|    n_updates            | 640          |
|    policy_gradient_loss | -88.2        |
|    std                  | 0.387        |
|    value_loss           | 1.56e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.60245156] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 11.849739     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.815        |
|    explained_variance   | 0.0291        |
|    learning_rate        | 0.0003        |
|    loss                 | -22.1         |
|    n_updates            | 630           |
|    policy_gradient_loss | -9.28         |
|    std                  | 0.387         |
|    value_loss           | 69.5          |
-------------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.02        |
|    n_updates            | 690          |
|    policy_gradient_loss | -4.53        |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 145408       |
-------------------------------------
------------------------------------
| reward             | [-1.654437] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 135168      |
------------------------------------
-------------------------------------------
| reward                  | [-0.58553445] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 28.77153      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.76         |
|    explained_variance   | 0.0534        |
|    learning_rate        | 0.0003        |
|    loss                 | -27.9         |
|    n_updates            | 640           |
|    policy_gradient_loss | -23.5         |
|    std                  | 0.379         |
|    value_loss           | 308           |
-------------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 145408       |
-------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -412         |
|    n_updates            | 710          |
|    policy_gradient_loss | -387         |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2321467] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 28.139862    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.842       |
|    explained_variance   | 0.00206      |
|    learning_rate        | 0.0003       |
|    loss                 | -114         |
|    n_updates            | 660          |
|    policy_gradient_loss | -78.6        |
|    std                  | 0.373        |
|    value_loss           | 1.6e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -12.5        |
|    n_updates            | 710          |
|    policy_gradient_loss | -12          |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
-------------------------------------
| reward             | [-1.2574472] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -148         |
|    n_updates            | 720          |
|    policy_gradient_loss | -261         |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.483818] |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 3           |
|    time_elapsed         | 36          |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 39.29526    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.785      |
|    explained_variance   | -0.0134     |
|    learning_rate        | 0.0003      |
|    loss                 | -140        |
|    n_updates            | 670         |
|    policy_gradient_loss | -89.4       |
|    std                  | 0.364       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.48        |
|    n_updates            | 720          |
|    policy_gradient_loss | -8.3         |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -407         |
|    n_updates            | 730          |
|    policy_gradient_loss | -396         |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
------------------------------------------
| reward                  | [-1.5644883] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 21.8605      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.692       |
|    explained_variance   | 0.0351       |
|    learning_rate        | 0.0003       |
|    loss                 | -21.5        |
|    n_updates            | 660          |
|    policy_gradient_loss | -12.8        |
|    std                  | 0.368        |
|    value_loss           | 322          |
------------------------------------------
------------------------------------------
| reward                  | [-1.9843521] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 37.555725    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.733       |
|    explained_variance   | 0.0112       |
|    learning_rate        | 0.0003       |
|    loss                 | -103         |
|    n_updates            | 680          |
|    policy_gradient_loss | -106         |
|    std                  | 0.358        |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -12.4        |
|    n_updates            | 730          |
|    policy_gradient_loss | -12.2        |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 178           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -329          |
|    n_updates            | 740           |
|    policy_gradient_loss | -265          |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.46140808] |
| time/                   |               |
|    fps                  | 160           |
|    iterations           | 3             |
|    time_elapsed         | 38            |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 13.204603     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.638        |
|    explained_variance   | 0.0397        |
|    learning_rate        | 0.0003        |
|    loss                 | -15.6         |
|    n_updates            | 670           |
|    policy_gradient_loss | -12.8         |
|    std                  | 0.36          |
|    value_loss           | 569           |
-------------------------------------------
------------------------------------------
| reward                  | [-3.0942957] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 17.218632    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.692       |
|    explained_variance   | 0.0252       |
|    learning_rate        | 0.0003       |
|    loss                 | -37.7        |
|    n_updates            | 690          |
|    policy_gradient_loss | -47.6        |
|    std                  | 0.35         |
|    value_loss           | 1.4e+03      |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 176           |
|    iterations           | 5             |
|    time_elapsed         | 58            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -10.1         |
|    n_updates            | 740           |
|    policy_gradient_loss | -8.08         |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 155648       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.48386014] |
| time/                   |               |
|    fps                  | 159           |
|    iterations           | 4             |
|    time_elapsed         | 51            |
|    total_timesteps      | 141312        |
| train/                  |               |
|    approx_kl            | 22.892864     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.591        |
|    explained_variance   | 0.0318        |
|    learning_rate        | 0.0003        |
|    loss                 | -22.7         |
|    n_updates            | 680           |
|    policy_gradient_loss | -21.4         |
|    std                  | 0.354         |
|    value_loss           | 690           |
-------------------------------------------
-------------------------------------
| reward             | [-3.4528582] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 145408       |
-------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 155648       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -467         |
|    n_updates            | 760          |
|    policy_gradient_loss | -342         |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
-------------------------------------------
| reward                  | [-0.50531715] |
| time/                   |               |
|    fps                  | 160           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 143360        |
| train/                  |               |
|    approx_kl            | 23.886585     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.551        |
|    explained_variance   | 0.016         |
|    learning_rate        | 0.0003        |
|    loss                 | -25.5         |
|    n_updates            | 690           |
|    policy_gradient_loss | -18.5         |
|    std                  | 0.346         |
|    value_loss           | 576           |
-------------------------------------------
------------------------------------------
| reward                  | [-3.2459338] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 35.358864    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.624       |
|    explained_variance   | 0.00276      |
|    learning_rate        | 0.0003       |
|    loss                 | -92.7        |
|    n_updates            | 710          |
|    policy_gradient_loss | -76.5        |
|    std                  | 0.341        |
|    value_loss           | 1.54e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -264         |
|    n_updates            | 770          |
|    policy_gradient_loss | -294         |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -14.3        |
|    n_updates            | 760          |
|    policy_gradient_loss | -10.5        |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
--------------------------------------
| reward             | [-0.43401134] |
| time/              |               |
|    fps             | 173           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 145408        |
--------------------------------------
-------------------------------------------
| reward                  | [-0.55440205] |
| time/                   |               |
|    fps                  | 166           |
|    iterations           | 3             |
|    time_elapsed         | 36            |
|    total_timesteps      | 149504        |
| train/                  |               |
|    approx_kl            | 30.517284     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.59         |
|    explained_variance   | -0.0144       |
|    learning_rate        | 0.0003        |
|    loss                 | -101          |
|    n_updates            | 720           |
|    policy_gradient_loss | -74.2         |
|    std                  | 0.338         |
|    value_loss           | 1.37e+03      |
-------------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 4          |
|    time_elapsed         | 45         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -282       |
|    n_updates            | 780        |
|    policy_gradient_loss | -206       |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.17        |
|    n_updates            | 770          |
|    policy_gradient_loss | -9.07        |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.6587968] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 30.833841    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.451       |
|    explained_variance   | 0.0175       |
|    learning_rate        | 0.0003       |
|    loss                 | -30          |
|    n_updates            | 710          |
|    policy_gradient_loss | -26.9        |
|    std                  | 0.333        |
|    value_loss           | 587          |
------------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 176        |
|    iterations           | 4          |
|    time_elapsed         | 46         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -8.62      |
|    n_updates            | 780        |
|    policy_gradient_loss | -6.47      |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -282         |
|    n_updates            | 790          |
|    policy_gradient_loss | -237         |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.76356655] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 151552        |
| train/                  |               |
|    approx_kl            | 35.884865     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.556        |
|    explained_variance   | 0.0158        |
|    learning_rate        | 0.0003        |
|    loss                 | -97.5         |
|    n_updates            | 730           |
|    policy_gradient_loss | -99           |
|    std                  | 0.332         |
|    value_loss           | 1.36e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.55440205] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 149504        |
| train/                  |               |
|    approx_kl            | 26.394796     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.415        |
|    explained_variance   | 0.0283        |
|    learning_rate        | 0.0003        |
|    loss                 | -25.6         |
|    n_updates            | 720           |
|    policy_gradient_loss | -22.7         |
|    std                  | 0.328         |
|    value_loss           | 483           |
-------------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 165888       |
-------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.76        |
|    n_updates            | 790          |
|    policy_gradient_loss | -7.39        |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.33803797] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 19.505943     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.516        |
|    explained_variance   | 0.0137        |
|    learning_rate        | 0.0003        |
|    loss                 | -63.2         |
|    n_updates            | 740           |
|    policy_gradient_loss | -50.6         |
|    std                  | 0.327         |
|    value_loss           | 1.13e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-0.7996829] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 23.927593    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.381       |
|    explained_variance   | 0.0363       |
|    learning_rate        | 0.0003       |
|    loss                 | -19.6        |
|    n_updates            | 730          |
|    policy_gradient_loss | -23          |
|    std                  | 0.326        |
|    value_loss           | 865          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -274         |
|    n_updates            | 810          |
|    policy_gradient_loss | -314         |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 165888       |
-------------------------------------
-------------------------------------
| reward             | [-1.4150374] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 155648       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.31815112] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 32.27175      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.35         |
|    explained_variance   | 0.0358        |
|    learning_rate        | 0.0003        |
|    loss                 | -29.9         |
|    n_updates            | 740           |
|    policy_gradient_loss | -26.1         |
|    std                  | 0.32          |
|    value_loss           | 870           |
-------------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -338         |
|    n_updates            | 820          |
|    policy_gradient_loss | -480         |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -8.33        |
|    n_updates            | 810          |
|    policy_gradient_loss | -9.62        |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9129392] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 39.57435     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.441       |
|    explained_variance   | 0.0366       |
|    learning_rate        | 0.0003       |
|    loss                 | -152         |
|    n_updates            | 760          |
|    policy_gradient_loss | -110         |
|    std                  | 0.316        |
|    value_loss           | 1.23e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3105928] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 155648       |
-------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -469        |
|    n_updates            | 830         |
|    policy_gradient_loss | -317        |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -12.1        |
|    n_updates            | 820          |
|    policy_gradient_loss | -14.7        |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1750522] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 64.06232     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.405       |
|    explained_variance   | 0.0314       |
|    learning_rate        | 0.0003       |
|    loss                 | -206         |
|    n_updates            | 770          |
|    policy_gradient_loss | -166         |
|    std                  | 0.312        |
|    value_loss           | 816          |
------------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -746         |
|    n_updates            | 840          |
|    policy_gradient_loss | -397         |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6424851] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 27.388588    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.262       |
|    explained_variance   | 0.0466       |
|    learning_rate        | 0.0003       |
|    loss                 | -33.2        |
|    n_updates            | 760          |
|    policy_gradient_loss | -23.9        |
|    std                  | 0.308        |
|    value_loss           | 895          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -14.3       |
|    n_updates            | 830         |
|    policy_gradient_loss | -9.8        |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-2.7410834] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 161792       |
| train/                  |              |
|    approx_kl            | 35.191074    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.371       |
|    explained_variance   | 0.0297       |
|    learning_rate        | 0.0003       |
|    loss                 | -139         |
|    n_updates            | 780          |
|    policy_gradient_loss | -101         |
|    std                  | 0.309        |
|    value_loss           | 1.6e+03      |
------------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -22.5        |
|    n_updates            | 840          |
|    policy_gradient_loss | -12.2        |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9166911] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 58.681507    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.208       |
|    explained_variance   | 0.0419       |
|    learning_rate        | 0.0003       |
|    loss                 | -65.4        |
|    n_updates            | 770          |
|    policy_gradient_loss | -53.7        |
|    std                  | 0.302        |
|    value_loss           | 616          |
------------------------------------------
------------------------------------------
| reward                  | [-3.2044256] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 41.03865     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.337       |
|    explained_variance   | 0.027        |
|    learning_rate        | 0.0003       |
|    loss                 | -78.9        |
|    n_updates            | 790          |
|    policy_gradient_loss | -99.5        |
|    std                  | 0.304        |
|    value_loss           | 1.77e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -341         |
|    n_updates            | 860          |
|    policy_gradient_loss | -281         |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-2.2786412] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 161792       |
| train/                  |              |
|    approx_kl            | 27.93819     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.155       |
|    explained_variance   | 0.043        |
|    learning_rate        | 0.0003       |
|    loss                 | -30.6        |
|    n_updates            | 780          |
|    policy_gradient_loss | -23.9        |
|    std                  | 0.294        |
|    value_loss           | 936          |
------------------------------------------
-------------------------------------
| reward             | [-3.5626714] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 165888       |
-------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -716         |
|    n_updates            | 870          |
|    policy_gradient_loss | -589         |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -10.5        |
|    n_updates            | 860          |
|    policy_gradient_loss | -8.8         |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5904038] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.278004    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.102       |
|    explained_variance   | 0.0397       |
|    learning_rate        | 0.0003       |
|    loss                 | -25.8        |
|    n_updates            | 790          |
|    policy_gradient_loss | -21.3        |
|    std                  | 0.292        |
|    value_loss           | 976          |
------------------------------------------
------------------------------------------
| reward                  | [-3.7551842] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 47.637886    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.254       |
|    explained_variance   | 0.0186       |
|    learning_rate        | 0.0003       |
|    loss                 | -142         |
|    n_updates            | 810          |
|    policy_gradient_loss | -111         |
|    std                  | 0.297        |
|    value_loss           | 1.82e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -498         |
|    n_updates            | 880          |
|    policy_gradient_loss | -404         |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -21.8        |
|    n_updates            | 870          |
|    policy_gradient_loss | -18          |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.6075413] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 165888       |
-------------------------------------
------------------------------------------
| reward                  | [-4.1902094] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 43.529095    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.228       |
|    explained_variance   | 0.0087       |
|    learning_rate        | 0.0003       |
|    loss                 | -237         |
|    n_updates            | 820          |
|    policy_gradient_loss | -113         |
|    std                  | 0.294        |
|    value_loss           | 1.91e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -484         |
|    n_updates            | 890          |
|    policy_gradient_loss | -569         |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -15.1        |
|    n_updates            | 880          |
|    policy_gradient_loss | -12.4        |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.952998] |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 67.08002    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0226     |
|    explained_variance   | 0.0328      |
|    learning_rate        | 0.0003      |
|    loss                 | -85         |
|    n_updates            | 810         |
|    policy_gradient_loss | -54.2       |
|    std                  | 0.282       |
|    value_loss           | 805         |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.54063356] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 172032        |
| train/                  |               |
|    approx_kl            | 56.550125     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.185        |
|    explained_variance   | 0.00361       |
|    learning_rate        | 0.0003        |
|    loss                 | -174          |
|    n_updates            | 830           |
|    policy_gradient_loss | -139          |
|    std                  | 0.29          |
|    value_loss           | 1.9e+03       |
-------------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 186368       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.5        |
|    n_updates            | 890          |
|    policy_gradient_loss | -17.4        |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.025244] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 34.855835   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0147      |
|    explained_variance   | 0.0463      |
|    learning_rate        | 0.0003      |
|    loss                 | -52.8       |
|    n_updates            | 820         |
|    policy_gradient_loss | -29         |
|    std                  | 0.278       |
|    value_loss           | 1.16e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.0619959] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 51.445503    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.143       |
|    explained_variance   | 0.0202       |
|    learning_rate        | 0.0003       |
|    loss                 | -189         |
|    n_updates            | 840          |
|    policy_gradient_loss | -115         |
|    std                  | 0.283        |
|    value_loss           | 1.86e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -1.13e+03   |
|    n_updates            | 910         |
|    policy_gradient_loss | -754        |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 186368       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.37124845] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 172032        |
| train/                  |               |
|    approx_kl            | 49.518517     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.0625        |
|    explained_variance   | 0.0279        |
|    learning_rate        | 0.0003        |
|    loss                 | -37.2         |
|    n_updates            | 830           |
|    policy_gradient_loss | -45.1         |
|    std                  | 0.272         |
|    value_loss           | 1.07e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-1.4967928] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -458         |
|    n_updates            | 920          |
|    policy_gradient_loss | -425         |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -34.4       |
|    n_updates            | 910         |
|    policy_gradient_loss | -23.2       |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.6542949] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 44.99473     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.113        |
|    explained_variance   | 0.027        |
|    learning_rate        | 0.0003       |
|    loss                 | -59.3        |
|    n_updates            | 840          |
|    policy_gradient_loss | -36.5        |
|    std                  | 0.266        |
|    value_loss           | 1.02e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -555        |
|    n_updates            | 930         |
|    policy_gradient_loss | -606        |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.7089398] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 69.178856    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0116      |
|    explained_variance   | -0.00281     |
|    learning_rate        | 0.0003       |
|    loss                 | -208         |
|    n_updates            | 860          |
|    policy_gradient_loss | -184         |
|    std                  | 0.265        |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -15          |
|    n_updates            | 920          |
|    policy_gradient_loss | -13.1        |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.5290984] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -824         |
|    n_updates            | 940          |
|    policy_gradient_loss | -625         |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2443256] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.76004     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0411       |
|    explained_variance   | -0.00528     |
|    learning_rate        | 0.0003       |
|    loss                 | -139         |
|    n_updates            | 870          |
|    policy_gradient_loss | -157         |
|    std                  | 0.261        |
|    value_loss           | 1.89e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -17.5       |
|    n_updates            | 930         |
|    policy_gradient_loss | -18.5       |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.34186095] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 178176        |
| train/                  |               |
|    approx_kl            | 62.273495     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.206         |
|    explained_variance   | 0.0377        |
|    learning_rate        | 0.0003        |
|    loss                 | -77.1         |
|    n_updates            | 860           |
|    policy_gradient_loss | -58.4         |
|    std                  | 0.257         |
|    value_loss           | 662           |
-------------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 187           |
|    iterations      | 1             |
|    time_elapsed    | 10            |
|    total_timesteps | 196608        |
--------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -24.9        |
|    n_updates            | 940          |
|    policy_gradient_loss | -19.1        |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.7523255] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 59.351875    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0809       |
|    explained_variance   | 0.00854      |
|    learning_rate        | 0.0003       |
|    loss                 | -146         |
|    n_updates            | 880          |
|    policy_gradient_loss | -165         |
|    std                  | 0.257        |
|    value_loss           | 1.7e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -636         |
|    n_updates            | 960          |
|    policy_gradient_loss | -452         |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8876117] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 228.44522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.236        |
|    explained_variance   | 0.0638       |
|    learning_rate        | 0.0003       |
|    loss                 | -218         |
|    n_updates            | 870          |
|    policy_gradient_loss | -125         |
|    std                  | 0.255        |
|    value_loss           | 69.1         |
------------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 184           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 196608        |
--------------------------------------
------------------------------------------
| reward                  | [-3.1875713] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 5            |
|    time_elapsed         | 61           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 87.530876    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.121        |
|    explained_variance   | 0.0125       |
|    learning_rate        | 0.0003       |
|    loss                 | -195         |
|    n_updates            | 890          |
|    policy_gradient_loss | -220         |
|    std                  | 0.252        |
|    value_loss           | 1.98e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -804         |
|    n_updates            | 970          |
|    policy_gradient_loss | -696         |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -19.1        |
|    n_updates            | 960          |
|    policy_gradient_loss | -13.8        |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3375714] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 58.85361     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.269        |
|    explained_variance   | 0.0276       |
|    learning_rate        | 0.0003       |
|    loss                 | -58          |
|    n_updates            | 880          |
|    policy_gradient_loss | -49.3        |
|    std                  | 0.248        |
|    value_loss           | 402          |
------------------------------------------
-------------------------------------
| reward             | [-3.6798937] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 186368       |
-------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -608         |
|    n_updates            | 980          |
|    policy_gradient_loss | -905         |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -24.2        |
|    n_updates            | 970          |
|    policy_gradient_loss | -21.1        |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.7848728] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 5            |
|    time_elapsed         | 64           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 35.618835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.32         |
|    explained_variance   | 0.0323       |
|    learning_rate        | 0.0003       |
|    loss                 | -32.5        |
|    n_updates            | 890          |
|    policy_gradient_loss | -29.7        |
|    std                  | 0.246        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.7851386] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 76.13777     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.215        |
|    explained_variance   | 0.0096       |
|    learning_rate        | 0.0003       |
|    loss                 | -326         |
|    n_updates            | 910          |
|    policy_gradient_loss | -193         |
|    std                  | 0.245        |
|    value_loss           | 2.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -431         |
|    n_updates            | 990          |
|    policy_gradient_loss | -373         |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -18.4        |
|    n_updates            | 980          |
|    policy_gradient_loss | -27.4        |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.875868] |
| time/              |             |
|    fps             | 172         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 186368      |
------------------------------------
------------------------------------------
| reward                  | [-3.8788755] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 93.69588     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.253        |
|    explained_variance   | -0.00584     |
|    learning_rate        | 0.0003       |
|    loss                 | -346         |
|    n_updates            | 920          |
|    policy_gradient_loss | -249         |
|    std                  | 0.242        |
|    value_loss           | 1.98e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.4        |
|    n_updates            | 990          |
|    policy_gradient_loss | -11.4        |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9496968] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 46.204773    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.401        |
|    explained_variance   | 0.0343       |
|    learning_rate        | 0.0003       |
|    loss                 | -62.9        |
|    n_updates            | 910          |
|    policy_gradient_loss | -40.2        |
|    std                  | 0.237        |
|    value_loss           | 1.02e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.33670455] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 192512        |
| train/                  |               |
|    approx_kl            | 107.23365     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.279         |
|    explained_variance   | 0.00911       |
|    learning_rate        | 0.0003        |
|    loss                 | -401          |
|    n_updates            | 930           |
|    policy_gradient_loss | -259          |
|    std                  | 0.244         |
|    value_loss           | 2.11e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.48e+03    |
|    n_updates            | 1010         |
|    policy_gradient_loss | -1.66e+03    |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-3.0332377] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 96.102844    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.45         |
|    explained_variance   | 0.0366       |
|    learning_rate        | 0.0003       |
|    loss                 | -104         |
|    n_updates            | 920          |
|    policy_gradient_loss | -83.3        |
|    std                  | 0.234        |
|    value_loss           | 735          |
------------------------------------------
------------------------------------------
| reward                  | [-0.9148875] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 141.11984    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.289        |
|    explained_variance   | 0.00919      |
|    learning_rate        | 0.0003       |
|    loss                 | -436         |
|    n_updates            | 940          |
|    policy_gradient_loss | -380         |
|    std                  | 0.243        |
|    value_loss           | 1.96e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -815         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -905         |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -74.6        |
|    n_updates            | 1010         |
|    policy_gradient_loss | -50          |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
------------------------------------
| reward             | [-1.332296] |
| time/              |             |
|    fps             | 176         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 196608      |
------------------------------------
------------------------------------------
| reward                  | [-0.3451252] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 59.320568    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.475        |
|    explained_variance   | 0.0315       |
|    learning_rate        | 0.0003       |
|    loss                 | -58.9        |
|    n_updates            | 930          |
|    policy_gradient_loss | -49.8        |
|    std                  | 0.235        |
|    value_loss           | 1.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -863         |
|    n_updates            | 1030         |
|    policy_gradient_loss | -464         |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -24.9        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -27.3        |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.8223394] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 89.47104     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.372        |
|    explained_variance   | 0.0038       |
|    learning_rate        | 0.0003       |
|    loss                 | -353         |
|    n_updates            | 960          |
|    policy_gradient_loss | -211         |
|    std                  | 0.235        |
|    value_loss           | 1.9e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-0.6152725] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 61.34263     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.488        |
|    explained_variance   | 0.0342       |
|    learning_rate        | 0.0003       |
|    loss                 | -60.7        |
|    n_updates            | 940          |
|    policy_gradient_loss | -46.9        |
|    std                  | 0.233        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.14e+03    |
|    n_updates            | 1040         |
|    policy_gradient_loss | -588         |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -26          |
|    n_updates            | 1030         |
|    policy_gradient_loss | -14.2        |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.227655] |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 3           |
|    time_elapsed         | 36          |
|    total_timesteps      | 200704      |
| train/                  |             |
|    approx_kl            | 69.95053    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.415       |
|    explained_variance   | 0.0178      |
|    learning_rate        | 0.0003      |
|    loss                 | -157        |
|    n_updates            | 970         |
|    policy_gradient_loss | -161        |
|    std                  | 0.233       |
|    value_loss           | 1.91e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-1.0801448] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 196608       |
-------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 190         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 217088      |
------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -34.4        |
|    n_updates            | 1040         |
|    policy_gradient_loss | -17.9        |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -284          |
|    n_updates            | 1060          |
|    policy_gradient_loss | -482          |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.3966973] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 179.54742    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.45         |
|    explained_variance   | 0.0152       |
|    learning_rate        | 0.0003       |
|    loss                 | -741         |
|    n_updates            | 980          |
|    policy_gradient_loss | -409         |
|    std                  | 0.229        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3710219] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 54.57827     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.578        |
|    explained_variance   | 0.0451       |
|    learning_rate        | 0.0003       |
|    loss                 | -41.7        |
|    n_updates            | 960          |
|    policy_gradient_loss | -44.6        |
|    std                  | 0.225        |
|    value_loss           | 945          |
------------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 182         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 217088      |
------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.24e+03    |
|    n_updates            | 1070         |
|    policy_gradient_loss | -1.21e+03    |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.259812] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 84.107635   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.495       |
|    explained_variance   | 0.0199      |
|    learning_rate        | 0.0003      |
|    loss                 | -274        |
|    n_updates            | 990         |
|    policy_gradient_loss | -192        |
|    std                  | 0.226       |
|    value_loss           | 1.98e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.6038805] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 57.499733    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.621        |
|    explained_variance   | 0.0255       |
|    learning_rate        | 0.0003       |
|    loss                 | -52.9        |
|    n_updates            | 970          |
|    policy_gradient_loss | -41.4        |
|    std                  | 0.223        |
|    value_loss           | 1.2e+03      |
------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 2             |
|    time_elapsed         | 23            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -8.9          |
|    n_updates            | 1060          |
|    policy_gradient_loss | -14.8         |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -813         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -650         |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.4322093] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -37.7        |
|    n_updates            | 1070         |
|    policy_gradient_loss | -36.8        |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8393756] |
| time/                   |              |
|    fps                  | 157          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 59.433624    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.665        |
|    explained_variance   | 0.0378       |
|    learning_rate        | 0.0003       |
|    loss                 | -63          |
|    n_updates            | 980          |
|    policy_gradient_loss | -52.5        |
|    std                  | 0.217        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -810         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -1.4e+03     |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.797136] |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 70.45202    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.602       |
|    explained_variance   | 0.00855     |
|    learning_rate        | 0.0003      |
|    loss                 | -161        |
|    n_updates            | 1010        |
|    policy_gradient_loss | -160        |
|    std                  | 0.217       |
|    value_loss           | 2.1e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -24.5        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -19.7        |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.417446] |
| time/                   |             |
|    fps                  | 157         |
|    iterations           | 5           |
|    time_elapsed         | 65          |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 48.240532   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.719       |
|    explained_variance   | 0.0361      |
|    learning_rate        | 0.0003      |
|    loss                 | -61.6       |
|    n_updates            | 990         |
|    policy_gradient_loss | -43.9       |
|    std                  | 0.211       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 188         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 227328      |
------------------------------------
------------------------------------------
| reward                  | [-3.5494132] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 110.02663    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.645        |
|    explained_variance   | 0.0171       |
|    learning_rate        | 0.0003       |
|    loss                 | -317         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -288         |
|    std                  | 0.214        |
|    value_loss           | 2.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -24.6        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -42.2        |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.794458] |
| time/              |             |
|    fps             | 171         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 206848      |
------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -2.88e+03    |
|    n_updates            | 1110         |
|    policy_gradient_loss | -2.18e+03    |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 184         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 227328      |
------------------------------------
-----------------------------------------
| reward                  | [-4.149649] |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 4           |
|    time_elapsed         | 49          |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 71.679436   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.676       |
|    explained_variance   | -0.0228     |
|    learning_rate        | 0.0003      |
|    loss                 | -215        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -158        |
|    std                  | 0.214       |
|    value_loss           | 1.78e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.8510206] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 67.367325    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.829        |
|    explained_variance   | 0.0211       |
|    learning_rate        | 0.0003       |
|    loss                 | -51.3        |
|    n_updates            | 1010         |
|    policy_gradient_loss | -52.1        |
|    std                  | 0.205        |
|    value_loss           | 1.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.73e+03    |
|    n_updates            | 1120         |
|    policy_gradient_loss | -859         |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -86.7        |
|    n_updates            | 1110         |
|    policy_gradient_loss | -65.7        |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.59744513] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 215040        |
| train/                  |               |
|    approx_kl            | 122.11795     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.722         |
|    explained_variance   | 0.00827       |
|    learning_rate        | 0.0003        |
|    loss                 | -424          |
|    n_updates            | 1040          |
|    policy_gradient_loss | -312          |
|    std                  | 0.209         |
|    value_loss           | 2.26e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.9811187] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 65.86238     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.867        |
|    explained_variance   | 0.0194       |
|    learning_rate        | 0.0003       |
|    loss                 | -62.2        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -53.6        |
|    std                  | 0.201        |
|    value_loss           | 1.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.84e+03    |
|    n_updates            | 1130         |
|    policy_gradient_loss | -1.31e+03    |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -52          |
|    n_updates            | 1120         |
|    policy_gradient_loss | -26          |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
--------------------------------------
| reward             | [-0.96057546] |
| time/              |               |
|    fps             | 175           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 217088        |
--------------------------------------
----------------------------------------
| reward                  | [-3.02582] |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 4          |
|    time_elapsed         | 50         |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 61.734085  |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.914      |
|    explained_variance   | 0.0173     |
|    learning_rate        | 0.0003     |
|    loss                 | -56.6      |
|    n_updates            | 1030       |
|    policy_gradient_loss | -54.4      |
|    std                  | 0.199      |
|    value_loss           | 1.32e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.74e+03    |
|    n_updates            | 1140         |
|    policy_gradient_loss | -953         |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 4            |
|    time_elapsed         | 47           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -85.4        |
|    n_updates            | 1130         |
|    policy_gradient_loss | -39.5        |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5608163] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 230.1883     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.8          |
|    explained_variance   | -0.0311      |
|    learning_rate        | 0.0003       |
|    loss                 | -717         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -489         |
|    std                  | 0.206        |
|    value_loss           | 1.51e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5758964] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 71.75205     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.962        |
|    explained_variance   | 0.0319       |
|    learning_rate        | 0.0003       |
|    loss                 | -70.1        |
|    n_updates            | 1040         |
|    policy_gradient_loss | -67.3        |
|    std                  | 0.194        |
|    value_loss           | 999          |
------------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 237568       |
-------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -52.5        |
|    n_updates            | 1140         |
|    policy_gradient_loss | -29          |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1515214] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 114.633286   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.82         |
|    explained_variance   | -0.0124      |
|    learning_rate        | 0.0003       |
|    loss                 | -381         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -294         |
|    std                  | 0.206        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.37e+03    |
|    n_updates            | 1160         |
|    policy_gradient_loss | -3.16e+03    |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
-------------------------------------
| reward             | [-1.1156248] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 217088       |
-------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 237568       |
-------------------------------------
------------------------------------------
| reward                  | [-2.3741055] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 191.96953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.864        |
|    explained_variance   | 0.00651      |
|    learning_rate        | 0.0003       |
|    loss                 | -913         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -507         |
|    std                  | 0.201        |
|    value_loss           | 1.96e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.09e+04    |
|    n_updates            | 1170         |
|    policy_gradient_loss | -8.16e+03    |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3544822] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 81.68513     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.04         |
|    explained_variance   | 0.0227       |
|    learning_rate        | 0.0003       |
|    loss                 | -72.8        |
|    n_updates            | 1060         |
|    policy_gradient_loss | -64.9        |
|    std                  | 0.192        |
|    value_loss           | 1.35e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -191         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -94.8        |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
------------------------------------------
| reward                  | [-2.7317655] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 185.40715    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.921        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -526         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -521         |
|    std                  | 0.198        |
|    value_loss           | 2.02e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.15e+04    |
|    n_updates            | 1180         |
|    policy_gradient_loss | -2.81e+03    |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.553501] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 221184      |
| train/                  |             |
|    approx_kl            | 66.19       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.07        |
|    explained_variance   | 0.0179      |
|    learning_rate        | 0.0003      |
|    loss                 | -71.1       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -57.6       |
|    std                  | 0.192       |
|    value_loss           | 1.31e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -326         |
|    n_updates            | 1170         |
|    policy_gradient_loss | -245         |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
-------------------------------------
| reward             | [-3.4587328] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 227328       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.52e+03    |
|    n_updates            | 1190         |
|    policy_gradient_loss | -1.83e+03    |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0380847] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 108.77807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.1          |
|    explained_variance   | 0.0268       |
|    learning_rate        | 0.0003       |
|    loss                 | -163         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -91.9        |
|    std                  | 0.19         |
|    value_loss           | 1.22e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 171          |
|    iterations           | 4            |
|    time_elapsed         | 47           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -344         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -84.5        |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
------------------------------------------
| reward                  | [-3.5535612] |
| time/                   |              |
|    fps                  | 169          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 199.27545    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | 0.0188       |
|    learning_rate        | 0.0003       |
|    loss                 | -552         |
|    n_updates            | 1110         |
|    policy_gradient_loss | -587         |
|    std                  | 0.194        |
|    value_loss           | 1.94e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 247808       |
-------------------------------------
------------------------------------------
| reward                  | [-2.2485611] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 108.87626    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.14         |
|    explained_variance   | 0.03         |
|    learning_rate        | 0.0003       |
|    loss                 | -106         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -92.5        |
|    std                  | 0.186        |
|    value_loss           | 1.16e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 170          |
|    iterations           | 5            |
|    time_elapsed         | 60           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -106         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -55.1        |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -1.37e+03    |
|    n_updates            | 1210         |
|    policy_gradient_loss | -1.38e+03    |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.7266116] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 114.62001    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.03         |
|    explained_variance   | 0.0276       |
|    learning_rate        | 0.0003       |
|    loss                 | -362         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -332         |
|    std                  | 0.192        |
|    value_loss           | 1.92e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.3243315] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 227328       |
-------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 182          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 247808       |
-------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.14e+03    |
|    n_updates            | 1220         |
|    policy_gradient_loss | -1.19e+03    |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.7368505] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 162.73395    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.05         |
|    explained_variance   | 0.0145       |
|    learning_rate        | 0.0003       |
|    loss                 | -464         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -432         |
|    std                  | 0.192        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5482528] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 112.339806   |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | 0.035        |
|    learning_rate        | 0.0003       |
|    loss                 | -89.9        |
|    n_updates            | 1110         |
|    policy_gradient_loss | -88.1        |
|    std                  | 0.182        |
|    value_loss           | 781          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -41.1        |
|    n_updates            | 1210         |
|    policy_gradient_loss | -41.6        |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.84e+03    |
|    n_updates            | 1230         |
|    policy_gradient_loss | -2e+03       |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.24713214] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 224.42558     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.08          |
|    explained_variance   | 0.0259        |
|    learning_rate        | 0.0003        |
|    loss                 | -705          |
|    n_updates            | 1140          |
|    policy_gradient_loss | -516          |
|    std                  | 0.192         |
|    value_loss           | 2.01e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -34.4        |
|    n_updates            | 1220         |
|    policy_gradient_loss | -35.9        |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.8512197] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 370.85004    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.26         |
|    explained_variance   | 0.0352       |
|    learning_rate        | 0.0003       |
|    loss                 | -424         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -305         |
|    std                  | 0.18         |
|    value_loss           | 542          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.33e+03    |
|    n_updates            | 1240         |
|    policy_gradient_loss | -1.94e+03    |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
-------------------------------------
| reward             | [-1.0219514] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 237568       |
-------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 4            |
|    time_elapsed         | 47           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -55.5        |
|    n_updates            | 1230         |
|    policy_gradient_loss | -60.4        |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5638287] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 95.43559     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.3          |
|    explained_variance   | 0.0299       |
|    learning_rate        | 0.0003       |
|    loss                 | -103         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -78.7        |
|    std                  | 0.179        |
|    value_loss           | 811          |
------------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 258048       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2770704] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 126.42633    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.14         |
|    explained_variance   | 0.0278       |
|    learning_rate        | 0.0003       |
|    loss                 | -322         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -364         |
|    std                  | 0.189        |
|    value_loss           | 1.85e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 5            |
|    time_elapsed         | 59           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -40.3        |
|    n_updates            | 1240         |
|    policy_gradient_loss | -58.4        |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.39633748] |
| time/                   |               |
|    fps                  | 161           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 116.40355     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.33          |
|    explained_variance   | 0.0449        |
|    learning_rate        | 0.0003        |
|    loss                 | -114          |
|    n_updates            | 1140          |
|    policy_gradient_loss | -93.2         |
|    std                  | 0.178         |
|    value_loss           | 938           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -4.23e+03     |
|    n_updates            | 1260          |
|    policy_gradient_loss | -3.73e+03     |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.8163397] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 322.3716     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | 0.0237       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.19e+03    |
|    n_updates            | 1170         |
|    policy_gradient_loss | -811         |
|    std                  | 0.185        |
|    value_loss           | 2.05e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 180          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 258048       |
-------------------------------------
--------------------------------------
| reward             | [-0.73643583] |
| time/              |               |
|    fps             | 171           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 237568        |
--------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.48e+04     |
|    n_updates            | 1270          |
|    policy_gradient_loss | -1.14e+04     |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.1156733] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 176.41635    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | 0.0298       |
|    learning_rate        | 0.0003       |
|    loss                 | -729         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -483         |
|    std                  | 0.182        |
|    value_loss           | 1.86e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 175           |
|    iterations           | 2             |
|    time_elapsed         | 23            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -127          |
|    n_updates            | 1260          |
|    policy_gradient_loss | -112          |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 4           |
|    time_elapsed         | 45          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -3.06e+03   |
|    n_updates            | 1280        |
|    policy_gradient_loss | -2.64e+03   |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.52808565] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 239616        |
| train/                  |               |
|    approx_kl            | 104.64137     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.42          |
|    explained_variance   | 0.0346        |
|    learning_rate        | 0.0003        |
|    loss                 | -97.7         |
|    n_updates            | 1160          |
|    policy_gradient_loss | -93.5         |
|    std                  | 0.173         |
|    value_loss           | 504           |
-------------------------------------------
-----------------------------------------
| reward                  | [-2.600372] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 267.30243   |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.25        |
|    explained_variance   | 0.0282      |
|    learning_rate        | 0.0003      |
|    loss                 | -694        |
|    n_updates            | 1190        |
|    policy_gradient_loss | -692        |
|    std                  | 0.181       |
|    value_loss           | 1.87e+03    |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 174           |
|    iterations           | 3             |
|    time_elapsed         | 35            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -744          |
|    n_updates            | 1270          |
|    policy_gradient_loss | -341          |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.16e+03    |
|    n_updates            | 1290         |
|    policy_gradient_loss | -4.57e+03    |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
------------------------------------------
| reward                  | [-1.1030704] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 145.43536    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.46         |
|    explained_variance   | 0.0381       |
|    learning_rate        | 0.0003       |
|    loss                 | -250         |
|    n_updates            | 1170         |
|    policy_gradient_loss | -107         |
|    std                  | 0.17         |
|    value_loss           | 957          |
------------------------------------------
------------------------------------
| reward             | [-3.366531] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 247808      |
------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -91.9       |
|    n_updates            | 1280        |
|    policy_gradient_loss | -79.6       |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 268288       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.38569745] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 243712        |
| train/                  |               |
|    approx_kl            | 171.47348     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.5           |
|    explained_variance   | 0.0388        |
|    learning_rate        | 0.0003        |
|    loss                 | -231          |
|    n_updates            | 1180          |
|    policy_gradient_loss | -116          |
|    std                  | 0.166         |
|    value_loss           | 736           |
-------------------------------------------
------------------------------------------
| reward                  | [-3.6710122] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 197.55167    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.35         |
|    explained_variance   | 0.0219       |
|    learning_rate        | 0.0003       |
|    loss                 | -717         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -565         |
|    std                  | 0.173        |
|    value_loss           | 2.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -215         |
|    n_updates            | 1290         |
|    policy_gradient_loss | -137         |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 2           |
|    time_elapsed         | 23          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -3.81e+03   |
|    n_updates            | 1310        |
|    policy_gradient_loss | -3.15e+03   |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.6554335] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 191.23795    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.54         |
|    explained_variance   | 0.0377       |
|    learning_rate        | 0.0003       |
|    loss                 | -187         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -183         |
|    std                  | 0.166        |
|    value_loss           | 714          |
------------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 268288       |
-------------------------------------
-----------------------------------------
| reward                  | [-4.055373] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 251904      |
| train/                  |             |
|    approx_kl            | 363.5912    |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.4         |
|    explained_variance   | 0.0171      |
|    learning_rate        | 0.0003      |
|    loss                 | -1.1e+03    |
|    n_updates            | 1220        |
|    policy_gradient_loss | -920        |
|    std                  | 0.173       |
|    value_loss           | 2.35e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 3           |
|    time_elapsed         | 35          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -2.13e+03   |
|    n_updates            | 1320        |
|    policy_gradient_loss | -1.88e+03   |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------
| reward             | [-2.191125] |
| time/              |             |
|    fps             | 172         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 247808      |
------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 2           |
|    time_elapsed         | 23          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -114        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -94.7       |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.155282] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 4           |
|    time_elapsed         | 50          |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 349.50906   |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.43        |
|    explained_variance   | 0.0143      |
|    learning_rate        | 0.0003      |
|    loss                 | -897        |
|    n_updates            | 1230        |
|    policy_gradient_loss | -926        |
|    std                  | 0.172       |
|    value_loss           | 2.37e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 172         |
|    iterations           | 4           |
|    time_elapsed         | 47          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -3.43e+03   |
|    n_updates            | 1330        |
|    policy_gradient_loss | -1.92e+03   |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.41934168] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 249856        |
| train/                  |               |
|    approx_kl            | 119.54237     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.6           |
|    explained_variance   | 0.0343        |
|    learning_rate        | 0.0003        |
|    loss                 | -115          |
|    n_updates            | 1210          |
|    policy_gradient_loss | -112          |
|    std                  | 0.162         |
|    value_loss           | 558           |
-------------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 3           |
|    time_elapsed         | 35          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -64.1       |
|    n_updates            | 1320        |
|    policy_gradient_loss | -56.9       |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.5454493] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 325.8344     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.46         |
|    explained_variance   | 0.0183       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.13e+03    |
|    n_updates            | 1240         |
|    policy_gradient_loss | -915         |
|    std                  | 0.17         |
|    value_loss           | 2.32e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 5            |
|    time_elapsed         | 59           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.66e+03    |
|    n_updates            | 1340         |
|    policy_gradient_loss | -3.39e+03    |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.62613434] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 251904        |
| train/                  |               |
|    approx_kl            | 141.49518     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.64          |
|    explained_variance   | 0.0337        |
|    learning_rate        | 0.0003        |
|    loss                 | -107          |
|    n_updates            | 1220          |
|    policy_gradient_loss | -114          |
|    std                  | 0.162         |
|    value_loss           | 877           |
-------------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 174         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -103        |
|    n_updates            | 1330        |
|    policy_gradient_loss | -57.9       |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-3.7786243] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 278528       |
-------------------------------------
-------------------------------------
| reward             | [-0.8163102] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 258048       |
-------------------------------------
------------------------------------------
| reward                  | [-2.8231308] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 127.38881    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.67         |
|    explained_variance   | 0.0418       |
|    learning_rate        | 0.0003       |
|    loss                 | -145         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -125         |
|    std                  | 0.161        |
|    value_loss           | 758          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -110         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -102         |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9646173] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 336.47464    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.807        |
|    explained_variance   | 0.00696      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.88e+03    |
|    n_updates            | 1360         |
|    policy_gradient_loss | -2.69e+03    |
|    std                  | 0.344        |
|    value_loss           | 1.34e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2895141] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 260096       |
| train/                  |              |
|    approx_kl            | 428.96362    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.49         |
|    explained_variance   | 0.0183       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.23e+03    |
|    n_updates            | 1260         |
|    policy_gradient_loss | -1.28e+03    |
|    std                  | 0.172        |
|    value_loss           | 2.28e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7786243] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 278528       |
-------------------------------------
------------------------------------------
| reward                  | [-0.6078568] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 199.40865    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.71         |
|    explained_variance   | 0.0473       |
|    learning_rate        | 0.0003       |
|    loss                 | -193         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -213         |
|    std                  | 0.158        |
|    value_loss           | 632          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.86316013] |
| time/                   |               |
|    fps                  | 180           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 2037.7466     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.835         |
|    explained_variance   | -0.05         |
|    learning_rate        | 0.0003        |
|    loss                 | -2.11e+04     |
|    n_updates            | 1370          |
|    policy_gradient_loss | -1.19e+04     |
|    std                  | 0.349         |
|    value_loss           | 951           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.8064662] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 253.8581     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.52         |
|    explained_variance   | 0.0218       |
|    learning_rate        | 0.0003       |
|    loss                 | -940         |
|    n_updates            | 1270         |
|    policy_gradient_loss | -505         |
|    std                  | 0.172        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9646173] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 336.47464    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.807        |
|    explained_variance   | 0.00696      |
|    learning_rate        | 0.0003       |
|    loss                 | -87.5        |
|    n_updates            | 1360         |
|    policy_gradient_loss | -81          |
|    std                  | 0.344        |
|    value_loss           | 1.34e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.5269348] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 258048       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2530826] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 634.55835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.833        |
|    explained_variance   | 0.00955      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.37e+03    |
|    n_updates            | 1380         |
|    policy_gradient_loss | -3.61e+03    |
|    std                  | 0.349        |
|    value_loss           | 1.2e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.2229884] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 501.17673    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.56         |
|    explained_variance   | 0.0165       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.05e+03    |
|    n_updates            | 1280         |
|    policy_gradient_loss | -1.46e+03    |
|    std                  | 0.168        |
|    value_loss           | 2.26e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.86316013] |
| time/                   |               |
|    fps                  | 176           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 2037.7466     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.835         |
|    explained_variance   | -0.05         |
|    learning_rate        | 0.0003        |
|    loss                 | -634          |
|    n_updates            | 1370          |
|    policy_gradient_loss | -356          |
|    std                  | 0.349         |
|    value_loss           | 951           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.77757347] |
| time/                   |               |
|    fps                  | 166           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 308.57916     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.77          |
|    explained_variance   | 0.0292        |
|    learning_rate        | 0.0003        |
|    loss                 | -318          |
|    n_updates            | 1260          |
|    policy_gradient_loss | -278          |
|    std                  | 0.158         |
|    value_loss           | 493           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.4930831] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 1373.3953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.854        |
|    explained_variance   | -0.105       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.43e+04    |
|    n_updates            | 1390         |
|    policy_gradient_loss | -7.64e+03    |
|    std                  | 0.347        |
|    value_loss           | 829          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4902668] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 270.8941     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.6          |
|    explained_variance   | 0.023        |
|    learning_rate        | 0.0003       |
|    loss                 | -1.35e+03    |
|    n_updates            | 1290         |
|    policy_gradient_loss | -1.01e+03    |
|    std                  | 0.167        |
|    value_loss           | 2.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.2530826] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 634.55835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.833        |
|    explained_variance   | 0.00955      |
|    learning_rate        | 0.0003       |
|    loss                 | -221         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -108         |
|    std                  | 0.349        |
|    value_loss           | 1.2e+03      |
------------------------------------------
-------------------------------------
| reward             | [-1.7847402] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 288768       |
-------------------------------------
------------------------------------------
| reward                  | [-1.0791847] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 165.0846     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.79         |
|    explained_variance   | 0.028        |
|    learning_rate        | 0.0003       |
|    loss                 | -166         |
|    n_updates            | 1270         |
|    policy_gradient_loss | -168         |
|    std                  | 0.158        |
|    value_loss           | 735          |
------------------------------------------
-------------------------------------
| reward             | [-2.7360063] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 268288       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4930831] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 1373.3953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.854        |
|    explained_variance   | -0.105       |
|    learning_rate        | 0.0003       |
|    loss                 | -428         |
|    n_updates            | 1390         |
|    policy_gradient_loss | -229         |
|    std                  | 0.347        |
|    value_loss           | 829          |
------------------------------------------
------------------------------------------
| reward                  | [-1.7328235] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 496.2358     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.871        |
|    explained_variance   | -0.00716     |
|    learning_rate        | 0.0003       |
|    loss                 | -5.28e+03    |
|    n_updates            | 1410         |
|    policy_gradient_loss | -4.3e+03     |
|    std                  | 0.341        |
|    value_loss           | 1.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2739462] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 514.48285    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.82         |
|    explained_variance   | 0.0163       |
|    learning_rate        | 0.0003       |
|    loss                 | -524         |
|    n_updates            | 1280         |
|    policy_gradient_loss | -505         |
|    std                  | 0.157        |
|    value_loss           | 532          |
------------------------------------------
------------------------------------------
| reward                  | [-3.1342592] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 270336       |
| train/                  |              |
|    approx_kl            | 460.7447     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.66         |
|    explained_variance   | 0.0249       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.25e+03    |
|    n_updates            | 1310         |
|    policy_gradient_loss | -1.28e+03    |
|    std                  | 0.165        |
|    value_loss           | 2.06e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.7847402] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 288768       |
-------------------------------------
------------------------------------------
| reward                  | [-2.3012989] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 831.89606    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.901        |
|    explained_variance   | -0.0602      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.21e+04    |
|    n_updates            | 1420         |
|    policy_gradient_loss | -5.17e+03    |
|    std                  | 0.34         |
|    value_loss           | 896          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.53364736] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 266240        |
| train/                  |               |
|    approx_kl            | 150.18506     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.86          |
|    explained_variance   | 0.0265        |
|    learning_rate        | 0.0003        |
|    loss                 | -165          |
|    n_updates            | 1290          |
|    policy_gradient_loss | -148          |
|    std                  | 0.155         |
|    value_loss           | 291           |
-------------------------------------------
-----------------------------------------
| reward                  | [-3.533548] |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 3           |
|    time_elapsed         | 36          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 647.92004   |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.68        |
|    explained_variance   | 0.0322      |
|    learning_rate        | 0.0003      |
|    loss                 | -1.88e+03   |
|    n_updates            | 1320        |
|    policy_gradient_loss | -1.35e+03   |
|    std                  | 0.162       |
|    value_loss           | 1.9e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-1.7328235] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 290816       |
| train/                  |              |
|    approx_kl            | 496.2358     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.871        |
|    explained_variance   | -0.00716     |
|    learning_rate        | 0.0003       |
|    loss                 | -158         |
|    n_updates            | 1410         |
|    policy_gradient_loss | -129         |
|    std                  | 0.341        |
|    value_loss           | 1.08e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.860755] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 799.6845    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.919       |
|    explained_variance   | -0.0102     |
|    learning_rate        | 0.0003      |
|    loss                 | -6.48e+03   |
|    n_updates            | 1430        |
|    policy_gradient_loss | -4.53e+03   |
|    std                  | 0.335       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-0.5043178] |
| time/              |              |
|    fps             | 173          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 268288       |
-------------------------------------
------------------------------------------
| reward                  | [-3.4670172] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 274432       |
| train/                  |              |
|    approx_kl            | 803.04535    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.71         |
|    explained_variance   | 0.0433       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.4e+03     |
|    n_updates            | 1330         |
|    policy_gradient_loss | -1.67e+03    |
|    std                  | 0.162        |
|    value_loss           | 1.77e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3012989] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 831.89606    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.901        |
|    explained_variance   | -0.0602      |
|    learning_rate        | 0.0003       |
|    loss                 | -363         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -155         |
|    std                  | 0.34         |
|    value_loss           | 896          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6532316] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 1502.9814    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.943        |
|    explained_variance   | -0.0066      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.06e+04    |
|    n_updates            | 1440         |
|    policy_gradient_loss | -8.89e+03    |
|    std                  | 0.334        |
|    value_loss           | 964          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.38390258] |
| time/                   |               |
|    fps                  | 166           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 270336        |
| train/                  |               |
|    approx_kl            | 219.73141     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.93          |
|    explained_variance   | 0.0353        |
|    learning_rate        | 0.0003        |
|    loss                 | -228          |
|    n_updates            | 1310          |
|    policy_gradient_loss | -201          |
|    std                  | 0.151         |
|    value_loss           | 795           |
-------------------------------------------
------------------------------------------
| reward                  | [-3.4732924] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 757.1004     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.73         |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.07e+03    |
|    n_updates            | 1340         |
|    policy_gradient_loss | -2.03e+03    |
|    std                  | 0.161        |
|    value_loss           | 1.59e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.860755] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 799.6845    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.919       |
|    explained_variance   | -0.0102     |
|    learning_rate        | 0.0003      |
|    loss                 | -194        |
|    n_updates            | 1430        |
|    policy_gradient_loss | -136        |
|    std                  | 0.335       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-1.9521416] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 299008       |
-------------------------------------
------------------------------------------
| reward                  | [-2.5243611] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 286.8211     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.97         |
|    explained_variance   | 0.0365       |
|    learning_rate        | 0.0003       |
|    loss                 | -312         |
|    n_updates            | 1320         |
|    policy_gradient_loss | -258         |
|    std                  | 0.148        |
|    value_loss           | 524          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6532316] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 1502.9814    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.943        |
|    explained_variance   | -0.0066      |
|    learning_rate        | 0.0003       |
|    loss                 | -318         |
|    n_updates            | 1440         |
|    policy_gradient_loss | -267         |
|    std                  | 0.334        |
|    value_loss           | 964          |
------------------------------------------
-------------------------------------
| reward             | [-0.5689331] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 278528       |
-------------------------------------
------------------------------------------
| reward                  | [-2.2230222] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 2046.6458    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.968        |
|    explained_variance   | -0.0436      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.04e+04    |
|    n_updates            | 1460         |
|    policy_gradient_loss | -6.76e+03    |
|    std                  | 0.331        |
|    value_loss           | 596          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.813874] |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 4           |
|    time_elapsed         | 50          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 286.1271    |
|    clip_range           | 0.2         |
|    entropy_loss         | 2           |
|    explained_variance   | 0.0452      |
|    learning_rate        | 0.0003      |
|    loss                 | -242        |
|    n_updates            | 1330        |
|    policy_gradient_loss | -262        |
|    std                  | 0.148       |
|    value_loss           | 620         |
-----------------------------------------
-------------------------------------
| reward             | [-1.9521416] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 299008       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.86247766] |
| time/                   |               |
|    fps                  | 168           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 280576        |
| train/                  |               |
|    approx_kl            | 1152.8612     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.76          |
|    explained_variance   | 0.0801        |
|    learning_rate        | 0.0003        |
|    loss                 | -3.25e+03     |
|    n_updates            | 1360          |
|    policy_gradient_loss | -2.3e+03      |
|    std                  | 0.158         |
|    value_loss           | 1.04e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.44129673] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 1687.8555     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.98          |
|    explained_variance   | -0.0754       |
|    learning_rate        | 0.0003        |
|    loss                 | -1.81e+04     |
|    n_updates            | 1470          |
|    policy_gradient_loss | -8.77e+03     |
|    std                  | 0.329         |
|    value_loss           | 864           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.9650671] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 338.26117    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.03         |
|    explained_variance   | 0.045        |
|    learning_rate        | 0.0003       |
|    loss                 | -275         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -288         |
|    std                  | 0.146        |
|    value_loss           | 823          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2230222] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 2046.6458    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.968        |
|    explained_variance   | -0.0436      |
|    learning_rate        | 0.0003       |
|    loss                 | -611         |
|    n_updates            | 1460         |
|    policy_gradient_loss | -203         |
|    std                  | 0.331        |
|    value_loss           | 596          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.062077] |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 1099.2903   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.997       |
|    explained_variance   | -0.0383     |
|    learning_rate        | 0.0003      |
|    loss                 | -8.5e+03    |
|    n_updates            | 1480        |
|    policy_gradient_loss | -6.47e+03   |
|    std                  | 0.327       |
|    value_loss           | 938         |
-----------------------------------------
------------------------------------------
| reward                  | [-1.1675407] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 1321.5461    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.78         |
|    explained_variance   | 0.0627       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.32e+03    |
|    n_updates            | 1370         |
|    policy_gradient_loss | -3.16e+03    |
|    std                  | 0.157        |
|    value_loss           | 1.32e+03     |
------------------------------------------
--------------------------------------
| reward             | [-0.47649306] |
| time/              |               |
|    fps             | 171           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 278528        |
--------------------------------------
-------------------------------------------
| reward                  | [-0.44129673] |
| time/                   |               |
|    fps                  | 176           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 1687.8555     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.98          |
|    explained_variance   | -0.0754       |
|    learning_rate        | 0.0003        |
|    loss                 | -544          |
|    n_updates            | 1470          |
|    policy_gradient_loss | -263          |
|    std                  | 0.329         |
|    value_loss           | 864           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.5057038] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 1764.5735    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | -0.0299      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.41e+04    |
|    n_updates            | 1490         |
|    policy_gradient_loss | -7.23e+03    |
|    std                  | 0.326        |
|    value_loss           | 806          |
------------------------------------------
------------------------------------------
| reward                  | [-1.2817545] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 1909.7224    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.8          |
|    explained_variance   | 0.0956       |
|    learning_rate        | 0.0003       |
|    loss                 | -6.58e+03    |
|    n_updates            | 1380         |
|    policy_gradient_loss | -5.04e+03    |
|    std                  | 0.156        |
|    value_loss           | 957          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.062077] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 1099.2903   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.997       |
|    explained_variance   | -0.0383     |
|    learning_rate        | 0.0003      |
|    loss                 | -257        |
|    n_updates            | 1480        |
|    policy_gradient_loss | -194        |
|    std                  | 0.327       |
|    value_loss           | 938         |
-----------------------------------------
-------------------------------------
| reward             | [-1.6954689] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 309248       |
-------------------------------------
------------------------------------------
| reward                  | [-0.3388148] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 219.76784    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.1          |
|    explained_variance   | 0.0279       |
|    learning_rate        | 0.0003       |
|    loss                 | -240         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -191         |
|    std                  | 0.143        |
|    value_loss           | 590          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6860555] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 789.51917    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.84         |
|    explained_variance   | 0.0877       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.67e+03    |
|    n_updates            | 1390         |
|    policy_gradient_loss | -2.1e+03     |
|    std                  | 0.153        |
|    value_loss           | 967          |
------------------------------------------
------------------------------------------
| reward                  | [-1.5057038] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 1764.5735    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | -0.0299      |
|    learning_rate        | 0.0003       |
|    loss                 | -722         |
|    n_updates            | 1490         |
|    policy_gradient_loss | -217         |
|    std                  | 0.326        |
|    value_loss           | 806          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2569616] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 2666.0024    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | 0.00176      |
|    learning_rate        | 0.0003       |
|    loss                 | -2.77e+04    |
|    n_updates            | 1510         |
|    policy_gradient_loss | -1.31e+04    |
|    std                  | 0.316        |
|    value_loss           | 888          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.95959157] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 253.61203     |
|    clip_range           | 0.2           |
|    entropy_loss         | 2.13          |
|    explained_variance   | 0.0258        |
|    learning_rate        | 0.0003        |
|    loss                 | -261          |
|    n_updates            | 1370          |
|    policy_gradient_loss | -233          |
|    std                  | 0.142         |
|    value_loss           | 754           |
-------------------------------------------
-------------------------------------
| reward             | [-2.1537154] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 288768       |
-------------------------------------
-------------------------------------
| reward             | [-1.6954689] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 309248       |
-------------------------------------
------------------------------------------
| reward                  | [-1.9326414] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 2164.9014    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.00968     |
|    learning_rate        | 0.0003       |
|    loss                 | -3.06e+04    |
|    n_updates            | 1520         |
|    policy_gradient_loss | -6.29e+03    |
|    std                  | 0.318        |
|    value_loss           | 1.21e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.6388788] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 240.96175    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.15         |
|    explained_variance   | 0.0276       |
|    learning_rate        | 0.0003       |
|    loss                 | -160         |
|    n_updates            | 1380         |
|    policy_gradient_loss | -225         |
|    std                  | 0.143        |
|    value_loss           | 321          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.457864] |
| time/                   |             |
|    fps                  | 168         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 290816      |
| train/                  |             |
|    approx_kl            | 771.6596    |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.9         |
|    explained_variance   | 0.0824      |
|    learning_rate        | 0.0003      |
|    loss                 | -2.15e+03   |
|    n_updates            | 1410        |
|    policy_gradient_loss | -2.33e+03   |
|    std                  | 0.151       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.2569616] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 2666.0024    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | 0.00176      |
|    learning_rate        | 0.0003       |
|    loss                 | -831         |
|    n_updates            | 1510         |
|    policy_gradient_loss | -394         |
|    std                  | 0.316        |
|    value_loss           | 888          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6199595] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 3188.1294    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.0158      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.38e+04    |
|    n_updates            | 1530         |
|    policy_gradient_loss | -1.76e+04    |
|    std                  | 0.314        |
|    value_loss           | 868          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6128109] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 312.04785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.17         |
|    explained_variance   | 0.0244       |
|    learning_rate        | 0.0003       |
|    loss                 | -375         |
|    n_updates            | 1390         |
|    policy_gradient_loss | -287         |
|    std                  | 0.142        |
|    value_loss           | 857          |
------------------------------------------
------------------------------------------
| reward                  | [-2.5651727] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 2215.986     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.95         |
|    explained_variance   | 0.0731       |
|    learning_rate        | 0.0003       |
|    loss                 | -6.42e+03    |
|    n_updates            | 1420         |
|    policy_gradient_loss | -5.17e+03    |
|    std                  | 0.148        |
|    value_loss           | 1.2e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.9326414] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 2164.9014    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.00968     |
|    learning_rate        | 0.0003       |
|    loss                 | -917         |
|    n_updates            | 1520         |
|    policy_gradient_loss | -189         |
|    std                  | 0.318        |
|    value_loss           | 1.21e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2143655] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 1703.9617    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | -0.0894      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.84e+04    |
|    n_updates            | 1540         |
|    policy_gradient_loss | -8.05e+03    |
|    std                  | 0.313        |
|    value_loss           | 763          |
------------------------------------------
--------------------------------------
| reward             | [-0.46173236] |
| time/              |               |
|    fps             | 172           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 288768        |
--------------------------------------
------------------------------------------
| reward                  | [-2.3532734] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 2261.3118    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.99         |
|    explained_variance   | 0.089        |
|    learning_rate        | 0.0003       |
|    loss                 | -5.25e+03    |
|    n_updates            | 1430         |
|    policy_gradient_loss | -3e+03       |
|    std                  | 0.145        |
|    value_loss           | 966          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6199595] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 3188.1294    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.06         |
|    explained_variance   | -0.0158      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.02e+03    |
|    n_updates            | 1530         |
|    policy_gradient_loss | -527         |
|    std                  | 0.314        |
|    value_loss           | 868          |
------------------------------------------
-------------------------------------
| reward             | [-1.5131543] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 319488       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.39416596] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 290816        |
| train/                  |               |
|    approx_kl            | 343.002       |
|    clip_range           | 0.2           |
|    entropy_loss         | 2.21          |
|    explained_variance   | 0.0289        |
|    learning_rate        | 0.0003        |
|    loss                 | -345          |
|    n_updates            | 1410          |
|    policy_gradient_loss | -333          |
|    std                  | 0.14          |
|    value_loss           | 549           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.7380087] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 1054.8429    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.03         |
|    explained_variance   | 0.0857       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.6e+03     |
|    n_updates            | 1440         |
|    policy_gradient_loss | -2.43e+03    |
|    std                  | 0.144        |
|    value_loss           | 957          |
------------------------------------------
------------------------------------------
| reward                  | [-1.2143655] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 1703.9617    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.07         |
|    explained_variance   | -0.0894      |
|    learning_rate        | 0.0003       |
|    loss                 | -552         |
|    n_updates            | 1540         |
|    policy_gradient_loss | -242         |
|    std                  | 0.313        |
|    value_loss           | 763          |
------------------------------------------
------------------------------------------
| reward                  | [-2.6689618] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 1401.6238    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.09         |
|    explained_variance   | -0.0797      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.73e+04    |
|    n_updates            | 1560         |
|    policy_gradient_loss | -7.69e+03    |
|    std                  | 0.309        |
|    value_loss           | 736          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5276216] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 698.24915    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.22         |
|    explained_variance   | -0.0991      |
|    learning_rate        | 0.0003       |
|    loss                 | -715         |
|    n_updates            | 1420         |
|    policy_gradient_loss | -659         |
|    std                  | 0.14         |
|    value_loss           | 54.7         |
------------------------------------------
-------------------------------------
| reward             | [-0.3578515] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 299008       |
-------------------------------------
-------------------------------------
| reward             | [-1.5131543] |
| time/              |              |
|    fps             | 181          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 319488       |
-------------------------------------
------------------------------------------
| reward                  | [-2.8958263] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 1261.7434    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.12         |
|    explained_variance   | -0.0943      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.41e+04    |
|    n_updates            | 1570         |
|    policy_gradient_loss | -6.69e+03    |
|    std                  | 0.307        |
|    value_loss           | 895          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5099924] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 231.28769    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.25         |
|    explained_variance   | 0.0249       |
|    learning_rate        | 0.0003       |
|    loss                 | -225         |
|    n_updates            | 1430         |
|    policy_gradient_loss | -217         |
|    std                  | 0.136        |
|    value_loss           | 556          |
------------------------------------------
------------------------------------------
| reward                  | [-0.6776031] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 301056       |
| train/                  |              |
|    approx_kl            | 2065.7297    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.08         |
|    explained_variance   | 0.0924       |
|    learning_rate        | 0.0003       |
|    loss                 | -8.44e+03    |
|    n_updates            | 1460         |
|    policy_gradient_loss | -3.93e+03    |
|    std                  | 0.142        |
|    value_loss           | 958          |
------------------------------------------
------------------------------------------
| reward                  | [-2.6689618] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 1401.6238    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.09         |
|    explained_variance   | -0.0797      |
|    learning_rate        | 0.0003       |
|    loss                 | -520         |
|    n_updates            | 1560         |
|    policy_gradient_loss | -231         |
|    std                  | 0.309        |
|    value_loss           | 736          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.90219796] |
| time/                   |               |
|    fps                  | 178           |
|    iterations           | 4             |
|    time_elapsed         | 45            |
|    total_timesteps      | 325632        |
| train/                  |               |
|    approx_kl            | 2163.672      |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.13          |
|    explained_variance   | -0.0711       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.2e+04      |
|    n_updates            | 1580          |
|    policy_gradient_loss | -1.08e+04     |
|    std                  | 0.307         |
|    value_loss           | 794           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.62140465] |
| time/                   |               |
|    fps                  | 161           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 296960        |
| train/                  |               |
|    approx_kl            | 614.4721      |
|    clip_range           | 0.2           |
|    entropy_loss         | 2.3           |
|    explained_variance   | 0.0265        |
|    learning_rate        | 0.0003        |
|    loss                 | -589          |
|    n_updates            | 1440          |
|    policy_gradient_loss | -496          |
|    std                  | 0.134         |
|    value_loss           | 333           |
-------------------------------------------
------------------------------------------
| reward                  | [-0.9235054] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 303104       |
| train/                  |              |
|    approx_kl            | 1056.0669    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.09         |
|    explained_variance   | 0.0845       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.12e+03    |
|    n_updates            | 1470         |
|    policy_gradient_loss | -1.21e+03    |
|    std                  | 0.141        |
|    value_loss           | 1.02e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.8958263] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 1261.7434    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.12         |
|    explained_variance   | -0.0943      |
|    learning_rate        | 0.0003       |
|    loss                 | -422         |
|    n_updates            | 1570         |
|    policy_gradient_loss | -201         |
|    std                  | 0.307        |
|    value_loss           | 895          |
------------------------------------------
------------------------------------------
| reward                  | [-1.1550593] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 890.99164    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.12         |
|    explained_variance   | -0.0564      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.81e+03    |
|    n_updates            | 1590         |
|    policy_gradient_loss | -4.2e+03     |
|    std                  | 0.309        |
|    value_loss           | 694          |
------------------------------------------
-------------------------------------
| reward             | [-0.3725288] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 299008       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4341882] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 305152       |
| train/                  |              |
|    approx_kl            | 1609.576     |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.11         |
|    explained_variance   | 0.0908       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.53e+03    |
|    n_updates            | 1480         |
|    policy_gradient_loss | -3.53e+03    |
|    std                  | 0.14         |
|    value_loss           | 940          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.90219796] |
| time/                   |               |
|    fps                  | 175           |
|    iterations           | 4             |
|    time_elapsed         | 46            |
|    total_timesteps      | 325632        |
| train/                  |               |
|    approx_kl            | 2163.672      |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.13          |
|    explained_variance   | -0.0711       |
|    learning_rate        | 0.0003        |
|    loss                 | -659          |
|    n_updates            | 1580          |
|    policy_gradient_loss | -325          |
|    std                  | 0.307         |
|    value_loss           | 794           |
-------------------------------------------
-------------------------------------
| reward             | [-1.2757176] |
| time/              |              |
|    fps             | 181          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 329728       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.37238625] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 301056        |
| train/                  |               |
|    approx_kl            | 226.00545     |
|    clip_range           | 0.2           |
|    entropy_loss         | 2.36          |
|    explained_variance   | 0.0397        |
|    learning_rate        | 0.0003        |
|    loss                 | -248          |
|    n_updates            | 1460          |
|    policy_gradient_loss | -203          |
|    std                  | 0.131         |
|    value_loss           | 1.09e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.1550593] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 890.99164    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.12         |
|    explained_variance   | -0.0564      |
|    learning_rate        | 0.0003       |
|    loss                 | -264         |
|    n_updates            | 1590         |
|    policy_gradient_loss | -126         |
|    std                  | 0.309        |
|    value_loss           | 694          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6096444] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 4149.3105    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.13         |
|    explained_variance   | 0.0884       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.13e+04    |
|    n_updates            | 1490         |
|    policy_gradient_loss | -6.29e+03    |
|    std                  | 0.14         |
|    value_loss           | 930          |
------------------------------------------
------------------------------------------
| reward                  | [-1.2780621] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 331776       |
| train/                  |              |
|    approx_kl            | 1132.7843    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.16         |
|    explained_variance   | -0.0658      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.36e+04    |
|    n_updates            | 1610         |
|    policy_gradient_loss | -5.58e+03    |
|    std                  | 0.304        |
|    value_loss           | 807          |
------------------------------------------
-------------------------------------
| reward             | [-1.2757176] |
| time/              |              |
|    fps             | 180          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 329728       |
-------------------------------------
------------------------------------------
| reward                  | [-0.4113659] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 303104       |
| train/                  |              |
|    approx_kl            | 554.74786    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.41         |
|    explained_variance   | 0.0349       |
|    learning_rate        | 0.0003       |
|    loss                 | -509         |
|    n_updates            | 1470         |
|    policy_gradient_loss | -500         |
|    std                  | 0.129        |
|    value_loss           | 323          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3508794] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 1526.2327    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | -0.078       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.53e+04    |
|    n_updates            | 1620         |
|    policy_gradient_loss | -1.03e+04    |
|    std                  | 0.303        |
|    value_loss           | 679          |
------------------------------------------
------------------------------------
| reward             | [-2.436783] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 309248      |
------------------------------------
------------------------------------------
| reward                  | [-1.2780621] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 331776       |
| train/                  |              |
|    approx_kl            | 1132.7843    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.16         |
|    explained_variance   | -0.0658      |
|    learning_rate        | 0.0003       |
|    loss                 | -409         |
|    n_updates            | 1610         |
|    policy_gradient_loss | -167         |
|    std                  | 0.304        |
|    value_loss           | 807          |
------------------------------------------
------------------------------------------
| reward                  | [-1.5007566] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 993.3564     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.19         |
|    explained_variance   | -0.0657      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.8e+03     |
|    n_updates            | 1630         |
|    policy_gradient_loss | -7.28e+03    |
|    std                  | 0.305        |
|    value_loss           | 820          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.044059] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 4           |
|    time_elapsed         | 50          |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 562.4354    |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.44        |
|    explained_variance   | 0.0413      |
|    learning_rate        | 0.0003      |
|    loss                 | -550        |
|    n_updates            | 1480        |
|    policy_gradient_loss | -424        |
|    std                  | 0.128       |
|    value_loss           | 541         |
-----------------------------------------
------------------------------------------
| reward                  | [-3.0599475] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 2038.7764    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.15         |
|    explained_variance   | 0.0361       |
|    learning_rate        | 0.0003       |
|    loss                 | -6.7e+03     |
|    n_updates            | 1510         |
|    policy_gradient_loss | -3.64e+03    |
|    std                  | 0.139        |
|    value_loss           | 1.76e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3508794] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 1526.2327    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | -0.078       |
|    learning_rate        | 0.0003       |
|    loss                 | -460         |
|    n_updates            | 1620         |
|    policy_gradient_loss | -310         |
|    std                  | 0.303        |
|    value_loss           | 679          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8684181] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 1834.22      |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | -0.0694      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.94e+04    |
|    n_updates            | 1640         |
|    policy_gradient_loss | -1.07e+04    |
|    std                  | 0.306        |
|    value_loss           | 742          |
------------------------------------------
------------------------------------------
| reward                  | [-1.1537532] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 929.7112     |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.46         |
|    explained_variance   | 0.0339       |
|    learning_rate        | 0.0003       |
|    loss                 | -974         |
|    n_updates            | 1490         |
|    policy_gradient_loss | -896         |
|    std                  | 0.127        |
|    value_loss           | 310          |
------------------------------------------
------------------------------------------
| reward                  | [-3.5664444] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 321.6234     |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.17         |
|    explained_variance   | 0.0288       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.26e+03    |
|    n_updates            | 1520         |
|    policy_gradient_loss | -1.52e+03    |
|    std                  | 0.139        |
|    value_loss           | 2.02e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5007566] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 993.3564     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.19         |
|    explained_variance   | -0.0657      |
|    learning_rate        | 0.0003       |
|    loss                 | -294         |
|    n_updates            | 1630         |
|    policy_gradient_loss | -218         |
|    std                  | 0.305        |
|    value_loss           | 820          |
------------------------------------------
-------------------------------------
| reward             | [-1.4154465] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 339968       |
-------------------------------------
-------------------------------------
| reward             | [-1.6832281] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 309248       |
-------------------------------------
------------------------------------------
| reward                  | [-3.7259064] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 2250.3477    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.19         |
|    explained_variance   | 0.0274       |
|    learning_rate        | 0.0003       |
|    loss                 | -7.2e+03     |
|    n_updates            | 1530         |
|    policy_gradient_loss | -3.96e+03    |
|    std                  | 0.139        |
|    value_loss           | 2.13e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8684181] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 1834.22      |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | -0.0694      |
|    learning_rate        | 0.0003       |
|    loss                 | -581         |
|    n_updates            | 1640         |
|    policy_gradient_loss | -325         |
|    std                  | 0.306        |
|    value_loss           | 742          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0654643] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 342016       |
| train/                  |              |
|    approx_kl            | 817.6089     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.21         |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.15e+03    |
|    n_updates            | 1660         |
|    policy_gradient_loss | -6.55e+03    |
|    std                  | 0.308        |
|    value_loss           | 756          |
------------------------------------------
------------------------------------------
| reward                  | [-2.4405344] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 362.8942     |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.53         |
|    explained_variance   | 0.038        |
|    learning_rate        | 0.0003       |
|    loss                 | -339         |
|    n_updates            | 1510         |
|    policy_gradient_loss | -247         |
|    std                  | 0.125        |
|    value_loss           | 1.01e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.233064] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 5           |
|    time_elapsed         | 63          |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 936.7063    |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.2         |
|    explained_variance   | 0.0348      |
|    learning_rate        | 0.0003      |
|    loss                 | -2.67e+03   |
|    n_updates            | 1540        |
|    policy_gradient_loss | -2.21e+03   |
|    std                  | 0.14        |
|    value_loss           | 1.73e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-1.4154465] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 339968       |
-------------------------------------
------------------------------------------
| reward                  | [-2.3107834] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 838.7041     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | -0.0723      |
|    learning_rate        | 0.0003       |
|    loss                 | -7.95e+03    |
|    n_updates            | 1670         |
|    policy_gradient_loss | -7.21e+03    |
|    std                  | 0.309        |
|    value_loss           | 685          |
------------------------------------------
------------------------------------------
| reward                  | [-2.7107038] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 564.2081     |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.55         |
|    explained_variance   | 0.0481       |
|    learning_rate        | 0.0003       |
|    loss                 | -430         |
|    n_updates            | 1520         |
|    policy_gradient_loss | -539         |
|    std                  | 0.124        |
|    value_loss           | 869          |
------------------------------------------
-------------------------------------
| reward             | [-4.5454297] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 319488       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.29458213] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 4             |
|    time_elapsed         | 46            |
|    total_timesteps      | 346112        |
| train/                  |               |
|    approx_kl            | 2480.199      |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.22          |
|    explained_variance   | -0.0876       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.15e+04     |
|    n_updates            | 1680          |
|    policy_gradient_loss | -1.08e+04     |
|    std                  | 0.309         |
|    value_loss           | 720           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.0654643] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 342016       |
| train/                  |              |
|    approx_kl            | 817.6089     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.21         |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -245         |
|    n_updates            | 1660         |
|    policy_gradient_loss | -196         |
|    std                  | 0.308        |
|    value_loss           | 756          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.976281] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 4           |
|    time_elapsed         | 50          |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 585.96136   |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.56        |
|    explained_variance   | 0.0421      |
|    learning_rate        | 0.0003      |
|    loss                 | -765        |
|    n_updates            | 1530        |
|    policy_gradient_loss | -529        |
|    std                  | 0.125       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.40028003] |
| time/                   |               |
|    fps                  | 168           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 321536        |
| train/                  |               |
|    approx_kl            | 1142.7954     |
|    clip_range           | 0.2           |
|    entropy_loss         | 2.26          |
|    explained_variance   | 0.0272        |
|    learning_rate        | 0.0003        |
|    loss                 | -4.45e+03     |
|    n_updates            | 1560          |
|    policy_gradient_loss | -2.27e+03     |
|    std                  | 0.136         |
|    value_loss           | 2.19e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.1889738] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 2183.1836    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.23         |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.65e+04    |
|    n_updates            | 1690         |
|    policy_gradient_loss | -1.2e+04     |
|    std                  | 0.31         |
|    value_loss           | 584          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3107834] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 838.7041     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | -0.0723      |
|    learning_rate        | 0.0003       |
|    loss                 | -239         |
|    n_updates            | 1670         |
|    policy_gradient_loss | -216         |
|    std                  | 0.309        |
|    value_loss           | 685          |
------------------------------------------
------------------------------------------
| reward                  | [-1.0697916] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 1350.7026    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.27         |
|    explained_variance   | 0.0344       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.78e+03    |
|    n_updates            | 1570         |
|    policy_gradient_loss | -2.22e+03    |
|    std                  | 0.137        |
|    value_loss           | 1.85e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1946003] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 536.90015    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.59         |
|    explained_variance   | 0.038        |
|    learning_rate        | 0.0003       |
|    loss                 | -407         |
|    n_updates            | 1540         |
|    policy_gradient_loss | -472         |
|    std                  | 0.122        |
|    value_loss           | 674          |
------------------------------------------
-------------------------------------
| reward             | [-1.4144108] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 350208       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.29458213] |
| time/                   |               |
|    fps                  | 174           |
|    iterations           | 4             |
|    time_elapsed         | 46            |
|    total_timesteps      | 346112        |
| train/                  |               |
|    approx_kl            | 2480.199      |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.22          |
|    explained_variance   | -0.0876       |
|    learning_rate        | 0.0003        |
|    loss                 | -644          |
|    n_updates            | 1680          |
|    policy_gradient_loss | -323          |
|    std                  | 0.309         |
|    value_loss           | 720           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.3508499] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 325632       |
| train/                  |              |
|    approx_kl            | 2970.29      |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.28         |
|    explained_variance   | 0.0308       |
|    learning_rate        | 0.0003       |
|    loss                 | -7.14e+03    |
|    n_updates            | 1580         |
|    policy_gradient_loss | -6.16e+03    |
|    std                  | 0.137        |
|    value_loss           | 2.11e+03     |
------------------------------------------
------------------------------------
| reward             | [-3.147072] |
| time/              |             |
|    fps             | 171         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 319488      |
------------------------------------
------------------------------------------
| reward                  | [-1.6216848] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 1575.1588    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.5e+04     |
|    n_updates            | 1710         |
|    policy_gradient_loss | -1.05e+04    |
|    std                  | 0.31         |
|    value_loss           | 752          |
------------------------------------------
------------------------------------------
| reward                  | [-1.1889738] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 2183.1836    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.23         |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -795         |
|    n_updates            | 1690         |
|    policy_gradient_loss | -360         |
|    std                  | 0.31         |
|    value_loss           | 584          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.45662582] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 3279.5828     |
|    clip_range           | 0.2           |
|    entropy_loss         | 2.29          |
|    explained_variance   | 0.0408        |
|    learning_rate        | 0.0003        |
|    loss                 | -9.66e+03     |
|    n_updates            | 1590          |
|    policy_gradient_loss | -6.38e+03     |
|    std                  | 0.138         |
|    value_loss           | 1.49e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-0.5435829] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 321536       |
| train/                  |              |
|    approx_kl            | 420.32352    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.65         |
|    explained_variance   | 0.0273       |
|    learning_rate        | 0.0003       |
|    loss                 | -455         |
|    n_updates            | 1560         |
|    policy_gradient_loss | -381         |
|    std                  | 0.119        |
|    value_loss           | 1.03e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0997016] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 354304       |
| train/                  |              |
|    approx_kl            | 1413.2979    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.24         |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.45e+04    |
|    n_updates            | 1720         |
|    policy_gradient_loss | -9.78e+03    |
|    std                  | 0.307        |
|    value_loss           | 660          |
------------------------------------------
-------------------------------------
| reward             | [-1.4144108] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 350208       |
-------------------------------------
-------------------------------------
| reward             | [-1.8796877] |
| time/              |              |
|    fps             | 173          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 329728       |
-------------------------------------
------------------------------------------
| reward                  | [-0.9304021] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 896.36475    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.67         |
|    explained_variance   | 0.0364       |
|    learning_rate        | 0.0003       |
|    loss                 | -695         |
|    n_updates            | 1570         |
|    policy_gradient_loss | -844         |
|    std                  | 0.118        |
|    value_loss           | 641          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8927789] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 356352       |
| train/                  |              |
|    approx_kl            | 862.0071     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.25         |
|    explained_variance   | -0.123       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.04e+03    |
|    n_updates            | 1730         |
|    policy_gradient_loss | -7.16e+03    |
|    std                  | 0.311        |
|    value_loss           | 815          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6216848] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 1575.1588    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -451         |
|    n_updates            | 1710         |
|    policy_gradient_loss | -314         |
|    std                  | 0.31         |
|    value_loss           | 752          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2654479] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 331776       |
| train/                  |              |
|    approx_kl            | 1027.9381    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.32         |
|    explained_variance   | 0.032        |
|    learning_rate        | 0.0003       |
|    loss                 | -3.06e+03    |
|    n_updates            | 1610         |
|    policy_gradient_loss | -1.96e+03    |
|    std                  | 0.138        |
|    value_loss           | 1.61e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1232805] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 325632       |
| train/                  |              |
|    approx_kl            | 633.2157     |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.7          |
|    explained_variance   | 0.0298       |
|    learning_rate        | 0.0003       |
|    loss                 | -578         |
|    n_updates            | 1580         |
|    policy_gradient_loss | -530         |
|    std                  | 0.118        |
|    value_loss           | 986          |
------------------------------------------
------------------------------------------
| reward                  | [-1.9371482] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 2538.542     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.25         |
|    explained_variance   | -0.101       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.71e+04    |
|    n_updates            | 1740         |
|    policy_gradient_loss | -1.44e+04    |
|    std                  | 0.312        |
|    value_loss           | 758          |
------------------------------------------
------------------------------------------
| reward                  | [-1.0997016] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 354304       |
| train/                  |              |
|    approx_kl            | 1413.2979    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.24         |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -437         |
|    n_updates            | 1720         |
|    policy_gradient_loss | -294         |
|    std                  | 0.307        |
|    value_loss           | 660          |
------------------------------------------
------------------------------------------
| reward                  | [-3.4667883] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 5672.433     |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.34         |
|    explained_variance   | 0.0296       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.68e+04    |
|    n_updates            | 1620         |
|    policy_gradient_loss | -1e+04       |
|    std                  | 0.137        |
|    value_loss           | 1.78e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.8418007] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 360448       |
-------------------------------------
------------------------------------------
| reward                  | [-1.8927789] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 356352       |
| train/                  |              |
|    approx_kl            | 862.0071     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.25         |
|    explained_variance   | -0.123       |
|    learning_rate        | 0.0003       |
|    loss                 | -272         |
|    n_updates            | 1730         |
|    policy_gradient_loss | -215         |
|    std                  | 0.311        |
|    value_loss           | 815          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.44306967] |
| time/                   |               |
|    fps                  | 160           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 447.12018     |
|    clip_range           | 0.2           |
|    entropy_loss         | 2.73          |
|    explained_variance   | 0.0378        |
|    learning_rate        | 0.0003        |
|    loss                 | -588          |
|    n_updates            | 1590          |
|    policy_gradient_loss | -591          |
|    std                  | 0.116         |
|    value_loss           | 925           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.4384053] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 362496       |
| train/                  |              |
|    approx_kl            | 4687.436     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.28         |
|    explained_variance   | -0.101       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.27e+04    |
|    n_updates            | 1760         |
|    policy_gradient_loss | -2.95e+04    |
|    std                  | 0.308        |
|    value_loss           | 784          |
------------------------------------------
------------------------------------------
| reward                  | [-3.7747917] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 1332.5458    |
|    clip_range           | 0.2          |
|    entropy_loss         | 2.35         |
|    explained_variance   | 0.0254       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.27e+03    |
|    n_updates            | 1630         |
|    policy_gradient_loss | -2.86e+03    |
|    std                  | 0.137        |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9371482] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 2538.542     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.25         |
|    explained_variance   | -0.101       |
|    learning_rate        | 0.0003       |
|    loss                 | -812         |
|    n_updates            | 1740         |
|    policy_gradient_loss | -433         |
|    std                  | 0.312        |
|    value_loss           | 758          |
------------------------------------------
-------------------------------------
| reward             | [-0.6049772] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 329728       |
-------------------------------------
slurmstepd: error: *** STEP 76104.2 ON ppo.ist.berkeley.edu CANCELLED AT 2023-10-17T15:59:05 ***
slurmstepd: error: *** STEP 76104.1 ON gan.ist.berkeley.edu CANCELLED AT 2023-10-17T15:59:05 ***
slurmstepd: error: *** STEP 76104.3 ON sac.ist.berkeley.edu CANCELLED AT 2023-10-17T22:59:05 ***
slurmstepd: error: *** JOB 76104 ON airl.ist.berkeley.edu CANCELLED AT 2023-10-17T22:59:05 ***
slurmstepd: error: *** STEP 76104.0 ON airl.ist.berkeley.edu CANCELLED AT 2023-10-17T22:59:05 ***
