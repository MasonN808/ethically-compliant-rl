wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_215539-olah08ke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: ⭐️ View project at https://wandb.ai/ecrl/PPO
wandb: 🚀 View run at https://wandb.ai/ecrl/PPO/runs/olah08ke
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_145539-zt5asblj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: ⭐️ View project at https://wandb.ai/ecrl/PPO
wandb: 🚀 View run at https://wandb.ai/ecrl/PPO/runs/zt5asblj
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_215539-xk36tbpr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: ⭐️ View project at https://wandb.ai/ecrl/PPO
wandb: 🚀 View run at https://wandb.ai/ecrl/PPO/runs/xk36tbpr
wandb: wandb version 0.15.12 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231017_145539-mey6y6qb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-highway-parking
wandb: ⭐️ View project at https://wandb.ai/ecrl/PPO
wandb: 🚀 View run at https://wandb.ai/ecrl/PPO/runs/mey6y6qb
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 802: system not yet initialized (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
-------------------------------------
| reward             | [-1.4640868] |
| time/              |              |
|    fps             | 182          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 2048         |
-------------------------------------
Using cuda device
-------------------------------------
| reward             | [-0.5640039] |
| time/              |              |
|    fps             | 158          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2048         |
-------------------------------------
Using cuda device
-------------------------------------
| reward             | [-0.5640039] |
| time/              |              |
|    fps             | 158          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2048         |
-------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 183           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.443        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0793       |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.58534485] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.15166444    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0414        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.443        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0793       |
|    std                  | 0.993         |
|    value_loss           | 298           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.48300558] |
| time/                   |               |
|    fps                  | 159           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 4096          |
| train/                  |               |
|    approx_kl            | 0.09492223    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.85         |
|    explained_variance   | 0.0942        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.049        |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.0491       |
|    std                  | 1.01          |
|    value_loss           | 160           |
-------------------------------------------
------------------------------------------
| reward                  | [-0.4830056] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 2            |
|    time_elapsed         | 25           |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.094922215  |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | 0.0942       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.049       |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.0491      |
|    std                  | 1.01         |
|    value_loss           | 160          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 3             |
|    time_elapsed         | 33            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.791        |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.248        |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.78479373] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.54889315    |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.0594        |
|    learning_rate        | 0.0003        |
|    loss                 | -0.791        |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.248        |
|    std                  | 0.996         |
|    value_loss           | 196           |
-------------------------------------------
-----------------------------------------
| reward                  | [-2.153896] |
| time/                   |             |
|    fps                  | 160         |
|    iterations           | 3           |
|    time_elapsed         | 38          |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.11541881  |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.0104      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.186      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0596     |
|    std                  | 1.01        |
|    value_loss           | 625         |
-----------------------------------------
------------------------------------------
| reward                  | [-2.1538985] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.11541857   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0104       |
|    learning_rate        | 0.0003       |
|    loss                 | -0.186       |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.0596      |
|    std                  | 1.01         |
|    value_loss           | 625          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.634       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.216       |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5839704] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.5152277    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.102        |
|    learning_rate        | 0.0003       |
|    loss                 | -0.634       |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.216       |
|    std                  | 1            |
|    value_loss           | 306          |
------------------------------------------
------------------------------------------
| reward                  | [-2.6212974] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.06942722   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | -0.0122      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0569      |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0331      |
|    std                  | 1            |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.6212268] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 4            |
|    time_elapsed         | 51           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.06937348   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | -0.0122      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.0569      |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0331      |
|    std                  | 1            |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.331       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.161       |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/save_util.py:283: UserWarning: Path 'PPO_penalty/models' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
------------------------------------------
| reward                  | [-1.3529372] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.26126283   |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | -0.0076      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.331       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.161       |
|    std                  | 0.998        |
|    value_loss           | 900          |
------------------------------------------
------------------------------------------
| reward                  | [-3.2562778] |
| time/                   |              |
|    fps                  | 159          |
|    iterations           | 5            |
|    time_elapsed         | 64           |
|    total_timesteps      | 10240        |
| train/                  |              |
|    approx_kl            | 0.5236391    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.00946      |
|    learning_rate        | 0.0003       |
|    loss                 | -0.898       |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.217       |
|    std                  | 1.02         |
|    value_loss           | 2.1e+03      |
------------------------------------------
-----------------------------------------
| reward                  | [-3.256111] |
| time/                   |             |
|    fps                  | 159         |
|    iterations           | 5           |
|    time_elapsed         | 64          |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.52337277  |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.00946     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.898      |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.217      |
|    std                  | 1.02        |
|    value_loss           | 2.1e+03     |
-----------------------------------------
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-2.4382849] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-3.9111745] |
| time/              |              |
|    fps             | 173          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 12288        |
-------------------------------------
-------------------------------------
| reward             | [-3.8846962] |
| time/              |              |
|    fps             | 169          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 12288        |
-------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.27        |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.399       |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2339594] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.0407298    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0155       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.27        |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.399       |
|    std                  | 1            |
|    value_loss           | 2.75e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.3049574] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 1.6402833    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0279       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.57        |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.779       |
|    std                  | 1.01         |
|    value_loss           | 3.38e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.36        |
|    n_updates            | 70           |
|    policy_gradient_loss | -1.29        |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.483775] |
| time/                   |             |
|    fps                  | 161         |
|    iterations           | 2           |
|    time_elapsed         | 25          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 1.1637082   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.0276      |
|    learning_rate        | 0.0003      |
|    loss                 | -1.51       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.585      |
|    std                  | 1.01        |
|    value_loss           | 3.38e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.1957934] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.9328527    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00873      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.36        |
|    n_updates            | 70           |
|    policy_gradient_loss | -1.29        |
|    std                  | 0.988        |
|    value_loss           | 2.57e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.29        |
|    n_updates            | 80           |
|    policy_gradient_loss | -2.56        |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.6292953] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 2.2459025    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.86        |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.895       |
|    std                  | 1.01         |
|    value_loss           | 3.32e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.6850843] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 3            |
|    time_elapsed         | 38           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 1.4541783    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0243       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.2         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.536       |
|    std                  | 1.01         |
|    value_loss           | 3.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.1294026] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 4.496603     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.0195       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.29        |
|    n_updates            | 80           |
|    policy_gradient_loss | -2.56        |
|    std                  | 0.981        |
|    value_loss           | 2.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.44        |
|    n_updates            | 90           |
|    policy_gradient_loss | -2.17        |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.8069754] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 2.8601832    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.0263       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.53        |
|    n_updates            | 80           |
|    policy_gradient_loss | -1.48        |
|    std                  | 0.992        |
|    value_loss           | 3.77e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.2938156] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.079999     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.0147       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.44        |
|    n_updates            | 90           |
|    policy_gradient_loss | -2.17        |
|    std                  | 0.967        |
|    value_loss           | 2.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.7033916] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 1.7364526    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.86        |
|    explained_variance   | 0.0285       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.93        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.637       |
|    std                  | 1.01         |
|    value_loss           | 3.83e+03     |
------------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 22528        |
-------------------------------------
-------------------------------------
| reward             | [-4.2858114] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 22528        |
-------------------------------------
------------------------------------------
| reward                  | [-3.9336812] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 4.684393     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.029        |
|    learning_rate        | 0.0003       |
|    loss                 | -6.06        |
|    n_updates            | 90           |
|    policy_gradient_loss | -2.85        |
|    std                  | 0.967        |
|    value_loss           | 3.58e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.7710004] |
| time/                   |              |
|    fps                  | 160          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 3.7510333    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.85        |
|    explained_variance   | 0.00872      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.63        |
|    n_updates            | 90           |
|    policy_gradient_loss | -1.43        |
|    std                  | 1            |
|    value_loss           | 2.63e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.08        |
|    n_updates            | 110          |
|    policy_gradient_loss | -2.98        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-5.0819564] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.6577096    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.00196      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.08        |
|    n_updates            | 110          |
|    policy_gradient_loss | -2.98        |
|    std                  | 0.952        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------
| reward             | [-0.641781] |
| time/              |             |
|    fps             | 172         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 22528       |
------------------------------------
-------------------------------------
| reward             | [-0.7004713] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 22528        |
-------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.75        |
|    n_updates            | 120          |
|    policy_gradient_loss | -4.27        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.6590864] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 7.4623985    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.75        |
|    n_updates            | 120          |
|    policy_gradient_loss | -4.27        |
|    std                  | 0.942        |
|    value_loss           | 3.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3899173] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 6.169423     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | -0.0265      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.27        |
|    n_updates            | 110          |
|    policy_gradient_loss | -2.98        |
|    std                  | 0.952        |
|    value_loss           | 2.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0880268] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 5.310428     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.00599      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.18        |
|    n_updates            | 110          |
|    policy_gradient_loss | -3.73        |
|    std                  | 0.992        |
|    value_loss           | 2.92e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.06        |
|    n_updates            | 130          |
|    policy_gradient_loss | -3.68        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4089038] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 6.0030413    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.00284      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.06        |
|    n_updates            | 130          |
|    policy_gradient_loss | -3.68        |
|    std                  | 0.915        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7972231] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 3.2659848    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.74        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -3.54        |
|    n_updates            | 120          |
|    policy_gradient_loss | -1.67        |
|    std                  | 0.948        |
|    value_loss           | 2.99e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7263199] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 6.078926     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.0181       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.49        |
|    n_updates            | 120          |
|    policy_gradient_loss | -3.36        |
|    std                  | 0.984        |
|    value_loss           | 2.7e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.48        |
|    n_updates            | 140          |
|    policy_gradient_loss | -3.11        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1252704] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 5.0570273    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0441       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.48        |
|    n_updates            | 140          |
|    policy_gradient_loss | -3.11        |
|    std                  | 0.904        |
|    value_loss           | 1.39e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0131261] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 4.1690865    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | -0.0257      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.13        |
|    n_updates            | 130          |
|    policy_gradient_loss | -1.58        |
|    std                  | 0.939        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5884455] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 5.916591     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | -0.00506     |
|    learning_rate        | 0.0003       |
|    loss                 | -6.94        |
|    n_updates            | 130          |
|    policy_gradient_loss | -1.92        |
|    std                  | 0.967        |
|    value_loss           | 1.66e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 32768        |
-------------------------------------
-------------------------------------
| reward             | [-2.5978532] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 32768        |
-------------------------------------
------------------------------------------
| reward                  | [-2.3279715] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 30720        |
| train/                  |              |
|    approx_kl            | 7.6754103    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.71        |
|    explained_variance   | -0.0365      |
|    learning_rate        | 0.0003       |
|    loss                 | -5.49        |
|    n_updates            | 140          |
|    policy_gradient_loss | -5.43        |
|    std                  | 0.938        |
|    value_loss           | 2.29e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.590965] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 30720       |
| train/                  |             |
|    approx_kl            | 11.864141   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.75       |
|    explained_variance   | -0.033      |
|    learning_rate        | 0.0003      |
|    loss                 | -12.6       |
|    n_updates            | 140         |
|    policy_gradient_loss | -6.25       |
|    std                  | 0.949       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -4.38       |
|    n_updates            | 160         |
|    policy_gradient_loss | -2.24       |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.720141] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 3.4222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.0461      |
|    learning_rate        | 0.0003      |
|    loss                 | -4.38       |
|    n_updates            | 160         |
|    policy_gradient_loss | -2.24       |
|    std                  | 0.889       |
|    value_loss           | 1.62e+03    |
-----------------------------------------
------------------------------------
| reward             | [-2.471163] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 32768       |
------------------------------------
------------------------------------
| reward             | [-2.885056] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 32768       |
------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 181         |
|    iterations           | 3           |
|    time_elapsed         | 33          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -3.93       |
|    n_updates            | 170         |
|    policy_gradient_loss | -1.65       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.984849] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 3.8716764   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.033       |
|    learning_rate        | 0.0003      |
|    loss                 | -3.93       |
|    n_updates            | 170         |
|    policy_gradient_loss | -1.65       |
|    std                  | 0.869       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.77        |
|    n_updates            | 180          |
|    policy_gradient_loss | -3.14        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1464353] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 12.66841     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.68        |
|    explained_variance   | -0.038       |
|    learning_rate        | 0.0003       |
|    loss                 | -18.2        |
|    n_updates            | 160          |
|    policy_gradient_loss | -5.32        |
|    std                  | 0.922        |
|    value_loss           | 2e+03        |
------------------------------------------
------------------------------------------
| reward                  | [-3.3654208] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 5.7706428    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.0211       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.57        |
|    n_updates            | 160          |
|    policy_gradient_loss | -3.29        |
|    std                  | 0.912        |
|    value_loss           | 1.9e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.1864355] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 4.870161     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.0407       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.77        |
|    n_updates            | 180          |
|    policy_gradient_loss | -3.14        |
|    std                  | 0.854        |
|    value_loss           | 1.62e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.88        |
|    n_updates            | 190          |
|    policy_gradient_loss | -1.58        |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2365603] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 7.453274     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.64        |
|    explained_variance   | -0.0054      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.17        |
|    n_updates            | 170          |
|    policy_gradient_loss | -5.24        |
|    std                  | 0.899        |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.6896093] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 11.153001    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | -0.0414      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.74        |
|    n_updates            | 170          |
|    policy_gradient_loss | -9.11        |
|    std                  | 0.901        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.2194228] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 4.0592093    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.0383       |
|    learning_rate        | 0.0003       |
|    loss                 | -5.88        |
|    n_updates            | 190          |
|    policy_gradient_loss | -1.58        |
|    std                  | 0.851        |
|    value_loss           | 1.78e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 43008        |
-------------------------------------
------------------------------------------
| reward                  | [-3.5802398] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 6.829602     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | -0.000333    |
|    learning_rate        | 0.0003       |
|    loss                 | -7.78        |
|    n_updates            | 180          |
|    policy_gradient_loss | -4.82        |
|    std                  | 0.888        |
|    value_loss           | 1.84e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8704584] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 11.927754    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.62        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -12.6        |
|    n_updates            | 180          |
|    policy_gradient_loss | -8.69        |
|    std                  | 0.89         |
|    value_loss           | 2.14e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.7046645] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 43008        |
-------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.05        |
|    n_updates            | 210          |
|    policy_gradient_loss | -6.43        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.202526] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 40960       |
| train/                  |             |
|    approx_kl            | 11.111057   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.59       |
|    explained_variance   | 0.00624     |
|    learning_rate        | 0.0003      |
|    loss                 | -15.1       |
|    n_updates            | 190         |
|    policy_gradient_loss | -6.25       |
|    std                  | 0.874       |
|    value_loss           | 1.95e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.9747608] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 15.073423    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | -0.0373      |
|    learning_rate        | 0.0003       |
|    loss                 | -19.1        |
|    n_updates            | 190          |
|    policy_gradient_loss | -10.6        |
|    std                  | 0.875        |
|    value_loss           | 2.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.3835816] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 8.994655     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.0325      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.05        |
|    n_updates            | 210          |
|    policy_gradient_loss | -6.43        |
|    std                  | 0.811        |
|    value_loss           | 2.16e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 177           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -8.28         |
|    n_updates            | 220           |
|    policy_gradient_loss | -6.04         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
------------------------------------
| reward             | [-0.504515] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 43008       |
------------------------------------
------------------------------------
| reward             | [-0.504515] |
| time/              |             |
|    fps             | 172         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 43008       |
------------------------------------
-------------------------------------------
| reward                  | [-0.40299225] |
| time/                   |               |
|    fps                  | 172           |
|    iterations           | 3             |
|    time_elapsed         | 35            |
|    total_timesteps      | 47104         |
| train/                  |               |
|    approx_kl            | 8.436071      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.4          |
|    explained_variance   | -0.0332       |
|    learning_rate        | 0.0003        |
|    loss                 | -8.28         |
|    n_updates            | 220           |
|    policy_gradient_loss | -6.04         |
|    std                  | 0.8           |
|    value_loss           | 2.29e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.6        |
|    n_updates            | 230          |
|    policy_gradient_loss | -5.33        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7824407] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 12.65394     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | -0.0145      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.9        |
|    n_updates            | 210          |
|    policy_gradient_loss | -8.26        |
|    std                  | 0.841        |
|    value_loss           | 2.27e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2357254] |
| time/                   |              |
|    fps                  | 171          |
|    iterations           | 4            |
|    time_elapsed         | 47           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 9.69503      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.0374      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.6        |
|    n_updates            | 230          |
|    policy_gradient_loss | -5.33        |
|    std                  | 0.784        |
|    value_loss           | 2.23e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.9213489] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 14.327866    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | -0.0385      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.28        |
|    n_updates            | 210          |
|    policy_gradient_loss | -11.1        |
|    std                  | 0.852        |
|    value_loss           | 2.33e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 5           |
|    time_elapsed         | 58          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -8.33       |
|    n_updates            | 240         |
|    policy_gradient_loss | -4.59       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-1.785107] |
| time/                   |             |
|    fps                  | 171         |
|    iterations           | 5           |
|    time_elapsed         | 59          |
|    total_timesteps      | 51200       |
| train/                  |             |
|    approx_kl            | 9.148939    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -8.33       |
|    n_updates            | 240         |
|    policy_gradient_loss | -4.59       |
|    std                  | 0.78        |
|    value_loss           | 1.98e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.2001625] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 12.718302    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.00388      |
|    learning_rate        | 0.0003       |
|    loss                 | -14          |
|    n_updates            | 220          |
|    policy_gradient_loss | -8.64        |
|    std                  | 0.834        |
|    value_loss           | 1.93e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4068387] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 17.578575    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | -0.0392      |
|    learning_rate        | 0.0003       |
|    loss                 | -23.9        |
|    n_updates            | 220          |
|    policy_gradient_loss | -12.7        |
|    std                  | 0.85         |
|    value_loss           | 2.13e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 53248        |
-------------------------------------
-------------------------------------
| reward             | [-1.8153689] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 53248        |
-------------------------------------
------------------------------------------
| reward                  | [-1.1245387] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 8.083958     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.0399       |
|    learning_rate        | 0.0003       |
|    loss                 | -8.17        |
|    n_updates            | 230          |
|    policy_gradient_loss | -6           |
|    std                  | 0.815        |
|    value_loss           | 1.49e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6888704] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 17.328632    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | -0.0397      |
|    learning_rate        | 0.0003       |
|    loss                 | -17.5        |
|    n_updates            | 230          |
|    policy_gradient_loss | -11.4        |
|    std                  | 0.829        |
|    value_loss           | 1.93e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.6        |
|    n_updates            | 260          |
|    policy_gradient_loss | -8.88        |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7835559] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 12.105678    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0372      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.6        |
|    n_updates            | 260          |
|    policy_gradient_loss | -8.88        |
|    std                  | 0.764        |
|    value_loss           | 2.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7839156] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 3.8191137    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.045        |
|    learning_rate        | 0.0003       |
|    loss                 | -6.25        |
|    n_updates            | 240          |
|    policy_gradient_loss | -1.18        |
|    std                  | 0.809        |
|    value_loss           | 1.2e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.2624052] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 51200        |
| train/                  |              |
|    approx_kl            | 13.995142    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | -0.035       |
|    learning_rate        | 0.0003       |
|    loss                 | -12.6        |
|    n_updates            | 240          |
|    policy_gradient_loss | -11.1        |
|    std                  | 0.814        |
|    value_loss           | 1.93e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.62        |
|    n_updates            | 270          |
|    policy_gradient_loss | -8.49        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.8329843] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 11.857178    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | -0.0382      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.62        |
|    n_updates            | 270          |
|    policy_gradient_loss | -8.49        |
|    std                  | 0.75         |
|    value_loss           | 1.79e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.3731763] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 53248        |
-------------------------------------
-------------------------------------
| reward             | [-2.4090486] |
| time/              |              |
|    fps             | 173          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 53248        |
-------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.73        |
|    n_updates            | 280          |
|    policy_gradient_loss | -7.6         |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.4401186] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 10.160826    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | -0.0309      |
|    learning_rate        | 0.0003       |
|    loss                 | -8.73        |
|    n_updates            | 280          |
|    policy_gradient_loss | -7.6         |
|    std                  | 0.735        |
|    value_loss           | 1.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5468013] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 6.145095     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.0284       |
|    learning_rate        | 0.0003       |
|    loss                 | -19.3        |
|    n_updates            | 260          |
|    policy_gradient_loss | -4.56        |
|    std                  | 0.767        |
|    value_loss           | 1.54e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.933221] |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 10.931383   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | -0.0433     |
|    learning_rate        | 0.0003      |
|    loss                 | -11.3       |
|    n_updates            | 260         |
|    policy_gradient_loss | -9.89       |
|    std                  | 0.781       |
|    value_loss           | 2.21e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -10.4        |
|    n_updates            | 290          |
|    policy_gradient_loss | -5.85        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.2830179] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 9.4651       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | -0.0279      |
|    learning_rate        | 0.0003       |
|    loss                 | -10.4        |
|    n_updates            | 290          |
|    policy_gradient_loss | -5.85        |
|    std                  | 0.721        |
|    value_loss           | 1.3e+03      |
------------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 63488        |
-------------------------------------
----------------------------------------
| reward                  | [-2.70485] |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 3          |
|    time_elapsed         | 37         |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 7.386668   |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.28      |
|    explained_variance   | 0.0516     |
|    learning_rate        | 0.0003     |
|    loss                 | -12.4      |
|    n_updates            | 270        |
|    policy_gradient_loss | -6         |
|    std                  | 0.757      |
|    value_loss           | 1.44e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-3.5067427] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 13.253141    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | -0.0398      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.2        |
|    n_updates            | 270          |
|    policy_gradient_loss | -11.4        |
|    std                  | 0.768        |
|    value_loss           | 2.25e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.1432996] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 63488        |
-------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -18.6       |
|    n_updates            | 310         |
|    policy_gradient_loss | -10.7       |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
----------------------------------------
| reward                  | [-2.77428] |
| time/                   |            |
|    fps                  | 163        |
|    iterations           | 4          |
|    time_elapsed         | 50         |
|    total_timesteps      | 59392      |
| train/                  |            |
|    approx_kl            | 6.55002    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.25      |
|    explained_variance   | 0.056      |
|    learning_rate        | 0.0003     |
|    loss                 | -6.74      |
|    n_updates            | 280        |
|    policy_gradient_loss | -4.24      |
|    std                  | 0.743      |
|    value_loss           | 1.26e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-3.9269423] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 14.764171    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | -0.0291      |
|    learning_rate        | 0.0003       |
|    loss                 | -11.5        |
|    n_updates            | 280          |
|    policy_gradient_loss | -11.4        |
|    std                  | 0.75         |
|    value_loss           | 2.51e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.154857] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 2           |
|    time_elapsed         | 23          |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 14.532846   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | -0.00823    |
|    learning_rate        | 0.0003      |
|    loss                 | -18.6       |
|    n_updates            | 310         |
|    policy_gradient_loss | -10.7       |
|    std                  | 0.694       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.2        |
|    n_updates            | 320          |
|    policy_gradient_loss | -8.95        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.1665008] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 61440        |
| train/                  |              |
|    approx_kl            | 4.9664097    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.0606       |
|    learning_rate        | 0.0003       |
|    loss                 | -7.3         |
|    n_updates            | 290          |
|    policy_gradient_loss | -3.2         |
|    std                  | 0.727        |
|    value_loss           | 1.14e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-4.021211] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 61440       |
| train/                  |             |
|    approx_kl            | 14.216991   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | -0.0286     |
|    learning_rate        | 0.0003      |
|    loss                 | -22.5       |
|    n_updates            | 290         |
|    policy_gradient_loss | -11.8       |
|    std                  | 0.736       |
|    value_loss           | 2.14e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-5.0380845] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 11.065942    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | -0.0143      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.2        |
|    n_updates            | 320          |
|    policy_gradient_loss | -8.95        |
|    std                  | 0.687        |
|    value_loss           | 1.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.5        |
|    n_updates            | 330          |
|    policy_gradient_loss | -9.12        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.9519663] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 63488        |
-------------------------------------
------------------------------------
| reward             | [-4.407244] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 63488       |
------------------------------------
------------------------------------------
| reward                  | [-0.7958145] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 13.47011     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.5        |
|    n_updates            | 330          |
|    policy_gradient_loss | -9.12        |
|    std                  | 0.681        |
|    value_loss           | 3.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -21.6        |
|    n_updates            | 340          |
|    policy_gradient_loss | -12.8        |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.8405134] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 2.3213165    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.0852       |
|    learning_rate        | 0.0003       |
|    loss                 | -2.46        |
|    n_updates            | 310          |
|    policy_gradient_loss | -1.7         |
|    std                  | 0.693        |
|    value_loss           | 1.42e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5679788] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 15.616434    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | -0.035       |
|    learning_rate        | 0.0003       |
|    loss                 | -14.4        |
|    n_updates            | 310          |
|    policy_gradient_loss | -11.8        |
|    std                  | 0.71         |
|    value_loss           | 2.09e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1983843] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 17.899765    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | -0.0226      |
|    learning_rate        | 0.0003       |
|    loss                 | -21.6        |
|    n_updates            | 340          |
|    policy_gradient_loss | -12.8        |
|    std                  | 0.669        |
|    value_loss           | 2.95e+03     |
------------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 188         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 73728       |
------------------------------------
------------------------------------------
| reward                  | [-1.2843888] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 2.9813147    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.079        |
|    learning_rate        | 0.0003       |
|    loss                 | -2.76        |
|    n_updates            | 320          |
|    policy_gradient_loss | -1.95        |
|    std                  | 0.687        |
|    value_loss           | 1.36e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0727842] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 17.369162    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | -0.0315      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.3        |
|    n_updates            | 320          |
|    policy_gradient_loss | -12          |
|    std                  | 0.7          |
|    value_loss           | 2.15e+03     |
------------------------------------------
------------------------------------
| reward             | [-1.598556] |
| time/              |             |
|    fps             | 186         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 73728       |
------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -5.41       |
|    n_updates            | 360         |
|    policy_gradient_loss | -5.3        |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.4231841] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 4.2337685    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.0758       |
|    learning_rate        | 0.0003       |
|    loss                 | -3.78        |
|    n_updates            | 330          |
|    policy_gradient_loss | -2.38        |
|    std                  | 0.681        |
|    value_loss           | 1.27e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.168324] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 4           |
|    time_elapsed         | 49          |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 15.422986   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | -0.025      |
|    learning_rate        | 0.0003      |
|    loss                 | -14.4       |
|    n_updates            | 330         |
|    policy_gradient_loss | -10.9       |
|    std                  | 0.697       |
|    value_loss           | 1.97e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.652447] |
| time/                   |             |
|    fps                  | 180         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 7.1627216   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | -0.0521     |
|    learning_rate        | 0.0003      |
|    loss                 | -5.41       |
|    n_updates            | 360         |
|    policy_gradient_loss | -5.3        |
|    std                  | 0.659       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -29.5        |
|    n_updates            | 370          |
|    policy_gradient_loss | -12.3        |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0202816] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 19.41237     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | -0.0166      |
|    learning_rate        | 0.0003       |
|    loss                 | -29.5        |
|    n_updates            | 370          |
|    policy_gradient_loss | -12.3        |
|    std                  | 0.656        |
|    value_loss           | 2.71e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0433595] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 14.594057    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.109        |
|    learning_rate        | 0.0003       |
|    loss                 | -15.2        |
|    n_updates            | 340          |
|    policy_gradient_loss | -9.64        |
|    std                  | 0.675        |
|    value_loss           | 601          |
------------------------------------------
------------------------------------------
| reward                  | [-1.6092161] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 71680        |
| train/                  |              |
|    approx_kl            | 24.237415    |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | -0.0251      |
|    learning_rate        | 0.0003       |
|    loss                 | -21.8        |
|    n_updates            | 340          |
|    policy_gradient_loss | -20.4        |
|    std                  | 0.69         |
|    value_loss           | 983          |
------------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -13          |
|    n_updates            | 380          |
|    policy_gradient_loss | -12.7        |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.6021535] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 18.19968     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | -0.0165      |
|    learning_rate        | 0.0003       |
|    loss                 | -13          |
|    n_updates            | 380          |
|    policy_gradient_loss | -12.7        |
|    std                  | 0.649        |
|    value_loss           | 3.01e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3068751] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 73728        |
-------------------------------------
-------------------------------------
| reward             | [-1.9376808] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 73728        |
-------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.3        |
|    n_updates            | 390          |
|    policy_gradient_loss | -9.75        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8674934] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 12.876022    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0241      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.3        |
|    n_updates            | 390          |
|    policy_gradient_loss | -9.75        |
|    std                  | 0.641        |
|    value_loss           | 3.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9387783] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 10.141265    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.0751       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.28        |
|    n_updates            | 360          |
|    policy_gradient_loss | -7.08        |
|    std                  | 0.643        |
|    value_loss           | 744          |
------------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 190          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 83968        |
-------------------------------------
-----------------------------------------
| reward                  | [-2.260013] |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 28.682014   |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | -0.0419     |
|    learning_rate        | 0.0003      |
|    loss                 | -15.7       |
|    n_updates            | 360         |
|    policy_gradient_loss | -21.3       |
|    std                  | 0.649       |
|    value_loss           | 1.01e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-4.2101793] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 83968        |
-------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 184         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -27.2       |
|    n_updates            | 410         |
|    policy_gradient_loss | -16.9       |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.9844785] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 9.976055     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.0728       |
|    learning_rate        | 0.0003       |
|    loss                 | -11.4        |
|    n_updates            | 370          |
|    policy_gradient_loss | -6.32        |
|    std                  | 0.63         |
|    value_loss           | 924          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.347942] |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 19.994303   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | -0.041      |
|    learning_rate        | 0.0003      |
|    loss                 | -20.3       |
|    n_updates            | 370         |
|    policy_gradient_loss | -13.8       |
|    std                  | 0.642       |
|    value_loss           | 1.38e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.383058] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 21.161839   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | -0.026      |
|    learning_rate        | 0.0003      |
|    loss                 | -27.2       |
|    n_updates            | 410         |
|    policy_gradient_loss | -16.9       |
|    std                  | 0.626       |
|    value_loss           | 2.86e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -22.3        |
|    n_updates            | 420          |
|    policy_gradient_loss | -18.2        |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6912304] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 4.871605     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.88        |
|    explained_variance   | 0.0778       |
|    learning_rate        | 0.0003       |
|    loss                 | -4.52        |
|    n_updates            | 380          |
|    policy_gradient_loss | -3.41        |
|    std                  | 0.619        |
|    value_loss           | 808          |
------------------------------------------
------------------------------------------
| reward                  | [-3.1097689] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 16.157642    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | -0.0487      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.9        |
|    n_updates            | 380          |
|    policy_gradient_loss | -12.7        |
|    std                  | 0.621        |
|    value_loss           | 1.25e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4362717] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 26.560486    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.77        |
|    explained_variance   | -0.0199      |
|    learning_rate        | 0.0003       |
|    loss                 | -22.3        |
|    n_updates            | 420          |
|    policy_gradient_loss | -18.2        |
|    std                  | 0.615        |
|    value_loss           | 2.72e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 180           |
|    iterations           | 4             |
|    time_elapsed         | 45            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -29.3         |
|    n_updates            | 430           |
|    policy_gradient_loss | -17.3         |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.1149142] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 15.624599    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.83        |
|    explained_variance   | 0.103        |
|    learning_rate        | 0.0003       |
|    loss                 | -16.3        |
|    n_updates            | 390          |
|    policy_gradient_loss | -10.7        |
|    std                  | 0.604        |
|    value_loss           | 465          |
------------------------------------------
------------------------------------------
| reward                  | [-3.5121868] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 16.636742    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.87        |
|    explained_variance   | -0.0367      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.7        |
|    n_updates            | 390          |
|    policy_gradient_loss | -15.4        |
|    std                  | 0.611        |
|    value_loss           | 1.55e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.47044784] |
| time/                   |               |
|    fps                  | 175           |
|    iterations           | 4             |
|    time_elapsed         | 46            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 23.475704     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.73         |
|    explained_variance   | -0.0219       |
|    learning_rate        | 0.0003        |
|    loss                 | -29.3         |
|    n_updates            | 430           |
|    policy_gradient_loss | -17.3         |
|    std                  | 0.609         |
|    value_loss           | 2.89e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -18.3        |
|    n_updates            | 440          |
|    policy_gradient_loss | -18.2        |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.7000338] |
| time/              |              |
|    fps             | 176          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 83968        |
-------------------------------------
-------------------------------------
| reward             | [-3.3650484] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 83968        |
-------------------------------------
------------------------------------------
| reward                  | [-1.2597076] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 23.305683    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.69        |
|    explained_variance   | -0.0234      |
|    learning_rate        | 0.0003       |
|    loss                 | -18.3        |
|    n_updates            | 440          |
|    policy_gradient_loss | -18.2        |
|    std                  | 0.601        |
|    value_loss           | 3.08e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 94208        |
-------------------------------------
------------------------------------------
| reward                  | [-0.5069671] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 13.567049    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.73        |
|    explained_variance   | 0.0623       |
|    learning_rate        | 0.0003       |
|    loss                 | -13.7        |
|    n_updates            | 410          |
|    policy_gradient_loss | -11          |
|    std                  | 0.578        |
|    value_loss           | 165          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.40460238] |
| time/                   |               |
|    fps                  | 168           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 86016         |
| train/                  |               |
|    approx_kl            | 22.188478     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.79         |
|    explained_variance   | -0.0491       |
|    learning_rate        | 0.0003        |
|    loss                 | -21           |
|    n_updates            | 410           |
|    policy_gradient_loss | -15.3         |
|    std                  | 0.586         |
|    value_loss           | 1.38e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-1.4650625] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 94208        |
-------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 183         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -16.2       |
|    n_updates            | 460         |
|    policy_gradient_loss | -14.3       |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.31339088] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 88064         |
| train/                  |               |
|    approx_kl            | 19.99268      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.68         |
|    explained_variance   | 0.109         |
|    learning_rate        | 0.0003        |
|    loss                 | -21.7         |
|    n_updates            | 420           |
|    policy_gradient_loss | -16           |
|    std                  | 0.564         |
|    value_loss           | 296           |
-------------------------------------------
------------------------------------------
| reward                  | [-0.9120159] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 3            |
|    time_elapsed         | 36           |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 15.884604    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.74        |
|    explained_variance   | -0.0417      |
|    learning_rate        | 0.0003       |
|    loss                 | -23.6        |
|    n_updates            | 420          |
|    policy_gradient_loss | -15.1        |
|    std                  | 0.57         |
|    value_loss           | 1.33e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.382566] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 15.719763   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | -0.0191     |
|    learning_rate        | 0.0003      |
|    loss                 | -16.2       |
|    n_updates            | 460         |
|    policy_gradient_loss | -14.3       |
|    std                  | 0.587       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.2        |
|    n_updates            | 470          |
|    policy_gradient_loss | -15.5        |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.62695354] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 17.578941     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.65         |
|    explained_variance   | 0.117         |
|    learning_rate        | 0.0003        |
|    loss                 | -18.3         |
|    n_updates            | 430           |
|    policy_gradient_loss | -12.9         |
|    std                  | 0.561         |
|    value_loss           | 198           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.3354069] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 90112        |
| train/                  |              |
|    approx_kl            | 10.249743    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.7         |
|    explained_variance   | -0.0389      |
|    learning_rate        | 0.0003       |
|    loss                 | -10.7        |
|    n_updates            | 430          |
|    policy_gradient_loss | -9.23        |
|    std                  | 0.565        |
|    value_loss           | 984          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3985217] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 20.18742     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | -0.0198      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.2        |
|    n_updates            | 470          |
|    policy_gradient_loss | -15.5        |
|    std                  | 0.572        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -18.6        |
|    n_updates            | 480          |
|    policy_gradient_loss | -16.8        |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.9899591] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 10.92287     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | 0.119        |
|    learning_rate        | 0.0003       |
|    loss                 | -10.7        |
|    n_updates            | 440          |
|    policy_gradient_loss | -8.25        |
|    std                  | 0.552        |
|    value_loss           | 411          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3028623] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 19.733112    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.68        |
|    explained_variance   | -0.0421      |
|    learning_rate        | 0.0003       |
|    loss                 | -27.5        |
|    n_updates            | 440          |
|    policy_gradient_loss | -14.5        |
|    std                  | 0.559        |
|    value_loss           | 1.27e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9617121] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 20.591309    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.52        |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -18.6        |
|    n_updates            | 480          |
|    policy_gradient_loss | -16.8        |
|    std                  | 0.568        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -16.7        |
|    n_updates            | 490          |
|    policy_gradient_loss | -14.4        |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.8048717] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 94208        |
-------------------------------------
--------------------------------------
| reward             | [-0.91202253] |
| time/              |               |
|    fps             | 175           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 94208         |
--------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 104448       |
-------------------------------------
------------------------------------------
| reward                  | [-3.3902042] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 19.002644    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.48        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | -16.7        |
|    n_updates            | 490          |
|    policy_gradient_loss | -14.4        |
|    std                  | 0.56         |
|    value_loss           | 2.76e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3432128] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 8.1230135    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.57        |
|    explained_variance   | 0.00336      |
|    learning_rate        | 0.0003       |
|    loss                 | -6.49        |
|    n_updates            | 460          |
|    policy_gradient_loss | -5.53        |
|    std                  | 0.539        |
|    value_loss           | 438          |
------------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.1        |
|    n_updates            | 510          |
|    policy_gradient_loss | -12.9        |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5886182] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 11.521524    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.62        |
|    explained_variance   | -0.0259      |
|    learning_rate        | 0.0003       |
|    loss                 | -17.2        |
|    n_updates            | 460          |
|    policy_gradient_loss | -13.1        |
|    std                  | 0.542        |
|    value_loss           | 428          |
------------------------------------------
-------------------------------------
| reward             | [-3.5831733] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 104448       |
-------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -37          |
|    n_updates            | 520          |
|    policy_gradient_loss | -22.3        |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8513719] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 9.632156     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.53        |
|    explained_variance   | 0.0506       |
|    learning_rate        | 0.0003       |
|    loss                 | -10.8        |
|    n_updates            | 470          |
|    policy_gradient_loss | -7.55        |
|    std                  | 0.529        |
|    value_loss           | 572          |
------------------------------------------
------------------------------------------
| reward                  | [-4.0144596] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 14.963018    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.4         |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -15.1        |
|    n_updates            | 510          |
|    policy_gradient_loss | -12.9        |
|    std                  | 0.541        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2488267] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 16.468967    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.59        |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -19.1        |
|    n_updates            | 470          |
|    policy_gradient_loss | -14.1        |
|    std                  | 0.535        |
|    value_loss           | 832          |
------------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -23.7        |
|    n_updates            | 530          |
|    policy_gradient_loss | -15.1        |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-4.4563866] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 27.86518     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.36        |
|    explained_variance   | -0.0269      |
|    learning_rate        | 0.0003       |
|    loss                 | -37          |
|    n_updates            | 520          |
|    policy_gradient_loss | -22.3        |
|    std                  | 0.539        |
|    value_loss           | 2.36e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.71028095] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 100352        |
| train/                  |               |
|    approx_kl            | 11.19893      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.46         |
|    explained_variance   | 0.0102        |
|    learning_rate        | 0.0003        |
|    loss                 | -12.6         |
|    n_updates            | 480           |
|    policy_gradient_loss | -9.26         |
|    std                  | 0.508         |
|    value_loss           | 343           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.8938593] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 100352       |
| train/                  |              |
|    approx_kl            | 11.654386    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.55        |
|    explained_variance   | -0.00333     |
|    learning_rate        | 0.0003       |
|    loss                 | -11.3        |
|    n_updates            | 480          |
|    policy_gradient_loss | -10.2        |
|    std                  | 0.517        |
|    value_loss           | 641          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 178           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -31.4         |
|    n_updates            | 540           |
|    policy_gradient_loss | -22.4         |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-4.2049556] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.554157    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0245      |
|    learning_rate        | 0.0003       |
|    loss                 | -23.7        |
|    n_updates            | 530          |
|    policy_gradient_loss | -15.1        |
|    std                  | 0.535        |
|    value_loss           | 2.67e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.604351] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 13.913856   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.39       |
|    explained_variance   | 0.0971      |
|    learning_rate        | 0.0003      |
|    loss                 | -15.2       |
|    n_updates            | 490         |
|    policy_gradient_loss | -11.5       |
|    std                  | 0.494       |
|    value_loss           | 500         |
-----------------------------------------
------------------------------------------
| reward                  | [-1.4693774] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 10.53932     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.49        |
|    explained_variance   | -0.0303      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.4        |
|    n_updates            | 490          |
|    policy_gradient_loss | -10.7        |
|    std                  | 0.502        |
|    value_loss           | 935          |
------------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 114688       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.81164765] |
| time/                   |               |
|    fps                  | 174           |
|    iterations           | 5             |
|    time_elapsed         | 58            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 27.28467      |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.28         |
|    explained_variance   | -0.025        |
|    learning_rate        | 0.0003        |
|    loss                 | -31.4         |
|    n_updates            | 540           |
|    policy_gradient_loss | -22.4         |
|    std                  | 0.523         |
|    value_loss           | 2.06e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-2.7194948] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 104448       |
-------------------------------------
------------------------------------
| reward             | [-2.632796] |
| time/              |             |
|    fps             | 173         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 104448      |
------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -20.6        |
|    n_updates            | 560          |
|    policy_gradient_loss | -22.4        |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3946857] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 114688       |
-------------------------------------
----------------------------------------
| reward                  | [-2.80404] |
| time/                   |            |
|    fps                  | 166        |
|    iterations           | 2          |
|    time_elapsed         | 24         |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 18.72711   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.3       |
|    explained_variance   | 0.0766     |
|    learning_rate        | 0.0003     |
|    loss                 | -17.8      |
|    n_updates            | 510        |
|    policy_gradient_loss | -13.8      |
|    std                  | 0.478      |
|    value_loss           | 869        |
----------------------------------------
------------------------------------------
| reward                  | [-1.4922426] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 16.230824    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.41        |
|    explained_variance   | -0.0246      |
|    learning_rate        | 0.0003       |
|    loss                 | -14.1        |
|    n_updates            | 510          |
|    policy_gradient_loss | -11.6        |
|    std                  | 0.487        |
|    value_loss           | 960          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.5        |
|    n_updates            | 570          |
|    policy_gradient_loss | -20.9        |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.3872375] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 26.933693    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.22        |
|    explained_variance   | -0.0146      |
|    learning_rate        | 0.0003       |
|    loss                 | -20.6        |
|    n_updates            | 560          |
|    policy_gradient_loss | -22.4        |
|    std                  | 0.509        |
|    value_loss           | 1.73e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48277327] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 108544        |
| train/                  |               |
|    approx_kl            | 17.541775     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.26         |
|    explained_variance   | 0.0895        |
|    learning_rate        | 0.0003        |
|    loss                 | -17.5         |
|    n_updates            | 520           |
|    policy_gradient_loss | -13.1         |
|    std                  | 0.471         |
|    value_loss           | 553           |
-------------------------------------------
------------------------------------------
| reward                  | [-0.7149894] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 15.181426    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.37        |
|    explained_variance   | -0.0122      |
|    learning_rate        | 0.0003       |
|    loss                 | -13.2        |
|    n_updates            | 520          |
|    policy_gradient_loss | -13.4        |
|    std                  | 0.481        |
|    value_loss           | 759          |
------------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.2        |
|    n_updates            | 580          |
|    policy_gradient_loss | -18.8        |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2428534] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 27.715805    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.16        |
|    explained_variance   | -0.0233      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.5        |
|    n_updates            | 570          |
|    policy_gradient_loss | -20.9        |
|    std                  | 0.497        |
|    value_loss           | 2.05e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5282567] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 12.507125    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.23        |
|    explained_variance   | 0.0792       |
|    learning_rate        | 0.0003       |
|    loss                 | -17.6        |
|    n_updates            | 530          |
|    policy_gradient_loss | -10.4        |
|    std                  | 0.466        |
|    value_loss           | 709          |
------------------------------------------
------------------------------------------
| reward                  | [-0.9385597] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 110592       |
| train/                  |              |
|    approx_kl            | 17.617958    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.33        |
|    explained_variance   | -0.0147      |
|    learning_rate        | 0.0003       |
|    loss                 | -25.1        |
|    n_updates            | 530          |
|    policy_gradient_loss | -13.2        |
|    std                  | 0.47         |
|    value_loss           | 965          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -19          |
|    n_updates            | 590          |
|    policy_gradient_loss | -13.5        |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0536141] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 25.33812     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.11        |
|    explained_variance   | -0.0182      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.2        |
|    n_updates            | 580          |
|    policy_gradient_loss | -18.8        |
|    std                  | 0.49         |
|    value_loss           | 2.01e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.31671664] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 112640        |
| train/                  |               |
|    approx_kl            | 12.554815     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.19         |
|    explained_variance   | 0.0991        |
|    learning_rate        | 0.0003        |
|    loss                 | -22.6         |
|    n_updates            | 540           |
|    policy_gradient_loss | -11           |
|    std                  | 0.458         |
|    value_loss           | 433           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.3185405] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 9.800533     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.29        |
|    explained_variance   | -0.0144      |
|    learning_rate        | 0.0003       |
|    loss                 | -9.37        |
|    n_updates            | 540          |
|    policy_gradient_loss | -10.4        |
|    std                  | 0.464        |
|    value_loss           | 546          |
------------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 124928       |
-------------------------------------
------------------------------------------
| reward                  | [-2.2993135] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 20.186638    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.07        |
|    explained_variance   | -0.0243      |
|    learning_rate        | 0.0003       |
|    loss                 | -19          |
|    n_updates            | 590          |
|    policy_gradient_loss | -13.5        |
|    std                  | 0.486        |
|    value_loss           | 2.69e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3172163] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 114688       |
-------------------------------------
-------------------------------------
| reward             | [-1.8660786] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 114688       |
-------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -27.4        |
|    n_updates            | 610          |
|    policy_gradient_loss | -21.8        |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
-------------------------------------
| reward             | [-3.4374967] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 124928       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.60897666] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 116736        |
| train/                  |               |
|    approx_kl            | 23.887133     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.12         |
|    explained_variance   | 0.0857        |
|    learning_rate        | 0.0003        |
|    loss                 | -24.8         |
|    n_updates            | 560           |
|    policy_gradient_loss | -20.9         |
|    std                  | 0.446         |
|    value_loss           | 439           |
-------------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 179        |
|    iterations           | 3          |
|    time_elapsed         | 34         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -29        |
|    n_updates            | 620        |
|    policy_gradient_loss | -23.8      |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
----------------------------------------
| reward                  | [-2.05239] |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 2          |
|    time_elapsed         | 24         |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 22.66473   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.21      |
|    explained_variance   | -0.0138    |
|    learning_rate        | 0.0003     |
|    loss                 | -29.1      |
|    n_updates            | 560        |
|    policy_gradient_loss | -16.7      |
|    std                  | 0.445      |
|    value_loss           | 960        |
----------------------------------------
------------------------------------------
| reward                  | [-3.4782426] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 24.715263    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.03        |
|    explained_variance   | -0.00932     |
|    learning_rate        | 0.0003       |
|    loss                 | -27.4        |
|    n_updates            | 610          |
|    policy_gradient_loss | -21.8        |
|    std                  | 0.487        |
|    value_loss           | 2.12e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -42.2        |
|    n_updates            | 630          |
|    policy_gradient_loss | -37.8        |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7640867] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 30.74097     |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.09        |
|    explained_variance   | 0.0844       |
|    learning_rate        | 0.0003       |
|    loss                 | -23.9        |
|    n_updates            | 570          |
|    policy_gradient_loss | -25.1        |
|    std                  | 0.435        |
|    value_loss           | 659          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.198088] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 32.007423   |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | -0.0254     |
|    learning_rate        | 0.0003      |
|    loss                 | -22.3       |
|    n_updates            | 570         |
|    policy_gradient_loss | -26.5       |
|    std                  | 0.432       |
|    value_loss           | 1.15e+03    |
-----------------------------------------
----------------------------------------
| reward                  | [-4.25054] |
| time/                   |            |
|    fps                  | 173        |
|    iterations           | 3          |
|    time_elapsed         | 35         |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 28.81844   |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | -0.00195   |
|    learning_rate        | 0.0003     |
|    loss                 | -29        |
|    n_updates            | 620        |
|    policy_gradient_loss | -23.8      |
|    std                  | 0.482      |
|    value_loss           | 2.09e+03   |
----------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 178           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -28.1         |
|    n_updates            | 640           |
|    policy_gradient_loss | -28.9         |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.66464335] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 120832        |
| train/                  |               |
|    approx_kl            | 26.949306     |
|    clip_range           | 0.2           |
|    entropy_loss         | -1.03         |
|    explained_variance   | 0.0827        |
|    learning_rate        | 0.0003        |
|    loss                 | -26.4         |
|    n_updates            | 580           |
|    policy_gradient_loss | -19.7         |
|    std                  | 0.424         |
|    value_loss           | 306           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.5257442] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 120832       |
| train/                  |              |
|    approx_kl            | 17.223454    |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.1         |
|    explained_variance   | -0.023       |
|    learning_rate        | 0.0003       |
|    loss                 | -12.6        |
|    n_updates            | 580          |
|    policy_gradient_loss | -15.2        |
|    std                  | 0.421        |
|    value_loss           | 1.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5266137] |
| time/                   |              |
|    fps                  | 171          |
|    iterations           | 4            |
|    time_elapsed         | 47           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 44.666924    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.973       |
|    explained_variance   | -0.0217      |
|    learning_rate        | 0.0003       |
|    loss                 | -42.2        |
|    n_updates            | 630          |
|    policy_gradient_loss | -37.8        |
|    std                  | 0.483        |
|    value_loss           | 2.06e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------------
| reward                  | [-0.5497661] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 19.899132    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.993       |
|    explained_variance   | 0.097        |
|    learning_rate        | 0.0003       |
|    loss                 | -23.8        |
|    n_updates            | 590          |
|    policy_gradient_loss | -16.2        |
|    std                  | 0.418        |
|    value_loss           | 606          |
------------------------------------------
----------------------------------------
| reward                  | [-2.57632] |
| time/                   |            |
|    fps                  | 162        |
|    iterations           | 5          |
|    time_elapsed         | 62         |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 17.911133  |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | -0.0206    |
|    learning_rate        | 0.0003     |
|    loss                 | -26.6      |
|    n_updates            | 590        |
|    policy_gradient_loss | -15.4      |
|    std                  | 0.411      |
|    value_loss           | 1.11e+03   |
----------------------------------------
-------------------------------------------
| reward                  | [-0.57519597] |
| time/                   |               |
|    fps                  | 172           |
|    iterations           | 5             |
|    time_elapsed         | 59            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 32.60486      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.937        |
|    explained_variance   | -0.0016       |
|    learning_rate        | 0.0003        |
|    loss                 | -28.1         |
|    n_updates            | 640           |
|    policy_gradient_loss | -28.9         |
|    std                  | 0.474         |
|    value_loss           | 1.21e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -21          |
|    n_updates            | 660          |
|    policy_gradient_loss | -28.9        |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
-------------------------------------
| reward             | [-2.9637582] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 124928       |
-------------------------------------
-------------------------------------
| reward             | [-1.0823514] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------
| reward             | [-2.615175] |
| time/              |             |
|    fps             | 171         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 124928      |
------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -55.5        |
|    n_updates            | 670          |
|    policy_gradient_loss | -36.1        |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4630947] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 23.623184    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.848       |
|    explained_variance   | -0.109       |
|    learning_rate        | 0.0003       |
|    loss                 | -21          |
|    n_updates            | 660          |
|    policy_gradient_loss | -28.9        |
|    std                  | 0.459        |
|    value_loss           | 729          |
------------------------------------------
------------------------------------------
| reward                  | [-3.1143267] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 12.0007105   |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.911       |
|    explained_variance   | 0.0602       |
|    learning_rate        | 0.0003       |
|    loss                 | -9.64        |
|    n_updates            | 610          |
|    policy_gradient_loss | -9.19        |
|    std                  | 0.406        |
|    value_loss           | 967          |
------------------------------------------
------------------------------------------
| reward                  | [-2.9760742] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 28.97602     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.998       |
|    explained_variance   | -0.0193      |
|    learning_rate        | 0.0003       |
|    loss                 | -22.2        |
|    n_updates            | 610          |
|    policy_gradient_loss | -25.1        |
|    std                  | 0.404        |
|    value_loss           | 1.16e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -53.4        |
|    n_updates            | 680          |
|    policy_gradient_loss | -39          |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8757311] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 47.0007      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.818       |
|    explained_variance   | -0.09        |
|    learning_rate        | 0.0003       |
|    loss                 | -55.5        |
|    n_updates            | 670          |
|    policy_gradient_loss | -36.1        |
|    std                  | 0.454        |
|    value_loss           | 747          |
------------------------------------------
------------------------------------------
| reward                  | [-0.5486923] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 17.024405    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.874       |
|    explained_variance   | 0.0607       |
|    learning_rate        | 0.0003       |
|    loss                 | -12          |
|    n_updates            | 620          |
|    policy_gradient_loss | -12.5        |
|    std                  | 0.398        |
|    value_loss           | 847          |
------------------------------------------
-----------------------------------------
| reward                  | [-0.415749] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 18.829689   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.98       |
|    explained_variance   | -0.0217     |
|    learning_rate        | 0.0003      |
|    loss                 | -14.1       |
|    n_updates            | 620         |
|    policy_gradient_loss | -14.8       |
|    std                  | 0.402       |
|    value_loss           | 1e+03       |
-----------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -16          |
|    n_updates            | 690          |
|    policy_gradient_loss | -14.4        |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4509791] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 50.67933     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.784       |
|    explained_variance   | -0.11        |
|    learning_rate        | 0.0003       |
|    loss                 | -53.4        |
|    n_updates            | 680          |
|    policy_gradient_loss | -39          |
|    std                  | 0.448        |
|    value_loss           | 739          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.60245156] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 131072        |
| train/                  |               |
|    approx_kl            | 11.849739     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.815        |
|    explained_variance   | 0.0291        |
|    learning_rate        | 0.0003        |
|    loss                 | -22.1         |
|    n_updates            | 630           |
|    policy_gradient_loss | -9.28         |
|    std                  | 0.387         |
|    value_loss           | 69.5          |
-------------------------------------------
------------------------------------------
| reward                  | [-1.0469946] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 28.812054    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.963       |
|    explained_variance   | -0.0258      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.9        |
|    n_updates            | 630          |
|    policy_gradient_loss | -23.9        |
|    std                  | 0.397        |
|    value_loss           | 1.22e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 145408       |
-------------------------------------
------------------------------------------
| reward                  | [-2.0930808] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 19.166327    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.742       |
|    explained_variance   | -0.0791      |
|    learning_rate        | 0.0003       |
|    loss                 | -16          |
|    n_updates            | 690          |
|    policy_gradient_loss | -14.4        |
|    std                  | 0.445        |
|    value_loss           | 808          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.58553445] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 133120        |
| train/                  |               |
|    approx_kl            | 28.77153      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.76         |
|    explained_variance   | 0.0534        |
|    learning_rate        | 0.0003        |
|    loss                 | -27.9         |
|    n_updates            | 640           |
|    policy_gradient_loss | -23.5         |
|    std                  | 0.379         |
|    value_loss           | 308           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.1350309] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 34.38217     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.917       |
|    explained_variance   | -0.0264      |
|    learning_rate        | 0.0003       |
|    loss                 | -30.2        |
|    n_updates            | 640          |
|    policy_gradient_loss | -29.6        |
|    std                  | 0.387        |
|    value_loss           | 1.56e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -41.3        |
|    n_updates            | 710          |
|    policy_gradient_loss | -39.1        |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
-------------------------------------
| reward             | [-1.9639217] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 145408       |
-------------------------------------
-------------------------------------
| reward             | [-1.2574472] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 135168       |
-------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -14.9        |
|    n_updates            | 720          |
|    policy_gradient_loss | -26.6        |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
------------------------------------
| reward             | [-1.654437] |
| time/              |             |
|    fps             | 172         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 135168      |
------------------------------------
------------------------------------------
| reward                  | [-1.8347055] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 44.61058     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.687       |
|    explained_variance   | -0.12        |
|    learning_rate        | 0.0003       |
|    loss                 | -41.3        |
|    n_updates            | 710          |
|    policy_gradient_loss | -39.1        |
|    std                  | 0.442        |
|    value_loss           | 771          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -40.9        |
|    n_updates            | 730          |
|    policy_gradient_loss | -39.9        |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
------------------------------------------
| reward                  | [-1.5644883] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 21.8605      |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.692       |
|    explained_variance   | 0.0351       |
|    learning_rate        | 0.0003       |
|    loss                 | -21.5        |
|    n_updates            | 660          |
|    policy_gradient_loss | -12.8        |
|    std                  | 0.368        |
|    value_loss           | 322          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2321467] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 28.139862    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.842       |
|    explained_variance   | 0.00206      |
|    learning_rate        | 0.0003       |
|    loss                 | -38.1        |
|    n_updates            | 660          |
|    policy_gradient_loss | -26.5        |
|    std                  | 0.373        |
|    value_loss           | 1.6e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.8142756] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 32.27811     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.656       |
|    explained_variance   | 0.0253       |
|    learning_rate        | 0.0003       |
|    loss                 | -14.9        |
|    n_updates            | 720          |
|    policy_gradient_loss | -26.6        |
|    std                  | 0.437        |
|    value_loss           | 1.07e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 178           |
|    iterations           | 5             |
|    time_elapsed         | 57            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -33.1         |
|    n_updates            | 740           |
|    policy_gradient_loss | -26.6         |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.46140808] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 13.204603     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.638        |
|    explained_variance   | 0.0397        |
|    learning_rate        | 0.0003        |
|    loss                 | -15.6         |
|    n_updates            | 670           |
|    policy_gradient_loss | -12.8         |
|    std                  | 0.36          |
|    value_loss           | 569           |
-------------------------------------------
-----------------------------------------
| reward                  | [-2.483818] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 39.29526    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.785      |
|    explained_variance   | -0.0134     |
|    learning_rate        | 0.0003      |
|    loss                 | -47         |
|    n_updates            | 670         |
|    policy_gradient_loss | -30.1       |
|    std                  | 0.364       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-2.2694552] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 51.875076    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.609       |
|    explained_variance   | -0.0966      |
|    learning_rate        | 0.0003       |
|    loss                 | -40.9        |
|    n_updates            | 730          |
|    policy_gradient_loss | -39.9        |
|    std                  | 0.427        |
|    value_loss           | 849          |
------------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 155648       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.48386014] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 141312        |
| train/                  |               |
|    approx_kl            | 22.892864     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.591        |
|    explained_variance   | 0.0318        |
|    learning_rate        | 0.0003        |
|    loss                 | -22.7         |
|    n_updates            | 680           |
|    policy_gradient_loss | -21.4         |
|    std                  | 0.354         |
|    value_loss           | 690           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.9843521] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 141312       |
| train/                  |              |
|    approx_kl            | 37.555725    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.733       |
|    explained_variance   | 0.0112       |
|    learning_rate        | 0.0003       |
|    loss                 | -34.7        |
|    n_updates            | 680          |
|    policy_gradient_loss | -35.6        |
|    std                  | 0.358        |
|    value_loss           | 1.65e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.48316893] |
| time/                   |               |
|    fps                  | 174           |
|    iterations           | 5             |
|    time_elapsed         | 58            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 33.423805     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.572        |
|    explained_variance   | 0.0277        |
|    learning_rate        | 0.0003        |
|    loss                 | -33.1         |
|    n_updates            | 740           |
|    policy_gradient_loss | -26.6         |
|    std                  | 0.428         |
|    value_loss           | 1.12e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -46.9        |
|    n_updates            | 760          |
|    policy_gradient_loss | -34.4        |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
-------------------------------------------
| reward                  | [-0.50531715] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 143360        |
| train/                  |               |
|    approx_kl            | 23.886585     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.551        |
|    explained_variance   | 0.016         |
|    learning_rate        | 0.0003        |
|    loss                 | -25.5         |
|    n_updates            | 690           |
|    policy_gradient_loss | -18.5         |
|    std                  | 0.346         |
|    value_loss           | 576           |
-------------------------------------------
------------------------------------------
| reward                  | [-3.0942957] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 17.218632    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.692       |
|    explained_variance   | 0.0252       |
|    learning_rate        | 0.0003       |
|    loss                 | -13          |
|    n_updates            | 690          |
|    policy_gradient_loss | -16.4        |
|    std                  | 0.35         |
|    value_loss           | 1.4e+03      |
------------------------------------------
-------------------------------------
| reward             | [-0.8942305] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 155648       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -26.7        |
|    n_updates            | 770          |
|    policy_gradient_loss | -29.6        |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
--------------------------------------
| reward             | [-0.43401134] |
| time/              |               |
|    fps             | 175           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 145408        |
--------------------------------------
-------------------------------------
| reward             | [-3.4528582] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 145408       |
-------------------------------------
------------------------------------------
| reward                  | [-1.2674972] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 38.48768     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.528       |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -46.9        |
|    n_updates            | 760          |
|    policy_gradient_loss | -34.4        |
|    std                  | 0.423        |
|    value_loss           | 1.1e+03      |
------------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 180        |
|    iterations           | 4          |
|    time_elapsed         | 45         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -28.3      |
|    n_updates            | 780        |
|    policy_gradient_loss | -20.9      |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
------------------------------------------
| reward                  | [-2.6587968] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 30.833841    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.451       |
|    explained_variance   | 0.0175       |
|    learning_rate        | 0.0003       |
|    loss                 | -30          |
|    n_updates            | 710          |
|    policy_gradient_loss | -26.9        |
|    std                  | 0.333        |
|    value_loss           | 587          |
------------------------------------------
------------------------------------------
| reward                  | [-1.4918827] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 32.293842    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.49        |
|    explained_variance   | 0.00827      |
|    learning_rate        | 0.0003       |
|    loss                 | -26.7        |
|    n_updates            | 770          |
|    policy_gradient_loss | -29.6        |
|    std                  | 0.417        |
|    value_loss           | 1.1e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.2459338] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 35.358864    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.624       |
|    explained_variance   | 0.00276      |
|    learning_rate        | 0.0003       |
|    loss                 | -31.3        |
|    n_updates            | 710          |
|    policy_gradient_loss | -25.8        |
|    std                  | 0.341        |
|    value_loss           | 1.54e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -28.5        |
|    n_updates            | 790          |
|    policy_gradient_loss | -24          |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.55440205] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 149504        |
| train/                  |               |
|    approx_kl            | 26.394796     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.415        |
|    explained_variance   | 0.0283        |
|    learning_rate        | 0.0003        |
|    loss                 | -25.6         |
|    n_updates            | 720           |
|    policy_gradient_loss | -22.7         |
|    std                  | 0.328         |
|    value_loss           | 483           |
-------------------------------------------
----------------------------------------
| reward                  | [-2.12471] |
| time/                   |            |
|    fps                  | 177        |
|    iterations           | 4          |
|    time_elapsed         | 46         |
|    total_timesteps      | 161792     |
| train/                  |            |
|    approx_kl            | 26.041569  |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | -28.3      |
|    n_updates            | 780        |
|    policy_gradient_loss | -20.9      |
|    std                  | 0.413      |
|    value_loss           | 1.12e+03   |
----------------------------------------
-------------------------------------------
| reward                  | [-0.55440205] |
| time/                   |               |
|    fps                  | 165           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 149504        |
| train/                  |               |
|    approx_kl            | 30.517284     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.59         |
|    explained_variance   | -0.0144       |
|    learning_rate        | 0.0003        |
|    loss                 | -33.9         |
|    n_updates            | 720           |
|    policy_gradient_loss | -25           |
|    std                  | 0.338         |
|    value_loss           | 1.37e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 165888       |
-------------------------------------
------------------------------------------
| reward                  | [-1.6923792] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.595177    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.428       |
|    explained_variance   | -0.0547      |
|    learning_rate        | 0.0003       |
|    loss                 | -28.5        |
|    n_updates            | 790          |
|    policy_gradient_loss | -24          |
|    std                  | 0.411        |
|    value_loss           | 875          |
------------------------------------------
------------------------------------------
| reward                  | [-0.7996829] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 151552       |
| train/                  |              |
|    approx_kl            | 23.927593    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.381       |
|    explained_variance   | 0.0363       |
|    learning_rate        | 0.0003       |
|    loss                 | -19.6        |
|    n_updates            | 730          |
|    policy_gradient_loss | -23          |
|    std                  | 0.326        |
|    value_loss           | 865          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.76356655] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 151552        |
| train/                  |               |
|    approx_kl            | 35.884865     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.556        |
|    explained_variance   | 0.0158        |
|    learning_rate        | 0.0003        |
|    loss                 | -32.8         |
|    n_updates            | 730           |
|    policy_gradient_loss | -33.3         |
|    std                  | 0.332         |
|    value_loss           | 1.36e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -27.5        |
|    n_updates            | 810          |
|    policy_gradient_loss | -31.6        |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.7211037] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 165888       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.31815112] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 32.27175      |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.35         |
|    explained_variance   | 0.0358        |
|    learning_rate        | 0.0003        |
|    loss                 | -29.9         |
|    n_updates            | 740           |
|    policy_gradient_loss | -26.1         |
|    std                  | 0.32          |
|    value_loss           | 870           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.33803797] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 5             |
|    time_elapsed         | 62            |
|    total_timesteps      | 153600        |
| train/                  |               |
|    approx_kl            | 19.505943     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.516        |
|    explained_variance   | 0.0137        |
|    learning_rate        | 0.0003        |
|    loss                 | -21.5         |
|    n_updates            | 740           |
|    policy_gradient_loss | -17.2         |
|    std                  | 0.327         |
|    value_loss           | 1.13e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -35.6        |
|    n_updates            | 820          |
|    policy_gradient_loss | -48.2        |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4201086] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 45.36876     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.383       |
|    explained_variance   | -0.00612     |
|    learning_rate        | 0.0003       |
|    loss                 | -27.5        |
|    n_updates            | 810          |
|    policy_gradient_loss | -31.6        |
|    std                  | 0.405        |
|    value_loss           | 1.23e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.3105928] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 155648       |
-------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 4           |
|    time_elapsed         | 45          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -47.2       |
|    n_updates            | 830         |
|    policy_gradient_loss | -32         |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
-------------------------------------
| reward             | [-1.4150374] |
| time/              |              |
|    fps             | 173          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 155648       |
-------------------------------------
------------------------------------------
| reward                  | [-3.5106978] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 52.85004     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.352       |
|    explained_variance   | 0.0141       |
|    learning_rate        | 0.0003       |
|    loss                 | -35.6        |
|    n_updates            | 820          |
|    policy_gradient_loss | -48.2        |
|    std                  | 0.402        |
|    value_loss           | 1.24e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -74.7        |
|    n_updates            | 840          |
|    policy_gradient_loss | -40          |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6424851] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 27.388588    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.262       |
|    explained_variance   | 0.0466       |
|    learning_rate        | 0.0003       |
|    loss                 | -33.2        |
|    n_updates            | 760          |
|    policy_gradient_loss | -23.9        |
|    std                  | 0.308        |
|    value_loss           | 895          |
------------------------------------------
------------------------------------------
| reward                  | [-1.9129392] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 39.57435     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.441       |
|    explained_variance   | 0.0366       |
|    learning_rate        | 0.0003       |
|    loss                 | -50.9        |
|    n_updates            | 760          |
|    policy_gradient_loss | -37.1        |
|    std                  | 0.316        |
|    value_loss           | 1.23e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.289084] |
| time/                   |             |
|    fps                  | 175         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 172032      |
| train/                  |             |
|    approx_kl            | 39.898468   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.333      |
|    explained_variance   | 0.00124     |
|    learning_rate        | 0.0003      |
|    loss                 | -47.2       |
|    n_updates            | 830         |
|    policy_gradient_loss | -32         |
|    std                  | 0.402       |
|    value_loss           | 1.6e+03     |
-----------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-1.9166911] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 58.681507    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.208       |
|    explained_variance   | 0.0419       |
|    learning_rate        | 0.0003       |
|    loss                 | -65.4        |
|    n_updates            | 770          |
|    policy_gradient_loss | -53.7        |
|    std                  | 0.302        |
|    value_loss           | 616          |
------------------------------------------
------------------------------------------
| reward                  | [-2.1750522] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 64.06232     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.405       |
|    explained_variance   | 0.0314       |
|    learning_rate        | 0.0003       |
|    loss                 | -69.1        |
|    n_updates            | 770          |
|    policy_gradient_loss | -55.6        |
|    std                  | 0.312        |
|    value_loss           | 816          |
------------------------------------------
------------------------------------------
| reward                  | [-3.7552917] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 65.30134     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.299       |
|    explained_variance   | 0.0106       |
|    learning_rate        | 0.0003       |
|    loss                 | -74.7        |
|    n_updates            | 840          |
|    policy_gradient_loss | -40          |
|    std                  | 0.394        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -34.4        |
|    n_updates            | 860          |
|    policy_gradient_loss | -28.4        |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2786412] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 161792       |
| train/                  |              |
|    approx_kl            | 27.93819     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.155       |
|    explained_variance   | 0.043        |
|    learning_rate        | 0.0003       |
|    loss                 | -30.6        |
|    n_updates            | 780          |
|    policy_gradient_loss | -23.9        |
|    std                  | 0.294        |
|    value_loss           | 936          |
------------------------------------------
------------------------------------------
| reward                  | [-2.7410834] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 161792       |
| train/                  |              |
|    approx_kl            | 35.191074    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.371       |
|    explained_variance   | 0.0297       |
|    learning_rate        | 0.0003       |
|    loss                 | -46.3        |
|    n_updates            | 780          |
|    policy_gradient_loss | -33.8        |
|    std                  | 0.309        |
|    value_loss           | 1.6e+03      |
------------------------------------------
-------------------------------------
| reward             | [-0.5545792] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -71.9        |
|    n_updates            | 870          |
|    policy_gradient_loss | -59.2        |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.5904038] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 24.278004    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.102       |
|    explained_variance   | 0.0397       |
|    learning_rate        | 0.0003       |
|    loss                 | -25.8        |
|    n_updates            | 790          |
|    policy_gradient_loss | -21.3        |
|    std                  | 0.292        |
|    value_loss           | 976          |
------------------------------------------
------------------------------------------
| reward                  | [-3.2044256] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 41.03865     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.337       |
|    explained_variance   | 0.027        |
|    learning_rate        | 0.0003       |
|    loss                 | -26.5        |
|    n_updates            | 790          |
|    policy_gradient_loss | -33.4        |
|    std                  | 0.304        |
|    value_loss           | 1.77e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.2155575] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 37.42736     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.213       |
|    explained_variance   | -0.00675     |
|    learning_rate        | 0.0003       |
|    loss                 | -34.4        |
|    n_updates            | 860          |
|    policy_gradient_loss | -28.4        |
|    std                  | 0.384        |
|    value_loss           | 1.59e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -50          |
|    n_updates            | 880          |
|    policy_gradient_loss | -40.7        |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.6075413] |
| time/              |              |
|    fps             | 173          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 165888       |
-------------------------------------
-------------------------------------
| reward             | [-3.5626714] |
| time/              |              |
|    fps             | 171          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 165888       |
-------------------------------------
------------------------------------------
| reward                  | [-1.5683413] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.25597     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.175       |
|    explained_variance   | -0.0329      |
|    learning_rate        | 0.0003       |
|    loss                 | -71.9        |
|    n_updates            | 870          |
|    policy_gradient_loss | -59.2        |
|    std                  | 0.381        |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -48.4        |
|    n_updates            | 890          |
|    policy_gradient_loss | -57.2        |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.952998] |
| time/                   |             |
|    fps                  | 166         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 67.08002    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0226     |
|    explained_variance   | 0.0328      |
|    learning_rate        | 0.0003      |
|    loss                 | -85         |
|    n_updates            | 810         |
|    policy_gradient_loss | -54.2       |
|    std                  | 0.282       |
|    value_loss           | 805         |
-----------------------------------------
------------------------------------------
| reward                  | [-3.7551842] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 47.637886    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.254       |
|    explained_variance   | 0.0186       |
|    learning_rate        | 0.0003       |
|    loss                 | -47.5        |
|    n_updates            | 810          |
|    policy_gradient_loss | -37.4        |
|    std                  | 0.297        |
|    value_loss           | 1.82e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0673087] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 50.353504    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.153       |
|    explained_variance   | -0.00733     |
|    learning_rate        | 0.0003       |
|    loss                 | -50          |
|    n_updates            | 880          |
|    policy_gradient_loss | -40.7        |
|    std                  | 0.381        |
|    value_loss           | 1.55e+03     |
------------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 186368       |
-------------------------------------
-----------------------------------------
| reward                  | [-3.025244] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 34.855835   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0147      |
|    explained_variance   | 0.0463      |
|    learning_rate        | 0.0003      |
|    loss                 | -52.8       |
|    n_updates            | 820         |
|    policy_gradient_loss | -29         |
|    std                  | 0.278       |
|    value_loss           | 1.16e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-4.1902094] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 43.529095    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.228       |
|    explained_variance   | 0.0087       |
|    learning_rate        | 0.0003       |
|    loss                 | -79.2        |
|    n_updates            | 820          |
|    policy_gradient_loss | -37.8        |
|    std                  | 0.294        |
|    value_loss           | 1.91e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0002675] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 58.232903    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.133       |
|    explained_variance   | 0.00354      |
|    learning_rate        | 0.0003       |
|    loss                 | -48.4        |
|    n_updates            | 890          |
|    policy_gradient_loss | -57.2        |
|    std                  | 0.381        |
|    value_loss           | 1.79e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -114        |
|    n_updates            | 910         |
|    policy_gradient_loss | -75.9       |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.37124845] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 172032        |
| train/                  |               |
|    approx_kl            | 49.518517     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.0625        |
|    explained_variance   | 0.0279        |
|    learning_rate        | 0.0003        |
|    loss                 | -37.2         |
|    n_updates            | 830           |
|    policy_gradient_loss | -45.1         |
|    std                  | 0.272         |
|    value_loss           | 1.07e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-2.1741376] |
| time/              |              |
|    fps             | 186          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 186368       |
-------------------------------------
-------------------------------------------
| reward                  | [-0.54063356] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 4             |
|    time_elapsed         | 50            |
|    total_timesteps      | 172032        |
| train/                  |               |
|    approx_kl            | 56.550125     |
|    clip_range           | 0.2           |
|    entropy_loss         | -0.185        |
|    explained_variance   | 0.00361       |
|    learning_rate        | 0.0003        |
|    loss                 | -58.2         |
|    n_updates            | 830           |
|    policy_gradient_loss | -46.7         |
|    std                  | 0.29          |
|    value_loss           | 1.9e+03       |
-------------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -47          |
|    n_updates            | 920          |
|    policy_gradient_loss | -42.8        |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.104883] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 95.64413    |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0661     |
|    explained_variance   | -0.00771    |
|    learning_rate        | 0.0003      |
|    loss                 | -114        |
|    n_updates            | 910         |
|    policy_gradient_loss | -75.9       |
|    std                  | 0.371       |
|    value_loss           | 1.69e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.6542949] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 44.99473     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.113        |
|    explained_variance   | 0.027        |
|    learning_rate        | 0.0003       |
|    loss                 | -59.3        |
|    n_updates            | 840          |
|    policy_gradient_loss | -36.5        |
|    std                  | 0.266        |
|    value_loss           | 1.02e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0619959] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 51.445503    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.143       |
|    explained_variance   | 0.0202       |
|    learning_rate        | 0.0003       |
|    loss                 | -63.3        |
|    n_updates            | 840          |
|    policy_gradient_loss | -38.6        |
|    std                  | 0.283        |
|    value_loss           | 1.86e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 4           |
|    time_elapsed         | 45          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -56.3       |
|    n_updates            | 930         |
|    policy_gradient_loss | -60.9       |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.2171333] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 56.65505     |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0328      |
|    explained_variance   | -0.0139      |
|    learning_rate        | 0.0003       |
|    loss                 | -47          |
|    n_updates            | 920          |
|    policy_gradient_loss | -42.8        |
|    std                  | 0.367        |
|    value_loss           | 1.88e+03     |
------------------------------------------
-------------------------------------
| reward             | [-0.5290984] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
-------------------------------------
| reward             | [-1.4967928] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 176128       |
-------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -82.6        |
|    n_updates            | 940          |
|    policy_gradient_loss | -62.8        |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.433385] |
| time/                   |             |
|    fps                  | 176         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 69.363144   |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.00601    |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | -56.3       |
|    n_updates            | 930         |
|    policy_gradient_loss | -60.9       |
|    std                  | 0.363       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 189           |
|    iterations      | 1             |
|    time_elapsed    | 10            |
|    total_timesteps | 196608        |
--------------------------------------
-------------------------------------------
| reward                  | [-0.34186095] |
| time/                   |               |
|    fps                  | 166           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 178176        |
| train/                  |               |
|    approx_kl            | 62.273495     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.206         |
|    explained_variance   | 0.0377        |
|    learning_rate        | 0.0003        |
|    loss                 | -77.1         |
|    n_updates            | 860           |
|    policy_gradient_loss | -58.4         |
|    std                  | 0.257         |
|    value_loss           | 662           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.7089398] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 69.178856    |
|    clip_range           | 0.2          |
|    entropy_loss         | -0.0116      |
|    explained_variance   | -0.00281     |
|    learning_rate        | 0.0003       |
|    loss                 | -69.6        |
|    n_updates            | 860          |
|    policy_gradient_loss | -61.6        |
|    std                  | 0.265        |
|    value_loss           | 2.01e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3170798] |
| time/                   |              |
|    fps                  | 175          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 69.33116     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0188       |
|    explained_variance   | 0.0102       |
|    learning_rate        | 0.0003       |
|    loss                 | -82.6        |
|    n_updates            | 940          |
|    policy_gradient_loss | -62.8        |
|    std                  | 0.361        |
|    value_loss           | 1.58e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -63.6        |
|    n_updates            | 960          |
|    policy_gradient_loss | -45.5        |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8876117] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 228.44522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.236        |
|    explained_variance   | 0.0638       |
|    learning_rate        | 0.0003       |
|    loss                 | -218         |
|    n_updates            | 870          |
|    policy_gradient_loss | -125         |
|    std                  | 0.255        |
|    value_loss           | 69.1         |
------------------------------------------
------------------------------------------
| reward                  | [-2.2443256] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 180224       |
| train/                  |              |
|    approx_kl            | 64.76004     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0411       |
|    explained_variance   | -0.00528     |
|    learning_rate        | 0.0003       |
|    loss                 | -46.6        |
|    n_updates            | 870          |
|    policy_gradient_loss | -52.7        |
|    std                  | 0.261        |
|    value_loss           | 1.89e+03     |
------------------------------------------
--------------------------------------
| reward             | [-0.34332812] |
| time/              |               |
|    fps             | 181           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 196608        |
--------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -80.4        |
|    n_updates            | 970          |
|    policy_gradient_loss | -69.8        |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3375714] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 58.85361     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.269        |
|    explained_variance   | 0.0276       |
|    learning_rate        | 0.0003       |
|    loss                 | -58          |
|    n_updates            | 880          |
|    policy_gradient_loss | -49.3        |
|    std                  | 0.248        |
|    value_loss           | 402          |
------------------------------------------
------------------------------------------
| reward                  | [-2.7523255] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 59.351875    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0809       |
|    explained_variance   | 0.00854      |
|    learning_rate        | 0.0003       |
|    loss                 | -48.8        |
|    n_updates            | 880          |
|    policy_gradient_loss | -55.2        |
|    std                  | 0.257        |
|    value_loss           | 1.7e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.0277133] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 59.383213    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.052        |
|    explained_variance   | 0.0081       |
|    learning_rate        | 0.0003       |
|    loss                 | -63.6        |
|    n_updates            | 960          |
|    policy_gradient_loss | -45.5        |
|    std                  | 0.365        |
|    value_loss           | 1.26e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -61          |
|    n_updates            | 980          |
|    policy_gradient_loss | -90.8        |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.7848728] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 35.618835    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.32         |
|    explained_variance   | 0.0323       |
|    learning_rate        | 0.0003       |
|    loss                 | -32.5        |
|    n_updates            | 890          |
|    policy_gradient_loss | -29.7        |
|    std                  | 0.246        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-3.1875713] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 87.530876    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.121        |
|    explained_variance   | 0.0125       |
|    learning_rate        | 0.0003       |
|    loss                 | -65.4        |
|    n_updates            | 890          |
|    policy_gradient_loss | -73.8        |
|    std                  | 0.252        |
|    value_loss           | 1.98e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4749953] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 3            |
|    time_elapsed         | 35           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 83.0468      |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0511       |
|    explained_variance   | -0.015       |
|    learning_rate        | 0.0003       |
|    loss                 | -80.4        |
|    n_updates            | 970          |
|    policy_gradient_loss | -69.8        |
|    std                  | 0.369        |
|    value_loss           | 1.19e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 56           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -43.5        |
|    n_updates            | 990          |
|    policy_gradient_loss | -37.5        |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.875868] |
| time/              |             |
|    fps             | 174         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 186368      |
------------------------------------
-------------------------------------
| reward             | [-3.6798937] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 186368       |
-------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-1.7257212] |
| time/                   |              |
|    fps                  | 173          |
|    iterations           | 4            |
|    time_elapsed         | 47           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 89.326355    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.0833       |
|    explained_variance   | 0.00101      |
|    learning_rate        | 0.0003       |
|    loss                 | -61          |
|    n_updates            | 980          |
|    policy_gradient_loss | -90.8        |
|    std                  | 0.363        |
|    value_loss           | 1.43e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.9496968] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 46.204773    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.401        |
|    explained_variance   | 0.0343       |
|    learning_rate        | 0.0003       |
|    loss                 | -62.9        |
|    n_updates            | 910          |
|    policy_gradient_loss | -40.2        |
|    std                  | 0.237        |
|    value_loss           | 1.02e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.7851386] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 76.13777     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.215        |
|    explained_variance   | 0.0096       |
|    learning_rate        | 0.0003       |
|    loss                 | -109         |
|    n_updates            | 910          |
|    policy_gradient_loss | -64.5        |
|    std                  | 0.245        |
|    value_loss           | 2.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -248         |
|    n_updates            | 1010         |
|    policy_gradient_loss | -166         |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
------------------------------------------
| reward                  | [-1.7154124] |
| time/                   |              |
|    fps                  | 174          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 48.563404    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.1          |
|    explained_variance   | 0.00162      |
|    learning_rate        | 0.0003       |
|    loss                 | -43.5        |
|    n_updates            | 990          |
|    policy_gradient_loss | -37.5        |
|    std                  | 0.365        |
|    value_loss           | 1.11e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.0332377] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 96.102844    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.45         |
|    explained_variance   | 0.0366       |
|    learning_rate        | 0.0003       |
|    loss                 | -104         |
|    n_updates            | 920          |
|    policy_gradient_loss | -83.3        |
|    std                  | 0.234        |
|    value_loss           | 735          |
------------------------------------------
------------------------------------------
| reward                  | [-3.8788755] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 190464       |
| train/                  |              |
|    approx_kl            | 93.69588     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.253        |
|    explained_variance   | -0.00584     |
|    learning_rate        | 0.0003       |
|    loss                 | -116         |
|    n_updates            | 920          |
|    policy_gradient_loss | -83.2        |
|    std                  | 0.242        |
|    value_loss           | 1.98e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -81.9        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -90.7        |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
-------------------------------------
| reward             | [-2.4973643] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-0.3451252] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 59.320568    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.475        |
|    explained_variance   | 0.0315       |
|    learning_rate        | 0.0003       |
|    loss                 | -58.9        |
|    n_updates            | 930          |
|    policy_gradient_loss | -49.8        |
|    std                  | 0.235        |
|    value_loss           | 1.42e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.33670455] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 4             |
|    time_elapsed         | 49            |
|    total_timesteps      | 192512        |
| train/                  |               |
|    approx_kl            | 107.23365     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.279         |
|    explained_variance   | 0.00911       |
|    learning_rate        | 0.0003        |
|    loss                 | -134          |
|    n_updates            | 930           |
|    policy_gradient_loss | -86.6         |
|    std                  | 0.244         |
|    value_loss           | 2.11e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -86.4        |
|    n_updates            | 1030         |
|    policy_gradient_loss | -46.7        |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4387097] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 247.21289    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.111        |
|    explained_variance   | -0.102       |
|    learning_rate        | 0.0003       |
|    loss                 | -248         |
|    n_updates            | 1010         |
|    policy_gradient_loss | -166         |
|    std                  | 0.37         |
|    value_loss           | 786          |
------------------------------------------
------------------------------------------
| reward                  | [-0.6152725] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 61.34263     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.488        |
|    explained_variance   | 0.0342       |
|    learning_rate        | 0.0003       |
|    loss                 | -60.7        |
|    n_updates            | 940          |
|    policy_gradient_loss | -46.9        |
|    std                  | 0.233        |
|    value_loss           | 1.3e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-0.9148875] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 194560       |
| train/                  |              |
|    approx_kl            | 141.11984    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.289        |
|    explained_variance   | 0.00919      |
|    learning_rate        | 0.0003       |
|    loss                 | -146         |
|    n_updates            | 940          |
|    policy_gradient_loss | -127         |
|    std                  | 0.243        |
|    value_loss           | 1.96e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -114         |
|    n_updates            | 1040         |
|    policy_gradient_loss | -59          |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.1427972] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 99.49448     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.126        |
|    explained_variance   | 0.0123       |
|    learning_rate        | 0.0003       |
|    loss                 | -81.9        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -90.7        |
|    std                  | 0.37         |
|    value_loss           | 1.3e+03      |
------------------------------------------
-------------------------------------
| reward             | [-1.0801448] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 196608       |
-------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 183         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 217088      |
------------------------------------
------------------------------------
| reward             | [-1.332296] |
| time/              |             |
|    fps             | 175         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 196608      |
------------------------------------
------------------------------------------
| reward                  | [-3.4400408] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 72.42245     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.145        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -86.4        |
|    n_updates            | 1030         |
|    policy_gradient_loss | -46.7        |
|    std                  | 0.369        |
|    value_loss           | 1.14e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 180           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -28.8         |
|    n_updates            | 1060          |
|    policy_gradient_loss | -48.5         |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.3710219] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 54.57827     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.578        |
|    explained_variance   | 0.0451       |
|    learning_rate        | 0.0003       |
|    loss                 | -41.7        |
|    n_updates            | 960          |
|    policy_gradient_loss | -44.6        |
|    std                  | 0.225        |
|    value_loss           | 945          |
------------------------------------------
------------------------------------------
| reward                  | [-3.8836465] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 88.821       |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.171        |
|    explained_variance   | 0.00562      |
|    learning_rate        | 0.0003       |
|    loss                 | -114         |
|    n_updates            | 1040         |
|    policy_gradient_loss | -59          |
|    std                  | 0.369        |
|    value_loss           | 1.53e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.8223394] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 89.47104     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.372        |
|    explained_variance   | 0.0038       |
|    learning_rate        | 0.0003       |
|    loss                 | -118         |
|    n_updates            | 960          |
|    policy_gradient_loss | -70.7        |
|    std                  | 0.235        |
|    value_loss           | 1.9e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -125         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -122         |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
------------------------------------
| reward             | [-4.421654] |
| time/              |             |
|    fps             | 185         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 217088      |
------------------------------------
------------------------------------------
| reward                  | [-1.6038805] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 200704       |
| train/                  |              |
|    approx_kl            | 57.499733    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.621        |
|    explained_variance   | 0.0255       |
|    learning_rate        | 0.0003       |
|    loss                 | -52.9        |
|    n_updates            | 970          |
|    policy_gradient_loss | -41.4        |
|    std                  | 0.223        |
|    value_loss           | 1.2e+03      |
------------------------------------------
-----------------------------------------
| reward                  | [-2.227655] |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 200704      |
| train/                  |             |
|    approx_kl            | 69.95053    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.415       |
|    explained_variance   | 0.0178      |
|    learning_rate        | 0.0003      |
|    loss                 | -53         |
|    n_updates            | 970         |
|    policy_gradient_loss | -54         |
|    std                  | 0.233       |
|    value_loss           | 1.91e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -81.4        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -65.2        |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.83040607] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 219136        |
| train/                  |               |
|    approx_kl            | 56.917686     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.211         |
|    explained_variance   | -0.00212      |
|    learning_rate        | 0.0003        |
|    loss                 | -28.8         |
|    n_updates            | 1060          |
|    policy_gradient_loss | -48.5         |
|    std                  | 0.366         |
|    value_loss           | 2.08e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-1.8393756] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 59.433624    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.665        |
|    explained_variance   | 0.0378       |
|    learning_rate        | 0.0003       |
|    loss                 | -63          |
|    n_updates            | 980          |
|    policy_gradient_loss | -52.5        |
|    std                  | 0.217        |
|    value_loss           | 1.14e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3966973] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 179.54742    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.45         |
|    explained_variance   | 0.0152       |
|    learning_rate        | 0.0003       |
|    loss                 | -247         |
|    n_updates            | 980          |
|    policy_gradient_loss | -137         |
|    std                  | 0.229        |
|    value_loss           | 2.04e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -81.3        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -140         |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.4503136] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 127.92296    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.24         |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.0003       |
|    loss                 | -125         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -122         |
|    std                  | 0.367        |
|    value_loss           | 1.73e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-2.417446] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 48.240532   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.719       |
|    explained_variance   | 0.0361      |
|    learning_rate        | 0.0003      |
|    loss                 | -61.6       |
|    n_updates            | 990         |
|    policy_gradient_loss | -43.9       |
|    std                  | 0.211       |
|    value_loss           | 1.09e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-3.259812] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 84.107635   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.495       |
|    explained_variance   | 0.0199      |
|    learning_rate        | 0.0003      |
|    loss                 | -91.6       |
|    n_updates            | 990         |
|    policy_gradient_loss | -64.4       |
|    std                  | 0.226       |
|    value_loss           | 1.98e+03    |
-----------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 186         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 227328      |
------------------------------------
------------------------------------------
| reward                  | [-1.6851132] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 75.64732     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.258        |
|    explained_variance   | -0.0017      |
|    learning_rate        | 0.0003       |
|    loss                 | -81.4        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -65.2        |
|    std                  | 0.365        |
|    value_loss           | 1.57e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.794458] |
| time/              |             |
|    fps             | 174         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 206848      |
------------------------------------
-------------------------------------
| reward             | [-3.4322093] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 206848       |
-------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 181          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -289         |
|    n_updates            | 1110         |
|    policy_gradient_loss | -219         |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.6492611] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 83.00077     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.288        |
|    explained_variance   | -0.00413     |
|    learning_rate        | 0.0003       |
|    loss                 | -81.3        |
|    n_updates            | 1090         |
|    policy_gradient_loss | -140         |
|    std                  | 0.36         |
|    value_loss           | 1.81e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.8510206] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 67.367325    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.829        |
|    explained_variance   | 0.0211       |
|    learning_rate        | 0.0003       |
|    loss                 | -51.3        |
|    n_updates            | 1010         |
|    policy_gradient_loss | -52.1        |
|    std                  | 0.205        |
|    value_loss           | 1.23e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-3.797136] |
| time/                   |             |
|    fps                  | 167         |
|    iterations           | 2           |
|    time_elapsed         | 24          |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 70.45202    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.602       |
|    explained_variance   | 0.00855     |
|    learning_rate        | 0.0003      |
|    loss                 | -54         |
|    n_updates            | 1010        |
|    policy_gradient_loss | -53.8       |
|    std                  | 0.217       |
|    value_loss           | 2.1e+03     |
-----------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -173         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -86.1        |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------
| reward             | [-2.024026] |
| time/              |             |
|    fps             | 186         |
|    iterations      | 1           |
|    time_elapsed    | 10          |
|    total_timesteps | 227328      |
------------------------------------
------------------------------------------
| reward                  | [-2.9811187] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 65.86238     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.867        |
|    explained_variance   | 0.0194       |
|    learning_rate        | 0.0003       |
|    loss                 | -62.2        |
|    n_updates            | 1020         |
|    policy_gradient_loss | -53.6        |
|    std                  | 0.201        |
|    value_loss           | 1.28e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.5494132] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 210944       |
| train/                  |              |
|    approx_kl            | 110.02663    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.645        |
|    explained_variance   | 0.0171       |
|    learning_rate        | 0.0003       |
|    loss                 | -106         |
|    n_updates            | 1020         |
|    policy_gradient_loss | -96.2        |
|    std                  | 0.214        |
|    value_loss           | 2.08e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -284         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -131         |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.9711424] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 257.97522    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.328        |
|    explained_variance   | -0.00253     |
|    learning_rate        | 0.0003       |
|    loss                 | -289         |
|    n_updates            | 1110         |
|    policy_gradient_loss | -219         |
|    std                  | 0.36         |
|    value_loss           | 1.35e+03     |
------------------------------------------
----------------------------------------
| reward                  | [-3.02582] |
| time/                   |            |
|    fps                  | 164        |
|    iterations           | 4          |
|    time_elapsed         | 49         |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 61.734085  |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.914      |
|    explained_variance   | 0.0173     |
|    learning_rate        | 0.0003     |
|    loss                 | -56.6      |
|    n_updates            | 1030       |
|    policy_gradient_loss | -54.4      |
|    std                  | 0.199      |
|    value_loss           | 1.32e+03   |
----------------------------------------
-----------------------------------------
| reward                  | [-4.149649] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 4           |
|    time_elapsed         | 50          |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 71.679436   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.676       |
|    explained_variance   | -0.0228     |
|    learning_rate        | 0.0003      |
|    loss                 | -72.1       |
|    n_updates            | 1030        |
|    policy_gradient_loss | -52.8       |
|    std                  | 0.214       |
|    value_loss           | 1.78e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -174         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -95.7        |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-3.3265586] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 124.60712    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.349        |
|    explained_variance   | -0.00433     |
|    learning_rate        | 0.0003       |
|    loss                 | -173         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -86.1        |
|    std                  | 0.36         |
|    value_loss           | 1.65e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5758964] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 71.75205     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.962        |
|    explained_variance   | 0.0319       |
|    learning_rate        | 0.0003       |
|    loss                 | -70.1        |
|    n_updates            | 1040         |
|    policy_gradient_loss | -67.3        |
|    std                  | 0.194        |
|    value_loss           | 999          |
------------------------------------------
-------------------------------------------
| reward                  | [-0.59744513] |
| time/                   |               |
|    fps                  | 161           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 215040        |
| train/                  |               |
|    approx_kl            | 122.11795     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.722         |
|    explained_variance   | 0.00827       |
|    learning_rate        | 0.0003        |
|    loss                 | -142          |
|    n_updates            | 1040          |
|    policy_gradient_loss | -104          |
|    std                  | 0.209         |
|    value_loss           | 2.26e+03      |
-------------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 237568       |
-------------------------------------
------------------------------------------
| reward                  | [-3.3456163] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 257.01807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.361        |
|    explained_variance   | 0.00439      |
|    learning_rate        | 0.0003       |
|    loss                 | -284         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -131         |
|    std                  | 0.367        |
|    value_loss           | 1.83e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.1156248] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 217088       |
-------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 182          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -637         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -316         |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
--------------------------------------
| reward             | [-0.96057546] |
| time/              |               |
|    fps             | 175           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 217088        |
--------------------------------------
------------------------------------------
| reward                  | [-3.4841785] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 122.657425   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.375        |
|    explained_variance   | -0.00266     |
|    learning_rate        | 0.0003       |
|    loss                 | -174         |
|    n_updates            | 1140         |
|    policy_gradient_loss | -95.7        |
|    std                  | 0.372        |
|    value_loss           | 1.97e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 33           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.09e+03    |
|    n_updates            | 1170         |
|    policy_gradient_loss | -816         |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
------------------------------------------
| reward                  | [-1.3544822] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 81.68513     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.04         |
|    explained_variance   | 0.0227       |
|    learning_rate        | 0.0003       |
|    loss                 | -72.8        |
|    n_updates            | 1060         |
|    policy_gradient_loss | -64.9        |
|    std                  | 0.192        |
|    value_loss           | 1.35e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.5608163] |
| time/                   |              |
|    fps                  | 168          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 230.1883     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.8          |
|    explained_variance   | -0.0311      |
|    learning_rate        | 0.0003       |
|    loss                 | -239         |
|    n_updates            | 1060         |
|    policy_gradient_loss | -163         |
|    std                  | 0.206        |
|    value_loss           | 1.51e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.7379471] |
| time/              |              |
|    fps             | 184          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 237568       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.15e+03    |
|    n_updates            | 1180         |
|    policy_gradient_loss | -281         |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.553501] |
| time/                   |             |
|    fps                  | 165         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 221184      |
| train/                  |             |
|    approx_kl            | 66.19       |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.07        |
|    explained_variance   | 0.0179      |
|    learning_rate        | 0.0003      |
|    loss                 | -71.1       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -57.6       |
|    std                  | 0.192       |
|    value_loss           | 1.31e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.1515214] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 114.633286   |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.82         |
|    explained_variance   | -0.0124      |
|    learning_rate        | 0.0003       |
|    loss                 | -127         |
|    n_updates            | 1070         |
|    policy_gradient_loss | -98.1        |
|    std                  | 0.206        |
|    value_loss           | 1.55e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.5932144] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 2            |
|    time_elapsed         | 23           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 478.26562    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.403        |
|    explained_variance   | -0.0496      |
|    learning_rate        | 0.0003       |
|    loss                 | -637         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -316         |
|    std                  | 0.368        |
|    value_loss           | 906          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -353         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -183         |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
------------------------------------------
| reward                  | [-2.0380847] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 108.77807    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.1          |
|    explained_variance   | 0.0268       |
|    learning_rate        | 0.0003       |
|    loss                 | -163         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -91.9        |
|    std                  | 0.19         |
|    value_loss           | 1.22e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.0381571] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 1226.2227    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.42         |
|    explained_variance   | -0.0701      |
|    learning_rate        | 0.0003       |
|    loss                 | -1.09e+03    |
|    n_updates            | 1170         |
|    policy_gradient_loss | -816         |
|    std                  | 0.366        |
|    value_loss           | 652          |
------------------------------------------
------------------------------------------
| reward                  | [-2.3741055] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 191.96953    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.864        |
|    explained_variance   | 0.00651      |
|    learning_rate        | 0.0003       |
|    loss                 | -305         |
|    n_updates            | 1080         |
|    policy_gradient_loss | -169         |
|    std                  | 0.201        |
|    value_loss           | 1.96e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 247808       |
-------------------------------------
------------------------------------------
| reward                  | [-1.4188985] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 967.3385     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.444        |
|    explained_variance   | 0.0178       |
|    learning_rate        | 0.0003       |
|    loss                 | -1.15e+03    |
|    n_updates            | 1180         |
|    policy_gradient_loss | -281         |
|    std                  | 0.366        |
|    value_loss           | 991          |
------------------------------------------
------------------------------------------
| reward                  | [-2.2485611] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 108.87626    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.14         |
|    explained_variance   | 0.03         |
|    learning_rate        | 0.0003       |
|    loss                 | -106         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -92.5        |
|    std                  | 0.186        |
|    value_loss           | 1.16e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.7317655] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 185.40715    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.921        |
|    explained_variance   | 0.013        |
|    learning_rate        | 0.0003       |
|    loss                 | -176         |
|    n_updates            | 1090         |
|    policy_gradient_loss | -174         |
|    std                  | 0.198        |
|    value_loss           | 2.02e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -137         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -138         |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.0095382] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 343.00537    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.454        |
|    explained_variance   | 0.0129       |
|    learning_rate        | 0.0003       |
|    loss                 | -353         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -183         |
|    std                  | 0.372        |
|    value_loss           | 955          |
------------------------------------------
-------------------------------------
| reward             | [-2.3243315] |
| time/              |              |
|    fps             | 174          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 227328       |
-------------------------------------
-------------------------------------
| reward             | [-3.4587328] |
| time/              |              |
|    fps             | 172          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 227328       |
-------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 180          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -114         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -119         |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
-------------------------------------
| reward             | [-1.9615445] |
| time/              |              |
|    fps             | 185          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 247808       |
-------------------------------------
------------------------------------------
| reward                  | [-2.5482528] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 112.339806   |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | 0.035        |
|    learning_rate        | 0.0003       |
|    loss                 | -89.9        |
|    n_updates            | 1110         |
|    policy_gradient_loss | -88.1        |
|    std                  | 0.182        |
|    value_loss           | 781          |
------------------------------------------
------------------------------------------
| reward                  | [-3.5535612] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 199.27545    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1            |
|    explained_variance   | 0.0188       |
|    learning_rate        | 0.0003       |
|    loss                 | -184         |
|    n_updates            | 1110         |
|    policy_gradient_loss | -196         |
|    std                  | 0.194        |
|    value_loss           | 1.94e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 4            |
|    time_elapsed         | 45           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -185         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -201         |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.4598815] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 224.6451     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.485        |
|    explained_variance   | -0.00322     |
|    learning_rate        | 0.0003       |
|    loss                 | -137         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -138         |
|    std                  | 0.369        |
|    value_loss           | 1.41e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.8512197] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 370.85004    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.26         |
|    explained_variance   | 0.0352       |
|    learning_rate        | 0.0003       |
|    loss                 | -424         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -305         |
|    std                  | 0.18         |
|    value_loss           | 542          |
------------------------------------------
------------------------------------------
| reward                  | [-3.7266116] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 231424       |
| train/                  |              |
|    approx_kl            | 114.62001    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.03         |
|    explained_variance   | 0.0276       |
|    learning_rate        | 0.0003       |
|    loss                 | -121         |
|    n_updates            | 1120         |
|    policy_gradient_loss | -111         |
|    std                  | 0.192        |
|    value_loss           | 1.92e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -134         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -194         |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
------------------------------------------
| reward                  | [-2.1638138] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 3            |
|    time_elapsed         | 34           |
|    total_timesteps      | 251904       |
| train/                  |              |
|    approx_kl            | 150.06055    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.507        |
|    explained_variance   | 0.00911      |
|    learning_rate        | 0.0003       |
|    loss                 | -114         |
|    n_updates            | 1220         |
|    policy_gradient_loss | -119         |
|    std                  | 0.364        |
|    value_loss           | 1.4e+03      |
------------------------------------------
------------------------------------------
| reward                  | [-2.5638287] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 95.43559     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.3          |
|    explained_variance   | 0.0299       |
|    learning_rate        | 0.0003       |
|    loss                 | -103         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -78.7        |
|    std                  | 0.179        |
|    value_loss           | 811          |
------------------------------------------
------------------------------------------
| reward                  | [-3.7368505] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 162.73395    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.05         |
|    explained_variance   | 0.0145       |
|    learning_rate        | 0.0003       |
|    loss                 | -155         |
|    n_updates            | 1130         |
|    policy_gradient_loss | -144         |
|    std                  | 0.192        |
|    value_loss           | 2.04e+03     |
------------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 258048       |
-------------------------------------
------------------------------------------
| reward                  | [-1.1800537] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 4            |
|    time_elapsed         | 46           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 180.13785    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.531        |
|    explained_variance   | 0.0172       |
|    learning_rate        | 0.0003       |
|    loss                 | -185         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -201         |
|    std                  | 0.365        |
|    value_loss           | 1.52e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.39633748] |
| time/                   |               |
|    fps                  | 161           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 116.40355     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.33          |
|    explained_variance   | 0.0449        |
|    learning_rate        | 0.0003        |
|    loss                 | -114          |
|    n_updates            | 1140          |
|    policy_gradient_loss | -93.2         |
|    std                  | 0.178         |
|    value_loss           | 938           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 182           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -423          |
|    n_updates            | 1260          |
|    policy_gradient_loss | -373          |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
-------------------------------------------
| reward                  | [-0.24713214] |
| time/                   |               |
|    fps                  | 162           |
|    iterations           | 5             |
|    time_elapsed         | 63            |
|    total_timesteps      | 235520        |
| train/                  |               |
|    approx_kl            | 224.42558     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.08          |
|    explained_variance   | 0.0259        |
|    learning_rate        | 0.0003        |
|    loss                 | -235          |
|    n_updates            | 1140          |
|    policy_gradient_loss | -172          |
|    std                  | 0.192         |
|    value_loss           | 2.01e+03      |
-------------------------------------------
------------------------------------------
| reward                  | [-2.3308349] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 245.0787     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.55         |
|    explained_variance   | 0.00062      |
|    learning_rate        | 0.0003       |
|    loss                 | -134         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -194         |
|    std                  | 0.367        |
|    value_loss           | 944          |
------------------------------------------
--------------------------------------
| reward             | [-0.73643583] |
| time/              |               |
|    fps             | 174           |
|    iterations      | 1             |
|    time_elapsed    | 11            |
|    total_timesteps | 237568        |
--------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 180           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.48e+03     |
|    n_updates            | 1270          |
|    policy_gradient_loss | -1.14e+03     |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
-------------------------------------
| reward             | [-1.0219514] |
| time/              |              |
|    fps             | 175          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 237568       |
-------------------------------------
-------------------------------------
| reward             | [-1.6967204] |
| time/              |              |
|    fps             | 188          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 258048       |
-------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 4           |
|    time_elapsed         | 45          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -306        |
|    n_updates            | 1280        |
|    policy_gradient_loss | -264        |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.52808565] |
| time/                   |               |
|    fps                  | 163           |
|    iterations           | 2             |
|    time_elapsed         | 25            |
|    total_timesteps      | 239616        |
| train/                  |               |
|    approx_kl            | 104.64137     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.42          |
|    explained_variance   | 0.0346        |
|    learning_rate        | 0.0003        |
|    loss                 | -97.7         |
|    n_updates            | 1160          |
|    policy_gradient_loss | -93.5         |
|    std                  | 0.173         |
|    value_loss           | 504           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.2770704] |
| time/                   |              |
|    fps                  | 167          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 126.42633    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.14         |
|    explained_variance   | 0.0278       |
|    learning_rate        | 0.0003       |
|    loss                 | -108         |
|    n_updates            | 1160         |
|    policy_gradient_loss | -122         |
|    std                  | 0.189        |
|    value_loss           | 1.85e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.43241167] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 2             |
|    time_elapsed         | 22            |
|    total_timesteps      | 260096        |
| train/                  |               |
|    approx_kl            | 332.9421      |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.578         |
|    explained_variance   | 0.00806       |
|    learning_rate        | 0.0003        |
|    loss                 | -423          |
|    n_updates            | 1260          |
|    policy_gradient_loss | -373          |
|    std                  | 0.364         |
|    value_loss           | 997           |
-------------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 179          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -716         |
|    n_updates            | 1290         |
|    policy_gradient_loss | -457         |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
------------------------------------------
| reward                  | [-1.1030704] |
| time/                   |              |
|    fps                  | 162          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 145.43536    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.46         |
|    explained_variance   | 0.0381       |
|    learning_rate        | 0.0003       |
|    loss                 | -250         |
|    n_updates            | 1170         |
|    policy_gradient_loss | -107         |
|    std                  | 0.17         |
|    value_loss           | 957          |
------------------------------------------
------------------------------------------
| reward                  | [-1.8163397] |
| time/                   |              |
|    fps                  | 165          |
|    iterations           | 3            |
|    time_elapsed         | 37           |
|    total_timesteps      | 241664       |
| train/                  |              |
|    approx_kl            | 322.3716     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.18         |
|    explained_variance   | 0.0237       |
|    learning_rate        | 0.0003       |
|    loss                 | -396         |
|    n_updates            | 1170         |
|    policy_gradient_loss | -270         |
|    std                  | 0.185        |
|    value_loss           | 2.05e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.96124345] |
| time/                   |               |
|    fps                  | 179           |
|    iterations           | 3             |
|    time_elapsed         | 34            |
|    total_timesteps      | 262144        |
| train/                  |               |
|    approx_kl            | 2215.8525     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.599         |
|    explained_variance   | -0.0468       |
|    learning_rate        | 0.0003        |
|    loss                 | -2.48e+03     |
|    n_updates            | 1270          |
|    policy_gradient_loss | -1.14e+03     |
|    std                  | 0.361         |
|    value_loss           | 647           |
-------------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 187          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 268288       |
-------------------------------------
------------------------------------------
| reward                  | [-2.1156733] |
| time/                   |              |
|    fps                  | 164          |
|    iterations           | 4            |
|    time_elapsed         | 49           |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 176.41635    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.22         |
|    explained_variance   | 0.0298       |
|    learning_rate        | 0.0003       |
|    loss                 | -243         |
|    n_updates            | 1180         |
|    policy_gradient_loss | -161         |
|    std                  | 0.182        |
|    value_loss           | 1.86e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.38569745] |
| time/                   |               |
|    fps                  | 159           |
|    iterations           | 4             |
|    time_elapsed         | 51            |
|    total_timesteps      | 243712        |
| train/                  |               |
|    approx_kl            | 171.47348     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.5           |
|    explained_variance   | 0.0388        |
|    learning_rate        | 0.0003        |
|    loss                 | -231          |
|    n_updates            | 1180          |
|    policy_gradient_loss | -116          |
|    std                  | 0.166         |
|    value_loss           | 736           |
-------------------------------------------
-----------------------------------------
| reward                  | [-1.053716] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 4           |
|    time_elapsed         | 45          |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 299.58447   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.614       |
|    explained_variance   | 0.00285     |
|    learning_rate        | 0.0003      |
|    loss                 | -306        |
|    n_updates            | 1280        |
|    policy_gradient_loss | -264        |
|    std                  | 0.363       |
|    value_loss           | 974         |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 182         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -381        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -315        |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-1.6537086] |
| time/                   |              |
|    fps                  | 177          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 755.10693    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.628        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.0003       |
|    loss                 | -716         |
|    n_updates            | 1290         |
|    policy_gradient_loss | -457         |
|    std                  | 0.362        |
|    value_loss           | 891          |
------------------------------------------
-----------------------------------------
| reward                  | [-2.600372] |
| time/                   |             |
|    fps                  | 163         |
|    iterations           | 5           |
|    time_elapsed         | 62          |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 267.30243   |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.25        |
|    explained_variance   | 0.0282      |
|    learning_rate        | 0.0003      |
|    loss                 | -232        |
|    n_updates            | 1190        |
|    policy_gradient_loss | -231        |
|    std                  | 0.181       |
|    value_loss           | 1.87e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-0.6554335] |
| time/                   |              |
|    fps                  | 158          |
|    iterations           | 5            |
|    time_elapsed         | 64           |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 191.23795    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.54         |
|    explained_variance   | 0.0377       |
|    learning_rate        | 0.0003       |
|    loss                 | -187         |
|    n_updates            | 1190         |
|    policy_gradient_loss | -183         |
|    std                  | 0.166        |
|    value_loss           | 714          |
------------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -213        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -189        |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-------------------------------------
| reward             | [-1.9945924] |
| time/              |              |
|    fps             | 183          |
|    iterations      | 1            |
|    time_elapsed    | 11           |
|    total_timesteps | 268288       |
-------------------------------------
------------------------------------
| reward             | [-3.366531] |
| time/              |             |
|    fps             | 173         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 247808      |
------------------------------------
------------------------------------
| reward             | [-2.191125] |
| time/              |             |
|    fps             | 174         |
|    iterations      | 1           |
|    time_elapsed    | 11          |
|    total_timesteps | 247808      |
------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 178         |
|    iterations           | 4           |
|    time_elapsed         | 45          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -343        |
|    n_updates            | 1330        |
|    policy_gradient_loss | -192        |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-2.466066] |
| time/                   |             |
|    fps                  | 179         |
|    iterations           | 2           |
|    time_elapsed         | 22          |
|    total_timesteps      | 270336      |
| train/                  |             |
|    approx_kl            | 484.67938   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.671       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | -381        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -315        |
|    std                  | 0.361       |
|    value_loss           | 1.17e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-3.6710122] |
| time/                   |              |
|    fps                  | 166          |
|    iterations           | 2            |
|    time_elapsed         | 24           |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 197.55167    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.35         |
|    explained_variance   | 0.0219       |
|    learning_rate        | 0.0003       |
|    loss                 | -239         |
|    n_updates            | 1210         |
|    policy_gradient_loss | -189         |
|    std                  | 0.173        |
|    value_loss           | 2.14e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.41934168] |
| time/                   |               |
|    fps                  | 167           |
|    iterations           | 2             |
|    time_elapsed         | 24            |
|    total_timesteps      | 249856        |
| train/                  |               |
|    approx_kl            | 119.54237     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.6           |
|    explained_variance   | 0.0343        |
|    learning_rate        | 0.0003        |
|    loss                 | -115          |
|    n_updates            | 1210          |
|    policy_gradient_loss | -112          |
|    std                  | 0.162         |
|    value_loss           | 558           |
-------------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 178          |
|    iterations           | 5            |
|    time_elapsed         | 57           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -366         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -339         |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| reward                  | [-1.854845] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 3           |
|    time_elapsed         | 34          |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 220.6456    |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.701       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | -213        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -189        |
|    std                  | 0.354       |
|    value_loss           | 1.47e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.055373] |
| time/                   |             |
|    fps                  | 164         |
|    iterations           | 3           |
|    time_elapsed         | 37          |
|    total_timesteps      | 251904      |
| train/                  |             |
|    approx_kl            | 363.5912    |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.4         |
|    explained_variance   | 0.0171      |
|    learning_rate        | 0.0003      |
|    loss                 | -366        |
|    n_updates            | 1220        |
|    policy_gradient_loss | -307        |
|    std                  | 0.173       |
|    value_loss           | 2.35e+03    |
-----------------------------------------
-------------------------------------------
| reward                  | [-0.62613434] |
| time/                   |               |
|    fps                  | 164           |
|    iterations           | 3             |
|    time_elapsed         | 37            |
|    total_timesteps      | 251904        |
| train/                  |               |
|    approx_kl            | 141.49518     |
|    clip_range           | 0.2           |
|    entropy_loss         | 1.64          |
|    explained_variance   | 0.0337        |
|    learning_rate        | 0.0003        |
|    loss                 | -107          |
|    n_updates            | 1220          |
|    policy_gradient_loss | -114          |
|    std                  | 0.162         |
|    value_loss           | 877           |
-------------------------------------------
-------------------------------------
| reward             | [-3.7786243] |
| time/              |              |
|    fps             | 189          |
|    iterations      | 1            |
|    time_elapsed    | 10           |
|    total_timesteps | 278528       |
-------------------------------------
-----------------------------------------
| reward                  | [-3.156622] |
| time/                   |             |
|    fps                  | 177         |
|    iterations           | 4           |
|    time_elapsed         | 46          |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 252.09741   |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.73        |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | -343        |
|    n_updates            | 1330        |
|    policy_gradient_loss | -192        |
|    std                  | 0.35        |
|    value_loss           | 1.72e+03    |
-----------------------------------------
-----------------------------------------
| reward                  | [-4.155282] |
| time/                   |             |
|    fps                  | 162         |
|    iterations           | 4           |
|    time_elapsed         | 50          |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 349.50906   |
|    clip_range           | 0.2         |
|    entropy_loss         | 1.43        |
|    explained_variance   | 0.0143      |
|    learning_rate        | 0.0003      |
|    loss                 | -300        |
|    n_updates            | 1230        |
|    policy_gradient_loss | -309        |
|    std                  | 0.172       |
|    value_loss           | 2.37e+03    |
-----------------------------------------
------------------------------------------
| reward                  | [-2.8231308] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 4            |
|    time_elapsed         | 50           |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 127.38881    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.67         |
|    explained_variance   | 0.0418       |
|    learning_rate        | 0.0003       |
|    loss                 | -145         |
|    n_updates            | 1230         |
|    policy_gradient_loss | -125         |
|    std                  | 0.161        |
|    value_loss           | 758          |
------------------------------------------
------------------------------------------
| reward                  | [-2.9646173] |
| time/                   |              |
|    fps                  | 183          |
|    iterations           | 2            |
|    time_elapsed         | 22           |
|    total_timesteps      | 280576       |
| train/                  |              |
|    approx_kl            | 336.47464    |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.807        |
|    explained_variance   | 0.00696      |
|    learning_rate        | 0.0003       |
|    loss                 | -289         |
|    n_updates            | 1360         |
|    policy_gradient_loss | -270         |
|    std                  | 0.344        |
|    value_loss           | 1.34e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-2.2574308] |
| time/                   |              |
|    fps                  | 176          |
|    iterations           | 5            |
|    time_elapsed         | 58           |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 410.3053     |
|    clip_range           | 0.2          |
|    entropy_loss         | 0.762        |
|    explained_variance   | 0.0229       |
|    learning_rate        | 0.0003       |
|    loss                 | -366         |
|    n_updates            | 1340         |
|    policy_gradient_loss | -339         |
|    std                  | 0.349        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-------------------------------------------
| reward                  | [-0.86316013] |
| time/                   |               |
|    fps                  | 181           |
|    iterations           | 3             |
|    time_elapsed         | 33            |
|    total_timesteps      | 282624        |
| train/                  |               |
|    approx_kl            | 2037.7466     |
|    clip_range           | 0.2           |
|    entropy_loss         | 0.835         |
|    explained_variance   | -0.05         |
|    learning_rate        | 0.0003        |
|    loss                 | -2.11e+03     |
|    n_updates            | 1370          |
|    policy_gradient_loss | -1.19e+03     |
|    std                  | 0.349         |
|    value_loss           | 951           |
-------------------------------------------
------------------------------------------
| reward                  | [-4.5454493] |
| time/                   |              |
|    fps                  | 161          |
|    iterations           | 5            |
|    time_elapsed         | 63           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 325.8344     |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.46         |
|    explained_variance   | 0.0183       |
|    learning_rate        | 0.0003       |
|    loss                 | -377         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -305         |
|    std                  | 0.17         |
|    value_loss           | 2.32e+03     |
------------------------------------------
------------------------------------------
| reward                  | [-0.6078568] |
| time/                   |              |
|    fps                  | 163          |
|    iterations           | 5            |
|    time_elapsed         | 62           |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 199.40865    |
|    clip_range           | 0.2          |
|    entropy_loss         | 1.71         |
|    explained_variance   | 0.0473       |
|    learning_rate        | 0.0003       |
|    loss                 | -193         |
|    n_updates            | 1240         |
|    policy_gradient_loss | -213         |
|    std                  | 0.158        |
|    value_loss           | 632          |
------------------------------------------
slurmstepd: error: *** STEP 76100.2 ON ppo.ist.berkeley.edu CANCELLED AT 2023-10-17T15:22:14 ***
slurmstepd: error: *** STEP 76100.1 ON gan.ist.berkeley.edu CANCELLED AT 2023-10-17T15:22:14 ***
slurmstepd: error: *** STEP 76100.3 ON sac.ist.berkeley.edu CANCELLED AT 2023-10-17T22:22:14 ***
slurmstepd: error: *** STEP 76100.0 ON airl.ist.berkeley.edu CANCELLED AT 2023-10-17T22:22:14 ***
slurmstepd: error: *** JOB 76100 ON airl.ist.berkeley.edu CANCELLED AT 2023-10-17T22:22:14 ***
