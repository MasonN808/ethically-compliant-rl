wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240123_015329-mnx68d9o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-leaf-43
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/seed-testing
wandb: üöÄ View run at https://wandb.ai/ecrl/seed-testing/runs/mnx68d9o
Using cpu device
------------------------------------
| avg_speed          | 0.897       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.897       |
| reward             | -0.48690677 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -3.89e+03   |
| time/              |             |
|    fps             | 91          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2048        |
------------------------------------
-----------------------------------------
| avg_speed                | 2.56       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.56       |
| reward                   | -1.0404055 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -3.89e+03  |
| time/                    |            |
|    fps                   | 89         |
|    iterations            | 2          |
|    time_elapsed          | 45         |
|    total_timesteps       | 4096       |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.274      |
|    cost_value_loss       | 0.0463     |
|    cost_values           | 0.152      |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00125    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.18e+03   |
|    n_updates             | 10         |
|    policy_gradient_loss  | 1.45e-08   |
|    std                   | 1          |
|    value_loss            | 4.62e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 5.04       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.04       |
| reward                   | -1.5816702 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -3.84e+03  |
| time/                    |            |
|    fps                   | 89         |
|    iterations            | 3          |
|    time_elapsed          | 68         |
|    total_timesteps       | 6144       |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0604     |
|    cost_value_loss       | 0.00662    |
|    cost_values           | 0.0362     |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0516     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.25e+03   |
|    n_updates             | 20         |
|    policy_gradient_loss  | 1.76e-08   |
|    std                   | 1          |
|    value_loss            | 4.59e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 4.47       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.47       |
| reward                   | -1.6150597 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -3.85e+03  |
| time/                    |            |
|    fps                   | 89         |
|    iterations            | 4          |
|    time_elapsed          | 91         |
|    total_timesteps       | 8192       |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0509     |
|    cost_value_loss       | 0.000882   |
|    cost_values           | 0.0516     |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.077      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.08e+03   |
|    n_updates             | 30         |
|    policy_gradient_loss  | -1.43e-09  |
|    std                   | 1          |
|    value_loss            | 4.26e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -2.2563522 |
| rollout/                 |            |
|    ep_len_mean           | 915        |
|    ep_rew_mean           | -3.47e+03  |
| time/                    |            |
|    fps                   | 89         |
|    iterations            | 5          |
|    time_elapsed          | 114        |
|    total_timesteps       | 10240      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0532     |
|    cost_value_loss       | 0.000233   |
|    cost_values           | 0.0546     |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0848     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.25e+03   |
|    n_updates             | 40         |
|    policy_gradient_loss  | 1.3e-08    |
|    std                   | 1          |
|    value_loss            | 4.55e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 5.17       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.17       |
| reward                   | -1.6514374 |
| rollout/                 |            |
|    ep_len_mean           | 928        |
|    ep_rew_mean           | -3.54e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 6          |
|    time_elapsed          | 138        |
|    total_timesteps       | 12288      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.044      |
|    cost_value_loss       | 0.000301   |
|    cost_values           | 0.0469     |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0848     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.17e+03   |
|    n_updates             | 50         |
|    policy_gradient_loss  | -1.25e-08  |
|    std                   | 1          |
|    value_loss            | 4.31e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -3.440216 |
| rollout/                 |           |
|    ep_len_mean           | 938       |
|    ep_rew_mean           | -3.57e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 7         |
|    time_elapsed          | 161       |
|    total_timesteps       | 14336     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.036     |
|    cost_value_loss       | 0.000232  |
|    cost_values           | 0.0381    |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0807    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.29e+03  |
|    n_updates             | 60        |
|    policy_gradient_loss  | -1.24e-08 |
|    std                   | 1         |
|    value_loss            | 4.61e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -3.9154818 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -3.59e+03  |
| time/                    |            |
|    fps                   | 89         |
|    iterations            | 8          |
|    time_elapsed          | 183        |
|    total_timesteps       | 16384      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0289     |
|    cost_value_loss       | 4.16e-05   |
|    cost_values           | 0.0297     |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0634     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.24e+03   |
|    n_updates             | 70         |
|    policy_gradient_loss  | 3.36e-08   |
|    std                   | 1          |
|    value_loss            | 4.31e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -3.9184875 |
| rollout/                 |            |
|    ep_len_mean           | 951        |
|    ep_rew_mean           | -3.62e+03  |
| time/                    |            |
|    fps                   | 89         |
|    iterations            | 9          |
|    time_elapsed          | 206        |
|    total_timesteps       | 18432      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0247     |
|    cost_value_loss       | 0.000272   |
|    cost_values           | 0.0265     |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0657     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.21e+03   |
|    n_updates             | 80         |
|    policy_gradient_loss  | 7.44e-09   |
|    std                   | 1          |
|    value_loss            | 4.44e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.393128 |
| rollout/                 |           |
|    ep_len_mean           | 956       |
|    ep_rew_mean           | -3.64e+03 |
| time/                    |           |
|    fps                   | 89        |
|    iterations            | 10        |
|    time_elapsed          | 229       |
|    total_timesteps       | 20480     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.0223    |
|    cost_value_loss       | 0.000286  |
|    cost_values           | 0.024     |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0611    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.1e+03   |
|    n_updates             | 90        |
|    policy_gradient_loss  | 1.82e-08  |
|    std                   | 1         |
|    value_loss            | 4.36e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.4281783 |
| rollout/                 |            |
|    ep_len_mean           | 922        |
|    ep_rew_mean           | -3.5e+03   |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 11         |
|    time_elapsed          | 253        |
|    total_timesteps       | 22528      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0142     |
|    cost_value_loss       | 2.79e-05   |
|    cost_values           | 0.0148     |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.052      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.24e+03   |
|    n_updates             | 100        |
|    policy_gradient_loss  | 1.42e-08   |
|    std                   | 1          |
|    value_loss            | 4.45e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.553076 |
| rollout/                 |           |
|    ep_len_mean           | 928       |
|    ep_rew_mean           | -3.52e+03 |
| time/                    |           |
|    fps                   | 89        |
|    iterations            | 12        |
|    time_elapsed          | 276       |
|    total_timesteps       | 24576     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.0138    |
|    cost_value_loss       | 0.000282  |
|    cost_values           | 0.0156    |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0605    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.02e+03  |
|    n_updates             | 110       |
|    policy_gradient_loss  | 1.34e-08  |
|    std                   | 1         |
|    value_loss            | 4.22e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.768664 |
| rollout/                 |           |
|    ep_len_mean           | 933       |
|    ep_rew_mean           | -3.54e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 13        |
|    time_elapsed          | 299       |
|    total_timesteps       | 26624     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.00784   |
|    cost_value_loss       | 2.22e-05  |
|    cost_values           | 0.00821   |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0447    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.2e+03   |
|    n_updates             | 120       |
|    policy_gradient_loss  | -3.62e-09 |
|    std                   | 1         |
|    value_loss            | 4.48e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.81026  |
| rollout/                 |           |
|    ep_len_mean           | 938       |
|    ep_rew_mean           | -3.55e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 14        |
|    time_elapsed          | 322       |
|    total_timesteps       | 28672     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.00658   |
|    cost_value_loss       | 1.94e-05  |
|    cost_values           | 0.00684   |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.04      |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.17e+03  |
|    n_updates             | 130       |
|    policy_gradient_loss  | 9.47e-09  |
|    std                   | 1         |
|    value_loss            | 4.28e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.668126 |
| rollout/                 |           |
|    ep_len_mean           | 942       |
|    ep_rew_mean           | -3.57e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 15        |
|    time_elapsed          | 345       |
|    total_timesteps       | 30720     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.00565   |
|    cost_value_loss       | 0.00023   |
|    cost_values           | 0.00701   |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0491    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.11e+03  |
|    n_updates             | 140       |
|    policy_gradient_loss  | 1.5e-08   |
|    std                   | 1         |
|    value_loss            | 4.25e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8458743 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -3.59e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 16         |
|    time_elapsed          | 368        |
|    total_timesteps       | 32768      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0049     |
|    cost_value_loss       | 0.000185   |
|    cost_values           | 0.00585    |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0446     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.06e+03   |
|    n_updates             | 150        |
|    policy_gradient_loss  | -2.99e-09  |
|    std                   | 1          |
|    value_loss            | 4.34e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.927449 |
| rollout/                 |           |
|    ep_len_mean           | 948       |
|    ep_rew_mean           | -3.61e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 17        |
|    time_elapsed          | 392       |
|    total_timesteps       | 34816     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.00139   |
|    cost_value_loss       | 8.12e-06  |
|    cost_values           | 0.0015    |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0311    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.3e+03   |
|    n_updates             | 160       |
|    policy_gradient_loss  | -1.32e-08 |
|    std                   | 1         |
|    value_loss            | 4.48e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8275285 |
| rollout/                 |            |
|    ep_len_mean           | 951        |
|    ep_rew_mean           | -3.62e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 18         |
|    time_elapsed          | 415        |
|    total_timesteps       | 36864      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00195    |
|    cost_value_loss       | 0.000111   |
|    cost_values           | 0.00238    |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0334     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.21e+03   |
|    n_updates             | 170        |
|    policy_gradient_loss  | -3.52e-08  |
|    std                   | 1          |
|    value_loss            | 4.44e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.9172525 |
| rollout/                 |            |
|    ep_len_mean           | 954        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 19         |
|    time_elapsed          | 438        |
|    total_timesteps       | 38912      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00218    |
|    cost_value_loss       | 8.48e-05   |
|    cost_values           | 0.00253    |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0343     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.11e+03   |
|    n_updates             | 180        |
|    policy_gradient_loss  | -1.71e-09  |
|    std                   | 1          |
|    value_loss            | 4.28e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.0104356 |
| rollout/                 |            |
|    ep_len_mean           | 956        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 20         |
|    time_elapsed          | 461        |
|    total_timesteps       | 40960      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.000426   |
|    cost_value_loss       | 6.71e-06   |
|    cost_values           | 0.000498   |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0276     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.08e+03   |
|    n_updates             | 190        |
|    policy_gradient_loss  | -1.27e-08  |
|    std                   | 1          |
|    value_loss            | 4.32e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.058602 |
| rollout/                 |           |
|    ep_len_mean           | 958       |
|    ep_rew_mean           | -3.64e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 21        |
|    time_elapsed          | 484       |
|    total_timesteps       | 43008     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | -9.18e-05 |
|    cost_value_loss       | 5.35e-06  |
|    cost_values           | -3.37e-05 |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0244    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.15e+03  |
|    n_updates             | 200       |
|    policy_gradient_loss  | 9.06e-09  |
|    std                   | 1         |
|    value_loss            | 4.38e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.273572 |
| rollout/                 |           |
|    ep_len_mean           | 960       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 22        |
|    time_elapsed          | 508       |
|    total_timesteps       | 45056     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 5.07e-05  |
|    cost_value_loss       | 2.54e-05  |
|    cost_values           | 0.000123  |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0231    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.03e+03  |
|    n_updates             | 210       |
|    policy_gradient_loss  | 1.19e-08  |
|    std                   | 1         |
|    value_loss            | 4.16e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.235861 |
| rollout/                 |           |
|    ep_len_mean           | 962       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 23        |
|    time_elapsed          | 531       |
|    total_timesteps       | 47104     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 0.00101   |
|    cost_value_loss       | 0.000101  |
|    cost_values           | 0.00127   |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0272    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.05e+03  |
|    n_updates             | 220       |
|    policy_gradient_loss  | 3.29e-09  |
|    std                   | 1         |
|    value_loss            | 4.15e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.3932157 |
| rollout/                 |            |
|    ep_len_mean           | 963        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 24         |
|    time_elapsed          | 554        |
|    total_timesteps       | 49152      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 0.000487   |
|    cost_value_loss       | 3.49e-05   |
|    cost_values           | 0.00057    |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0243     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.05e+03   |
|    n_updates             | 230        |
|    policy_gradient_loss  | -1.27e-09  |
|    std                   | 1          |
|    value_loss            | 4.08e+03   |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.476       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.476       |
| reward                   | -0.48226663 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -3.66e+03   |
| time/                    |             |
|    fps                   | 88          |
|    iterations            | 25          |
|    time_elapsed          | 577         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.0         |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000642    |
|    cost_value_loss       | 4.05e-05    |
|    cost_values           | 0.000711    |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0217      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04e+03    |
|    n_updates             | 240         |
|    policy_gradient_loss  | 4.29e-09    |
|    std                   | 1           |
|    value_loss            | 4.03e+03    |
------------------------------------------
------------------------------------------
| avg_speed                | 2.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.63        |
| reward                   | -0.80882096 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -3.67e+03   |
| time/                    |             |
|    fps                   | 88          |
|    iterations            | 26          |
|    time_elapsed          | 601         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.0         |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000564   |
|    cost_value_loss       | 2.03e-06    |
|    cost_values           | -0.000541   |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0193      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.91e+03    |
|    n_updates             | 250         |
|    policy_gradient_loss  | -8.14e-09   |
|    std                   | 1           |
|    value_loss            | 4.14e+03    |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.34       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.34       |
| reward                   | -1.4453217 |
| rollout/                 |            |
|    ep_len_mean           | 968        |
|    ep_rew_mean           | -3.68e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 27         |
|    time_elapsed          | 624        |
|    total_timesteps       | 55296      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00103   |
|    cost_value_loss       | 1.62e-06   |
|    cost_values           | -0.00102   |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0144     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.05e+03   |
|    n_updates             | 260        |
|    policy_gradient_loss  | -7.24e-09  |
|    std                   | 1          |
|    value_loss            | 4.15e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 6.11       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.11       |
| reward                   | -1.7427349 |
| rollout/                 |            |
|    ep_len_mean           | 969        |
|    ep_rew_mean           | -3.68e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 28         |
|    time_elapsed          | 647        |
|    total_timesteps       | 57344      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00117   |
|    cost_value_loss       | 1.26e-06   |
|    cost_values           | -0.00117   |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.012      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.09e+03   |
|    n_updates             | 270        |
|    policy_gradient_loss  | 2.22e-08   |
|    std                   | 1          |
|    value_loss            | 4.29e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 5.42       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.42       |
| reward                   | -1.6589808 |
| rollout/                 |            |
|    ep_len_mean           | 955        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 29         |
|    time_elapsed          | 670        |
|    total_timesteps       | 59392      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000446  |
|    cost_value_loss       | 3.2e-05    |
|    cost_values           | -0.00037   |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.015      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.09e+03   |
|    n_updates             | 280        |
|    policy_gradient_loss  | 5.89e-09   |
|    std                   | 1          |
|    value_loss            | 4.05e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -2.8677053 |
| rollout/                 |            |
|    ep_len_mean           | 957        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 30         |
|    time_elapsed          | 693        |
|    total_timesteps       | 61440      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000754  |
|    cost_value_loss       | 2.07e-06   |
|    cost_values           | -0.000739  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0143     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.9e+03    |
|    n_updates             | 290        |
|    policy_gradient_loss  | -9.91e-09  |
|    std                   | 1          |
|    value_loss            | 3.92e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -2.3643968 |
| rollout/                 |            |
|    ep_len_mean           | 958        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 31         |
|    time_elapsed          | 716        |
|    total_timesteps       | 63488      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00129   |
|    cost_value_loss       | 9.09e-07   |
|    cost_values           | -0.00129   |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0106     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.02e+03   |
|    n_updates             | 300        |
|    policy_gradient_loss  | 2e-08      |
|    std                   | 1          |
|    value_loss            | 4.03e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -3.9094179 |
| rollout/                 |            |
|    ep_len_mean           | 959        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 32         |
|    time_elapsed          | 739        |
|    total_timesteps       | 65536      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -9.57e-05  |
|    cost_value_loss       | 2.92e-05   |
|    cost_values           | -5.48e-05  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0138     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.99e+03   |
|    n_updates             | 310        |
|    policy_gradient_loss  | -9.33e-09  |
|    std                   | 1          |
|    value_loss            | 3.99e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.3562703 |
| rollout/                 |            |
|    ep_len_mean           | 960        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 33         |
|    time_elapsed          | 762        |
|    total_timesteps       | 67584      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00106   |
|    cost_value_loss       | 6.77e-07   |
|    cost_values           | -0.00106   |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00986    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.98e+03   |
|    n_updates             | 320        |
|    policy_gradient_loss  | 7.27e-09   |
|    std                   | 1          |
|    value_loss            | 4.04e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.4656672 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -3.65e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 34         |
|    time_elapsed          | 785        |
|    total_timesteps       | 69632      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00076   |
|    cost_value_loss       | 1.24e-05   |
|    cost_values           | -0.000741  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.011      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.06e+03   |
|    n_updates             | 330        |
|    policy_gradient_loss  | -5.43e-09  |
|    std                   | 1          |
|    value_loss            | 4.15e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.682626 |
| rollout/                 |           |
|    ep_len_mean           | 963       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 35        |
|    time_elapsed          | 808       |
|    total_timesteps       | 71680     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | -0.000661 |
|    cost_value_loss       | 7.4e-06   |
|    cost_values           | -0.00065  |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.01      |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.04e+03  |
|    n_updates             | 340       |
|    policy_gradient_loss  | 7.26e-09  |
|    std                   | 1         |
|    value_loss            | 4.07e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.7748156 |
| rollout/                 |            |
|    ep_len_mean           | 964        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 36         |
|    time_elapsed          | 831        |
|    total_timesteps       | 73728      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000775  |
|    cost_value_loss       | 5.52e-07   |
|    cost_values           | -0.000776  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00961    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.94e+03   |
|    n_updates             | 350        |
|    policy_gradient_loss  | -2e-08     |
|    std                   | 1          |
|    value_loss            | 3.98e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8137403 |
| rollout/                 |            |
|    ep_len_mean           | 965        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 37         |
|    time_elapsed          | 854        |
|    total_timesteps       | 75776      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000171  |
|    cost_value_loss       | 1.71e-05   |
|    cost_values           | -0.000149  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0114     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.88e+03   |
|    n_updates             | 360        |
|    policy_gradient_loss  | 1.49e-08   |
|    std                   | 1          |
|    value_loss            | 3.88e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8439116 |
| rollout/                 |            |
|    ep_len_mean           | 965        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 38         |
|    time_elapsed          | 877        |
|    total_timesteps       | 77824      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000608  |
|    cost_value_loss       | 5.43e-06   |
|    cost_values           | -0.000601  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00915    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.08e+03   |
|    n_updates             | 370        |
|    policy_gradient_loss  | -1.45e-09  |
|    std                   | 1          |
|    value_loss            | 4.12e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.7872314 |
| rollout/                 |            |
|    ep_len_mean           | 955        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 39         |
|    time_elapsed          | 900        |
|    total_timesteps       | 79872      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000327  |
|    cost_value_loss       | 7.01e-06   |
|    cost_values           | -0.000319  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00968    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.96e+03   |
|    n_updates             | 380        |
|    policy_gradient_loss  | 7.13e-10   |
|    std                   | 1          |
|    value_loss            | 3.82e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.540085 |
| rollout/                 |           |
|    ep_len_mean           | 956       |
|    ep_rew_mean           | -3.63e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 40        |
|    time_elapsed          | 923       |
|    total_timesteps       | 81920     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | -0.00063  |
|    cost_value_loss       | 5.44e-07  |
|    cost_values           | -0.000626 |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.00892   |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 1.93e+03  |
|    n_updates             | 390       |
|    policy_gradient_loss  | -2.21e-09 |
|    std                   | 1         |
|    value_loss            | 4.01e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.891749 |
| rollout/                 |           |
|    ep_len_mean           | 957       |
|    ep_rew_mean           | -3.64e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 41        |
|    time_elapsed          | 946       |
|    total_timesteps       | 83968     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | -0.000546 |
|    cost_value_loss       | 3.63e-07  |
|    cost_values           | -0.000546 |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.00864   |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 1.98e+03  |
|    n_updates             | 400       |
|    policy_gradient_loss  | 1.42e-08  |
|    std                   | 1         |
|    value_loss            | 3.93e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.9660373 |
| rollout/                 |            |
|    ep_len_mean           | 958        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 42         |
|    time_elapsed          | 969        |
|    total_timesteps       | 86016      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000768  |
|    cost_value_loss       | 2.15e-07   |
|    cost_values           | -0.000771  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00688    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.04e+03   |
|    n_updates             | 410        |
|    policy_gradient_loss  | -1.68e-08  |
|    std                   | 1          |
|    value_loss            | 4.1e+03    |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.5977883 |
| rollout/                 |            |
|    ep_len_mean           | 959        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 43         |
|    time_elapsed          | 992        |
|    total_timesteps       | 88064      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000368  |
|    cost_value_loss       | 5.36e-06   |
|    cost_values           | -0.000362  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00763    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.02e+03   |
|    n_updates             | 420        |
|    policy_gradient_loss  | 1.04e-08   |
|    std                   | 1          |
|    value_loss            | 3.96e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.1415396 |
| rollout/                 |            |
|    ep_len_mean           | 960        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 44         |
|    time_elapsed          | 1015       |
|    total_timesteps       | 90112      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000378  |
|    cost_value_loss       | 1.8e-06    |
|    cost_values           | -0.000376  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00745    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.84e+03   |
|    n_updates             | 430        |
|    policy_gradient_loss  | -6.8e-09   |
|    std                   | 1          |
|    value_loss            | 3.73e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.082294 |
| rollout/                 |           |
|    ep_len_mean           | 961       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 88        |
|    iterations            | 45        |
|    time_elapsed          | 1038      |
|    total_timesteps       | 92160     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | -0.000321 |
|    cost_value_loss       | 1.16e-06  |
|    cost_values           | -0.000317 |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.00806   |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 1.71e+03  |
|    n_updates             | 440       |
|    policy_gradient_loss  | 4.14e-08  |
|    std                   | 1         |
|    value_loss            | 3.61e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.0792747 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -3.65e+03  |
| time/                    |            |
|    fps                   | 88         |
|    iterations            | 46         |
|    time_elapsed          | 1061       |
|    total_timesteps       | 94208      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00033   |
|    cost_value_loss       | 3.31e-06   |
|    cost_values           | -0.000329  |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0073     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.99e+03   |
|    n_updates             | 450        |
|    policy_gradient_loss  | 7.28e-09   |
|    std                   | 1          |
|    value_loss            | 3.93e+03   |
-----------------------------------------
slurmstepd: error: *** STEP 120156.0 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-01-23T02:11:33 ***
slurmstepd: error: *** JOB 120156 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-01-23T02:11:33 ***
