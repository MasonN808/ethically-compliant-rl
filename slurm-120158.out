wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240123_095329-ghefdg8c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-darkness-45
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/seed-testing
wandb: üöÄ View run at https://wandb.ai/ecrl/seed-testing/runs/ghefdg8c
Using cpu device
------------------------------------
| avg_speed          | 0.897       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.897       |
| reward             | -0.48690677 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -3.89e+03   |
| time/              |             |
|    fps             | 97          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2048        |
------------------------------------
-----------------------------------------
| avg_speed                | 2.56       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.56       |
| reward                   | -1.0404055 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -3.89e+03  |
| time/                    |            |
|    fps                   | 95         |
|    iterations            | 2          |
|    time_elapsed          | 42         |
|    total_timesteps       | 4096       |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 15.1       |
|    cost_value_loss       | 243        |
|    cost_values           | 0.323      |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00125    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.3e+03    |
|    n_updates             | 10         |
|    policy_gradient_loss  | 1.45e-08   |
|    std                   | 1          |
|    value_loss            | 4.62e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 5.04       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5.04       |
| reward                   | -1.5816702 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -3.84e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 3          |
|    time_elapsed          | 64         |
|    total_timesteps       | 6144       |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 15.1       |
|    cost_value_loss       | 237        |
|    cost_values           | 0.551      |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0511     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.37e+03   |
|    n_updates             | 20         |
|    policy_gradient_loss  | -7.06e-09  |
|    std                   | 1          |
|    value_loss            | 4.6e+03    |
-----------------------------------------
-----------------------------------------
| avg_speed                | 4.47       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.47       |
| reward                   | -1.6150597 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -3.85e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 4          |
|    time_elapsed          | 86         |
|    total_timesteps       | 8192       |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 15.7       |
|    cost_value_loss       | 231        |
|    cost_values           | 1.23       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0752     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.19e+03   |
|    n_updates             | 30         |
|    policy_gradient_loss  | 3.35e-08   |
|    std                   | 1          |
|    value_loss            | 4.27e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -2.2563522 |
| rollout/                 |            |
|    ep_len_mean           | 915        |
|    ep_rew_mean           | -3.47e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 5          |
|    time_elapsed          | 108        |
|    total_timesteps       | 10240      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 15.8       |
|    cost_value_loss       | 215        |
|    cost_values           | 2.11       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0835     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.35e+03   |
|    n_updates             | 40         |
|    policy_gradient_loss  | 1.11e-08   |
|    std                   | 1          |
|    value_loss            | 4.55e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 5.17       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5.17       |
| reward                   | -1.6514374 |
| rollout/                 |            |
|    ep_len_mean           | 928        |
|    ep_rew_mean           | -3.54e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 6          |
|    time_elapsed          | 129        |
|    total_timesteps       | 12288      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.4       |
|    cost_value_loss       | 222        |
|    cost_values           | 2.53       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.084      |
|    lagrangian_multiplier | 0.000489   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.83e+03   |
|    n_updates             | 50         |
|    policy_gradient_loss  | -1.86e-08  |
|    std                   | 1          |
|    value_loss            | 4.32e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -3.440216 |
| rollout/                 |           |
|    ep_len_mean           | 938       |
|    ep_rew_mean           | -3.57e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 7         |
|    time_elapsed          | 151       |
|    total_timesteps       | 14336     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.8      |
|    cost_value_loss       | 228       |
|    cost_values           | 2.55      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0794    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.4e+03   |
|    n_updates             | 60        |
|    policy_gradient_loss  | 2.31e-08  |
|    std                   | 1         |
|    value_loss            | 4.62e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -3.9154818 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -3.59e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 8          |
|    time_elapsed          | 173        |
|    total_timesteps       | 16384      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.61       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0638     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.36e+03   |
|    n_updates             | 70         |
|    policy_gradient_loss  | -6.64e-10  |
|    std                   | 1          |
|    value_loss            | 4.32e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -3.9184875 |
| rollout/                 |            |
|    ep_len_mean           | 951        |
|    ep_rew_mean           | -3.62e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 9          |
|    time_elapsed          | 194        |
|    total_timesteps       | 18432      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.9       |
|    cost_value_loss       | 229        |
|    cost_values           | 2.6        |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0655     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.33e+03   |
|    n_updates             | 80         |
|    policy_gradient_loss  | 2.81e-08   |
|    std                   | 1          |
|    value_loss            | 4.45e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.393128 |
| rollout/                 |           |
|    ep_len_mean           | 956       |
|    ep_rew_mean           | -3.64e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 10        |
|    time_elapsed          | 216       |
|    total_timesteps       | 20480     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.6      |
|    cost_value_loss       | 224       |
|    cost_values           | 2.61      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0623    |
|    lagrangian_multiplier | 0.000281  |
|    learning_rate         | 0.0003    |
|    loss                  | 1.94e+03  |
|    n_updates             | 90        |
|    policy_gradient_loss  | -1.4e-08  |
|    std                   | 1         |
|    value_loss            | 4.37e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.4281783 |
| rollout/                 |            |
|    ep_len_mean           | 922        |
|    ep_rew_mean           | -3.5e+03   |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 11         |
|    time_elapsed          | 237        |
|    total_timesteps       | 22528      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.65       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0527     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.36e+03   |
|    n_updates             | 100        |
|    policy_gradient_loss  | -2.75e-08  |
|    std                   | 1          |
|    value_loss            | 4.46e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.553076 |
| rollout/                 |           |
|    ep_len_mean           | 928       |
|    ep_rew_mean           | -3.52e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 12        |
|    time_elapsed          | 259       |
|    total_timesteps       | 24576     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.5      |
|    cost_value_loss       | 222       |
|    cost_values           | 2.62      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0613    |
|    lagrangian_multiplier | 0.00365   |
|    learning_rate         | 0.0003    |
|    loss                  | 746       |
|    n_updates             | 110       |
|    policy_gradient_loss  | -6.45e-09 |
|    std                   | 1         |
|    value_loss            | 4.23e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.7686644 |
| rollout/                 |            |
|    ep_len_mean           | 933        |
|    ep_rew_mean           | -3.54e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 13         |
|    time_elapsed          | 281        |
|    total_timesteps       | 26624      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.67       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0457     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.31e+03   |
|    n_updates             | 120        |
|    policy_gradient_loss  | 1.17e-08   |
|    std                   | 1          |
|    value_loss            | 4.49e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.81026  |
| rollout/                 |           |
|    ep_len_mean           | 938       |
|    ep_rew_mean           | -3.55e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 14        |
|    time_elapsed          | 302       |
|    total_timesteps       | 28672     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.7      |
|    cost_value_loss       | 225       |
|    cost_values           | 2.67      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0424    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.29e+03  |
|    n_updates             | 130       |
|    policy_gradient_loss  | -3.7e-09  |
|    std                   | 1         |
|    value_loss            | 4.29e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.6681256 |
| rollout/                 |            |
|    ep_len_mean           | 942        |
|    ep_rew_mean           | -3.57e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 15         |
|    time_elapsed          | 324        |
|    total_timesteps       | 30720      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.65       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0495     |
|    lagrangian_multiplier | 0.000244   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.98e+03   |
|    n_updates             | 140        |
|    policy_gradient_loss  | -3.07e-08  |
|    std                   | 1          |
|    value_loss            | 4.26e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8458743 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -3.59e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 16         |
|    time_elapsed          | 346        |
|    total_timesteps       | 32768      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.67       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0451     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.18e+03   |
|    n_updates             | 150        |
|    policy_gradient_loss  | -9.06e-09  |
|    std                   | 1          |
|    value_loss            | 4.35e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.927449 |
| rollout/                 |           |
|    ep_len_mean           | 948       |
|    ep_rew_mean           | -3.61e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 17        |
|    time_elapsed          | 368       |
|    total_timesteps       | 34816     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 17.3      |
|    cost_value_loss       | 234       |
|    cost_values           | 2.69      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0312    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.42e+03  |
|    n_updates             | 160       |
|    policy_gradient_loss  | -2.64e-08 |
|    std                   | 1         |
|    value_loss            | 4.49e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8275285 |
| rollout/                 |            |
|    ep_len_mean           | 951        |
|    ep_rew_mean           | -3.62e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 18         |
|    time_elapsed          | 389        |
|    total_timesteps       | 36864      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17.3       |
|    cost_value_loss       | 234        |
|    cost_values           | 2.69       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0336     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.33e+03   |
|    n_updates             | 170        |
|    policy_gradient_loss  | 1.15e-08   |
|    std                   | 1          |
|    value_loss            | 4.45e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.9172525 |
| rollout/                 |            |
|    ep_len_mean           | 954        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 19         |
|    time_elapsed          | 411        |
|    total_timesteps       | 38912      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.69       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0355     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.23e+03   |
|    n_updates             | 180        |
|    policy_gradient_loss  | -1.28e-08  |
|    std                   | 1          |
|    value_loss            | 4.29e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.0104356 |
| rollout/                 |            |
|    ep_len_mean           | 956        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 20         |
|    time_elapsed          | 432        |
|    total_timesteps       | 40960      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 230        |
|    cost_values           | 2.7        |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0291     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.2e+03    |
|    n_updates             | 190        |
|    policy_gradient_loss  | -1.97e-08  |
|    std                   | 1          |
|    value_loss            | 4.33e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.058602 |
| rollout/                 |           |
|    ep_len_mean           | 958       |
|    ep_rew_mean           | -3.64e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 21        |
|    time_elapsed          | 454       |
|    total_timesteps       | 43008     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 17        |
|    cost_value_loss       | 229       |
|    cost_values           | 2.7       |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0254    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.27e+03  |
|    n_updates             | 200       |
|    policy_gradient_loss  | 4.06e-09  |
|    std                   | 1         |
|    value_loss            | 4.39e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.2735724 |
| rollout/                 |            |
|    ep_len_mean           | 960        |
|    ep_rew_mean           | -3.65e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 22         |
|    time_elapsed          | 475        |
|    total_timesteps       | 45056      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.7        |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0244     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.15e+03   |
|    n_updates             | 210        |
|    policy_gradient_loss  | -9.3e-09   |
|    std                   | 1          |
|    value_loss            | 4.17e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.235861 |
| rollout/                 |           |
|    ep_len_mean           | 962       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 23        |
|    time_elapsed          | 497       |
|    total_timesteps       | 47104     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.9      |
|    cost_value_loss       | 228       |
|    cost_values           | 2.7       |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0283    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.17e+03  |
|    n_updates             | 220       |
|    policy_gradient_loss  | -3.32e-10 |
|    std                   | 1         |
|    value_loss            | 4.16e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.3932157 |
| rollout/                 |            |
|    ep_len_mean           | 963        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 24         |
|    time_elapsed          | 518        |
|    total_timesteps       | 49152      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.6       |
|    cost_value_loss       | 223        |
|    cost_values           | 2.7        |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.026      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.17e+03   |
|    n_updates             | 230        |
|    policy_gradient_loss  | -5.57e-08  |
|    std                   | 1          |
|    value_loss            | 4.09e+03   |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.476       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.476       |
| reward                   | -0.48226663 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -3.66e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 25          |
|    time_elapsed          | 540         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.0         |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 16.6        |
|    cost_value_loss       | 222         |
|    cost_values           | 2.7         |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.023       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15e+03    |
|    n_updates             | 240         |
|    policy_gradient_loss  | 8.54e-09    |
|    std                   | 1           |
|    value_loss            | 4.04e+03    |
------------------------------------------
------------------------------------------
| avg_speed                | 2.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.63        |
| reward                   | -0.80882096 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -3.67e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 26          |
|    time_elapsed          | 561         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.0         |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 16.8        |
|    cost_value_loss       | 227         |
|    cost_values           | 2.71        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0207      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02e+03    |
|    n_updates             | 250         |
|    policy_gradient_loss  | -2.47e-08   |
|    std                   | 1           |
|    value_loss            | 4.15e+03    |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.34       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.34       |
| reward                   | -1.4453217 |
| rollout/                 |            |
|    ep_len_mean           | 968        |
|    ep_rew_mean           | -3.68e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 27         |
|    time_elapsed          | 583        |
|    total_timesteps       | 55296      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.8       |
|    cost_value_loss       | 226        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0151     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.18e+03   |
|    n_updates             | 260        |
|    policy_gradient_loss  | 3.11e-09   |
|    std                   | 1          |
|    value_loss            | 4.16e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 6.11       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.11       |
| reward                   | -1.7427349 |
| rollout/                 |            |
|    ep_len_mean           | 969        |
|    ep_rew_mean           | -3.68e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 28         |
|    time_elapsed          | 605        |
|    total_timesteps       | 57344      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17.3       |
|    cost_value_loss       | 233        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0123     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.21e+03   |
|    n_updates             | 270        |
|    policy_gradient_loss  | 1.44e-09   |
|    std                   | 1          |
|    value_loss            | 4.3e+03    |
-----------------------------------------
-----------------------------------------
| avg_speed                | 5.42       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5.42       |
| reward                   | -1.6589808 |
| rollout/                 |            |
|    ep_len_mean           | 955        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 29         |
|    time_elapsed          | 627        |
|    total_timesteps       | 59392      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.7       |
|    cost_value_loss       | 225        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0162     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.21e+03   |
|    n_updates             | 280        |
|    policy_gradient_loss  | 1.2e-08    |
|    std                   | 1          |
|    value_loss            | 4.06e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -2.8677053 |
| rollout/                 |            |
|    ep_len_mean           | 957        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 30         |
|    time_elapsed          | 648        |
|    total_timesteps       | 61440      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.3       |
|    cost_value_loss       | 218        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0155     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.01e+03   |
|    n_updates             | 290        |
|    policy_gradient_loss  | 6.51e-09   |
|    std                   | 1          |
|    value_loss            | 3.93e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -2.3643968 |
| rollout/                 |            |
|    ep_len_mean           | 958        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 31         |
|    time_elapsed          | 670        |
|    total_timesteps       | 63488      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0112     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.14e+03   |
|    n_updates             | 300        |
|    policy_gradient_loss  | -3.35e-08  |
|    std                   | 1          |
|    value_loss            | 4.04e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -3.9094179 |
| rollout/                 |            |
|    ep_len_mean           | 959        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 32         |
|    time_elapsed          | 691        |
|    total_timesteps       | 65536      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.6       |
|    cost_value_loss       | 222        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0147     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.11e+03   |
|    n_updates             | 310        |
|    policy_gradient_loss  | 2.31e-08   |
|    std                   | 1          |
|    value_loss            | 4e+03      |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.3562703 |
| rollout/                 |            |
|    ep_len_mean           | 960        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 33         |
|    time_elapsed          | 713        |
|    total_timesteps       | 67584      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 229        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0105     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.11e+03   |
|    n_updates             | 320        |
|    policy_gradient_loss  | -1.73e-09  |
|    std                   | 1          |
|    value_loss            | 4.06e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.4656672 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -3.65e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 34         |
|    time_elapsed          | 734        |
|    total_timesteps       | 69632      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17.3       |
|    cost_value_loss       | 234        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0115     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.18e+03   |
|    n_updates             | 330        |
|    policy_gradient_loss  | -3.12e-08  |
|    std                   | 1          |
|    value_loss            | 4.16e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.682626 |
| rollout/                 |           |
|    ep_len_mean           | 963       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 35        |
|    time_elapsed          | 756       |
|    total_timesteps       | 71680     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 17        |
|    cost_value_loss       | 228       |
|    cost_values           | 2.71      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.0107    |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.16e+03  |
|    n_updates             | 340       |
|    policy_gradient_loss  | -5.9e-09  |
|    std                   | 1         |
|    value_loss            | 4.08e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.7748156 |
| rollout/                 |            |
|    ep_len_mean           | 964        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 36         |
|    time_elapsed          | 777        |
|    total_timesteps       | 73728      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.7       |
|    cost_value_loss       | 225        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0105     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.06e+03   |
|    n_updates             | 350        |
|    policy_gradient_loss  | -6.9e-09   |
|    std                   | 1          |
|    value_loss            | 3.99e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8137403 |
| rollout/                 |            |
|    ep_len_mean           | 965        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 37         |
|    time_elapsed          | 799        |
|    total_timesteps       | 75776      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.9       |
|    cost_value_loss       | 227        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0119     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2e+03      |
|    n_updates             | 360        |
|    policy_gradient_loss  | -1.9e-08   |
|    std                   | 1          |
|    value_loss            | 3.89e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.8439116 |
| rollout/                 |            |
|    ep_len_mean           | 965        |
|    ep_rew_mean           | -3.66e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 38         |
|    time_elapsed          | 821        |
|    total_timesteps       | 77824      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17.3       |
|    cost_value_loss       | 233        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00958    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.2e+03    |
|    n_updates             | 370        |
|    policy_gradient_loss  | 6.87e-09   |
|    std                   | 1          |
|    value_loss            | 4.14e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.7872314 |
| rollout/                 |            |
|    ep_len_mean           | 955        |
|    ep_rew_mean           | -3.63e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 39         |
|    time_elapsed          | 842        |
|    total_timesteps       | 79872      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.9       |
|    cost_value_loss       | 228        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.0102     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.08e+03   |
|    n_updates             | 380        |
|    policy_gradient_loss  | -9.76e-09  |
|    std                   | 1          |
|    value_loss            | 3.84e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.540085 |
| rollout/                 |           |
|    ep_len_mean           | 956       |
|    ep_rew_mean           | -3.63e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 40        |
|    time_elapsed          | 864       |
|    total_timesteps       | 81920     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.9      |
|    cost_value_loss       | 227       |
|    cost_values           | 2.71      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.00952   |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.05e+03  |
|    n_updates             | 390       |
|    policy_gradient_loss  | 4e-09     |
|    std                   | 1         |
|    value_loss            | 4.03e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -4.891749 |
| rollout/                 |           |
|    ep_len_mean           | 957       |
|    ep_rew_mean           | -3.64e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 41        |
|    time_elapsed          | 885       |
|    total_timesteps       | 83968     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.7      |
|    cost_value_loss       | 224       |
|    cost_values           | 2.71      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.00946   |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.1e+03   |
|    n_updates             | 400       |
|    policy_gradient_loss  | 1.75e-08  |
|    std                   | 1         |
|    value_loss            | 3.95e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.9660373 |
| rollout/                 |            |
|    ep_len_mean           | 958        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 42         |
|    time_elapsed          | 907        |
|    total_timesteps       | 86016      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17.3       |
|    cost_value_loss       | 234        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00731    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.17e+03   |
|    n_updates             | 410        |
|    policy_gradient_loss  | -1.13e-09  |
|    std                   | 1          |
|    value_loss            | 4.11e+03   |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -4.5977874 |
| rollout/                 |            |
|    ep_len_mean           | 959        |
|    ep_rew_mean           | -3.64e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 43         |
|    time_elapsed          | 928        |
|    total_timesteps       | 88064      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17.3       |
|    cost_value_loss       | 233        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00809    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.15e+03   |
|    n_updates             | 420        |
|    policy_gradient_loss  | 2.63e-09   |
|    std                   | 1          |
|    value_loss            | 3.98e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.141539 |
| rollout/                 |           |
|    ep_len_mean           | 960       |
|    ep_rew_mean           | -3.64e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 44        |
|    time_elapsed          | 950       |
|    total_timesteps       | 90112     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.9      |
|    cost_value_loss       | 228       |
|    cost_values           | 2.71      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.008     |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 1.96e+03  |
|    n_updates             | 430       |
|    policy_gradient_loss  | 4.54e-09  |
|    std                   | 1         |
|    value_loss            | 3.75e+03  |
----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.082294 |
| rollout/                 |           |
|    ep_len_mean           | 961       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 45        |
|    time_elapsed          | 972       |
|    total_timesteps       | 92160     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 16.7      |
|    cost_value_loss       | 224       |
|    cost_values           | 2.71      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.00889   |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 1.82e+03  |
|    n_updates             | 440       |
|    policy_gradient_loss  | 1.47e-08  |
|    std                   | 1         |
|    value_loss            | 3.63e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.0792747 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -3.65e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 46         |
|    time_elapsed          | 993        |
|    total_timesteps       | 94208      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 16.9       |
|    cost_value_loss       | 228        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00782    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.11e+03   |
|    n_updates             | 450        |
|    policy_gradient_loss  | -6.2e-09   |
|    std                   | 1          |
|    value_loss            | 3.95e+03   |
-----------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 1         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -5.16123  |
| rollout/                 |           |
|    ep_len_mean           | 963       |
|    ep_rew_mean           | -3.65e+03 |
| time/                    |           |
|    fps                   | 94        |
|    iterations            | 47        |
|    time_elapsed          | 1015      |
|    total_timesteps       | 96256     |
| train/                   |           |
|    approx_kl             | 0.0       |
|    clip_fraction         | 0         |
|    clip_range            | 0.2       |
|    cost_returns          | 17        |
|    cost_value_loss       | 229       |
|    cost_values           | 2.71      |
|    entropy               | -2.84     |
|    entropy_loss          | -2.84     |
|    explained_variance    | 0.00755   |
|    lagrangian_multiplier | 0         |
|    learning_rate         | 0.0003    |
|    loss                  | 2.05e+03  |
|    n_updates             | 460       |
|    policy_gradient_loss  | 8.15e-09  |
|    std                   | 1         |
|    value_loss            | 3.83e+03  |
----------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -5.3691196 |
| rollout/                 |            |
|    ep_len_mean           | 963        |
|    ep_rew_mean           | -3.65e+03  |
| time/                    |            |
|    fps                   | 94         |
|    iterations            | 48         |
|    time_elapsed          | 1036       |
|    total_timesteps       | 98304      |
| train/                   |            |
|    approx_kl             | 0.0        |
|    clip_fraction         | 0          |
|    clip_range            | 0.2        |
|    cost_returns          | 17.3       |
|    cost_value_loss       | 234        |
|    cost_values           | 2.71       |
|    entropy               | -2.84      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.00638    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.05e+03   |
|    n_updates             | 470        |
|    policy_gradient_loss  | 3.79e-08   |
|    std                   | 1          |
|    value_loss            | 4e+03      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.375       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.375       |
| reward                   | -0.45301288 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -3.65e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 49          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 100352      |
| train/                   |             |
|    approx_kl             | 0.0         |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 17          |
|    cost_value_loss       | 229         |
|    cost_values           | 2.71        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.00697     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02e+03    |
|    n_updates             | 480         |
|    policy_gradient_loss  | 8.24e-09    |
|    std                   | 1           |
|    value_loss            | 3.85e+03    |
------------------------------------------
slurmstepd: error: *** JOB 120158 ON airl.ist.berkeley.edu CANCELLED AT 2024-01-23T10:11:25 ***
slurmstepd: error: *** STEP 120158.0 ON airl.ist.berkeley.edu CANCELLED AT 2024-01-23T10:11:25 ***
