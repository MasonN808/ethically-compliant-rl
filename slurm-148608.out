wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240307_032750-gcskytqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sun-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/gcskytqy
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
Using cpu device
------------------------------------
| avg_speed          | 1.67        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.67        |
| reward             | -0.47781765 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -810        |
| time/              |             |
|    fps             | 100         |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 0.825        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.825        |
| reward                   | -0.45940512  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0030972082 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 9.77         |
|    cost_values           | 0.401        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.000666     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.5         |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 1            |
|    value_loss            | 151          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 2.99          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.99          |
| reward                   | -0.8368373    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -1.23e+03     |
| time/                    |               |
|    fps                   | 75            |
|    iterations            | 3             |
|    time_elapsed          | 80            |
|    total_timesteps       | 6144          |
| train/                   |               |
|    approx_kl             | 0.00044807556 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.72          |
|    cost_value_loss       | 9.28          |
|    cost_values           | 0.979         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -0.063        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 442           |
|    n_updates             | 20            |
|    policy_gradient_loss  | -0.000621     |
|    std                   | 1             |
|    value_loss            | 967           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.82         |
| reward                   | -0.832117    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0009670062 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 4.81         |
|    cost_values           | 0.98         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.0715      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 130          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.000755    |
|    std                   | 1.01         |
|    value_loss            | 285          |
-------------------------------------------
srun: Job 148608 step creation temporarily disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.45         |
| reward                   | -2.0088072   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 141          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0019690387 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 4.98         |
|    cost_values           | 0.983        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00121      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 236          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 1.01         |
|    value_loss            | 483          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.56         |
| reward                   | -0.39450476  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0021178366 |
|    clip_fraction         | 0.00122      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 3.84         |
|    cost_values           | 0.975        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000256    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 135          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 1.01         |
|    value_loss            | 290          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.29        |
| reward                   | -0.8185544  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 14336       |
| train/                   |             |
|    approx_kl             | 0.001183266 |
|    clip_fraction         | 0.000293    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 2.47        |
|    cost_values           | 0.992       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -1.6e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 221         |
|    n_updates             | 60          |
|    policy_gradient_loss  | -0.000686   |
|    std                   | 1.01        |
|    value_loss            | 485         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.77433884  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 8            |
|    time_elapsed          | 233          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0059567587 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 7.67         |
|    cost_values           | 0.98         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000106    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 98.7         |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 1            |
|    value_loss            | 209          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 0.696         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.696         |
| reward                   | -0.4508101    |
| rollout/                 |               |
|    ep_len_mean           | 921           |
|    ep_rew_mean           | -1.07e+03     |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 9             |
|    time_elapsed          | 263           |
|    total_timesteps       | 18432         |
| train/                   |               |
|    approx_kl             | 0.00042864715 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.46          |
|    cost_value_loss       | 4.05          |
|    cost_values           | 0.983         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -0.00181      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 70.2          |
|    n_updates             | 80            |
|    policy_gradient_loss  | -0.000439     |
|    std                   | 1.01          |
|    value_loss            | 160           |
--------------------------------------------
--------------------------------------------
| avg_speed                | 3.77          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 3.77          |
| reward                   | -0.80102146   |
| rollout/                 |               |
|    ep_len_mean           | 928           |
|    ep_rew_mean           | -1.08e+03     |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 10            |
|    time_elapsed          | 293           |
|    total_timesteps       | 20480         |
| train/                   |               |
|    approx_kl             | 0.00079285627 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.5           |
|    cost_value_loss       | 3.92          |
|    cost_values           | 0.981         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -0.000267     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 124           |
|    n_updates             | 90            |
|    policy_gradient_loss  | -0.000286     |
|    std                   | 1.01          |
|    value_loss            | 277           |
--------------------------------------------
------------------------------------------
| avg_speed                | 2.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.92        |
| reward                   | -0.59216386 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 324         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.005134275 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 6.06        |
|    cost_values           | 0.988       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 3.19e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 114         |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.002      |
|    std                   | 1           |
|    value_loss            | 251         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0141       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0141       |
| reward                   | -0.33158445  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 354          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0047090305 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 7.29         |
|    cost_values           | 0.998        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.000276    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.4         |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 1            |
|    value_loss            | 191          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 1.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.28         |
| reward                   | -0.40884775  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -988         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 385          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0045354282 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 8.83         |
|    cost_values           | 1            |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.000572    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.7         |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.997        |
|    value_loss            | 102          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -1.3021786   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -954         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 416          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0029233913 |
|    clip_fraction         | 0.00405      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.89         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 1.03         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 6.4e-05      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.8         |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.997        |
|    value_loss            | 64.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.48         |
| reward                   | -0.68711644  |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -957         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 446          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0018642367 |
|    clip_fraction         | 0.00225      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 36.2         |
|    cost_values           | 1.32         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -3.58e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.8         |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.999        |
|    value_loss            | 50.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.45         |
| reward                   | -1.0660582   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -938         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 477          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0024192778 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 6.99         |
|    cost_values           | 1.67         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.36e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.3         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.000523    |
|    std                   | 0.996        |
|    value_loss            | 145          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 2.59          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.59          |
| reward                   | -1.0528954    |
| rollout/                 |               |
|    ep_len_mean           | 923           |
|    ep_rew_mean           | -926          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 17            |
|    time_elapsed          | 507           |
|    total_timesteps       | 34816         |
| train/                   |               |
|    approx_kl             | 0.00060379563 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.9           |
|    cost_value_loss       | 15.7          |
|    cost_values           | 1.17          |
|    entropy               | -2.83         |
|    entropy_loss          | -2.83         |
|    explained_variance    | -9.66e-06     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21.3          |
|    n_updates             | 160           |
|    policy_gradient_loss  | -0.000357     |
|    std                   | 0.998         |
|    value_loss            | 33.1          |
--------------------------------------------
------------------------------------------
| avg_speed                | 5.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.47        |
| reward                   | -1.2561257  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -923        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 538         |
|    total_timesteps       | 36864       |
| train/                   |             |
|    approx_kl             | 0.004046309 |
|    clip_fraction         | 0.0133      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 1.06        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -1.63e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.6        |
|    n_updates             | 170         |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.999       |
|    value_loss            | 58.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.4093451  |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -924        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 568         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.005633541 |
|    clip_fraction         | 0.0134      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.39        |
|    cost_value_loss       | 16.3        |
|    cost_values           | 1           |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -2.16e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 53          |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00245    |
|    std                   | 0.997       |
|    value_loss            | 109         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.6545782   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -918         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 598          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0055151256 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 7.1          |
|    cost_values           | 1            |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -5.84e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.2         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.998        |
|    value_loss            | 142          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -1.2155511  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -937        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 628         |
|    total_timesteps       | 43008       |
| train/                   |             |
|    approx_kl             | 0.004817431 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.78        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1           |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -3.08e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 37.6        |
|    n_updates             | 200         |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 1           |
|    value_loss            | 88.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.3143904   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -923         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 659          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0018196804 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 2.27         |
|    cost_values           | 0.993        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.000941    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 175          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.000967    |
|    std                   | 1            |
|    value_loss            | 376          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.41         |
| reward                   | -2.5480402   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -929         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 689          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0054634726 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 6.55         |
|    cost_values           | 1            |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -7.5e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34           |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 1            |
|    value_loss            | 70.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9636571   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -951         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 720          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0022673907 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 1            |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.15        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 180          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 1            |
|    value_loss            | 382          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.8268906  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -950        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 750         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.005099684 |
|    clip_fraction         | 0.0112      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 4.81        |
|    cost_values           | 0.999       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -5.36e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 1           |
|    value_loss            | 273         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.3338555  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -955        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 781         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.001962539 |
|    clip_fraction         | 0.000488    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 5.95        |
|    cost_values           | 1           |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -5.84e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 168         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 1           |
|    value_loss            | 356         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.1415324  |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -953        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 811         |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.005339979 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 5.39        |
|    cost_values           | 0.999       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 1.13e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67          |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 0.999       |
|    value_loss            | 153         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.1769397   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -963         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 841          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0040326733 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 2.73         |
|    cost_values           | 0.995        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.0001      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.9         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.994        |
|    value_loss            | 205          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3869166   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -962         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 871          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0039676665 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 4.51         |
|    cost_values           | 0.997        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -2.59e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.7         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.992        |
|    value_loss            | 132          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.261        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.261        |
| reward                   | -0.6080828   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -958         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 902          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0059902486 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 6.49         |
|    cost_values           | 1.01         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -4.05e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.9         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 0.985        |
|    value_loss            | 50.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.771       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.771       |
| reward                   | -0.40784252 |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -965        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 932         |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.005166812 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 7.99        |
|    cost_values           | 1.01        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -5.59e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.6        |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 0.983       |
|    value_loss            | 47.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.89        |
| reward                   | -0.43191886 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -977        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 962         |
|    total_timesteps       | 65536       |
| train/                   |             |
|    approx_kl             | 0.006151003 |
|    clip_fraction         | 0.0362      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.83        |
|    cost_value_loss       | 7.67        |
|    cost_values           | 0.991       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.8        |
|    explained_variance    | -3.1e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 77.3        |
|    n_updates             | 310         |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.984       |
|    value_loss            | 155         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 1.33        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.33        |
| reward                   | -0.54408675 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -982        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 993         |
|    total_timesteps       | 67584       |
| train/                   |             |
|    approx_kl             | 0.005431185 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 2.19        |
|    cost_values           | 0.994       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -2.26e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 139         |
|    n_updates             | 320         |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.982       |
|    value_loss            | 313         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.40287936 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -979        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1023        |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.004855818 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 7.6         |
|    cost_values           | 1           |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -4.17e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67.7        |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.981       |
|    value_loss            | 143         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.325        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.325        |
| reward                   | -0.66412073  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -970         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 35           |
|    time_elapsed          | 1054         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0051870756 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 19.1         |
|    cost_values           | 1.03         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.8         |
|    explained_variance    | -3.46e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.9         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.984        |
|    value_loss            | 65.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.83        |
| reward                   | -0.58629906 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -965        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1084        |
|    total_timesteps       | 73728       |
| train/                   |             |
|    approx_kl             | 0.005366695 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.43        |
|    cost_value_loss       | 7.9         |
|    cost_values           | 1.56        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -6.2e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 350         |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.999       |
|    value_loss            | 5.56        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.78        |
| reward                   | -0.5146645  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -964        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1115        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.003351902 |
|    clip_fraction         | 0.0497      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.81        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 2.6         |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0.00412     |
|    learning_rate         | 0.0003      |
|    loss                  | 16.8        |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.995       |
|    value_loss            | 81.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.182        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.182        |
| reward                   | -0.5067572   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -956         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1145         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0038961745 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 6.66         |
|    cost_values           | 2.81         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.67e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.7         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.995        |
|    value_loss            | 54.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.67         |
| reward                   | -0.940872    |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -950         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1176         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0063467277 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.58         |
|    cost_value_loss       | 24.8         |
|    cost_values           | 2.82         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 1.43e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.993        |
|    value_loss            | 15.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.43        |
| reward                   | -1.3334779  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -956        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1206        |
|    total_timesteps       | 81920       |
| train/                   |             |
|    approx_kl             | 0.004350863 |
|    clip_fraction         | 0.0472      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.99        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -1.91e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.3        |
|    n_updates             | 390         |
|    policy_gradient_loss  | -0.00197    |
|    std                   | 0.989       |
|    value_loss            | 13.7        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -2.3221564   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -963         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1236         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0032451502 |
|    clip_fraction         | 0.00552      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 7.65         |
|    cost_values           | 2.81         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 73.8         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.988        |
|    value_loss            | 160          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.6181695   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -976         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1267         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0022379197 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 3.91         |
|    cost_values           | 2.26         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.03e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.988        |
|    value_loss            | 226          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.4404383   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -987         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1297         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0010132887 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 5.16         |
|    cost_values           | 1.58         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 167          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.000905    |
|    std                   | 0.989        |
|    value_loss            | 348          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.33         |
| reward                   | -1.0604784   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -990         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1328         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0016740267 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 9.37         |
|    cost_values           | 1.03         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 149          |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.988        |
|    value_loss            | 323          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.0373907   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -990         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1358         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0055592046 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 1.01         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -3.1e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.4         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00458     |
|    std                   | 0.991        |
|    value_loss            | 76.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -1.2574189   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -998         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1389         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0049988516 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.39         |
|    cost_values           | 0.982        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.3         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.989        |
|    value_loss            | 159          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.28         |
| reward                   | -1.8423667   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -998         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1419         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0041187215 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 8.09         |
|    cost_values           | 1            |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 8.94e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67.8         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.991        |
|    value_loss            | 149          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -1.064884    |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1449         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0058574956 |
|    clip_fraction         | 0.0659       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 5.89         |
|    cost_values           | 1            |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.2         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00577     |
|    std                   | 0.991        |
|    value_loss            | 73.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.6674823  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -983        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1480        |
|    total_timesteps       | 100352      |
| train/                   |             |
|    approx_kl             | 0.006225918 |
|    clip_fraction         | 0.0551      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 18.7        |
|    cost_values           | 1.04        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -1.04e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49.3        |
|    n_updates             | 480         |
|    policy_gradient_loss  | -0.00506    |
|    std                   | 0.992       |
|    value_loss            | 90          |
------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
------------------------------------
| avg_speed          | 4.06        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 4.06        |
| reward             | -0.77640176 |
| rollout/           |             |
|    ep_len_mean     | 954         |
|    ep_rew_mean     | -976        |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 102400      |
------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.1844536   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -967         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0034891777 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.37         |
|    cost_value_loss       | 8.42         |
|    cost_values           | 2.67         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 4.17e-07     |
|    lagrangian_multiplier | 0.00603      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 0.986        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1229861   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -949         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0068464577 |
|    clip_fraction         | 0.083        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 5.4          |
|    cost_values           | 2.87         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.1         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.985        |
|    value_loss            | 90.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 0.567        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.567        |
| reward                   | -0.3768527   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -940         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0073413784 |
|    clip_fraction         | 0.0747       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 4.33         |
|    cost_values           | 2.92         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0.00641      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.97         |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00424     |
|    std                   | 0.98         |
|    value_loss            | 63.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.09         |
| reward                   | -1.1683642   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -941         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 142          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0051369513 |
|    clip_fraction         | 0.0807       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 2.99         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -4.41e-06    |
|    lagrangian_multiplier | 0.022        |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.984        |
|    value_loss            | 22.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.91         |
| reward                   | -1.8125398   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -948         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0046054614 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.77         |
|    cost_value_loss       | 18.6         |
|    cost_values           | 2.99         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -9.54e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.7         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.986        |
|    value_loss            | 19.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.31         |
| reward                   | -0.9058154   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -954         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 202          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0021179398 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 7.63         |
|    cost_values           | 2.83         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.5e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.8         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.985        |
|    value_loss            | 172          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.06        |
| reward                   | -1.6091974  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -950        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 233         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.005484075 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 6.92        |
|    cost_values           | 2.34        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 1.19e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 94.6        |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.00335    |
|    std                   | 0.984       |
|    value_loss            | 195         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.41         |
| reward                   | -1.6096197   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -957         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 263          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0031090449 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 5.21         |
|    cost_values           | 1.87         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.6         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.984        |
|    value_loss            | 59.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.5710636  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -963        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 293         |
|    total_timesteps       | 120832      |
| train/                   |             |
|    approx_kl             | 0.003919572 |
|    clip_fraction         | 0.0118      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 7.45        |
|    cost_values           | 1.5         |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 66          |
|    n_updates             | 580         |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 0.982       |
|    value_loss            | 128         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.94470316  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -973         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 324          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0031103012 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 4.99         |
|    cost_values           | 1.19         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -2.15e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.4         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.981        |
|    value_loss            | 88.7         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.44         |
| reward                   | -1.5117048   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -976         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 354          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0046840156 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 5.85         |
|    cost_values           | 1.17         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00553     |
|    std                   | 0.985        |
|    value_loss            | 25.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.46        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.46        |
| reward                   | -0.25759056 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -982        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 384         |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.007783399 |
|    clip_fraction         | 0.0572      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.8         |
|    cost_value_loss       | 12.2        |
|    cost_values           | 1.86        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -2.15e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.3        |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.986       |
|    value_loss            | 15.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.41         |
| reward                   | -0.32084343  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -988         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 415          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0026843534 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 3.71         |
|    cost_values           | 2.49         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.7         |
|    n_updates             | 620          |
|    policy_gradient_loss  | 0.00256      |
|    std                   | 0.984        |
|    value_loss            | 77.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.37         |
| reward                   | -0.71568197  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -990         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 445          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0058460915 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 7.01         |
|    cost_values           | 2.31         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.1         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00575     |
|    std                   | 0.986        |
|    value_loss            | 55.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.85        |
| reward                   | -0.61687094 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1e+03      |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.010900737 |
|    clip_fraction         | 0.058       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 6.27        |
|    cost_values           | 2.85        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -1.08e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.7        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.984       |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.04        |
| reward                   | -0.78218615 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1e+03      |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 506         |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.004531654 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 3.68        |
|    cost_values           | 2.74        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -1.22e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.9        |
|    n_updates             | 650         |
|    policy_gradient_loss  | 0.00719     |
|    std                   | 0.983       |
|    value_loss            | 101         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.1425362   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 536          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0067279465 |
|    clip_fraction         | 0.0374       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 6.21         |
|    cost_values           | 2.27         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.8         |
|    explained_variance    | -7.51e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.3         |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.984        |
|    value_loss            | 117          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.08         |
| reward                   | -0.36665782  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -991         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 566          |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0050296085 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 3.97         |
|    cost_values           | 1.95         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.74e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.6         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.986        |
|    value_loss            | 41.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 1.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.69        |
| reward                   | -0.37856242 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 597         |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.004771511 |
|    clip_fraction         | 0.0783      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.5         |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.1         |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.6        |
|    n_updates             | 680         |
|    policy_gradient_loss  | 0.000259    |
|    std                   | 0.993       |
|    value_loss            | 62.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.51        |
| reward                   | -0.58255416 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 627         |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.010067096 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 7.66        |
|    cost_values           | 2.33        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 69.9        |
|    n_updates             | 690         |
|    policy_gradient_loss  | 0.00925     |
|    std                   | 0.997       |
|    value_loss            | 137         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.2          |
| reward                   | -0.58260596  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 658          |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0038339375 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 4.93         |
|    cost_values           | 1.95         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.3         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.998        |
|    value_loss            | 81.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.69        |
| reward                   | -0.73382527 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 688         |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.004325948 |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 7.33        |
|    cost_values           | 1.65        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -9.54e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 84.6        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.999       |
|    value_loss            | 159         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.338466    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 719          |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0059734667 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 7.04         |
|    cost_values           | 1.44         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.43e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.2         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.999        |
|    value_loss            | 69.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.85134345  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -999         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 749          |
|    total_timesteps       | 151552       |
| train/                   |              |
|    approx_kl             | 0.0026899169 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 1.73         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.7         |
|    n_updates             | 730          |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.997        |
|    value_loss            | 84.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.74        |
| reward                   | -1.0677168  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -991        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 780         |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.005300089 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 8.64        |
|    cost_values           | 2.41        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -1.91e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.1        |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00313    |
|    std                   | 0.994       |
|    value_loss            | 46          |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.93         |
| reward                   | -1.6898018   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -981         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 810          |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0051069073 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.93         |
|    cost_value_loss       | 27.6         |
|    cost_values           | 2.87         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0.0074       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.04         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.994        |
|    value_loss            | 20.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 6.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.95         |
| reward                   | -1.5651523   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -983         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 841          |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0031961338 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 13           |
|    cost_values           | 2.99         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0.00452      |
|    learning_rate         | 0.0003       |
|    loss                  | 20.8         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.000951    |
|    std                   | 0.994        |
|    value_loss            | 96.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -1.500502   |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -985        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 871         |
|    total_timesteps       | 159744      |
| train/                   |             |
|    approx_kl             | 0.007119662 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.69        |
|    cost_value_loss       | 8.3         |
|    cost_values           | 2.99        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -9.3e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.6        |
|    n_updates             | 770         |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.993       |
|    value_loss            | 37.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.04         |
| reward                   | -0.54480004  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -976         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 901          |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0049931025 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.64         |
|    cost_value_loss       | 5.47         |
|    cost_values           | 2.99         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.43e-06    |
|    lagrangian_multiplier | 0.0193       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.42         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.994        |
|    value_loss            | 53           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.03         |
| reward                   | -0.40134588  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -967         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 31           |
|    time_elapsed          | 932          |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0041431673 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.97         |
|    cost_value_loss       | 8.15         |
|    cost_values           | 2.99         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -1.19e-06    |
|    lagrangian_multiplier | 0.000507     |
|    learning_rate         | 0.0003       |
|    loss                  | 21.9         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.991        |
|    value_loss            | 44.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.62         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.62         |
| reward                   | -0.6151528   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -964         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 962          |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0038440386 |
|    clip_fraction         | 0.0496       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 5.76         |
|    cost_values           | 2.99         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -1.91e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 0.989        |
|    value_loss            | 31.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.687        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.687        |
| reward                   | -0.37752935  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -954         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 993          |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0033090939 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.25         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 3            |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.5         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.991        |
|    value_loss            | 36.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.105         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.105         |
| reward                   | -0.32909787   |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -953          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 34            |
|    time_elapsed          | 1023          |
|    total_timesteps       | 169984        |
| train/                   |               |
|    approx_kl             | 0.00082472165 |
|    clip_fraction         | 0.000146      |
|    clip_range            | 0.2           |
|    cost_returns          | 5.37          |
|    cost_value_loss       | 19.2          |
|    cost_values           | 2.99          |
|    entropy               | -2.82         |
|    entropy_loss          | -2.82         |
|    explained_variance    | 1.19e-07      |
|    lagrangian_multiplier | 0.00967       |
|    learning_rate         | 0.0003        |
|    loss                  | 10.2          |
|    n_updates             | 820           |
|    policy_gradient_loss  | -0.000803     |
|    std                   | 0.992         |
|    value_loss            | 63.5          |
--------------------------------------------
------------------------------------------
| avg_speed                | 1.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.72        |
| reward                   | -0.25413683 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -950        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1054        |
|    total_timesteps       | 172032      |
| train/                   |             |
|    approx_kl             | 0.00474461  |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.15        |
|    cost_value_loss       | 22.1        |
|    cost_values           | 3           |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0.00343     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.98        |
|    n_updates             | 830         |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 0.992       |
|    value_loss            | 16.2        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.478       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.478       |
| reward                   | -0.49973655 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -951        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1084        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.003732658 |
|    clip_fraction         | 0.0101      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 17.8        |
|    cost_values           | 2.99        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -1.07e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.6        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.993       |
|    value_loss            | 49.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.67         |
| reward                   | -0.48515797  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -953         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1115         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0014037351 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.34         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.99         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -1.91e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.000363    |
|    std                   | 0.993        |
|    value_loss            | 19.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.59695536  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -945         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1145         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0028279494 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.38         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.99         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0.00151      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.989        |
|    value_loss            | 37.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.75         |
| reward                   | -0.7102455   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1176         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0067660646 |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 2.99         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00478     |
|    std                   | 0.984        |
|    value_loss            | 13.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.61668605  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -907         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1207         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0024942628 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.82         |
|    cost_value_loss       | 23.6         |
|    cost_values           | 3            |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 5.36e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.000701    |
|    std                   | 0.981        |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.5          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.5          |
| reward                   | -0.42426762  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1237         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0040289373 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.66         |
|    cost_value_loss       | 6.85         |
|    cost_values           | 2.99         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.1         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.978        |
|    value_loss            | 95.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.951        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.951        |
| reward                   | -0.60097337  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -894         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1268         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0038890678 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 26.9         |
|    cost_values           | 3            |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -4.29e-06    |
|    lagrangian_multiplier | 0.00274      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.978        |
|    value_loss            | 38.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.9          |
| reward                   | -1.0254271   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -892         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1298         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0035666474 |
|    clip_fraction         | 0.00952      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.7          |
|    cost_value_loss       | 14.8         |
|    cost_values           | 3            |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 3.39e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 49.4         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.977        |
|    value_loss            | 89.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -1.4116668   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -900         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1329         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0007834496 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.9          |
|    cost_value_loss       | 8.75         |
|    cost_values           | 2.88         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -2.15e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 73.2         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.000528    |
|    std                   | 0.977        |
|    value_loss            | 148          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.41          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.41          |
| reward                   | -0.18477032   |
| rollout/                 |               |
|    ep_len_mean           | 949           |
|    ep_rew_mean           | -900          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 45            |
|    time_elapsed          | 1359          |
|    total_timesteps       | 192512        |
| train/                   |               |
|    approx_kl             | 0.00072286563 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 3.32          |
|    cost_value_loss       | 7.42          |
|    cost_values           | 2.55          |
|    entropy               | -2.79         |
|    entropy_loss          | -2.79         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 119           |
|    n_updates             | 930           |
|    policy_gradient_loss  | -0.000843     |
|    std                   | 0.977         |
|    value_loss            | 258           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.17         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.17         |
| reward                   | -0.6068305   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -912         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1390         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0046088872 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 8.92         |
|    cost_values           | 2.17         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 135          |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 0.977        |
|    value_loss            | 279          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.6742309   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1420         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0025596202 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 11.1         |
|    cost_values           | 1.88         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.6         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.977        |
|    value_loss            | 138          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.1284461   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -928         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1450         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0052254405 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 3.9          |
|    cost_values           | 1.63         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.79        |
|    explained_variance    | -2.38e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.4         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.979        |
|    value_loss            | 45.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -1.1376532   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -931         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1481         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0031116295 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 3.31         |
|    cost_values           | 1.58         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.979        |
|    value_loss            | 22.6         |
-------------------------------------------
----------------------------------
| avg_speed          | 7.78      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 7.78      |
| reward             | -1.119784 |
| rollout/           |           |
|    ep_len_mean     | 964       |
|    ep_rew_mean     | -940      |
| time/              |           |
|    fps             | 99        |
|    iterations      | 1         |
|    time_elapsed    | 20        |
|    total_timesteps | 202752    |
----------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.91301715 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -942        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 204800      |
| train/                   |             |
|    approx_kl             | 0.004782334 |
|    clip_fraction         | 0.0358      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.13        |
|    cost_value_loss       | 4.4         |
|    cost_values           | 1.79        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 990         |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.973       |
|    value_loss            | 24.7        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.070102   |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -947        |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 3           |
|    time_elapsed          | 81          |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.003504193 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 2.39        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | -2.03e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.966       |
|    value_loss            | 22.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.37595707 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -943        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 111         |
|    total_timesteps       | 208896      |
| train/                   |             |
|    approx_kl             | 0.002083798 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 2.72        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -1.67e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 1010        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.964       |
|    value_loss            | 20.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.95190734 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -931        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 5           |
|    time_elapsed          | 141         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.003062177 |
|    clip_fraction         | 0.015       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.67        |
|    cost_value_loss       | 2.27        |
|    cost_values           | 2.52        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -1.79e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.7        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.965       |
|    value_loss            | 46.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.4455802   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -930         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0039821933 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 3.26         |
|    cost_values           | 2.22         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.966        |
|    value_loss            | 25.2         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.7936934   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 202          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0030576973 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 2.74         |
|    cost_values           | 2.05         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.966        |
|    value_loss            | 23.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.86746746 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -927        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.005455344 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.04        |
|    cost_value_loss       | 2.2         |
|    cost_values           | 1.8         |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.9        |
|    n_updates             | 1050        |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.965       |
|    value_loss            | 59.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.2230396   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -927         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 263          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0063930573 |
|    clip_fraction         | 0.121        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 1.64         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.9         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | 0.00159      |
|    std                   | 0.961        |
|    value_loss            | 41.9         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.4817696 |
| rollout/                 |            |
|    ep_len_mean           | 955        |
|    ep_rew_mean           | -929       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 10         |
|    time_elapsed          | 293        |
|    total_timesteps       | 221184     |
| train/                   |            |
|    approx_kl             | 0.0080719  |
|    clip_fraction         | 0.075      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.05       |
|    cost_value_loss       | 3.44       |
|    cost_values           | 1.67       |
|    entropy               | -2.76      |
|    entropy_loss          | -2.76      |
|    explained_variance    | -9.54e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.1       |
|    n_updates             | 1070       |
|    policy_gradient_loss  | 0.00232    |
|    std                   | 0.961      |
|    value_loss            | 19.5       |
-----------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -1.3933879  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -929        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 323         |
|    total_timesteps       | 223232      |
| train/                   |             |
|    approx_kl             | 0.002120925 |
|    clip_fraction         | 0.00371     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 1.59        |
|    cost_values           | 1.59        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 87.5        |
|    n_updates             | 1080        |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.961       |
|    value_loss            | 190         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -1.0332202  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -931        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 354         |
|    total_timesteps       | 225280      |
| train/                   |             |
|    approx_kl             | 0.004914697 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 4.78        |
|    cost_values           | 1.27        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.1        |
|    n_updates             | 1090        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.961       |
|    value_loss            | 62.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -1.4327297   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0039854096 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 3.03         |
|    cost_values           | 1.28         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.5         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.961        |
|    value_loss            | 42.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.5935714   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 414          |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0031475371 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 1.58         |
|    cost_values           | 1.42         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 3.58e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.958        |
|    value_loss            | 21.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.2069722   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -896         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 15           |
|    time_elapsed          | 444          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0056056567 |
|    clip_fraction         | 0.0668       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 3.07         |
|    cost_values           | 1.42         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 1.25e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.0055      |
|    std                   | 0.96         |
|    value_loss            | 26.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.94580317 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -898        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.026754394 |
|    clip_fraction         | 0.388       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.3         |
|    cost_value_loss       | 4.06        |
|    cost_values           | 1.56        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 78.7        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | 0.0151      |
|    std                   | 0.962       |
|    value_loss            | 113         |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.3496057 |
| rollout/                 |            |
|    ep_len_mean           | 943        |
|    ep_rew_mean           | -900       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 17         |
|    time_elapsed          | 505        |
|    total_timesteps       | 235520     |
| train/                   |            |
|    approx_kl             | 0.00411698 |
|    clip_fraction         | 0.0237     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.77       |
|    cost_value_loss       | 2.33       |
|    cost_values           | 1.35       |
|    entropy               | -2.76      |
|    entropy_loss          | -2.76      |
|    explained_variance    | 2.98e-07   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 41.8       |
|    n_updates             | 1140       |
|    policy_gradient_loss  | -0.00227   |
|    std                   | 0.962      |
|    value_loss            | 76.8       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.5905491   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 535          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0063571786 |
|    clip_fraction         | 0.0512       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 3.1          |
|    cost_values           | 1.54         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.958        |
|    value_loss            | 20.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.27        |
| reward                   | -0.30644754 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -886        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 566         |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.004066297 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 5.04        |
|    cost_values           | 1.79        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.4        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | 0.00201     |
|    std                   | 0.957       |
|    value_loss            | 36          |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.00265    |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.00265    |
| reward                   | -0.3203581 |
| rollout/                 |            |
|    ep_len_mean           | 934        |
|    ep_rew_mean           | -873       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 20         |
|    time_elapsed          | 596        |
|    total_timesteps       | 241664     |
| train/                   |            |
|    approx_kl             | 0.00451972 |
|    clip_fraction         | 0.0228     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.19       |
|    cost_value_loss       | 3.44       |
|    cost_values           | 1.9        |
|    entropy               | -2.75      |
|    entropy_loss          | -2.75      |
|    explained_variance    | -3.58e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 24.3       |
|    n_updates             | 1170       |
|    policy_gradient_loss  | -0.00319   |
|    std                   | 0.958      |
|    value_loss            | 51         |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.03        |
| reward                   | -0.34051588 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -878        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 626         |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.005175426 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 5.02        |
|    cost_values           | 1.98        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.9        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.958       |
|    value_loss            | 86.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.88        |
| reward                   | -0.28581876 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -879        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 657         |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.009529021 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 2.38        |
|    cost_values           | 2.43        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.00197    |
|    std                   | 0.953       |
|    value_loss            | 27.7        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.91620296  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -888         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 687          |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0054583573 |
|    clip_fraction         | 0.177        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.75         |
|    cost_value_loss       | 3            |
|    cost_values           | 2.44         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.8         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | 0.00442      |
|    std                   | 0.952        |
|    value_loss            | 111          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.12        |
| reward                   | -0.44525322 |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -888        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 717         |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.004037161 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.61        |
|    cost_value_loss       | 2.29        |
|    cost_values           | 2.47        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.4        |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.953       |
|    value_loss            | 63.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.57802194 |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -888        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 748         |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.011659919 |
|    clip_fraction         | 0.0717      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.45        |
|    cost_value_loss       | 1.71        |
|    cost_values           | 2.37        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 2.38e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.951       |
|    value_loss            | 35.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.6          |
| reward                   | -0.7912135   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 778          |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0077641755 |
|    clip_fraction         | 0.0713       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.93         |
|    cost_value_loss       | 3.61         |
|    cost_values           | 2.64         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 1.49e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 0.947        |
|    value_loss            | 18.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -1.150362   |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -897        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 808         |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.023263251 |
|    clip_fraction         | 0.325       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 2.79        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.7        |
|    n_updates             | 1240        |
|    policy_gradient_loss  | 0.0209      |
|    std                   | 0.946       |
|    value_loss            | 102         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7215282  |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -900        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 839         |
|    total_timesteps       | 258048      |
| train/                   |             |
|    approx_kl             | 0.002679334 |
|    clip_fraction         | 0.00776     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 2.36        |
|    cost_values           | 2.45        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -1.67e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.1        |
|    n_updates             | 1250        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.946       |
|    value_loss            | 39.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1653134   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -909         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 869          |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0049540554 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.81         |
|    cost_value_loss       | 4.28         |
|    cost_values           | 2.66         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -1.19e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.942        |
|    value_loss            | 21.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.716535    |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -918         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 899          |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0024169134 |
|    clip_fraction         | 0.0887       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.96         |
|    cost_value_loss       | 3.24         |
|    cost_values           | 2.62         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | 0.00451      |
|    std                   | 0.941        |
|    value_loss            | 25.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.95505774 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -924        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 930         |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.007990875 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 4.35        |
|    cost_values           | 2.64        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 2.98e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.3        |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.939       |
|    value_loss            | 36.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0175871   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 960          |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0053008916 |
|    clip_fraction         | 0.0484       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.38         |
|    cost_value_loss       | 6.3          |
|    cost_values           | 2.95         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0.00825      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.34         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.939        |
|    value_loss            | 52.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6426813   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -938         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 990          |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0024448652 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.15         |
|    cost_value_loss       | 3.96         |
|    cost_values           | 2.83         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 5.36e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.6         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.000402    |
|    std                   | 0.94         |
|    value_loss            | 60.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.5063661   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -936         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 34           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0073451735 |
|    clip_fraction         | 0.04         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 3.59         |
|    cost_values           | 2.64         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.945        |
|    value_loss            | 25.2         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.1771146   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -940         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 35           |
|    time_elapsed          | 1051         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0036303499 |
|    clip_fraction         | 0.0649       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.15         |
|    cost_value_loss       | 4.88         |
|    cost_values           | 2.95         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.2         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.004       |
|    std                   | 0.943        |
|    value_loss            | 80.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.31845006  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -946         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1081         |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0036132257 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.17         |
|    cost_value_loss       | 3.24         |
|    cost_values           | 2.99         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.6         |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.937        |
|    value_loss            | 50.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.6945721   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -945         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1112         |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0025226567 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.74         |
|    cost_value_loss       | 5.04         |
|    cost_values           | 2.97         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 2.98e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.6         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00092     |
|    std                   | 0.936        |
|    value_loss            | 64           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -1.347981   |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -949        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1142        |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.005036166 |
|    clip_fraction         | 0.0377      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 2.51        |
|    cost_values           | 2.91        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -9.54e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 55          |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.936       |
|    value_loss            | 86.1        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 7.84       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.84       |
| reward                   | -1.1647267 |
| rollout/                 |            |
|    ep_len_mean           | 928        |
|    ep_rew_mean           | -949       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 39         |
|    time_elapsed          | 1172       |
|    total_timesteps       | 280576     |
| train/                   |            |
|    approx_kl             | 0.00432003 |
|    clip_fraction         | 0.0296     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.9        |
|    cost_value_loss       | 2.2        |
|    cost_values           | 2.79       |
|    entropy               | -2.71      |
|    entropy_loss          | -2.71      |
|    explained_variance    | 4.77e-07   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 20.8       |
|    n_updates             | 1360       |
|    policy_gradient_loss  | -0.00286   |
|    std                   | 0.937      |
|    value_loss            | 39         |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.4959666  |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -941        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.004190103 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.61        |
|    cost_value_loss       | 1.91        |
|    cost_values           | 2.59        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 36.2        |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.937       |
|    value_loss            | 71.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1407294  |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -928        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1232        |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.007885281 |
|    clip_fraction         | 0.0686      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.59        |
|    cost_value_loss       | 2.35        |
|    cost_values           | 2.42        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -1.19e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.6        |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00106    |
|    std                   | 0.94        |
|    value_loss            | 29.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -2.4334967  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -934        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1263        |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.008820692 |
|    clip_fraction         | 0.0796      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.7         |
|    cost_value_loss       | 1.77        |
|    cost_values           | 2.61        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.8        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.944       |
|    value_loss            | 44          |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.59585273 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -940        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1293        |
|    total_timesteps       | 288768      |
| train/                   |             |
|    approx_kl             | 0.004872688 |
|    clip_fraction         | 0.0457      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.55        |
|    cost_values           | 2.51        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 5.96e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 70.1        |
|    n_updates             | 1400        |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.945       |
|    value_loss            | 139         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7435396  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -934        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1323        |
|    total_timesteps       | 290816      |
| train/                   |             |
|    approx_kl             | 0.003536998 |
|    clip_fraction         | 0.00444     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 3.61        |
|    cost_values           | 2.21        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 5.96e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 88.3        |
|    n_updates             | 1410        |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.945       |
|    value_loss            | 169         |
------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.48820496   |
| rollout/                 |               |
|    ep_len_mean           | 937           |
|    ep_rew_mean           | -932          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 45            |
|    time_elapsed          | 1353          |
|    total_timesteps       | 292864        |
| train/                   |               |
|    approx_kl             | 0.00023934452 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.74          |
|    cost_value_loss       | 4.96          |
|    cost_values           | 2.03          |
|    entropy               | -2.73         |
|    entropy_loss          | -2.73         |
|    explained_variance    | 4.77e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 16            |
|    n_updates             | 1420          |
|    policy_gradient_loss  | -0.000361     |
|    std                   | 0.946         |
|    value_loss            | 32.3          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -1.1513357    |
| rollout/                 |               |
|    ep_len_mean           | 927           |
|    ep_rew_mean           | -916          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 46            |
|    time_elapsed          | 1384          |
|    total_timesteps       | 294912        |
| train/                   |               |
|    approx_kl             | 0.00048549336 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.52          |
|    cost_value_loss       | 3.49          |
|    cost_values           | 1.85          |
|    entropy               | -2.73         |
|    entropy_loss          | -2.73         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 17.5          |
|    n_updates             | 1430          |
|    policy_gradient_loss  | -0.00043      |
|    std                   | 0.946         |
|    value_loss            | 35.8          |
--------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1773633   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -917         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 47           |
|    time_elapsed          | 1414         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0009998098 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 5.29         |
|    cost_values           | 1.64         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.9         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.947        |
|    value_loss            | 78.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.8486255    |
| rollout/                 |               |
|    ep_len_mean           | 927           |
|    ep_rew_mean           | -918          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 48            |
|    time_elapsed          | 1445          |
|    total_timesteps       | 299008        |
| train/                   |               |
|    approx_kl             | 0.00062738743 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.77          |
|    cost_value_loss       | 2.63          |
|    cost_values           | 1.44          |
|    entropy               | -2.73         |
|    entropy_loss          | -2.73         |
|    explained_variance    | -1.43e-06     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 32.8          |
|    n_updates             | 1450          |
|    policy_gradient_loss  | -0.000633     |
|    std                   | 0.947         |
|    value_loss            | 66.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.302        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.302        |
| reward                   | -0.46928367  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -918         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 49           |
|    time_elapsed          | 1475         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0037522244 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 4.04         |
|    cost_values           | 1.15         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.2         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.947        |
|    value_loss            | 39           |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
-----------------------------------
| avg_speed          | 3.23       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 3.23       |
| reward             | -0.3353043 |
| rollout/           |            |
|    ep_len_mean     | 927        |
|    ep_rew_mean     | -926       |
| time/              |            |
|    fps             | 100        |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 303104     |
-----------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1353265   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -925         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0005615925 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 4.45         |
|    cost_values           | 1.36         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -2.03e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26           |
|    n_updates             | 1480         |
|    policy_gradient_loss  | 0.00141      |
|    std                   | 0.944        |
|    value_loss            | 48.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52530074  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -928         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0047897524 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 4.98         |
|    cost_values           | 1.35         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 2.26e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.944        |
|    value_loss            | 31.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -0.56493396  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -920         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0010910947 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 3.41         |
|    cost_values           | 1.42         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -2.26e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.6         |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.000373    |
|    std                   | 0.944        |
|    value_loss            | 39.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.31093633  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -923         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 141          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0005918216 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 3.59         |
|    cost_values           | 1.17         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.000503    |
|    std                   | 0.944        |
|    value_loss            | 28.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.8128288  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -923        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 171         |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.009008055 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 2.04        |
|    cost_values           | 1.17        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -1.67e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19          |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.947       |
|    value_loss            | 37.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.894885   |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -931        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 315392      |
| train/                   |             |
|    approx_kl             | 0.008184087 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 5.56        |
|    cost_values           | 1.3         |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -2.03e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 64.9        |
|    n_updates             | 1530        |
|    policy_gradient_loss  | -0.000891   |
|    std                   | 0.949       |
|    value_loss            | 131         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.39        |
| reward                   | -0.63335514 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -933        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 317440      |
| train/                   |             |
|    approx_kl             | 0.001681637 |
|    clip_fraction         | 0.000195    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 3.42        |
|    cost_values           | 1.17        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.5        |
|    n_updates             | 1540        |
|    policy_gradient_loss  | -0.000626   |
|    std                   | 0.95        |
|    value_loss            | 34.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.9862109  |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -933        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 263         |
|    total_timesteps       | 319488      |
| train/                   |             |
|    approx_kl             | 0.001923158 |
|    clip_fraction         | 0.000781    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 2.78        |
|    cost_values           | 1.19        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.9        |
|    n_updates             | 1550        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.95        |
|    value_loss            | 66.8        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0107025   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0038661007 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 4.66         |
|    cost_values           | 1.29         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.949        |
|    value_loss            | 34.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.0402578   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -938         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0033168108 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 3.19         |
|    cost_values           | 1.72         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 1570         |
|    policy_gradient_loss  | 0.00147      |
|    std                   | 0.948        |
|    value_loss            | 28.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.9212171  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -959        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 354         |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.000354633 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 1.95        |
|    cost_values           | 1.46        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -1.31e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35          |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.000373   |
|    std                   | 0.949       |
|    value_loss            | 71.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3972881   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -965         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0012322088 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 2.5          |
|    cost_values           | 1.08         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -2.86e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.9         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.000901    |
|    std                   | 0.949        |
|    value_loss            | 36           |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7422009  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -969        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 14          |
|    time_elapsed          | 415         |
|    total_timesteps       | 329728      |
| train/                   |             |
|    approx_kl             | 0.006414801 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 2.81        |
|    cost_values           | 1.12        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -1.91e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 1600        |
|    policy_gradient_loss  | -0.000984   |
|    std                   | 0.951       |
|    value_loss            | 26.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9816477   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -977         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 445          |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0019536188 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 2.1          |
|    cost_values           | 1.28         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.3         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | 0.0023       |
|    std                   | 0.953        |
|    value_loss            | 57           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.5584451    |
| rollout/                 |               |
|    ep_len_mean           | 955           |
|    ep_rew_mean           | -986          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 16            |
|    time_elapsed          | 476           |
|    total_timesteps       | 333824        |
| train/                   |               |
|    approx_kl             | 0.00046930672 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.62          |
|    cost_value_loss       | 3.21          |
|    cost_values           | 1.06          |
|    entropy               | -2.74         |
|    entropy_loss          | -2.74         |
|    explained_variance    | -3.58e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 87.8          |
|    n_updates             | 1620          |
|    policy_gradient_loss  | -0.000177     |
|    std                   | 0.953         |
|    value_loss            | 181           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.3434594   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -987         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 506          |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0056066355 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 2.78         |
|    cost_values           | 1.02         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.6         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 0.952        |
|    value_loss            | 77.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.128734    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -995         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 536          |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0030609553 |
|    clip_fraction         | 0.00498      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 3.73         |
|    cost_values           | 1.02         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.952        |
|    value_loss            | 48.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.9912835   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 567          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0064489515 |
|    clip_fraction         | 0.0562       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 1.18         |
|    cost_values           | 1.06         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.2         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.952        |
|    value_loss            | 60.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5635091   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 597          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0020909405 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 2.64         |
|    cost_values           | 1.03         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 4.17e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.5         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.000965    |
|    std                   | 0.952        |
|    value_loss            | 71           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.68720645  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 627          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0027771809 |
|    clip_fraction         | 0.0021       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 3.51         |
|    cost_values           | 1.01         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.4         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.952        |
|    value_loss            | 55.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 1.16          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 1.16          |
| reward                   | -0.47789308   |
| rollout/                 |               |
|    ep_len_mean           | 974           |
|    ep_rew_mean           | -1e+03        |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 22            |
|    time_elapsed          | 658           |
|    total_timesteps       | 346112        |
| train/                   |               |
|    approx_kl             | 0.00097637234 |
|    clip_fraction         | 0.000146      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.93          |
|    cost_value_loss       | 4.51          |
|    cost_values           | 1.01          |
|    entropy               | -2.74         |
|    entropy_loss          | -2.74         |
|    explained_variance    | -7.15e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 19.4          |
|    n_updates             | 1680          |
|    policy_gradient_loss  | -0.000623     |
|    std                   | 0.952         |
|    value_loss            | 40.3          |
--------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 4.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.32         |
| reward                   | -0.28946617  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 688          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0010902383 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 4.56         |
|    cost_values           | 1.01         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.4         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.000761    |
|    std                   | 0.952        |
|    value_loss            | 34.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.994834   |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -999        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 719         |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.003293374 |
|    clip_fraction         | 0.00835     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.6         |
|    cost_value_loss       | 3.6         |
|    cost_values           | 1.01        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 2.98e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.7        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.952       |
|    value_loss            | 44.5        |
------------------------------------------
--------------------------------------------
| avg_speed                | 3.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 3.01          |
| reward                   | -0.53598917   |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -1.01e+03     |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 25            |
|    time_elapsed          | 749           |
|    total_timesteps       | 352256        |
| train/                   |               |
|    approx_kl             | 0.00083529064 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.38          |
|    cost_value_loss       | 2.42          |
|    cost_values           | 0.992         |
|    entropy               | -2.74         |
|    entropy_loss          | -2.74         |
|    explained_variance    | -2.38e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 74.2          |
|    n_updates             | 1710          |
|    policy_gradient_loss  | -0.0011       |
|    std                   | 0.952         |
|    value_loss            | 190           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.27         |
| reward                   | -0.57298404  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 779          |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0020620376 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 3.44         |
|    cost_values           | 0.998        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.3         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.952        |
|    value_loss            | 106          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 6.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.83         |
| reward                   | -0.467421    |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 809          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0055426527 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 3.59         |
|    cost_values           | 1.3          |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.95         |
|    value_loss            | 27.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8750662  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 840         |
|    total_timesteps       | 358400      |
| train/                   |             |
|    approx_kl             | 0.002202334 |
|    clip_fraction         | 0.0511      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 2.26        |
|    cost_values           | 1.31        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 52.9        |
|    n_updates             | 1740        |
|    policy_gradient_loss  | 0.00406     |
|    std                   | 0.949       |
|    value_loss            | 112         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.95634085  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 870          |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0028622274 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 2.48         |
|    cost_values           | 1.03         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.8         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.949        |
|    value_loss            | 82.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.4          |
| reward                   | -0.95008445  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 900          |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0042463704 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 2.04         |
|    cost_values           | 1.06         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.949        |
|    value_loss            | 27.2         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.0256044  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 931         |
|    total_timesteps       | 364544      |
| train/                   |             |
|    approx_kl             | 0.006747271 |
|    clip_fraction         | 0.0691      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 2.83        |
|    cost_values           | 1.2         |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 5.36e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47.3        |
|    n_updates             | 1770        |
|    policy_gradient_loss  | -0.00626    |
|    std                   | 0.947       |
|    value_loss            | 89.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -0.8972308   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 961          |
|    total_timesteps       | 366592       |
| train/                   |              |
|    approx_kl             | 0.0045382306 |
|    clip_fraction         | 0.0577       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 1.61         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.4         |
|    n_updates             | 1780         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.947        |
|    value_loss            | 44.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.59918326 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 992         |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.005534314 |
|    clip_fraction         | 0.0833      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 3.21        |
|    cost_values           | 1.57        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | 0.0009      |
|    std                   | 0.948       |
|    value_loss            | 32.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1296026  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1022        |
|    total_timesteps       | 370688      |
| train/                   |             |
|    approx_kl             | 0.007464138 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.03        |
|    cost_value_loss       | 2.86        |
|    cost_values           | 1.45        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59          |
|    n_updates             | 1800        |
|    policy_gradient_loss  | -0.00473    |
|    std                   | 0.948       |
|    value_loss            | 120         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.8457681    |
| rollout/                 |               |
|    ep_len_mean           | 974           |
|    ep_rew_mean           | -1.03e+03     |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 35            |
|    time_elapsed          | 1052          |
|    total_timesteps       | 372736        |
| train/                   |               |
|    approx_kl             | 0.00047822922 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.84          |
|    cost_value_loss       | 2.94          |
|    cost_values           | 1.36          |
|    entropy               | -2.73         |
|    entropy_loss          | -2.73         |
|    explained_variance    | -5.96e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 11.4          |
|    n_updates             | 1810          |
|    policy_gradient_loss  | -0.000346     |
|    std                   | 0.947         |
|    value_loss            | 24.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9745672   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1083         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0026472975 |
|    clip_fraction         | 0.00562      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 1.96         |
|    cost_values           | 1.16         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.944        |
|    value_loss            | 33.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.34234497  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1113         |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0030801902 |
|    clip_fraction         | 0.00596      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 1.27         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.1         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.943        |
|    value_loss            | 101          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.2399098   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 38           |
|    time_elapsed          | 1143         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0009747571 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 2.99         |
|    cost_values           | 1.02         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 3.58e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.000721    |
|    std                   | 0.943        |
|    value_loss            | 26.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.4263546   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 39           |
|    time_elapsed          | 1173         |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0047456054 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 3.45         |
|    cost_values           | 1.33         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.4         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.943        |
|    value_loss            | 68.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.84836507 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1204        |
|    total_timesteps       | 382976      |
| train/                   |             |
|    approx_kl             | 0.008838626 |
|    clip_fraction         | 0.0858      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.6         |
|    cost_value_loss       | 1.27        |
|    cost_values           | 1.55        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -9.54e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 1860        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.953       |
|    value_loss            | 28.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.47208655  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 41           |
|    time_elapsed          | 1234         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0039221216 |
|    clip_fraction         | 0.0686       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 2.5          |
|    cost_values           | 1.47         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.9         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | 0.00121      |
|    std                   | 0.954        |
|    value_loss            | 97.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0208398   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1264         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0075809015 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 3.48         |
|    cost_values           | 1.69         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.7         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.000594    |
|    std                   | 0.952        |
|    value_loss            | 59           |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.37        |
| reward                   | -0.24431396 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1295        |
|    total_timesteps       | 389120      |
| train/                   |             |
|    approx_kl             | 0.01133083  |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.7         |
|    cost_value_loss       | 3.68        |
|    cost_values           | 2.01        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 53.1        |
|    n_updates             | 1890        |
|    policy_gradient_loss  | 0.0146      |
|    std                   | 0.95        |
|    value_loss            | 89.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.09         |
| reward                   | -0.4078685   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1325         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0016391586 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 3.18         |
|    cost_values           | 1.63         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 80.5         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.95         |
|    value_loss            | 165          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.66243154 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1356        |
|    total_timesteps       | 393216      |
| train/                   |             |
|    approx_kl             | 0.004265226 |
|    clip_fraction         | 0.013       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.23        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.2        |
|    n_updates             | 1910        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.95        |
|    value_loss            | 69.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.6351783   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1386         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0026585865 |
|    clip_fraction         | 0.00327      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.07         |
|    cost_values           | 1.08         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 5.36e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.3         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.95         |
|    value_loss            | 32.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.56478345   |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -1.06e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 47            |
|    time_elapsed          | 1416          |
|    total_timesteps       | 397312        |
| train/                   |               |
|    approx_kl             | 0.00061566144 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.24          |
|    cost_value_loss       | 2.29          |
|    cost_values           | 0.992         |
|    entropy               | -2.74         |
|    entropy_loss          | -2.74         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 33.9          |
|    n_updates             | 1930          |
|    policy_gradient_loss  | -0.000451     |
|    std                   | 0.95          |
|    value_loss            | 71.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.70551085 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1447        |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.004922605 |
|    clip_fraction         | 0.0509      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 1.68        |
|    cost_values           | 1.13        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.74       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.9        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.949       |
|    value_loss            | 39.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.73487985  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1477         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0038143033 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 3.52         |
|    cost_values           | 1.24         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.949        |
|    value_loss            | 30.9         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.65       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.65       |
| reward             | -0.9295068 |
| rollout/           |            |
|    ep_len_mean     | 981        |
|    ep_rew_mean     | -1.05e+03  |
| time/              |            |
|    fps             | 100        |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 403456     |
-----------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.6944905   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0029891932 |
|    clip_fraction         | 0.00615      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 3.42         |
|    cost_values           | 1.15         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 1.73e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.949        |
|    value_loss            | 22.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6708073   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 80           |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0012582408 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 4.1          |
|    cost_values           | 1.03         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.1         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00051     |
|    std                   | 0.948        |
|    value_loss            | 121          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.9193966   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0028361708 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 3.12         |
|    cost_values           | 1.02         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -2.26e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.947        |
|    value_loss            | 29.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.5260278   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 141          |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0050255987 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 4.1          |
|    cost_values           | 1.14         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.947        |
|    value_loss            | 21.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.6332722   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0038926306 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 2.58         |
|    cost_values           | 1.33         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -2.5e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.5         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.943        |
|    value_loss            | 38.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.4051536   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -999         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 202          |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0039950507 |
|    clip_fraction         | 0.075        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 6.84         |
|    cost_values           | 1.4          |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -2.98e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | 0.00766      |
|    std                   | 0.941        |
|    value_loss            | 26.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8388492   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 8            |
|    time_elapsed          | 232          |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0022896046 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 3.13         |
|    cost_values           | 1.48         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.7         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.941        |
|    value_loss            | 72.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4243605   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -994         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 9            |
|    time_elapsed          | 263          |
|    total_timesteps       | 419840       |
| train/                   |              |
|    approx_kl             | 0.0051401453 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 3.69         |
|    cost_values           | 1.68         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -2.98e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.6         |
|    n_updates             | 2040         |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 0.939        |
|    value_loss            | 62.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 1.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.35         |
| reward                   | -0.53856856  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -998         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0027965708 |
|    clip_fraction         | 0.193        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 2.37         |
|    cost_values           | 1.93         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.3         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | 0.0101       |
|    std                   | 0.938        |
|    value_loss            | 35.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.37         |
| reward                   | -0.5992355   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -998         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0022077458 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.49         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33           |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.938        |
|    value_loss            | 70.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.6344306  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -995        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 353         |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.004525655 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 2.45        |
|    cost_values           | 1.37        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.5        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.938       |
|    value_loss            | 56          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.66345465  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -977         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0039852085 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.1          |
|    cost_values           | 1.52         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.937        |
|    value_loss            | 35.5         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8282843   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -967         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 414          |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0045912364 |
|    clip_fraction         | 0.119        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 1.8          |
|    cost_values           | 1.65         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 2090         |
|    policy_gradient_loss  | 0.00265      |
|    std                   | 0.937        |
|    value_loss            | 31.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.191563     |
| rollout/                 |               |
|    ep_len_mean           | 958           |
|    ep_rew_mean           | -964          |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 15            |
|    time_elapsed          | 444           |
|    total_timesteps       | 432128        |
| train/                   |               |
|    approx_kl             | 0.00094847794 |
|    clip_fraction         | 0.000293      |
|    clip_range            | 0.2           |
|    cost_returns          | 2.51          |
|    cost_value_loss       | 5.26          |
|    cost_values           | 1.36          |
|    entropy               | -2.71         |
|    entropy_loss          | -2.71         |
|    explained_variance    | 7.15e-07      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13            |
|    n_updates             | 2100          |
|    policy_gradient_loss  | -0.00106      |
|    std                   | 0.937         |
|    value_loss            | 25.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.5481378  |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -952        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.006669256 |
|    clip_fraction         | 0.079       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.82        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 1.47        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.71       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.5        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.00595    |
|    std                   | 0.935       |
|    value_loss            | 25.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.0096191   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -945         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 505          |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0027687284 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 5.18         |
|    cost_values           | 1.72         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.9         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.934        |
|    value_loss            | 118          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0504571   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -946         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 535          |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0033183966 |
|    clip_fraction         | 0.043        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 2.79         |
|    cost_values           | 1.76         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.3         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.934        |
|    value_loss            | 77.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.513       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.513       |
| reward                   | -0.555845   |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -946        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 566         |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.011081238 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 2.24        |
|    cost_values           | 1.96        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 2.38e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.9         |
|    n_updates             | 2140        |
|    policy_gradient_loss  | 0.00154     |
|    std                   | 0.929       |
|    value_loss            | 17.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.07        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.07        |
| reward                   | -0.5355616  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -943        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 596         |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.013772659 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 2.7         |
|    cost_values           | 1.8         |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | -1.07e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.02        |
|    n_updates             | 2150        |
|    policy_gradient_loss  | 0.00661     |
|    std                   | 0.929       |
|    value_loss            | 19.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.39         |
| reward                   | -0.5533371   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -947         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 627          |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0013882965 |
|    clip_fraction         | 0.00137      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 3.22         |
|    cost_values           | 1.54         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.000885    |
|    std                   | 0.93         |
|    value_loss            | 13.7         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.17         |
| reward                   | -0.29092064  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -935         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 657          |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0055675483 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 4.82         |
|    cost_values           | 1.56         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 6.56e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 0.929        |
|    value_loss            | 36.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -0.5182027  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -934        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 687         |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.004978796 |
|    clip_fraction         | 0.0197      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 2.64        |
|    cost_values           | 1.91        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | -2.03e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.6        |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.928       |
|    value_loss            | 34.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4357502  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -928        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 717         |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.002308032 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 2.46        |
|    cost_values           | 1.97        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.2        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.000621   |
|    std                   | 0.928       |
|    value_loss            | 40.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.52413803  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -919         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 748          |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0014497841 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 4.88         |
|    cost_values           | 1.79         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.2         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.928        |
|    value_loss            | 36.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1909424   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -915         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 778          |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0016885154 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 3.91         |
|    cost_values           | 1.58         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.9         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.928        |
|    value_loss            | 30.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.6680824   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -910         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 808          |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0033582204 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 4.73         |
|    cost_values           | 1.71         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.3         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.925        |
|    value_loss            | 38.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89644456  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 839          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0053178268 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 2            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.000575    |
|    std                   | 0.924        |
|    value_loss            | 26.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.4925369   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -914         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 869          |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0027634848 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 1.71         |
|    cost_values           | 2            |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.922        |
|    value_loss            | 38.7         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6073788  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -923        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 900         |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.004498066 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 2.05        |
|    cost_values           | 1.86        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | -1.19e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.8        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.921       |
|    value_loss            | 62.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1481342   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 31           |
|    time_elapsed          | 930          |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0019237432 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 1.13         |
|    cost_values           | 1.39         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.5         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.000952    |
|    std                   | 0.921        |
|    value_loss            | 48           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.7619324  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -930        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 960         |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.003563631 |
|    clip_fraction         | 0.00415     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 1.97        |
|    cost_values           | 1.04        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.9        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 0.922       |
|    value_loss            | 104         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.0590256  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -929        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 991         |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.007319849 |
|    clip_fraction         | 0.0418      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 2.3         |
|    cost_values           | 0.994       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | -1.31e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.3        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.922       |
|    value_loss            | 48.8        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -1.4295777  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -923        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.006286681 |
|    clip_fraction         | 0.0631      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 2.03        |
|    cost_values           | 1.07        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 5.96e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28          |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.924       |
|    value_loss            | 52.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.5407959   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 35           |
|    time_elapsed          | 1051         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0056793327 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 1.79         |
|    cost_values           | 1.29         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 0.92         |
|    value_loss            | 22.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -1.9428709   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1082         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0067002727 |
|    clip_fraction         | 0.236        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 1.92         |
|    cost_values           | 1.23         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.3         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | 0.0102       |
|    std                   | 0.918        |
|    value_loss            | 84.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -2.40507     |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -937         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1112         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0011104195 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 4.22         |
|    cost_values           | 0.995        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27           |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.000602    |
|    std                   | 0.918        |
|    value_loss            | 60.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -1.0959264   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -956         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 38           |
|    time_elapsed          | 1142         |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0026291406 |
|    clip_fraction         | 0.00532      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 3.09         |
|    cost_values           | 0.999        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.7         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.918        |
|    value_loss            | 103          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -2.0956507  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -951        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1173        |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.005332185 |
|    clip_fraction         | 0.0378      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 1.99        |
|    cost_values           | 1.03        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.2        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.918       |
|    value_loss            | 71.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -1.0765169  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -960        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1203        |
|    total_timesteps       | 483328      |
| train/                   |             |
|    approx_kl             | 0.008847176 |
|    clip_fraction         | 0.0476      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 2.4         |
|    cost_values           | 1.17        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.8        |
|    n_updates             | 2350        |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.916       |
|    value_loss            | 55.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.715        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.715        |
| reward                   | -0.3649315   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -951         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 41           |
|    time_elapsed          | 1233         |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0019588359 |
|    clip_fraction         | 0.103        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 3.76         |
|    cost_values           | 1.22         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.4         |
|    n_updates             | 2360         |
|    policy_gradient_loss  | 0.00541      |
|    std                   | 0.914        |
|    value_loss            | 40.5         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -2.3684418   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -934         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 42           |
|    time_elapsed          | 1263         |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0044887587 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 3.87         |
|    cost_values           | 1.33         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.3         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.914        |
|    value_loss            | 75.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3159585   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -943         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 43           |
|    time_elapsed          | 1294         |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0040207673 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 1.47         |
|    cost_values           | 1.57         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.8         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.913        |
|    value_loss            | 145          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.43         |
| reward                   | -0.46567369  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 44           |
|    time_elapsed          | 1324         |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0029448215 |
|    clip_fraction         | 0.00547      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 1.35         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.3         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.913        |
|    value_loss            | 43.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.34         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.34         |
| reward                   | -0.4381574   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -931         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 45           |
|    time_elapsed          | 1354         |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0032196753 |
|    clip_fraction         | 0.00566      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 3.55         |
|    cost_values           | 1.13         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.913        |
|    value_loss            | 26.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.5096374  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -938        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1384        |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.004739317 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 2.05        |
|    cost_values           | 1.02        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.913       |
|    value_loss            | 29.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.58279026 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -936        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1415        |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.004375878 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.13        |
|    cost_values           | 1           |
|    entropy               | -2.65       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.7        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.912       |
|    value_loss            | 33.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.59243244  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 48           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0012876913 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 6.4          |
|    cost_values           | 1.01         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.2         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.912        |
|    value_loss            | 50.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.9230707   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -944         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 49           |
|    time_elapsed          | 1475         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0029072461 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 3.12         |
|    cost_values           | 1            |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.92         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.912        |
|    value_loss            | 20.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.67456377 |
| rollout/           |             |
|    ep_len_mean     | 972         |
|    ep_rew_mean     | -953        |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 7.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.14         |
| reward                   | -1.0902432   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -957         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0058461395 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 3.18         |
|    cost_values           | 1.52         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 4.17e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.8         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.911        |
|    value_loss            | 53.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.58         |
| reward                   | -1.1103098   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -960         |
| time/                    |              |
|    fps                   | 76           |
|    iterations            | 3            |
|    time_elapsed          | 80           |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0025605361 |
|    clip_fraction         | 0.0548       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 4.22         |
|    cost_values           | 2.02         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.7         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.907        |
|    value_loss            | 43.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.4704529   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -953         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 110          |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0063517815 |
|    clip_fraction         | 0.0557       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.5          |
|    cost_value_loss       | 3.03         |
|    cost_values           | 2.31         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.3         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.909        |
|    value_loss            | 65.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9466485  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -968        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 5           |
|    time_elapsed          | 141         |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.008117992 |
|    clip_fraction         | 0.0868      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 3.7         |
|    cost_values           | 2.54        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 40.3        |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 0.909       |
|    value_loss            | 79.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.5789559  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -966        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 171         |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.006913232 |
|    clip_fraction         | 0.0925      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 2.61        |
|    cost_values           | 2.41        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 4.17e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 60.8        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | 0.000781    |
|    std                   | 0.909       |
|    value_loss            | 122         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.72013307 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -969        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.002321193 |
|    clip_fraction         | 0.00156     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 3.37        |
|    cost_values           | 1.96        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.909       |
|    value_loss            | 24.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -1.1316857  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -961        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 518144      |
| train/                   |             |
|    approx_kl             | 0.006942251 |
|    clip_fraction         | 0.0842      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 3.1         |
|    cost_values           | 2.05        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.4        |
|    n_updates             | 2520        |
|    policy_gradient_loss  | -0.00543    |
|    std                   | 0.905       |
|    value_loss            | 33.7        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8561332  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -955        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 262         |
|    total_timesteps       | 520192      |
| train/                   |             |
|    approx_kl             | 0.004401127 |
|    clip_fraction         | 0.0761      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 2.1         |
|    cost_values           | 1.94        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 2530        |
|    policy_gradient_loss  | -9.72e-05   |
|    std                   | 0.906       |
|    value_loss            | 21.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.3618185   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -956         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 292          |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0040199365 |
|    clip_fraction         | 0.0441       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 3.81         |
|    cost_values           | 1.98         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.908        |
|    value_loss            | 29.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.8065204   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -959         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0038559127 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.77         |
|    cost_value_loss       | 3.51         |
|    cost_values           | 2.23         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 2550         |
|    policy_gradient_loss  | 0.000207     |
|    std                   | 0.909        |
|    value_loss            | 28.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3649672   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -959         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 353          |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0028632744 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 2.28         |
|    cost_values           | 2.04         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 5.96e-08     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.8         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.909        |
|    value_loss            | 53.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 7.96       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.96       |
| reward                   | -1.2881181 |
| rollout/                 |            |
|    ep_len_mean           | 967        |
|    ep_rew_mean           | -962       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 13         |
|    time_elapsed          | 383        |
|    total_timesteps       | 528384     |
| train/                   |            |
|    approx_kl             | 0.00166659 |
|    clip_fraction         | 0.000684   |
|    clip_range            | 0.2        |
|    cost_returns          | 3.01       |
|    cost_value_loss       | 6.67       |
|    cost_values           | 1.78       |
|    entropy               | -2.65      |
|    entropy_loss          | -2.65      |
|    explained_variance    | -1.91e-06  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 22         |
|    n_updates             | 2570       |
|    policy_gradient_loss  | -0.000913  |
|    std                   | 0.909      |
|    value_loss            | 39.6       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4486759   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -958         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 413          |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0044952547 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 3.05         |
|    cost_values           | 1.95         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.8         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 0.909        |
|    value_loss            | 30.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.808547    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -970         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 15           |
|    time_elapsed          | 444          |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0050045857 |
|    clip_fraction         | 0.0623       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 2.17         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 1.01e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.24         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.000886    |
|    std                   | 0.908        |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.19         |
| reward                   | -1.158961    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -974         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 16           |
|    time_elapsed          | 474          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0047577624 |
|    clip_fraction         | 0.107        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 2.28         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 3.52e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.2         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.908        |
|    value_loss            | 104          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.5110098  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -972        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 505         |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.005800616 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 3.8         |
|    cost_values           | 2.39        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | -1.07e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.908       |
|    value_loss            | 19.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.01         |
| reward                   | -0.29649425  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -978         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 535          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0014606463 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.63         |
|    cost_value_loss       | 3.47         |
|    cost_values           | 2.1          |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 4.17e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.2         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.908        |
|    value_loss            | 71.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.65         |
| reward                   | -0.40444085  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -979         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 565          |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0006361886 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 3.92         |
|    cost_values           | 1.82         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 7.15e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.000583    |
|    std                   | 0.908        |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.03         |
| reward                   | -0.23906417  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -977         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 596          |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0013238713 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 8.1          |
|    cost_values           | 1.79         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.5         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.907        |
|    value_loss            | 39.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.27442732  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -978         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 626          |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0067924242 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 3.32         |
|    cost_values           | 1.96         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | -1.23e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.906        |
|    value_loss            | 25.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.5540863   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -973         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 656          |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0023804312 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 2.21         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | -3.81e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.7         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00072     |
|    std                   | 0.904        |
|    value_loss            | 48.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -0.96279156  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -980         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 686          |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0033658287 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 1.07         |
|    cost_values           | 1.88         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | -2.5e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.33         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.904        |
|    value_loss            | 19.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.54376405 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -984        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 717         |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.000559905 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 4.34        |
|    cost_values           | 1.48        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.2        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.000573   |
|    std                   | 0.903       |
|    value_loss            | 60.9        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.9537284  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -983        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 747         |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.003662698 |
|    clip_fraction         | 0.00698     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.95        |
|    cost_value_loss       | 3.72        |
|    cost_values           | 1.35        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00235    |
|    std                   | 0.903       |
|    value_loss            | 24.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.97260475  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -982         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 778          |
|    total_timesteps       | 555008       |
| train/                   |              |
|    approx_kl             | 0.0057676253 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 1.87         |
|    cost_values           | 1.49         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | -3.22e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 2700         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.903        |
|    value_loss            | 15.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.2532772   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -980         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 808          |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0067793406 |
|    clip_fraction         | 0.0667       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 5.13         |
|    cost_values           | 1.9          |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.0062      |
|    std                   | 0.898        |
|    value_loss            | 24.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2609233  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -978        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 839         |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.004874567 |
|    clip_fraction         | 0.0599      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 3.25        |
|    cost_values           | 2.3         |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -4.17e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 0.893       |
|    value_loss            | 23.6        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.45210937  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -974         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 869          |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0069606663 |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 2.41         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -2.5e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.891        |
|    value_loss            | 24.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.8605878  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -963        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 900         |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.005465911 |
|    clip_fraction         | 0.0506      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 3.25        |
|    cost_values           | 2.55        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 2.98e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.8        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.892       |
|    value_loss            | 52          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.8051147   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -958         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 31           |
|    time_elapsed          | 930          |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0046810657 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.06         |
|    cost_value_loss       | 2.21         |
|    cost_values           | 2.68         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.03         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | 9.88e-05     |
|    std                   | 0.891        |
|    value_loss            | 16.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.406708    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -961         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 960          |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0034243139 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 3.25         |
|    cost_values           | 2.41         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 4.77e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.6         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.892        |
|    value_loss            | 51.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.91840124  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -965         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 991          |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0017898617 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 4.01         |
|    cost_values           | 2.13         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 5.36e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.4         |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.000977    |
|    std                   | 0.892        |
|    value_loss            | 58.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.3405641   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -963         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 34           |
|    time_elapsed          | 1021         |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0034160106 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 2.84         |
|    cost_values           | 1.76         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.892        |
|    value_loss            | 32.5         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.92       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.92       |
| reward                   | -1.9208679 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -960       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 35         |
|    time_elapsed          | 1051       |
|    total_timesteps       | 573440     |
| train/                   |            |
|    approx_kl             | 0.00813576 |
|    clip_fraction         | 0.0336     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.68       |
|    cost_value_loss       | 1.62       |
|    cost_values           | 1.49       |
|    entropy               | -2.61      |
|    entropy_loss          | -2.61      |
|    explained_variance    | -3.58e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.7       |
|    n_updates             | 2790       |
|    policy_gradient_loss  | -0.00225   |
|    std                   | 0.892      |
|    value_loss            | 20.5       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.906639   |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -952        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.006133828 |
|    clip_fraction         | 0.0691      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 3.16        |
|    cost_values           | 1.44        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.4        |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.00563    |
|    std                   | 0.893       |
|    value_loss            | 55.5        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4298695   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -941         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1112         |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0013360138 |
|    clip_fraction         | 0.000488     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 4.6          |
|    cost_values           | 1.35         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 3.58e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.000569    |
|    std                   | 0.894        |
|    value_loss            | 51.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1378076  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -929        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1142        |
|    total_timesteps       | 579584      |
| train/                   |             |
|    approx_kl             | 0.004604133 |
|    clip_fraction         | 0.00986     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 1.24        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 2820        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.893       |
|    value_loss            | 22.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.2461562  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -937        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1172        |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.003342485 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 5.5         |
|    cost_values           | 1.4         |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.6        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.893       |
|    value_loss            | 62.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -2.0106747   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -942         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 40           |
|    time_elapsed          | 1202         |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0031296876 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 1.67         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 2.98e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.2         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.000921    |
|    std                   | 0.893        |
|    value_loss            | 113          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9012329  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -942        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1233        |
|    total_timesteps       | 585728      |
| train/                   |             |
|    approx_kl             | 0.004080959 |
|    clip_fraction         | 0.00771     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.82        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 1.3         |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 61.9        |
|    n_updates             | 2850        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.892       |
|    value_loss            | 133         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -1.3563292  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -938        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1263        |
|    total_timesteps       | 587776      |
| train/                   |             |
|    approx_kl             | 0.004628272 |
|    clip_fraction         | 0.0224      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 4.79        |
|    cost_values           | 1.49        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 6.56e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.7        |
|    n_updates             | 2860        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.89        |
|    value_loss            | 60.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.93028224 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -929        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1293        |
|    total_timesteps       | 589824      |
| train/                   |             |
|    approx_kl             | 0.005749132 |
|    clip_fraction         | 0.0701      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 2.01        |
|    cost_values           | 1.83        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 5.36e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 2870        |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 0.88        |
|    value_loss            | 20.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0424564  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -926        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1324        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.010518884 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 4.49        |
|    cost_values           | 1.73        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.9        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | 0.00769     |
|    std                   | 0.879       |
|    value_loss            | 69          |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 7.86       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.86       |
| reward                   | -1.7251511 |
| rollout/                 |            |
|    ep_len_mean           | 967        |
|    ep_rew_mean           | -930       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 45         |
|    time_elapsed          | 1354       |
|    total_timesteps       | 593920     |
| train/                   |            |
|    approx_kl             | 0.00589728 |
|    clip_fraction         | 0.0514     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.99       |
|    cost_value_loss       | 2.41       |
|    cost_values           | 1.84       |
|    entropy               | -2.57      |
|    entropy_loss          | -2.57      |
|    explained_variance    | -5.25e-06  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 20.7       |
|    n_updates             | 2890       |
|    policy_gradient_loss  | -0.00281   |
|    std                   | 0.874      |
|    value_loss            | 38.1       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.9626741   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -943         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 46           |
|    time_elapsed          | 1384         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0037906212 |
|    clip_fraction         | 0.0593       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 1.71         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -1.19e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.1         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.000224    |
|    std                   | 0.872        |
|    value_loss            | 72.8         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -1.3696821    |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -952          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 47            |
|    time_elapsed          | 1414          |
|    total_timesteps       | 598016        |
| train/                   |               |
|    approx_kl             | 0.00051764154 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.68          |
|    cost_value_loss       | 2.63          |
|    cost_values           | 1.31          |
|    entropy               | -2.56         |
|    entropy_loss          | -2.56         |
|    explained_variance    | -1.07e-06     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 63.6          |
|    n_updates             | 2910          |
|    policy_gradient_loss  | -0.000527     |
|    std                   | 0.872         |
|    value_loss            | 138           |
--------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.4631462  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -958        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1444        |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.004844287 |
|    clip_fraction         | 0.00977     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.534       |
|    cost_values           | 0.932       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | -1.67e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.7        |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 0.872       |
|    value_loss            | 58.9        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -2.2401567   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -974         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 49           |
|    time_elapsed          | 1475         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0012496716 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 3.27         |
|    cost_values           | 0.962        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -1.67e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81.6         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.872        |
|    value_loss            | 168          |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.9893008 |
| rollout/           |            |
|    ep_len_mean     | 967        |
|    ep_rew_mean     | -976       |
| time/              |            |
|    fps             | 100        |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 604160     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.199        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.199        |
| reward                   | -0.44526842  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -993         |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0033056168 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 2.45         |
|    cost_values           | 1.04         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.6         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.872        |
|    value_loss            | 49.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.77         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.77         |
| reward                   | -0.50209993  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -986         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 80           |
|    total_timesteps       | 608256       |
| train/                   |              |
|    approx_kl             | 0.0012262576 |
|    clip_fraction         | 0.00122      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 2.42         |
|    cost_values           | 1.04         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.7         |
|    n_updates             | 2960         |
|    policy_gradient_loss  | -0.000855    |
|    std                   | 0.871        |
|    value_loss            | 70           |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5234594   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -947         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0038775383 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 3.23         |
|    cost_values           | 1.1          |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.871        |
|    value_loss            | 26.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.99396664   |
| rollout/                 |               |
|    ep_len_mean           | 945           |
|    ep_rew_mean           | -945          |
| time/                    |               |
|    fps                   | 72            |
|    iterations            | 5             |
|    time_elapsed          | 141           |
|    total_timesteps       | 612352        |
| train/                   |               |
|    approx_kl             | 0.00032906607 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.69          |
|    cost_value_loss       | 6.26          |
|    cost_values           | 1.19          |
|    entropy               | -2.56         |
|    entropy_loss          | -2.56         |
|    explained_variance    | 0             |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 134           |
|    n_updates             | 2980          |
|    policy_gradient_loss  | -0.000525     |
|    std                   | 0.871         |
|    value_loss            | 277           |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.9540814    |
| rollout/                 |               |
|    ep_len_mean           | 945           |
|    ep_rew_mean           | -943          |
| time/                    |               |
|    fps                   | 71            |
|    iterations            | 6             |
|    time_elapsed          | 172           |
|    total_timesteps       | 614400        |
| train/                   |               |
|    approx_kl             | 0.00033307838 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.81          |
|    cost_value_loss       | 3.26          |
|    cost_values           | 1             |
|    entropy               | -2.56         |
|    entropy_loss          | -2.56         |
|    explained_variance    | -2.38e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 15.7          |
|    n_updates             | 2990          |
|    policy_gradient_loss  | -0.0006       |
|    std                   | 0.871         |
|    value_loss            | 35.5          |
--------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.7539352 |
| rollout/                 |            |
|    ep_len_mean           | 945        |
|    ep_rew_mean           | -942       |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 7          |
|    time_elapsed          | 202        |
|    total_timesteps       | 616448     |
| train/                   |            |
|    approx_kl             | 0.00649063 |
|    clip_fraction         | 0.0402     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.31       |
|    cost_value_loss       | 1.98       |
|    cost_values           | 1.02       |
|    entropy               | -2.56      |
|    entropy_loss          | -2.56      |
|    explained_variance    | -4.77e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 13         |
|    n_updates             | 3000       |
|    policy_gradient_loss  | -0.00418   |
|    std                   | 0.87       |
|    value_loss            | 27.7       |
-----------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7936534   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -930         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 8            |
|    time_elapsed          | 232          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0047925906 |
|    clip_fraction         | 0.0733       |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 4.94         |
|    cost_values           | 1.19         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | 8.31e-05     |
|    std                   | 0.869        |
|    value_loss            | 20.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.48043296 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -930        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 263         |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.004715572 |
|    clip_fraction         | 0.0129      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 2.71        |
|    cost_values           | 1.11        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.5        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.868       |
|    value_loss            | 65.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0955703   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -935         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0042834794 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 4.32         |
|    cost_values           | 1.03         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.93         |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.868        |
|    value_loss            | 17.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.3799554   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -930         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0039099744 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2.33         |
|    cost_values           | 0.994        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 1.19e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.5         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.868        |
|    value_loss            | 90.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.35268173  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 354          |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0026727542 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 3.59         |
|    cost_values           | 1.02         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.868        |
|    value_loss            | 38.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6286174   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -921         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0018269732 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 5.78         |
|    cost_values           | 1.1          |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.3         |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.000969    |
|    std                   | 0.868        |
|    value_loss            | 76.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.58072335 |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -921        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 14          |
|    time_elapsed          | 414         |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.016692264 |
|    clip_fraction         | 0.0769      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 3.18        |
|    cost_values           | 1.51        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.55       |
|    explained_variance    | -7.15e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00464    |
|    std                   | 0.862       |
|    value_loss            | 18.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8573363   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -928         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 15           |
|    time_elapsed          | 444          |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0052205753 |
|    clip_fraction         | 0.0755       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 2.13         |
|    cost_values           | 1.36         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.5         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.862        |
|    value_loss            | 78.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.896102    |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -928         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 475          |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0065841093 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 3.43         |
|    cost_values           | 1.18         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.54        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 0.86         |
|    value_loss            | 33.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.4470811   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -930         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 505          |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0065102987 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 3.45         |
|    cost_values           | 1.76         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.857        |
|    value_loss            | 30.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -1.4586087  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -933        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 535         |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.005553332 |
|    clip_fraction         | 0.0996      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.06        |
|    cost_value_loss       | 2.35        |
|    cost_values           | 1.85        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.2        |
|    n_updates             | 3110        |
|    policy_gradient_loss  | 0.00103     |
|    std                   | 0.857       |
|    value_loss            | 24.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.9332325   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 566          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0025498134 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 1.61         |
|    cost_values           | 1.82         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | 0.000859     |
|    std                   | 0.856        |
|    value_loss            | 34.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.6668435  |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -921        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 596         |
|    total_timesteps       | 643072      |
| train/                   |             |
|    approx_kl             | 0.005105518 |
|    clip_fraction         | 0.041       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.13        |
|    cost_value_loss       | 3.86        |
|    cost_values           | 1.72        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.8        |
|    n_updates             | 3130        |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 0.858       |
|    value_loss            | 36.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.48585156 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -909        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 626         |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.005049546 |
|    clip_fraction         | 0.06        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 4.05        |
|    cost_values           | 1.96        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 1.79e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 37          |
|    n_updates             | 3140        |
|    policy_gradient_loss  | 0.00131     |
|    std                   | 0.858       |
|    value_loss            | 74.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.3502474   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -904         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 657          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0005674875 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 5.7          |
|    cost_values           | 1.71         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.4         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.000703    |
|    std                   | 0.858        |
|    value_loss            | 79.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6300436   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -900         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 687          |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0006959095 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 4.82         |
|    cost_values           | 1.48         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.000662    |
|    std                   | 0.858        |
|    value_loss            | 25.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.43940797 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -894        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 718         |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.00443916  |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 2.93        |
|    cost_values           | 1.42        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.53       |
|    explained_variance    | -1.19e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 0.856       |
|    value_loss            | 19.6        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31175226  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 748          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0033191391 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 3.28         |
|    cost_values           | 1.42         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.64         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.856        |
|    value_loss            | 16.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.48670948  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 778          |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0027438342 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 3.96         |
|    cost_values           | 1.37         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.857        |
|    value_loss            | 26.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.6887966   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -883         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 808          |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0035098963 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 3.56         |
|    cost_values           | 1.59         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.59         |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.858        |
|    value_loss            | 17.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.79260564  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 839          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0022724688 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 2.51         |
|    cost_values           | 1.36         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.27         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.000833    |
|    std                   | 0.858        |
|    value_loss            | 16.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.0867834 |
| rollout/                 |            |
|    ep_len_mean           | 914        |
|    ep_rew_mean           | -870       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 29         |
|    time_elapsed          | 869        |
|    total_timesteps       | 661504     |
| train/                   |            |
|    approx_kl             | 0.00423882 |
|    clip_fraction         | 0.0398     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.96       |
|    cost_value_loss       | 4.14       |
|    cost_values           | 1.42       |
|    entropy               | -2.53      |
|    entropy_loss          | -2.53      |
|    explained_variance    | -7e-05     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.66       |
|    n_updates             | 3220       |
|    policy_gradient_loss  | -0.00321   |
|    std                   | 0.859      |
|    value_loss            | 17.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6464097   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -857         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 899          |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0128876455 |
|    clip_fraction         | 0.107        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 2            |
|    cost_values           | 1.99         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 4.17e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00552     |
|    std                   | 0.856        |
|    value_loss            | 19.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8519831  |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -855        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 930         |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.004909246 |
|    clip_fraction         | 0.0884      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 4.34        |
|    cost_values           | 2.23        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 5.96e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 48.3        |
|    n_updates             | 3240        |
|    policy_gradient_loss  | 0.0014      |
|    std                   | 0.853       |
|    value_loss            | 55.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.88666224  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -851         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 960          |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0056784498 |
|    clip_fraction         | 0.0492       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.45         |
|    cost_value_loss       | 4.15         |
|    cost_values           | 2.91         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 6.32e-06     |
|    lagrangian_multiplier | 0.0196       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.11         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.851        |
|    value_loss            | 25.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9559049   |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -852         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 991          |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0055422336 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 4.45         |
|    cost_values           | 2.95         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | -2.11e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.34         |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.851        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.55000144  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -850         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 34           |
|    time_elapsed          | 1021         |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0038003796 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.26         |
|    cost_value_loss       | 3.61         |
|    cost_values           | 2.9          |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.000104     |
|    lagrangian_multiplier | 0.00415      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.95         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.851        |
|    value_loss            | 33.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45955524  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 35           |
|    time_elapsed          | 1051         |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0030498926 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 4.94         |
|    cost_values           | 2.92         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | -1.12e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.5         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.85         |
|    value_loss            | 114          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.81078875 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -838        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.001502659 |
|    clip_fraction         | 0.00229     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.8         |
|    cost_value_loss       | 5.43        |
|    cost_values           | 2.98        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | -3.21e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.000422   |
|    std                   | 0.85        |
|    value_loss            | 21.1        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.7840057   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -842         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1112         |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0050560283 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 3.77         |
|    cost_values           | 2.92         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 1.09e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.93         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.85         |
|    value_loss            | 10.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.74571735 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -843        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1142        |
|    total_timesteps       | 679936      |
| train/                   |             |
|    approx_kl             | 0.00435152  |
|    clip_fraction         | 0.00767     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 3.47        |
|    cost_values           | 2.9         |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 9.48e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19          |
|    n_updates             | 3310        |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.85        |
|    value_loss            | 40.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.88687277  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -848         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 39           |
|    time_elapsed          | 1172         |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0019730814 |
|    clip_fraction         | 0.00396      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.89         |
|    cost_value_loss       | 2.4          |
|    cost_values           | 2.58         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | -1.56e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.4         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.85         |
|    value_loss            | 48.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.6300673   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 40           |
|    time_elapsed          | 1203         |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0010489294 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.86         |
|    cost_value_loss       | 6.2          |
|    cost_values           | 2.4          |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 2.52e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.35         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.000829    |
|    std                   | 0.849        |
|    value_loss            | 15.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3507684  |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -844        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1233        |
|    total_timesteps       | 686080      |
| train/                   |             |
|    approx_kl             | 0.011313591 |
|    clip_fraction         | 0.0713      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.89        |
|    cost_values           | 2.74        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | -2.26e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 3340        |
|    policy_gradient_loss  | -0.00521    |
|    std                   | 0.848       |
|    value_loss            | 31.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.8863612   |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 42           |
|    time_elapsed          | 1263         |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0030618098 |
|    clip_fraction         | 0.0427       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.5          |
|    cost_value_loss       | 4.51         |
|    cost_values           | 2.83         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.000541    |
|    std                   | 0.847        |
|    value_loss            | 49.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.0333571  |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -824        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1294        |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.002853568 |
|    clip_fraction         | 0.00947     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.39        |
|    cost_value_loss       | 4.57        |
|    cost_values           | 2.87        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 8.11e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.31        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.000965   |
|    std                   | 0.846       |
|    value_loss            | 11.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.91582936  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 44           |
|    time_elapsed          | 1324         |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0029329336 |
|    clip_fraction         | 0.00269      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.72         |
|    cost_value_loss       | 1.52         |
|    cost_values           | 2.77         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.846        |
|    value_loss            | 26.5         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0817554   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 45           |
|    time_elapsed          | 1354         |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0034175548 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 2.44         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 3.4e-06      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 0.843        |
|    value_loss            | 20.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.85954756  |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 46           |
|    time_elapsed          | 1385         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0066570826 |
|    clip_fraction         | 0.0568       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 3.5          |
|    cost_values           | 2.49         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 7.45e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.3         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | 0.00191      |
|    std                   | 0.841        |
|    value_loss            | 47           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.89654195  |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -777         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 47           |
|    time_elapsed          | 1415         |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0044399914 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 1.21         |
|    cost_values           | 2.22         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 1.61e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.839        |
|    value_loss            | 24.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -1.0077438  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -773        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1445        |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.004836877 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 2.96        |
|    cost_values           | 1.99        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 2.09e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.35        |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.839       |
|    value_loss            | 14.3        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1006476   |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -790         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 49           |
|    time_elapsed          | 1475         |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0045898063 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 1.73         |
|    cost_values           | 2.17         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 5.67e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.7          |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.837        |
|    value_loss            | 13           |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
-----------------------------------
| avg_speed          | 8.04       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.04       |
| reward             | -0.5864755 |
| rollout/           |            |
|    ep_len_mean     | 942        |
|    ep_rew_mean     | -800       |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 704512     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -1.0571992   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0027652548 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 2.92         |
|    cost_values           | 2.51         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | -5.01e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.95         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.837        |
|    value_loss            | 16.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.68959403  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 80           |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0075088767 |
|    clip_fraction         | 0.0487       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 2.49         |
|    cost_values           | 2.63         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.48        |
|    explained_variance    | -1.53e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.41         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.833        |
|    value_loss            | 11.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2430192   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0049012834 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 2.33         |
|    cost_values           | 2.64         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | 0.000445     |
|    std                   | 0.83         |
|    value_loss            | 23.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.013354   |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -810        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 5           |
|    time_elapsed          | 141         |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.003408839 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.75        |
|    cost_value_loss       | 1.67        |
|    cost_values           | 2.64        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 1.31e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.826       |
|    value_loss            | 14.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.25         |
| reward                   | -0.54025805  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0032964377 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 3.94         |
|    cost_values           | 2.49         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.2         |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.000294    |
|    std                   | 0.825        |
|    value_loss            | 56.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.16         |
| reward                   | -0.60463667  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 202          |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0029542707 |
|    clip_fraction         | 0.00488      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 2.26         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | -2.26e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.7         |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.826        |
|    value_loss            | 53.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.49        |
| reward                   | -1.2395955  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -806        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.004612808 |
|    clip_fraction         | 0.0346      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 2.71        |
|    cost_values           | 2.36        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 0.818       |
|    value_loss            | 21.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.45         |
| reward                   | -0.24608287  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -821         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 9            |
|    time_elapsed          | 262          |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0027445005 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 2.16         |
|    cost_values           | 2.31         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 2.38e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.4         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.816        |
|    value_loss            | 103          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.68         |
| reward                   | -0.56525636  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0010903535 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.71         |
|    cost_value_loss       | 4.45         |
|    cost_values           | 2.2          |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 1.31e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.2         |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00099     |
|    std                   | 0.816        |
|    value_loss            | 71.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.65125996  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0014781452 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 6.84         |
|    cost_values           | 1.93         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.97e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.816        |
|    value_loss            | 22.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.617123    |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 353          |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0005679744 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.49         |
|    cost_value_loss       | 8.65         |
|    cost_values           | 1.84         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 1.19e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.4         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.000389    |
|    std                   | 0.816        |
|    value_loss            | 55.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8197496   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0007050633 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 3.85         |
|    cost_values           | 1.79         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.000594    |
|    std                   | 0.816        |
|    value_loss            | 17.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.8948439   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -781         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 414          |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0045937328 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 4.64         |
|    cost_values           | 1.91         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.43e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.3         |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.816        |
|    value_loss            | 34.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.119503    |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 15           |
|    time_elapsed          | 444          |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0030985677 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.56         |
|    cost_value_loss       | 3.09         |
|    cost_values           | 2.19         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.816        |
|    value_loss            | 49.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.557138   |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -776        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.002720307 |
|    clip_fraction         | 0.00645     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.39        |
|    cost_value_loss       | 2.47        |
|    cost_values           | 1.89        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 8.94e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.7        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.816       |
|    value_loss            | 37.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.0520903   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 505          |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0040005436 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 3.35         |
|    cost_values           | 1.98         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.79e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.9         |
|    n_updates             | 3590         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.815        |
|    value_loss            | 30.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.803425   |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -788        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 535         |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.008159787 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 3.03        |
|    cost_values           | 2.36        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 7.15e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.813       |
|    value_loss            | 18.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.5926012   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -794         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 566          |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0053239055 |
|    clip_fraction         | 0.133        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 2.12         |
|    cost_values           | 2.36         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | 0.00208      |
|    std                   | 0.812        |
|    value_loss            | 41.8         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0140485  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -791        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 596         |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.004340362 |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.43        |
|    cost_value_loss       | 6.87        |
|    cost_values           | 2.12        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -3.34e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.4        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.811       |
|    value_loss            | 30.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9805414  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -794        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 626         |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.004394371 |
|    clip_fraction         | 0.0429      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 4.78        |
|    cost_values           | 2.21        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -4.77e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.811       |
|    value_loss            | 18          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2210339  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -794        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 657         |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.006990182 |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 3.97        |
|    cost_values           | 2.36        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 0.81        |
|    value_loss            | 23.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.5031562  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -799        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 687         |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.010291843 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 2.68        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -3.58e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 54.4        |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.811       |
|    value_loss            | 80.8        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -1.2565904   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 717          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0067033237 |
|    clip_fraction         | 0.14         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.78         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 2.67         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | -1.67e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.9         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | 0.00561      |
|    std                   | 0.811        |
|    value_loss            | 80.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1560538   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 748          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0036521582 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 2.27         |
|    cost_values           | 2.16         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 5.36e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.9         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.812        |
|    value_loss            | 59.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2725992   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -819         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 778          |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0042350274 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 3.2          |
|    cost_values           | 1.69         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 3.52e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.811        |
|    value_loss            | 52           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.4119899  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -820        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 808         |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.003581504 |
|    clip_fraction         | 0.0316      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 2.31        |
|    cost_values           | 1.44        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 7.15e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.812       |
|    value_loss            | 24          |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.138238   |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -830        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 838         |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.012553171 |
|    clip_fraction         | 0.0612      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 2.59        |
|    cost_values           | 1.6         |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 3.93e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.6        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.811       |
|    value_loss            | 27.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.74439937  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -811         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 869          |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0060138945 |
|    clip_fraction         | 0.183        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 1.27         |
|    cost_values           | 1.79         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 1.55e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 3710         |
|    policy_gradient_loss  | 0.00449      |
|    std                   | 0.81         |
|    value_loss            | 22.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.87848103  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 899          |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0043018106 |
|    clip_fraction         | 0.0695       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 4.36         |
|    cost_values           | 1.8          |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.9         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | 0.00248      |
|    std                   | 0.808        |
|    value_loss            | 145          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.7905692  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -807        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 929         |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.003981977 |
|    clip_fraction         | 0.0135      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.76        |
|    cost_value_loss       | 5.51        |
|    cost_values           | 1.87        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 1.19e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.24        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.809       |
|    value_loss            | 14.1        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.2648413  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -810        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 959         |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.004509622 |
|    clip_fraction         | 0.027       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 4.41        |
|    cost_values           | 2.01        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.808       |
|    value_loss            | 18.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5919441   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -816         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 990          |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0059890514 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 1.58         |
|    cost_values           | 2.1          |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 1.07e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.6         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.807        |
|    value_loss            | 37.9         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -1.1270639 |
| rollout/                 |            |
|    ep_len_mean           | 939        |
|    ep_rew_mean           | -812       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 34         |
|    time_elapsed          | 1020       |
|    total_timesteps       | 772096     |
| train/                   |            |
|    approx_kl             | 0.00621099 |
|    clip_fraction         | 0.0768     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.24       |
|    cost_value_loss       | 2.8        |
|    cost_values           | 2.07       |
|    entropy               | -2.4       |
|    entropy_loss          | -2.41      |
|    explained_variance    | 2.38e-06   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 17.1       |
|    n_updates             | 3760       |
|    policy_gradient_loss  | -0.00615   |
|    std                   | 0.806      |
|    value_loss            | 30.7       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6581787  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -809        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1050        |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.005744692 |
|    clip_fraction         | 0.0852      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.21        |
|    cost_value_loss       | 1.77        |
|    cost_values           | 2.05        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 1.31e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | 0.000244    |
|    std                   | 0.803       |
|    value_loss            | 20.8        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.92349976  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1081         |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0011554451 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 3.52         |
|    cost_values           | 2.06         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.8         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.000991    |
|    std                   | 0.803        |
|    value_loss            | 107          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.98706263 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -813        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1111        |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.002434288 |
|    clip_fraction         | 0.0128      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 4.24        |
|    cost_values           | 1.95        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 1.61e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.804       |
|    value_loss            | 21          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.97992504  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -812         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 38           |
|    time_elapsed          | 1141         |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0088343695 |
|    clip_fraction         | 0.0641       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.63         |
|    cost_value_loss       | 2.88         |
|    cost_values           | 2.5          |
|    entropy               | -2.39        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 1.31e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.799        |
|    value_loss            | 17.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.32758087  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 39           |
|    time_elapsed          | 1172         |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0052717193 |
|    clip_fraction         | 0.0489       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.69         |
|    cost_value_loss       | 2.6          |
|    cost_values           | 2.51         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | -5.01e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.82         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.796        |
|    value_loss            | 17.6         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.95867604 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -808        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 784384      |
| train/                   |             |
|    approx_kl             | 0.010912859 |
|    clip_fraction         | 0.0567      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 2.79        |
|    cost_values           | 2.89        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 7.15e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.1        |
|    n_updates             | 3820        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.791       |
|    value_loss            | 53.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.35894415 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -807        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1232        |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.004923451 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.75        |
|    cost_value_loss       | 1.45        |
|    cost_values           | 2.72        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 2.21e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.789       |
|    value_loss            | 24.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.89230645 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -809        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1263        |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.006123667 |
|    clip_fraction         | 0.0683      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 3.25        |
|    cost_values           | 2.58        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00637    |
|    std                   | 0.789       |
|    value_loss            | 29          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.544168    |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 43           |
|    time_elapsed          | 1293         |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0042111203 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.8          |
|    cost_value_loss       | 3.06         |
|    cost_values           | 2.45         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 4.77e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.5         |
|    n_updates             | 3850         |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.789        |
|    value_loss            | 52.5         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.83349067 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -792        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1323        |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.003116515 |
|    clip_fraction         | 0.0083      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 4.93        |
|    cost_values           | 2.24        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -4.77e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.2        |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.789       |
|    value_loss            | 48.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.008163   |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -787        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1354        |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.005445547 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 5.39        |
|    cost_values           | 2.44        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -5.72e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59.8        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00335    |
|    std                   | 0.789       |
|    value_loss            | 103         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.0987341   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 46           |
|    time_elapsed          | 1384         |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0054889675 |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 3.06         |
|    cost_values           | 2.75         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -1.9e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.11         |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.79         |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0536524   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 47           |
|    time_elapsed          | 1414         |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0031118416 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.86         |
|    cost_value_loss       | 7.05         |
|    cost_values           | 2.82         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -3.81e-06    |
|    lagrangian_multiplier | 0.00658      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.84         |
|    n_updates             | 3890         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.79         |
|    value_loss            | 23.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.104261    |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 48           |
|    time_elapsed          | 1445         |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0063270805 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 8.99         |
|    cost_values           | 2.99         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -1.99e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.1         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.789        |
|    value_loss            | 35.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.41617075 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -794        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1475        |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.002396788 |
|    clip_fraction         | 0.0111      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 4.74        |
|    cost_values           | 2.85        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 1.01e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.3        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.000826   |
|    std                   | 0.789       |
|    value_loss            | 61.3        |
------------------------------------------
----------------------------------
| avg_speed          | 7.93      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 7.93      |
| reward             | -1.057795 |
| rollout/           |           |
|    ep_len_mean     | 924       |
|    ep_rew_mean     | -785      |
| time/              |           |
|    fps             | 100       |
|    iterations      | 1         |
|    time_elapsed    | 20        |
|    total_timesteps | 804864    |
----------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -1.2043474  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 81          |
|    iterations            | 2           |
|    time_elapsed          | 50          |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.004483844 |
|    clip_fraction         | 0.00991     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.62        |
|    cost_value_loss       | 5.1         |
|    cost_values           | 2.99        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -7.99e-06   |
|    lagrangian_multiplier | 0.0003      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.02        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 0.788       |
|    value_loss            | 14.1        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.2035116   |
| rollout/                 |              |
|    ep_len_mean           | 915          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 76           |
|    iterations            | 3            |
|    time_elapsed          | 80           |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0063563157 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 2.08         |
|    cost_values           | 2.87         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.8         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 0.787        |
|    value_loss            | 52.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.3569171   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -780         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0050554443 |
|    clip_fraction         | 0.0468       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 2.53         |
|    cost_values           | 2.67         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.1         |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.786        |
|    value_loss            | 38.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3393718  |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -779        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 5           |
|    time_elapsed          | 141         |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.015374222 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.65        |
|    cost_value_loss       | 2.53        |
|    cost_values           | 2.58        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.87        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | 0.00264     |
|    std                   | 0.786       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9069836   |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0048512598 |
|    clip_fraction         | 0.118        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 3.18         |
|    cost_values           | 2.62         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 4.17e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 3970         |
|    policy_gradient_loss  | -0.000524    |
|    std                   | 0.784        |
|    value_loss            | 27.4         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.3413569   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 7            |
|    time_elapsed          | 201          |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0054538324 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.93         |
|    cost_value_loss       | 3.15         |
|    cost_values           | 2.72         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.35        |
|    explained_variance    | -4.17e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.36         |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.783        |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.74337286 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -777        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 231         |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.004005221 |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 2.86        |
|    cost_values           | 2.83        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -2.03e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.7        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.000675   |
|    std                   | 0.783       |
|    value_loss            | 52.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.87827617 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 262         |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.005569674 |
|    clip_fraction         | 0.0806      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.71        |
|    cost_value_loss       | 5.7         |
|    cost_values           | 2.98        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -1.23e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.42        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 0.782       |
|    value_loss            | 13.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.72240144 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -782        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 10          |
|    time_elapsed          | 292         |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.00632973  |
|    clip_fraction         | 0.0398      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 2.55        |
|    cost_values           | 2.98        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -1.55e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.782       |
|    value_loss            | 8.41        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0573777  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -782        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 322         |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.006712592 |
|    clip_fraction         | 0.0474      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 1.49        |
|    cost_values           | 2.87        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | -2.15e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.78        |
|    value_loss            | 6.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -1.1469368   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 352          |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0051543848 |
|    clip_fraction         | 0.0674       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.75         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 2.76         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.33        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.774        |
|    value_loss            | 7.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.69911355 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -774        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 383         |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.008107083 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 2.89        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -8.11e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.9        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.772       |
|    value_loss            | 43.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -1.037411   |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -757        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 14          |
|    time_elapsed          | 413         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.005698071 |
|    clip_fraction         | 0.0686      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 3.82        |
|    cost_values           | 2.97        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -6.44e-06   |
|    lagrangian_multiplier | 0.00426     |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.771       |
|    value_loss            | 22.6        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.4289527  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -759        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 15          |
|    time_elapsed          | 443         |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.003762221 |
|    clip_fraction         | 0.0404      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 1.78        |
|    cost_values           | 2.84        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.8        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.771       |
|    value_loss            | 51.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0355015  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -762        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 16          |
|    time_elapsed          | 474         |
|    total_timesteps       | 835584      |
| train/                   |             |
|    approx_kl             | 0.002610486 |
|    clip_fraction         | 0.0111      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.87        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0.00447     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.86        |
|    n_updates             | 4070        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.771       |
|    value_loss            | 27.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.199707    |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -760         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 504          |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0020315545 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 6.89         |
|    cost_values           | 3            |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0.00598      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.77         |
|    value_loss            | 38.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.3848079   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -767         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 534          |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0047059325 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 2.15         |
|    cost_values           | 2.88         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 7.75e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.769        |
|    value_loss            | 14.2         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.42072502  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 565          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0047982284 |
|    clip_fraction         | 0.149        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.56         |
|    cost_value_loss       | 4.13         |
|    cost_values           | 2.98         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.31        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0.00387      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | 0.0022       |
|    std                   | 0.767        |
|    value_loss            | 45.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -1.2061012  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -749        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 595         |
|    total_timesteps       | 843776      |
| train/                   |             |
|    approx_kl             | 0.005095474 |
|    clip_fraction         | 0.0158      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 4.1         |
|    cost_values           | 2.91        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | -2.15e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.44        |
|    n_updates             | 4110        |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.767       |
|    value_loss            | 14.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -1.315299   |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -740        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 625         |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.004219368 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 1.46        |
|    cost_values           | 2.73        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 6.56e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.767       |
|    value_loss            | 29.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.392       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.392       |
| reward                   | -0.550183   |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -740        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 655         |
|    total_timesteps       | 847872      |
| train/                   |             |
|    approx_kl             | 0.009248731 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 2.25        |
|    cost_values           | 2.56        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.9        |
|    n_updates             | 4130        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.764       |
|    value_loss            | 20.5        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6531656  |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 686         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.005424183 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 3.2         |
|    cost_values           | 2.54        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 5.36e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 4140        |
|    policy_gradient_loss  | 0.0065      |
|    std                   | 0.765       |
|    value_loss            | 19.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.315       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.315       |
| reward                   | -0.32538924 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 716         |
|    total_timesteps       | 851968      |
| train/                   |             |
|    approx_kl             | 0.003389303 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.58        |
|    cost_value_loss       | 5.86        |
|    cost_values           | 2.63        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.2        |
|    n_updates             | 4150        |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.764       |
|    value_loss            | 49.6        |
------------------------------------------
--------------------------------------------
| avg_speed                | 5.44          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 5.44          |
| reward                   | -0.46208835   |
| rollout/                 |               |
|    ep_len_mean           | 927           |
|    ep_rew_mean           | -737          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 25            |
|    time_elapsed          | 747           |
|    total_timesteps       | 854016        |
| train/                   |               |
|    approx_kl             | 0.00085671025 |
|    clip_fraction         | 0.000146      |
|    clip_range            | 0.2           |
|    cost_returns          | 3.78          |
|    cost_value_loss       | 7.36          |
|    cost_values           | 2.57          |
|    entropy               | -2.3          |
|    entropy_loss          | -2.3          |
|    explained_variance    | -2.38e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.94          |
|    n_updates             | 4160          |
|    policy_gradient_loss  | -0.000795     |
|    std                   | 0.764         |
|    value_loss            | 16            |
--------------------------------------------
--------------------------------------------
| avg_speed                | 7.95          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.95          |
| reward                   | -0.48921216   |
| rollout/                 |               |
|    ep_len_mean           | 934           |
|    ep_rew_mean           | -750          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 26            |
|    time_elapsed          | 777           |
|    total_timesteps       | 856064        |
| train/                   |               |
|    approx_kl             | 0.00091548107 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.72          |
|    cost_value_loss       | 1.98          |
|    cost_values           | 2.49          |
|    entropy               | -2.3          |
|    entropy_loss          | -2.3          |
|    explained_variance    | -4.77e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21            |
|    n_updates             | 4170          |
|    policy_gradient_loss  | -0.000816     |
|    std                   | 0.764         |
|    value_loss            | 43.6          |
--------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.52448696  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 807          |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0037974585 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 1.94         |
|    cost_values           | 2.09         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.1         |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.764        |
|    value_loss            | 38.6         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.9471548 |
| rollout/                 |            |
|    ep_len_mean           | 916        |
|    ep_rew_mean           | -733       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 28         |
|    time_elapsed          | 838        |
|    total_timesteps       | 860160     |
| train/                   |            |
|    approx_kl             | 0.01383464 |
|    clip_fraction         | 0.0939     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.11       |
|    cost_value_loss       | 2.26       |
|    cost_values           | 1.98       |
|    entropy               | -2.3       |
|    entropy_loss          | -2.3       |
|    explained_variance    | -4.77e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.88       |
|    n_updates             | 4190       |
|    policy_gradient_loss  | -0.00203   |
|    std                   | 0.767      |
|    value_loss            | 12.1       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1647958   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 868          |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0067115077 |
|    clip_fraction         | 0.315        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 4.8          |
|    cost_values           | 2.06         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.9         |
|    n_updates             | 4200         |
|    policy_gradient_loss  | 0.0146       |
|    std                   | 0.768        |
|    value_loss            | 75.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0127689   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 898          |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0052828807 |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 3.62         |
|    cost_values           | 1.95         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.3         |
|    n_updates             | 4210         |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 0.768        |
|    value_loss            | 50.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0340478   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 31           |
|    time_elapsed          | 929          |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0032020097 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 3.69         |
|    cost_values           | 1.73         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.768        |
|    value_loss            | 44.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0143416  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -716        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 959         |
|    total_timesteps       | 868352      |
| train/                   |             |
|    approx_kl             | 0.009886697 |
|    clip_fraction         | 0.0689      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 3.22        |
|    cost_values           | 1.91        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.3        |
|    n_updates             | 4230        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.766       |
|    value_loss            | 43.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.6892667  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -717        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 989         |
|    total_timesteps       | 870400      |
| train/                   |             |
|    approx_kl             | 0.005780885 |
|    clip_fraction         | 0.0719      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.7         |
|    cost_value_loss       | 4.08        |
|    cost_values           | 2.12        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 4.17e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.2        |
|    n_updates             | 4240        |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 0.765       |
|    value_loss            | 38.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3915162   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 34           |
|    time_elapsed          | 1019         |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0008228892 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 0.394        |
|    cost_values           | 1.9          |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.7         |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.000764    |
|    std                   | 0.765        |
|    value_loss            | 58.5         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.26290593 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1050        |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.00264276  |
|    clip_fraction         | 0.00786     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 1.71        |
|    cost_values           | 1.39        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.2        |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.765       |
|    value_loss            | 31.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.21        |
| reward                   | -0.48794022 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 876544      |
| train/                   |             |
|    approx_kl             | 0.00578788  |
|    clip_fraction         | 0.0325      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 3.18        |
|    cost_values           | 1.41        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 4.17e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 4270        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.767       |
|    value_loss            | 18.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.37985235 |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1110        |
|    total_timesteps       | 878592      |
| train/                   |             |
|    approx_kl             | 0.005581213 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 2.22        |
|    cost_values           | 1.8         |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 2.38e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.98        |
|    n_updates             | 4280        |
|    policy_gradient_loss  | 0.00296     |
|    std                   | 0.767       |
|    value_loss            | 20          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.07         |
| reward                   | -0.49051353  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 38           |
|    time_elapsed          | 1140         |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0054289997 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 5.25         |
|    cost_values           | 2.09         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.31        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.56         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00471     |
|    std                   | 0.767        |
|    value_loss            | 8.22         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.74097294  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -745         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 39           |
|    time_elapsed          | 1170         |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0029525165 |
|    clip_fraction         | 0.0545       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 1.19         |
|    cost_values           | 2.53         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 1.79e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.766        |
|    value_loss            | 23.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52358353  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 40           |
|    time_elapsed          | 1200         |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0027265293 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 2.73         |
|    cost_values           | 2.06         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.5         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.766        |
|    value_loss            | 71.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8888213   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 41           |
|    time_elapsed          | 1231         |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0033510383 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 4.12         |
|    cost_values           | 1.8          |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.766        |
|    value_loss            | 29           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.7657522  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -750        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1262        |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.002624035 |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 5.13        |
|    cost_values           | 2.14        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 2.98e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.5        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.765       |
|    value_loss            | 75.6        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.37666118 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1292        |
|    total_timesteps       | 890880      |
| train/                   |             |
|    approx_kl             | 0.004041199 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 2.66        |
|    cost_values           | 2.54        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 2.68e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.3        |
|    n_updates             | 4340        |
|    policy_gradient_loss  | -0.00451    |
|    std                   | 0.764       |
|    value_loss            | 58.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.67        |
| reward                   | -0.5266704  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -747        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1322        |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.004364932 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 3.87        |
|    cost_values           | 2.73        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.00029     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.765       |
|    value_loss            | 22.3        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.91       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.91       |
| reward                   | -0.5068669 |
| rollout/                 |            |
|    ep_len_mean           | 917        |
|    ep_rew_mean           | -750       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 45         |
|    time_elapsed          | 1353       |
|    total_timesteps       | 894976     |
| train/                   |            |
|    approx_kl             | 0.00807897 |
|    clip_fraction         | 0.0516     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.85       |
|    cost_value_loss       | 2.23       |
|    cost_values           | 2.75       |
|    entropy               | -2.29      |
|    entropy_loss          | -2.29      |
|    explained_variance    | -1.19e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 13.1       |
|    n_updates             | 4360       |
|    policy_gradient_loss  | -0.00258   |
|    std                   | 0.759      |
|    value_loss            | 23.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5030244   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 46           |
|    time_elapsed          | 1383         |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0051371153 |
|    clip_fraction         | 0.258        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 2.11         |
|    cost_values           | 2.77         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 3.58e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.75         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | 0.0204       |
|    std                   | 0.757        |
|    value_loss            | 17.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5237798   |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 47           |
|    time_elapsed          | 1414         |
|    total_timesteps       | 899072       |
| train/                   |              |
|    approx_kl             | 0.0055262363 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 4.67         |
|    cost_values           | 2.88         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 4380         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.757        |
|    value_loss            | 33.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1538987   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 48           |
|    time_elapsed          | 1444         |
|    total_timesteps       | 901120       |
| train/                   |              |
|    approx_kl             | 0.0025669546 |
|    clip_fraction         | 0.00337      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 5.33         |
|    cost_values           | 2.93         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 4390         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.757        |
|    value_loss            | 48.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6139782   |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -722         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 49           |
|    time_elapsed          | 1474         |
|    total_timesteps       | 903168       |
| train/                   |              |
|    approx_kl             | 0.0046434468 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 6.59         |
|    cost_values           | 2.85         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0.0063       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.34         |
|    n_updates             | 4400         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.756        |
|    value_loss            | 50           |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
-----------------------------------
| avg_speed          | 7.87       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.87       |
| reward             | -1.0588481 |
| rollout/           |            |
|    ep_len_mean     | 897        |
|    ep_rew_mean     | -724       |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 905216     |
-----------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.756102    |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0066017946 |
|    clip_fraction         | 0.0558       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 3.86         |
|    cost_values           | 2.95         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 1.39e-05     |
|    lagrangian_multiplier | 0.00254      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.09         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 0.756        |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5154425   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -732         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0034565516 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.52         |
|    cost_value_loss       | 8.58         |
|    cost_values           | 2.99         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 6.56e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.756        |
|    value_loss            | 20.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.1255443   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -734         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 111          |
|    total_timesteps       | 911360       |
| train/                   |              |
|    approx_kl             | 0.0034185015 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 3.29         |
|    cost_values           | 2.88         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 1.13e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 4440         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.756        |
|    value_loss            | 38.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6483827   |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 142          |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0035765646 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 3.38         |
|    cost_values           | 2.73         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 6.56e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.754        |
|    value_loss            | 35           |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.59922916 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 915456      |
| train/                   |             |
|    approx_kl             | 0.008451435 |
|    clip_fraction         | 0.0497      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 3.43        |
|    cost_values           | 2.93        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 1.85e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.9        |
|    n_updates             | 4460        |
|    policy_gradient_loss  | -0.0037     |
|    std                   | 0.75        |
|    value_loss            | 29          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0569326  |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.005632202 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 2.54        |
|    cost_values           | 2.98        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 3.91e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.00376    |
|    std                   | 0.749       |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.87        |
| reward                   | -0.41600984 |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -739        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.007842261 |
|    clip_fraction         | 0.0719      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 3.1         |
|    cost_values           | 2.95        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.000158    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.4        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.000126   |
|    std                   | 0.749       |
|    value_loss            | 34.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.3865103  |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 263         |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.004200994 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 2.89        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.000361    |
|    lagrangian_multiplier | 0.0106      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.73        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.75        |
|    value_loss            | 54.6        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6180374   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0024570897 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 2.59         |
|    cost_values           | 2.95         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.00064      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.3         |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.75         |
|    value_loss            | 66.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.42611492  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0032827465 |
|    clip_fraction         | 0.0886       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.47         |
|    cost_value_loss       | 9.1          |
|    cost_values           | 3            |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.000231     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | 0.00114      |
|    std                   | 0.75         |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.51087695  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 354          |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0044196444 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.74         |
|    cost_value_loss       | 6.67         |
|    cost_values           | 2.99         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.000194     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.75         |
|    value_loss            | 21.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.6936088  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -742        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 384         |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.004205052 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 7.07        |
|    cost_values           | 2.9         |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | -0.000286   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00216    |
|    std                   | 0.75        |
|    value_loss            | 5.79        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.53071034 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -739        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 14          |
|    time_elapsed          | 414         |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.004965887 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.52        |
|    cost_value_loss       | 5.35        |
|    cost_values           | 2.99        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | -0.000221   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.73        |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 0.749       |
|    value_loss            | 7.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.4364051   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 445          |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0046270783 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.83         |
|    cost_value_loss       | 5.57         |
|    cost_values           | 2.95         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | -0.000173    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.63         |
|    n_updates             | 4550         |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.749        |
|    value_loss            | 8.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8205352   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 475          |
|    total_timesteps       | 935936       |
| train/                   |              |
|    approx_kl             | 0.0032395252 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.12         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 2.88         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.000837     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34           |
|    n_updates             | 4560         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.749        |
|    value_loss            | 79.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.75765216 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -739        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 505         |
|    total_timesteps       | 937984      |
| train/                   |             |
|    approx_kl             | 0.005420124 |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 2.98        |
|    cost_values           | 2.71        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | -1.31e-06   |
|    lagrangian_multiplier | 0.0696      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.5         |
|    n_updates             | 4570        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.749       |
|    value_loss            | 70.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.8611107   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 536          |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0049938946 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 3.16         |
|    cost_values           | 2.32         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.0911       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.73         |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 0.749        |
|    value_loss            | 19.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0633037   |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -748         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 566          |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0052230493 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 3.18         |
|    cost_values           | 1.58         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.00221      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.29         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.00395     |
|    std                   | 0.749        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.0029912  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 596         |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.005186946 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 5.28        |
|    cost_values           | 1.68        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.0273      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.22        |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.748       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.7534289  |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -748        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 627         |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.005023785 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.06        |
|    cost_value_loss       | 2.93        |
|    cost_values           | 1.68        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.47        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.747       |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.46         |
| reward                   | -0.7675559   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 657          |
|    total_timesteps       | 948224       |
| train/                   |              |
|    approx_kl             | 0.0042927437 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 6.39         |
|    cost_values           | 1.51         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.816        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.34         |
|    n_updates             | 4620         |
|    policy_gradient_loss  | -0.00464     |
|    std                   | 0.747        |
|    value_loss            | 11.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8358207   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 687          |
|    total_timesteps       | 950272       |
| train/                   |              |
|    approx_kl             | 0.0024729415 |
|    clip_fraction         | 0.00474      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.67         |
|    cost_value_loss       | 8.29         |
|    cost_values           | 2.12         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.0302       |
|    lagrangian_multiplier | 0.000852     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.33         |
|    n_updates             | 4630         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.746        |
|    value_loss            | 28.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49233347  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 718          |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0018491939 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 5.19         |
|    cost_values           | 2.1          |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.76         |
|    lagrangian_multiplier | 0.000214     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.78         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.746        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.95283794  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 748          |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0030415542 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.27         |
|    cost_value_loss       | 7.64         |
|    cost_values           | 1.97         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.326        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.89         |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.746        |
|    value_loss            | 12.3         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.87138   |
| rollout/                 |            |
|    ep_len_mean           | 932        |
|    ep_rew_mean           | -738       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 26         |
|    time_elapsed          | 778        |
|    total_timesteps       | 956416     |
| train/                   |            |
|    approx_kl             | 0.00476983 |
|    clip_fraction         | 0.0213     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.23       |
|    cost_value_loss       | 6.72       |
|    cost_values           | 1.78       |
|    entropy               | -2.25      |
|    entropy_loss          | -2.25      |
|    explained_variance    | 0.719      |
|    lagrangian_multiplier | 0.000591   |
|    learning_rate         | 0.0003     |
|    loss                  | 5.64       |
|    n_updates             | 4660       |
|    policy_gradient_loss  | -0.00309   |
|    std                   | 0.745      |
|    value_loss            | 7.3        |
-----------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 6.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.35        |
| reward                   | -0.3114057  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -750        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 809         |
|    total_timesteps       | 958464      |
| train/                   |             |
|    approx_kl             | 0.005391334 |
|    clip_fraction         | 0.0184      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 5.57        |
|    cost_values           | 1.7         |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0.00425     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.85        |
|    n_updates             | 4670        |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.745       |
|    value_loss            | 5.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4254725   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 839          |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0030751764 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 1.27         |
|    cost_values           | 1.29         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.621        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.71         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.744        |
|    value_loss            | 7.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.56097615 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -751        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 869         |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.003787415 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 3.93        |
|    cost_values           | 1.01        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.76        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.744       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.5425729   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -752         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 900          |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0073723774 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 3.09         |
|    cost_values           | 1            |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.331        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.72         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00555     |
|    std                   | 0.745        |
|    value_loss            | 3.51         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 8.02          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.02          |
| reward                   | -0.5960045    |
| rollout/                 |               |
|    ep_len_mean           | 949           |
|    ep_rew_mean           | -745          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 31            |
|    time_elapsed          | 931           |
|    total_timesteps       | 966656        |
| train/                   |               |
|    approx_kl             | 0.00030918556 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.5           |
|    cost_value_loss       | 3.9           |
|    cost_values           | 0.861         |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | 0.657         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 41.3          |
|    n_updates             | 4710          |
|    policy_gradient_loss  | 2.45e-05      |
|    std                   | 0.745         |
|    value_loss            | 160           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.6039334   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 961          |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0074146166 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 3.04         |
|    cost_values           | 0.88         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.23         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 0.744        |
|    value_loss            | 7.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.45894018  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 992          |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0047741486 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 3.8          |
|    cost_values           | 0.963        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.699        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.745        |
|    value_loss            | 33.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5715099  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -719        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1022        |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.004295094 |
|    clip_fraction         | 0.00801     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.61        |
|    cost_value_loss       | 7.87        |
|    cost_values           | 1.02        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.637       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.745       |
|    value_loss            | 4.63        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.75565547 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1053        |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.004233701 |
|    clip_fraction         | 0.0155      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 6.31        |
|    cost_values           | 0.973       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.63        |
|    n_updates             | 4750        |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 0.745       |
|    value_loss            | 3.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7939859   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1083         |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0048383996 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 7.07         |
|    cost_values           | 0.965        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.835        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.745        |
|    value_loss            | 4.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1302689   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1113         |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0004831897 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 6.89         |
|    cost_values           | 0.898        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 4770         |
|    policy_gradient_loss  | -0.000781    |
|    std                   | 0.745        |
|    value_loss            | 30           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.97          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.97          |
| reward                   | -0.9462889    |
| rollout/                 |               |
|    ep_len_mean           | 937           |
|    ep_rew_mean           | -713          |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 38            |
|    time_elapsed          | 1144          |
|    total_timesteps       | 980992        |
| train/                   |               |
|    approx_kl             | 0.00088296103 |
|    clip_fraction         | 0.000342      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.14          |
|    cost_value_loss       | 2.16          |
|    cost_values           | 0.856         |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | 0.851         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 10.2          |
|    n_updates             | 4780          |
|    policy_gradient_loss  | -0.00126      |
|    std                   | 0.745         |
|    value_loss            | 22.8          |
--------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.9641561    |
| rollout/                 |               |
|    ep_len_mean           | 937           |
|    ep_rew_mean           | -710          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 39            |
|    time_elapsed          | 1174          |
|    total_timesteps       | 983040        |
| train/                   |               |
|    approx_kl             | 6.1045255e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.44          |
|    cost_value_loss       | 3.43          |
|    cost_values           | 0.88          |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | 0.825         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.12          |
|    n_updates             | 4790          |
|    policy_gradient_loss  | -9.86e-05     |
|    std                   | 0.745         |
|    value_loss            | 28.8          |
--------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -0.7721538    |
| rollout/                 |               |
|    ep_len_mean           | 937           |
|    ep_rew_mean           | -714          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 40            |
|    time_elapsed          | 1204          |
|    total_timesteps       | 985088        |
| train/                   |               |
|    approx_kl             | 5.5838667e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.63          |
|    cost_value_loss       | 4.42          |
|    cost_values           | 0.854         |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | 0.871         |
|    lagrangian_multiplier | 0.00227       |
|    learning_rate         | 0.0003        |
|    loss                  | 5.63          |
|    n_updates             | 4800          |
|    policy_gradient_loss  | -0.000284     |
|    std                   | 0.745         |
|    value_loss            | 32.2          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.6022015   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1234         |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 0.0032737819 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.93         |
|    cost_values           | 0.856        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.52         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.745        |
|    value_loss            | 15.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.55685484  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1265         |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0050491206 |
|    clip_fraction         | 0.0591       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 4.95         |
|    cost_values           | 0.942        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00626     |
|    std                   | 0.745        |
|    value_loss            | 4.05         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.9676362  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1295        |
|    total_timesteps       | 991232      |
| train/                   |             |
|    approx_kl             | 0.003954169 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.05        |
|    cost_value_loss       | 5.81        |
|    cost_values           | 0.986       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.48        |
|    n_updates             | 4830        |
|    policy_gradient_loss  | -0.00506    |
|    std                   | 0.744       |
|    value_loss            | 9.61        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.9623142 |
| rollout/                 |            |
|    ep_len_mean           | 934        |
|    ep_rew_mean           | -711       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 44         |
|    time_elapsed          | 1325       |
|    total_timesteps       | 993280     |
| train/                   |            |
|    approx_kl             | 0.00678761 |
|    clip_fraction         | 0.0467     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.65       |
|    cost_value_loss       | 3.36       |
|    cost_values           | 0.857      |
|    entropy               | -2.25      |
|    entropy_loss          | -2.25      |
|    explained_variance    | 0.884      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 4.78       |
|    n_updates             | 4840       |
|    policy_gradient_loss  | -0.00624   |
|    std                   | 0.744      |
|    value_loss            | 14.9       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8154048   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -720         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1355         |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0059284256 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.17         |
|    cost_values           | 0.845        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.875        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.63         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.744        |
|    value_loss            | 19.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6111248  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -722        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1386        |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.004497733 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 3.34        |
|    cost_values           | 0.922       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.744       |
|    value_loss            | 9.19        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.9496956   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1416         |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0055942386 |
|    clip_fraction         | 0.0658       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.31         |
|    cost_values           | 0.946        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.825        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.71         |
|    n_updates             | 4870         |
|    policy_gradient_loss  | -0.00664     |
|    std                   | 0.744        |
|    value_loss            | 4.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9887224  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1446        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.006891316 |
|    clip_fraction         | 0.048       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 3.74        |
|    cost_values           | 0.905       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.84        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00575    |
|    std                   | 0.744       |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -0.642787    |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1477         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0041822474 |
|    clip_fraction         | 0.0336       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.5          |
|    cost_values           | 0.877        |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 0.743        |
|    value_loss            | 7.24         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -1.0461279 |
| rollout/           |            |
|    ep_len_mean     | 959        |
|    ep_rew_mean     | -719       |
| time/              |            |
|    fps             | 101        |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 1005568    |
-----------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.4464737   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0004077313 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 4.97         |
|    cost_values           | 0.899        |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.624        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.000597    |
|    std                   | 0.743        |
|    value_loss            | 36.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6067155  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -706        |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 3           |
|    time_elapsed          | 81          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.004413521 |
|    clip_fraction         | 0.0173      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 14.4        |
|    cost_values           | 0.987       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.08        |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 0.743       |
|    value_loss            | 4.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.7425022  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1011712     |
| train/                   |             |
|    approx_kl             | 0.005938228 |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.54        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 1.07        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.684       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.4        |
|    n_updates             | 4930        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.742       |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6043556   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 142          |
|    total_timesteps       | 1013760      |
| train/                   |              |
|    approx_kl             | 0.0054345364 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 1.13         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 4940         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.742        |
|    value_loss            | 6.73         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.650484   |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 1015808     |
| train/                   |             |
|    approx_kl             | 0.005088932 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.14        |
|    cost_value_loss       | 9.17        |
|    cost_values           | 0.889       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.52        |
|    n_updates             | 4950        |
|    policy_gradient_loss  | -0.00537    |
|    std                   | 0.742       |
|    value_loss            | 9.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9301417  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1017856     |
| train/                   |             |
|    approx_kl             | 0.004181434 |
|    clip_fraction         | 0.0387      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 1.1         |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.53        |
|    n_updates             | 4960        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.742       |
|    value_loss            | 6.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.7418703  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 233         |
|    total_timesteps       | 1019904     |
| train/                   |             |
|    approx_kl             | 0.008040315 |
|    clip_fraction         | 0.054       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 5.71        |
|    cost_values           | 0.979       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.02        |
|    n_updates             | 4970        |
|    policy_gradient_loss  | -0.00837    |
|    std                   | 0.742       |
|    value_loss            | 9.57        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.6925412   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 263          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0031570033 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 7.53         |
|    cost_values           | 0.974        |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.68         |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.742        |
|    value_loss            | 4.8          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6049558  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 294         |
|    total_timesteps       | 1024000     |
| train/                   |             |
|    approx_kl             | 0.005474561 |
|    clip_fraction         | 0.0515      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 9.11        |
|    cost_values           | 0.999       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.753       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.5         |
|    n_updates             | 4990        |
|    policy_gradient_loss  | -0.00512    |
|    std                   | 0.742       |
|    value_loss            | 7.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.79875654 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -698        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 324         |
|    total_timesteps       | 1026048     |
| train/                   |             |
|    approx_kl             | 0.007855883 |
|    clip_fraction         | 0.0834      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.7         |
|    cost_value_loss       | 4.28        |
|    cost_values           | 0.969       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 5000        |
|    policy_gradient_loss  | -0.0113     |
|    std                   | 0.742       |
|    value_loss            | 5.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7104214  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 354         |
|    total_timesteps       | 1028096     |
| train/                   |             |
|    approx_kl             | 0.001811595 |
|    clip_fraction         | 0.000928    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 7.17        |
|    cost_values           | 0.939       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.856       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 5010        |
|    policy_gradient_loss  | -0.000609   |
|    std                   | 0.742       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.4990685   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 385          |
|    total_timesteps       | 1030144      |
| train/                   |              |
|    approx_kl             | 0.0052066045 |
|    clip_fraction         | 0.0597       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 4.52         |
|    cost_values           | 0.948        |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.924        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 5020         |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 0.742        |
|    value_loss            | 13.1         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.50409925 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 415         |
|    total_timesteps       | 1032192     |
| train/                   |             |
|    approx_kl             | 0.00414018  |
|    clip_fraction         | 0.0418      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 7.23        |
|    cost_values           | 0.987       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.28        |
|    n_updates             | 5030        |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.742       |
|    value_loss            | 4.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48161086  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 446          |
|    total_timesteps       | 1034240      |
| train/                   |              |
|    approx_kl             | 0.0063252654 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 8.04         |
|    cost_values           | 0.982        |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.13         |
|    n_updates             | 5040         |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 0.743        |
|    value_loss            | 7.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7767654   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -679         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 476          |
|    total_timesteps       | 1036288      |
| train/                   |              |
|    approx_kl             | 0.0043750764 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 11           |
|    cost_values           | 1.01         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.58         |
|    n_updates             | 5050         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.742        |
|    value_loss            | 4.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.7689252   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 506          |
|    total_timesteps       | 1038336      |
| train/                   |              |
|    approx_kl             | 0.0031366646 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 7.85         |
|    cost_values           | 1.01         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.29         |
|    n_updates             | 5060         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.743        |
|    value_loss            | 13.6         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.72         |
| reward                   | -0.6547847   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 537          |
|    total_timesteps       | 1040384      |
| train/                   |              |
|    approx_kl             | 0.0061950795 |
|    clip_fraction         | 0.0557       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 5.41         |
|    cost_values           | 0.973        |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.64         |
|    n_updates             | 5070         |
|    policy_gradient_loss  | -0.00678     |
|    std                   | 0.743        |
|    value_loss            | 4.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3414586   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -670         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 567          |
|    total_timesteps       | 1042432      |
| train/                   |              |
|    approx_kl             | 0.0055412957 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 7.38         |
|    cost_values           | 1.01         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.89         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 5080         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.742        |
|    value_loss            | 4.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4409859  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 597         |
|    total_timesteps       | 1044480     |
| train/                   |             |
|    approx_kl             | 0.007127424 |
|    clip_fraction         | 0.0635      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 3.67        |
|    cost_values           | 0.985       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 5090        |
|    policy_gradient_loss  | -0.00891    |
|    std                   | 0.742       |
|    value_loss            | 9.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1619022  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 627         |
|    total_timesteps       | 1046528     |
| train/                   |             |
|    approx_kl             | 0.004791948 |
|    clip_fraction         | 0.0243      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 2.99        |
|    cost_values           | 0.986       |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.3         |
|    n_updates             | 5100        |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.74        |
|    value_loss            | 5.12        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.40925863 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -668        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 658         |
|    total_timesteps       | 1048576     |
| train/                   |             |
|    approx_kl             | 0.006687757 |
|    clip_fraction         | 0.0611      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 3.17        |
|    cost_values           | 0.976       |
|    entropy               | -2.23       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 5110        |
|    policy_gradient_loss  | -0.00546    |
|    std                   | 0.74        |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0262529   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 688          |
|    total_timesteps       | 1050624      |
| train/                   |              |
|    approx_kl             | 0.0040302984 |
|    clip_fraction         | 0.0482       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 0.975        |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.19         |
|    n_updates             | 5120         |
|    policy_gradient_loss  | -0.00659     |
|    std                   | 0.74         |
|    value_loss            | 7.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.357        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.357        |
| reward                   | -0.3903425   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -658         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 719          |
|    total_timesteps       | 1052672      |
| train/                   |              |
|    approx_kl             | 0.0044750585 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.89         |
|    cost_value_loss       | 9.55         |
|    cost_values           | 1.03         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.92         |
|    n_updates             | 5130         |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.74         |
|    value_loss            | 6.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.568       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.568       |
| reward                   | -0.30082664 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -657        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 749         |
|    total_timesteps       | 1054720     |
| train/                   |             |
|    approx_kl             | 0.008487177 |
|    clip_fraction         | 0.0652      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 1.04        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 5140        |
|    policy_gradient_loss  | -0.0065     |
|    std                   | 0.739       |
|    value_loss            | 5.78        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.46         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.46         |
| reward                   | -0.2829028   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -655         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 779          |
|    total_timesteps       | 1056768      |
| train/                   |              |
|    approx_kl             | 0.0077622673 |
|    clip_fraction         | 0.138        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 4.35         |
|    cost_values           | 0.92         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.71         |
|    n_updates             | 5150         |
|    policy_gradient_loss  | -0.00936     |
|    std                   | 0.739        |
|    value_loss            | 8.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.5         |
| reward                   | -0.47558463 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -650        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 810         |
|    total_timesteps       | 1058816     |
| train/                   |             |
|    approx_kl             | 0.00387708  |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.12        |
|    cost_value_loss       | 6.6         |
|    cost_values           | 0.958       |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.84        |
|    n_updates             | 5160        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.74        |
|    value_loss            | 5.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32462138 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -644        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 840         |
|    total_timesteps       | 1060864     |
| train/                   |             |
|    approx_kl             | 0.00946431  |
|    clip_fraction         | 0.0967      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 4.41        |
|    cost_values           | 0.977       |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 5170        |
|    policy_gradient_loss  | -0.0112     |
|    std                   | 0.739       |
|    value_loss            | 5.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.44564378  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -641         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 871          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0060762884 |
|    clip_fraction         | 0.0993       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 16.7         |
|    cost_values           | 1.05         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 5180         |
|    policy_gradient_loss  | -0.0112      |
|    std                   | 0.739        |
|    value_loss            | 4.84         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.48        |
| reward                   | -0.41153023 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -652        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 901         |
|    total_timesteps       | 1064960     |
| train/                   |             |
|    approx_kl             | 0.006428185 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 9.61        |
|    cost_values           | 1.07        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.36        |
|    n_updates             | 5190        |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 0.738       |
|    value_loss            | 4.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.5498293   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -648         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 31           |
|    time_elapsed          | 931          |
|    total_timesteps       | 1067008      |
| train/                   |              |
|    approx_kl             | 0.0053728325 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.13         |
|    cost_values           | 0.967        |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.94         |
|    n_updates             | 5200         |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 0.737        |
|    value_loss            | 3.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0909      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0909      |
| reward                   | -0.6441843  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -651        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 962         |
|    total_timesteps       | 1069056     |
| train/                   |             |
|    approx_kl             | 0.004464114 |
|    clip_fraction         | 0.0904      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 9.06        |
|    cost_values           | 1.01        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 5210        |
|    policy_gradient_loss  | -0.00773    |
|    std                   | 0.736       |
|    value_loss            | 3.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.351311   |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -645        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 992         |
|    total_timesteps       | 1071104     |
| train/                   |             |
|    approx_kl             | 0.007785692 |
|    clip_fraction         | 0.0623      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.579       |
|    cost_values           | 0.943       |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 5220        |
|    policy_gradient_loss  | -0.00719    |
|    std                   | 0.736       |
|    value_loss            | 7.72        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.73386306 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -636        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1023        |
|    total_timesteps       | 1073152     |
| train/                   |             |
|    approx_kl             | 0.00893764  |
|    clip_fraction         | 0.0344      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 8.21        |
|    cost_values           | 1.1         |
|    entropy               | -2.23       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.47        |
|    n_updates             | 5230        |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.736       |
|    value_loss            | 9.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.08         |
| reward                   | -0.5557975   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -633         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 35           |
|    time_elapsed          | 1053         |
|    total_timesteps       | 1075200      |
| train/                   |              |
|    approx_kl             | 0.0074355844 |
|    clip_fraction         | 0.0758       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.04         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 0.952        |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.1         |
|    n_updates             | 5240         |
|    policy_gradient_loss  | -0.00617     |
|    std                   | 0.737        |
|    value_loss            | 33.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4335665  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -622        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1083        |
|    total_timesteps       | 1077248     |
| train/                   |             |
|    approx_kl             | 0.008521123 |
|    clip_fraction         | 0.0709      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.852       |
|    cost_value_loss       | 0.281       |
|    cost_values           | 0.868       |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 5250        |
|    policy_gradient_loss  | -0.00884    |
|    std                   | 0.735       |
|    value_loss            | 3.14        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.41       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.41       |
| reward                   | -0.5493727 |
| rollout/                 |            |
|    ep_len_mean           | 946        |
|    ep_rew_mean           | -612       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 37         |
|    time_elapsed          | 1114       |
|    total_timesteps       | 1079296    |
| train/                   |            |
|    approx_kl             | 0.00343356 |
|    clip_fraction         | 0.024      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.32       |
|    cost_value_loss       | 20.7       |
|    cost_values           | 0.999      |
|    entropy               | -2.22      |
|    entropy_loss          | -2.22      |
|    explained_variance    | 0.913      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 12.9       |
|    n_updates             | 5260       |
|    policy_gradient_loss  | -0.00172   |
|    std                   | 0.735      |
|    value_loss            | 8.67       |
-----------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 1.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.41         |
| reward                   | -0.5397745   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -609         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1144         |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 0.0038221753 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 1            |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.47         |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -0.00795     |
|    std                   | 0.734        |
|    value_loss            | 4.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42448437 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -603        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1175        |
|    total_timesteps       | 1083392     |
| train/                   |             |
|    approx_kl             | 0.006607325 |
|    clip_fraction         | 0.0817      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.04        |
|    cost_value_loss       | 5.01        |
|    cost_values           | 0.991       |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.85        |
|    n_updates             | 5280        |
|    policy_gradient_loss  | -0.00897    |
|    std                   | 0.734       |
|    value_loss            | 4.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.53         |
| reward                   | -0.6691881   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -592         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1205         |
|    total_timesteps       | 1085440      |
| train/                   |              |
|    approx_kl             | 0.0048906505 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 1            |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 5290         |
|    policy_gradient_loss  | -0.00523     |
|    std                   | 0.734        |
|    value_loss            | 8.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.323       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.323       |
| reward                   | -0.30538183 |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -599        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1236        |
|    total_timesteps       | 1087488     |
| train/                   |             |
|    approx_kl             | 0.004709384 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 14.3        |
|    cost_values           | 1.01        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 5300        |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 0.734       |
|    value_loss            | 9.03        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.28116247  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -595         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1266         |
|    total_timesteps       | 1089536      |
| train/                   |              |
|    approx_kl             | 0.0013333758 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.06         |
|    cost_value_loss       | 16           |
|    cost_values           | 0.403        |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.4         |
|    n_updates             | 5310         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.734        |
|    value_loss            | 69.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.33        |
| reward                   | -0.6183693  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -596        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1297        |
|    total_timesteps       | 1091584     |
| train/                   |             |
|    approx_kl             | 0.005148985 |
|    clip_fraction         | 0.014       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 2.81        |
|    cost_values           | 0.518       |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.75        |
|    n_updates             | 5320        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.734       |
|    value_loss            | 8.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.28849432  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -591         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1327         |
|    total_timesteps       | 1093632      |
| train/                   |              |
|    approx_kl             | 0.0036860902 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 0.733        |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.95         |
|    n_updates             | 5330         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.733        |
|    value_loss            | 5.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.07         |
| reward                   | -0.29229194  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -588         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1358         |
|    total_timesteps       | 1095680      |
| train/                   |              |
|    approx_kl             | 0.0061848173 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.37         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 1.03         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.828        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.34         |
|    n_updates             | 5340         |
|    policy_gradient_loss  | -0.00406     |
|    std                   | 0.734        |
|    value_loss            | 4.89         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0419385  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -583        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1388        |
|    total_timesteps       | 1097728     |
| train/                   |             |
|    approx_kl             | 0.004759562 |
|    clip_fraction         | 0.0444      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 12          |
|    cost_values           | 0.991       |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.29        |
|    n_updates             | 5350        |
|    policy_gradient_loss  | -0.00594    |
|    std                   | 0.734       |
|    value_loss            | 6.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.6394435  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -587        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1418        |
|    total_timesteps       | 1099776     |
| train/                   |             |
|    approx_kl             | 0.003945807 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.27        |
|    cost_value_loss       | 7.02        |
|    cost_values           | 0.995       |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 5360        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.733       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.3268529   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -581         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1448         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0088033145 |
|    clip_fraction         | 0.0712       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 6.7          |
|    cost_values           | 0.97         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.98         |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.00646     |
|    std                   | 0.732        |
|    value_loss            | 5            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.77169424  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -588         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1479         |
|    total_timesteps       | 1103872      |
| train/                   |              |
|    approx_kl             | 0.0045014955 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 9.01         |
|    cost_values           | 0.914        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.49         |
|    n_updates             | 5380         |
|    policy_gradient_loss  | -0.00506     |
|    std                   | 0.732        |
|    value_loss            | 6.32         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
-----------------------------------
| avg_speed          | 1.62e-05   |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.62e-05   |
| reward             | -0.3187284 |
| rollout/           |            |
|    ep_len_mean     | 945        |
|    ep_rew_mean     | -597       |
| time/              |            |
|    fps             | 100        |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 1105920    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42380998  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -596         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 1107968      |
| train/                   |              |
|    approx_kl             | 0.0016628061 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 4.45         |
|    cost_values           | 0.921        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.879        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.14         |
|    n_updates             | 5400         |
|    policy_gradient_loss  | -0.000743    |
|    std                   | 0.732        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7672677   |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -603         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1110016      |
| train/                   |              |
|    approx_kl             | 0.0075552906 |
|    clip_fraction         | 0.056        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 3.5          |
|    cost_values           | 0.917        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.66         |
|    n_updates             | 5410         |
|    policy_gradient_loss  | -0.00697     |
|    std                   | 0.732        |
|    value_loss            | 9.86         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 8             |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8             |
| reward                   | -0.5592426    |
| rollout/                 |               |
|    ep_len_mean           | 936           |
|    ep_rew_mean           | -598          |
| time/                    |               |
|    fps                   | 73            |
|    iterations            | 4             |
|    time_elapsed          | 111           |
|    total_timesteps       | 1112064       |
| train/                   |               |
|    approx_kl             | 0.00038008983 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.09          |
|    cost_value_loss       | 3.24          |
|    cost_values           | 0.648         |
|    entropy               | -2.21         |
|    entropy_loss          | -2.21         |
|    explained_variance    | 0.904         |
|    lagrangian_multiplier | 0.00531       |
|    learning_rate         | 0.0003        |
|    loss                  | 4.26          |
|    n_updates             | 5420          |
|    policy_gradient_loss  | -7.94e-05     |
|    std                   | 0.732         |
|    value_loss            | 72.3          |
--------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 0.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.74         |
| reward                   | -0.31111354  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -601         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 141          |
|    total_timesteps       | 1114112      |
| train/                   |              |
|    approx_kl             | 0.0006350156 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 6.23         |
|    cost_values           | 0.688        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.84         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.2         |
|    n_updates             | 5430         |
|    policy_gradient_loss  | -0.000572    |
|    std                   | 0.732        |
|    value_loss            | 42.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.36642116  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -593         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 1116160      |
| train/                   |              |
|    approx_kl             | 0.0003018565 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 2.21         |
|    cost_values           | 0.487        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 9.87e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.79         |
|    n_updates             | 5440         |
|    policy_gradient_loss  | -0.000554    |
|    std                   | 0.732        |
|    value_loss            | 69.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3394622  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -587        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1118208     |
| train/                   |             |
|    approx_kl             | 0.006187712 |
|    clip_fraction         | 0.0667      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 9.27        |
|    cost_values           | 0.85        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.9        |
|    n_updates             | 5450        |
|    policy_gradient_loss  | -0.00553    |
|    std                   | 0.731       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.0133368  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -589        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 1120256     |
| train/                   |             |
|    approx_kl             | 0.005421968 |
|    clip_fraction         | 0.0296      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 0.755       |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.9         |
|    n_updates             | 5460        |
|    policy_gradient_loss  | -0.00462    |
|    std                   | 0.732       |
|    value_loss            | 14.6        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.8134069  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -594        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 263         |
|    total_timesteps       | 1122304     |
| train/                   |             |
|    approx_kl             | 0.006363653 |
|    clip_fraction         | 0.075       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 3.56        |
|    cost_values           | 0.829       |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 5470        |
|    policy_gradient_loss  | -0.00693    |
|    std                   | 0.731       |
|    value_loss            | 8.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0908       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0908       |
| reward                   | -0.37697667  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -592         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 1124352      |
| train/                   |              |
|    approx_kl             | 0.0064455704 |
|    clip_fraction         | 0.076        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 6.18         |
|    cost_values           | 0.977        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.923        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.55         |
|    n_updates             | 5480         |
|    policy_gradient_loss  | -0.011       |
|    std                   | 0.731        |
|    value_loss            | 5.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.96         |
| reward                   | -0.31280515  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -593         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 323          |
|    total_timesteps       | 1126400      |
| train/                   |              |
|    approx_kl             | 0.0052601835 |
|    clip_fraction         | 0.0524       |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 7.22         |
|    cost_values           | 1            |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.818        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 5490         |
|    policy_gradient_loss  | -0.00526     |
|    std                   | 0.73         |
|    value_loss            | 2.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.07        |
| reward                   | -0.31639895 |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -599        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 354         |
|    total_timesteps       | 1128448     |
| train/                   |             |
|    approx_kl             | 0.004456233 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 8.35        |
|    cost_values           | 0.966       |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 5500        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.728       |
|    value_loss            | 4.51        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.08         |
| reward                   | -0.2546048   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -595         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 1130496      |
| train/                   |              |
|    approx_kl             | 0.0043000365 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 6.78         |
|    cost_values           | 0.9          |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 5510         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.726        |
|    value_loss            | 3.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.34         |
| reward                   | -0.6155885   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -585         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 415          |
|    total_timesteps       | 1132544      |
| train/                   |              |
|    approx_kl             | 0.0042671226 |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 1.01         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.19         |
|    n_updates             | 5520         |
|    policy_gradient_loss  | -0.00657     |
|    std                   | 0.725        |
|    value_loss            | 3.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.88762456 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -582        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 15          |
|    time_elapsed          | 445         |
|    total_timesteps       | 1134592     |
| train/                   |             |
|    approx_kl             | 0.004996243 |
|    clip_fraction         | 0.0455      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 13          |
|    cost_values           | 1           |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 5530        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.724       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.57429445  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -583         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 475          |
|    total_timesteps       | 1136640      |
| train/                   |              |
|    approx_kl             | 0.0075066513 |
|    clip_fraction         | 0.0846       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 12.4         |
|    cost_values           | 0.986        |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.48         |
|    n_updates             | 5540         |
|    policy_gradient_loss  | -0.00937     |
|    std                   | 0.724        |
|    value_loss            | 4.64         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8314674  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -578        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 506         |
|    total_timesteps       | 1138688     |
| train/                   |             |
|    approx_kl             | 0.005814556 |
|    clip_fraction         | 0.0517      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 1.03        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 5550        |
|    policy_gradient_loss  | -0.00577    |
|    std                   | 0.723       |
|    value_loss            | 3.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4211388  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -578        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 536         |
|    total_timesteps       | 1140736     |
| train/                   |             |
|    approx_kl             | 0.005345408 |
|    clip_fraction         | 0.0504      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 22.3        |
|    cost_values           | 1.02        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 5560        |
|    policy_gradient_loss  | -0.0052     |
|    std                   | 0.722       |
|    value_loss            | 14.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.8565352  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -578        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 566         |
|    total_timesteps       | 1142784     |
| train/                   |             |
|    approx_kl             | 0.009322397 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 6.79        |
|    cost_values           | 0.998       |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 5570        |
|    policy_gradient_loss  | -0.0115     |
|    std                   | 0.72        |
|    value_loss            | 3.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.7937147   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -581         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 597          |
|    total_timesteps       | 1144832      |
| train/                   |              |
|    approx_kl             | 0.0058927066 |
|    clip_fraction         | 0.0492       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 9.58         |
|    cost_values           | 1.01         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.96         |
|    n_updates             | 5580         |
|    policy_gradient_loss  | -0.00579     |
|    std                   | 0.718        |
|    value_loss            | 7.64         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.48866877  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -578         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 627          |
|    total_timesteps       | 1146880      |
| train/                   |              |
|    approx_kl             | 0.0042568725 |
|    clip_fraction         | 0.0457       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.77         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 0.996        |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 5590         |
|    policy_gradient_loss  | -0.00532     |
|    std                   | 0.717        |
|    value_loss            | 5.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.73804057  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -577         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 658          |
|    total_timesteps       | 1148928      |
| train/                   |              |
|    approx_kl             | 0.0064954124 |
|    clip_fraction         | 0.0543       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 8.69         |
|    cost_values           | 1            |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.07         |
|    n_updates             | 5600         |
|    policy_gradient_loss  | -0.00656     |
|    std                   | 0.716        |
|    value_loss            | 4.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.59         |
| reward                   | -0.479498    |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -578         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 688          |
|    total_timesteps       | 1150976      |
| train/                   |              |
|    approx_kl             | 0.0050901184 |
|    clip_fraction         | 0.0421       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.5          |
|    cost_values           | 0.948        |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 5610         |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 0.714        |
|    value_loss            | 8.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -0.9997098   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -575         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 719          |
|    total_timesteps       | 1153024      |
| train/                   |              |
|    approx_kl             | 0.0040754844 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 4.18         |
|    cost_values           | 0.996        |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.34         |
|    n_updates             | 5620         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.716        |
|    value_loss            | 4.6          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.77723444 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -580        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 749         |
|    total_timesteps       | 1155072     |
| train/                   |             |
|    approx_kl             | 0.006564948 |
|    clip_fraction         | 0.0863      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.66        |
|    cost_value_loss       | 17.7        |
|    cost_values           | 1.1         |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 5630        |
|    policy_gradient_loss  | -0.0086     |
|    std                   | 0.715       |
|    value_loss            | 2.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0511589   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 781          |
|    total_timesteps       | 1157120      |
| train/                   |              |
|    approx_kl             | 0.0077129425 |
|    clip_fraction         | 0.0659       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 2.36         |
|    cost_values           | 0.969        |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.17         |
|    n_updates             | 5640         |
|    policy_gradient_loss  | -0.00552     |
|    std                   | 0.715        |
|    value_loss            | 6.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.0665729   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -586         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 811          |
|    total_timesteps       | 1159168      |
| train/                   |              |
|    approx_kl             | 0.0067536593 |
|    clip_fraction         | 0.0962       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.4          |
|    cost_value_loss       | 45.8         |
|    cost_values           | 1.07         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.3         |
|    n_updates             | 5650         |
|    policy_gradient_loss  | -0.00856     |
|    std                   | 0.716        |
|    value_loss            | 4.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.15821    |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -582        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 842         |
|    total_timesteps       | 1161216     |
| train/                   |             |
|    approx_kl             | 0.010503377 |
|    clip_fraction         | 0.0591      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 1.26        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 5660        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.715       |
|    value_loss            | 3.1         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.96        |
| reward                   | -0.5776592  |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -592        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 872         |
|    total_timesteps       | 1163264     |
| train/                   |             |
|    approx_kl             | 0.007875215 |
|    clip_fraction         | 0.0525      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 23.6        |
|    cost_values           | 1.27        |
|    entropy               | -2.16       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00533     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.84        |
|    n_updates             | 5670        |
|    policy_gradient_loss  | -0.00471    |
|    std                   | 0.714       |
|    value_loss            | 3.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.35         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.35         |
| reward                   | -0.3110772   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -596         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 903          |
|    total_timesteps       | 1165312      |
| train/                   |              |
|    approx_kl             | 0.0040189014 |
|    clip_fraction         | 0.0548       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 6.41         |
|    cost_values           | 1.09         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.82         |
|    n_updates             | 5680         |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 0.712        |
|    value_loss            | 2.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.28        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.28        |
| reward                   | -0.51505953 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -593        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 934         |
|    total_timesteps       | 1167360     |
| train/                   |             |
|    approx_kl             | 0.005696978 |
|    clip_fraction         | 0.0649      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.67        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 1.01        |
|    entropy               | -2.16       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 5690        |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 0.712       |
|    value_loss            | 3.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.575388    |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -587         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 32           |
|    time_elapsed          | 965          |
|    total_timesteps       | 1169408      |
| train/                   |              |
|    approx_kl             | 0.0069574136 |
|    clip_fraction         | 0.0809       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 30.7         |
|    cost_values           | 1.68         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 5700         |
|    policy_gradient_loss  | -0.00787     |
|    std                   | 0.712        |
|    value_loss            | 2.58         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.421       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.421       |
| reward                   | -0.47282222 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -593        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1171456     |
| train/                   |             |
|    approx_kl             | 0.005896494 |
|    clip_fraction         | 0.081       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.11        |
|    cost_value_loss       | 38.1        |
|    cost_values           | 2.25        |
|    entropy               | -2.16       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0.0003      |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 5710        |
|    policy_gradient_loss  | -0.00626    |
|    std                   | 0.711       |
|    value_loss            | 2.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.565       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.565       |
| reward                   | -0.5470312  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -597        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 1173504     |
| train/                   |             |
|    approx_kl             | 0.008567907 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 3.95        |
|    cost_values           | 1.41        |
|    entropy               | -2.16       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.62        |
|    n_updates             | 5720        |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 0.711       |
|    value_loss            | 8.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.33        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.33        |
| reward                   | -0.5892922  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -597        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1056        |
|    total_timesteps       | 1175552     |
| train/                   |             |
|    approx_kl             | 0.006881997 |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 10.1        |
|    cost_values           | 0.89        |
|    entropy               | -2.15       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.11        |
|    n_updates             | 5730        |
|    policy_gradient_loss  | -0.0102     |
|    std                   | 0.711       |
|    value_loss            | 3           |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.53180146 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -603        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 1177600     |
| train/                   |             |
|    approx_kl             | 0.005273668 |
|    clip_fraction         | 0.0218      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.88        |
|    cost_value_loss       | 20.5        |
|    cost_values           | 1.09        |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.4         |
|    n_updates             | 5740        |
|    policy_gradient_loss  | -0.00489    |
|    std                   | 0.71        |
|    value_loss            | 1.97        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.7         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.7         |
| reward                   | -0.29401225 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -602        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1116        |
|    total_timesteps       | 1179648     |
| train/                   |             |
|    approx_kl             | 0.007450787 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 0.979       |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.41        |
|    n_updates             | 5750        |
|    policy_gradient_loss  | -0.00652    |
|    std                   | 0.709       |
|    value_loss            | 2.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.277       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.277       |
| reward                   | -0.3772061  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -595        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1147        |
|    total_timesteps       | 1181696     |
| train/                   |             |
|    approx_kl             | 0.004259236 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 1.75        |
|    cost_values           | 0.987       |
|    entropy               | -2.14       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.709       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 5760        |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 0.706       |
|    value_loss            | 9.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.323        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.323        |
| reward                   | -0.33088705  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -595         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1177         |
|    total_timesteps       | 1183744      |
| train/                   |              |
|    approx_kl             | 0.0031412756 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.51         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 1.17         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.04         |
|    n_updates             | 5770         |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 0.703        |
|    value_loss            | 2.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.08        |
| reward                   | -0.22315334 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -593        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1207        |
|    total_timesteps       | 1185792     |
| train/                   |             |
|    approx_kl             | 0.005729596 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 4.56        |
|    cost_values           | 1.07        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 5780        |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 0.701       |
|    value_loss            | 5.49        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5786715   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -588         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1238         |
|    total_timesteps       | 1187840      |
| train/                   |              |
|    approx_kl             | 0.0065762717 |
|    clip_fraction         | 0.0719       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 5.02         |
|    cost_values           | 0.946        |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.5          |
|    n_updates             | 5790         |
|    policy_gradient_loss  | -0.00729     |
|    std                   | 0.703        |
|    value_loss            | 3.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.48        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.48        |
| reward                   | -0.3544251  |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -586        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1269        |
|    total_timesteps       | 1189888     |
| train/                   |             |
|    approx_kl             | 0.006158354 |
|    clip_fraction         | 0.0473      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 32.5        |
|    cost_values           | 1.14        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.686       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.4        |
|    n_updates             | 5800        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.703       |
|    value_loss            | 9.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.49221638  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1299         |
|    total_timesteps       | 1191936      |
| train/                   |              |
|    approx_kl             | 0.0094710905 |
|    clip_fraction         | 0.0854       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 1.38         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.73         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 5810         |
|    policy_gradient_loss  | -0.00532     |
|    std                   | 0.702        |
|    value_loss            | 11.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4513084  |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -581        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1330        |
|    total_timesteps       | 1193984     |
| train/                   |             |
|    approx_kl             | 0.003574814 |
|    clip_fraction         | 0.0186      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 14.5        |
|    cost_values           | 1.47        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.63        |
|    n_updates             | 5820        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.7         |
|    value_loss            | 4.2         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.47321817  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -578         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1360         |
|    total_timesteps       | 1196032      |
| train/                   |              |
|    approx_kl             | 0.0068555586 |
|    clip_fraction         | 0.0752       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 1.17         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.75         |
|    n_updates             | 5830         |
|    policy_gradient_loss  | -0.0104      |
|    std                   | 0.698        |
|    value_loss            | 3.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.05         |
| reward                   | -0.32358402  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -577         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1391         |
|    total_timesteps       | 1198080      |
| train/                   |              |
|    approx_kl             | 0.0038838682 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 1.11         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.43         |
|    n_updates             | 5840         |
|    policy_gradient_loss  | -0.00564     |
|    std                   | 0.696        |
|    value_loss            | 3.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.345662    |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1422         |
|    total_timesteps       | 1200128      |
| train/                   |              |
|    approx_kl             | 0.0038413173 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 29.1         |
|    cost_values           | 1.48         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 5850         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.696        |
|    value_loss            | 2.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.13        |
| reward                   | -0.47625667 |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -541        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1452        |
|    total_timesteps       | 1202176     |
| train/                   |             |
|    approx_kl             | 0.007119996 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 1.47        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 5860        |
|    policy_gradient_loss  | -0.00673    |
|    std                   | 0.695       |
|    value_loss            | 3.86        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.416       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.416       |
| reward                   | -0.4059579  |
| rollout/                 |             |
|    ep_len_mean           | 921         |
|    ep_rew_mean           | -548        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1483        |
|    total_timesteps       | 1204224     |
| train/                   |             |
|    approx_kl             | 0.004422753 |
|    clip_fraction         | 0.0555      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 8.88        |
|    cost_values           | 1.35        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 5870        |
|    policy_gradient_loss  | -0.00532    |
|    std                   | 0.695       |
|    value_loss            | 20.7        |
------------------------------------------
------------------------------------
| avg_speed          | 4.87        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 4.87        |
| reward             | -0.49962282 |
| rollout/           |             |
|    ep_len_mean     | 916         |
|    ep_rew_mean     | -537        |
| time/              |             |
|    fps             | 97          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1206272     |
------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6874273  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -545        |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 1208320     |
| train/                   |             |
|    approx_kl             | 0.006695757 |
|    clip_fraction         | 0.0681      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.29        |
|    cost_value_loss       | 50.6        |
|    cost_values           | 1.39        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.5        |
|    n_updates             | 5890        |
|    policy_gradient_loss  | -0.00497    |
|    std                   | 0.697       |
|    value_loss            | 6.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -1.0494094   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1210368      |
| train/                   |              |
|    approx_kl             | 0.0033178376 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.49         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 1.75         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.36         |
|    n_updates             | 5900         |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.696        |
|    value_loss            | 4.57         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.61683    |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -544        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 1212416     |
| train/                   |             |
|    approx_kl             | 0.004278413 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.43        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 1.44        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.74        |
|    n_updates             | 5910        |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 0.697       |
|    value_loss            | 3.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.743314   |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -544        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1214464     |
| train/                   |             |
|    approx_kl             | 0.003098866 |
|    clip_fraction         | 0.0223      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 8.61        |
|    cost_values           | 1.37        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.42        |
|    n_updates             | 5920        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.697       |
|    value_loss            | 2.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.122449    |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 1216512      |
| train/                   |              |
|    approx_kl             | 0.0040491894 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 6.22         |
|    cost_values           | 1.23         |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.67         |
|    n_updates             | 5930         |
|    policy_gradient_loss  | -0.00428     |
|    std                   | 0.698        |
|    value_loss            | 3.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.85806036  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 203          |
|    total_timesteps       | 1218560      |
| train/                   |              |
|    approx_kl             | 0.0054905335 |
|    clip_fraction         | 0.0601       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 9.66         |
|    cost_values           | 0.86         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 5940         |
|    policy_gradient_loss  | -0.00607     |
|    std                   | 0.697        |
|    value_loss            | 3.22         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47981307 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -531        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 233         |
|    total_timesteps       | 1220608     |
| train/                   |             |
|    approx_kl             | 0.005329646 |
|    clip_fraction         | 0.0582      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 6.62        |
|    cost_values           | 0.948       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 5950        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.696       |
|    value_loss            | 3.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.50126195 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -531        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 264         |
|    total_timesteps       | 1222656     |
| train/                   |             |
|    approx_kl             | 0.005339098 |
|    clip_fraction         | 0.0603      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.65        |
|    cost_value_loss       | 8.48        |
|    cost_values           | 0.922       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 5960        |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 0.694       |
|    value_loss            | 18.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.43778595 |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -537        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 294         |
|    total_timesteps       | 1224704     |
| train/                   |             |
|    approx_kl             | 0.006647099 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.36        |
|    cost_value_loss       | 9.8         |
|    cost_values           | 0.992       |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.08        |
|    n_updates             | 5970        |
|    policy_gradient_loss  | -0.0131     |
|    std                   | 0.694       |
|    value_loss            | 5.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.81177247 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -542        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 324         |
|    total_timesteps       | 1226752     |
| train/                   |             |
|    approx_kl             | 0.006592747 |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 5.63        |
|    cost_values           | 0.963       |
|    entropy               | -2.1        |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 5980        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.693       |
|    value_loss            | 4.94        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.2211184 |
| rollout/                 |            |
|    ep_len_mean           | 933        |
|    ep_rew_mean           | -542       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 12         |
|    time_elapsed          | 355        |
|    total_timesteps       | 1228800    |
| train/                   |            |
|    approx_kl             | 0.00667903 |
|    clip_fraction         | 0.0723     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.13       |
|    cost_value_loss       | 7.4        |
|    cost_values           | 0.949      |
|    entropy               | -2.1       |
|    entropy_loss          | -2.1       |
|    explained_variance    | 0.967      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 4.51       |
|    n_updates             | 5990       |
|    policy_gradient_loss  | -0.00842   |
|    std                   | 0.69       |
|    value_loss            | 2.41       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.21         |
| reward                   | -0.4728617   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 386          |
|    total_timesteps       | 1230848      |
| train/                   |              |
|    approx_kl             | 0.0066841803 |
|    clip_fraction         | 0.0718       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.88         |
|    cost_value_loss       | 17.9         |
|    cost_values           | 1.1          |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.53         |
|    n_updates             | 6000         |
|    policy_gradient_loss  | -0.00562     |
|    std                   | 0.688        |
|    value_loss            | 1.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.04         |
| reward                   | -0.29886857  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 416          |
|    total_timesteps       | 1232896      |
| train/                   |              |
|    approx_kl             | 0.0064040786 |
|    clip_fraction         | 0.099        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 7.72         |
|    cost_values           | 1.22         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0.652        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 6010         |
|    policy_gradient_loss  | -0.00518     |
|    std                   | 0.685        |
|    value_loss            | 6.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.3         |
| reward                   | -0.20831433 |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 447         |
|    total_timesteps       | 1234944     |
| train/                   |             |
|    approx_kl             | 0.003290374 |
|    clip_fraction         | 0.0401      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.31        |
|    cost_value_loss       | 42.4        |
|    cost_values           | 1.21        |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.1        |
|    n_updates             | 6020        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.685       |
|    value_loss            | 6.5         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 1.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.41         |
| reward                   | -0.57509154  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 478          |
|    total_timesteps       | 1236992      |
| train/                   |              |
|    approx_kl             | 0.0035718207 |
|    clip_fraction         | 0.0526       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 26.4         |
|    cost_values           | 1.86         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 6030         |
|    policy_gradient_loss  | -0.00447     |
|    std                   | 0.686        |
|    value_loss            | 1.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.38         |
| reward                   | -0.56819254  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1239040      |
| train/                   |              |
|    approx_kl             | 0.0091348495 |
|    clip_fraction         | 0.073        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.52         |
|    cost_value_loss       | 28.6         |
|    cost_values           | 2.3          |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.8         |
|    n_updates             | 6040         |
|    policy_gradient_loss  | -0.00663     |
|    std                   | 0.686        |
|    value_loss            | 16.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.59485096  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 539          |
|    total_timesteps       | 1241088      |
| train/                   |              |
|    approx_kl             | 0.0073664933 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.26         |
|    cost_value_loss       | 7.29         |
|    cost_values           | 2.08         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.903        |
|    lagrangian_multiplier | 0.000483     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.29         |
|    n_updates             | 6050         |
|    policy_gradient_loss  | -0.00485     |
|    std                   | 0.685        |
|    value_loss            | 6.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5426971  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -524        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 569         |
|    total_timesteps       | 1243136     |
| train/                   |             |
|    approx_kl             | 0.008051429 |
|    clip_fraction         | 0.0736      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 7.71        |
|    cost_values           | 1.74        |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 6060        |
|    policy_gradient_loss  | -0.00668    |
|    std                   | 0.685       |
|    value_loss            | 4.09        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5623489  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 600         |
|    total_timesteps       | 1245184     |
| train/                   |             |
|    approx_kl             | 0.005761886 |
|    clip_fraction         | 0.058       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 1.21        |
|    entropy               | -2.07       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.12        |
|    n_updates             | 6070        |
|    policy_gradient_loss  | -0.00747    |
|    std                   | 0.682       |
|    value_loss            | 3.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.6456834  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -522        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 630         |
|    total_timesteps       | 1247232     |
| train/                   |             |
|    approx_kl             | 0.007751636 |
|    clip_fraction         | 0.0684      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.74        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 0.974       |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 6080        |
|    policy_gradient_loss  | -0.00674    |
|    std                   | 0.681       |
|    value_loss            | 2.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.50691897  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -521         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 660          |
|    total_timesteps       | 1249280      |
| train/                   |              |
|    approx_kl             | 0.0068197264 |
|    clip_fraction         | 0.0619       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.49         |
|    cost_value_loss       | 17.9         |
|    cost_values           | 0.963        |
|    entropy               | -2.06        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.39         |
|    n_updates             | 6090         |
|    policy_gradient_loss  | -0.00786     |
|    std                   | 0.679        |
|    value_loss            | 3.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4658114  |
| rollout/                 |             |
|    ep_len_mean           | 909         |
|    ep_rew_mean           | -517        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 691         |
|    total_timesteps       | 1251328     |
| train/                   |             |
|    approx_kl             | 0.009753015 |
|    clip_fraction         | 0.0707      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 16.5        |
|    cost_values           | 1.1         |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 6100        |
|    policy_gradient_loss  | -0.00754    |
|    std                   | 0.679       |
|    value_loss            | 2.47        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.48603866  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -515         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 721          |
|    total_timesteps       | 1253376      |
| train/                   |              |
|    approx_kl             | 0.0073866663 |
|    clip_fraction         | 0.0859       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.02         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1.15         |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.9          |
|    n_updates             | 6110         |
|    policy_gradient_loss  | -0.00632     |
|    std                   | 0.679        |
|    value_loss            | 9.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.27042556  |
| rollout/                 |              |
|    ep_len_mean           | 909          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 751          |
|    total_timesteps       | 1255424      |
| train/                   |              |
|    approx_kl             | 0.0035947184 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 6.51         |
|    cost_values           | 1.03         |
|    entropy               | -2.06        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0.878        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.19         |
|    n_updates             | 6120         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.677        |
|    value_loss            | 4.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.9137682   |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 782          |
|    total_timesteps       | 1257472      |
| train/                   |              |
|    approx_kl             | 0.0064706327 |
|    clip_fraction         | 0.0652       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 3.83         |
|    cost_values           | 0.958        |
|    entropy               | -2.05        |
|    entropy_loss          | -2.06        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.88         |
|    n_updates             | 6130         |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 0.675        |
|    value_loss            | 2.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7039494   |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 812          |
|    total_timesteps       | 1259520      |
| train/                   |              |
|    approx_kl             | 0.0065043382 |
|    clip_fraction         | 0.0868       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 5.53         |
|    cost_values           | 0.906        |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.16         |
|    n_updates             | 6140         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 0.675        |
|    value_loss            | 10.3         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.75549716  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 843          |
|    total_timesteps       | 1261568      |
| train/                   |              |
|    approx_kl             | 0.0040300777 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 6.33         |
|    cost_values           | 0.962        |
|    entropy               | -2.05        |
|    entropy_loss          | -2.05        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 6150         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 0.674        |
|    value_loss            | 2.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.7926799  |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -497        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 873         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.007128236 |
|    clip_fraction         | 0.0565      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 0.989       |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.00504    |
|    std                   | 0.675       |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.6125566  |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -498        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 903         |
|    total_timesteps       | 1265664     |
| train/                   |             |
|    approx_kl             | 0.008076934 |
|    clip_fraction         | 0.0729      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 7.47        |
|    cost_values           | 0.991       |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 6170        |
|    policy_gradient_loss  | -0.00714    |
|    std                   | 0.673       |
|    value_loss            | 2.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.66131663 |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -495        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 934         |
|    total_timesteps       | 1267712     |
| train/                   |             |
|    approx_kl             | 0.005514415 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 13          |
|    cost_values           | 1.01        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.81        |
|    n_updates             | 6180        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.671       |
|    value_loss            | 5.82        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.62860334 |
| rollout/                 |             |
|    ep_len_mean           | 877         |
|    ep_rew_mean           | -494        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 964         |
|    total_timesteps       | 1269760     |
| train/                   |             |
|    approx_kl             | 0.008129663 |
|    clip_fraction         | 0.0955      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 9.72        |
|    cost_values           | 1           |
|    entropy               | -2.03       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.31        |
|    n_updates             | 6190        |
|    policy_gradient_loss  | -0.00944    |
|    std                   | 0.669       |
|    value_loss            | 3.99        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.55010897  |
| rollout/                 |              |
|    ep_len_mean           | 877          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 33           |
|    time_elapsed          | 995          |
|    total_timesteps       | 1271808      |
| train/                   |              |
|    approx_kl             | 0.0048611206 |
|    clip_fraction         | 0.046        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 1            |
|    entropy               | -2.02        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.06         |
|    n_updates             | 6200         |
|    policy_gradient_loss  | -0.00462     |
|    std                   | 0.664        |
|    value_loss            | 6.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6057447  |
| rollout/                 |             |
|    ep_len_mean           | 877         |
|    ep_rew_mean           | -492        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 1273856     |
| train/                   |             |
|    approx_kl             | 0.008033695 |
|    clip_fraction         | 0.0674      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 1.01        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.73        |
|    n_updates             | 6210        |
|    policy_gradient_loss  | -0.00686    |
|    std                   | 0.665       |
|    value_loss            | 3.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6036891   |
| rollout/                 |              |
|    ep_len_mean           | 883          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 35           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 1275904      |
| train/                   |              |
|    approx_kl             | 0.0043974053 |
|    clip_fraction         | 0.0566       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.13         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 1.07         |
|    entropy               | -2.03        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 6220         |
|    policy_gradient_loss  | -0.00436     |
|    std                   | 0.666        |
|    value_loss            | 2.27         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -0.3833791 |
| rollout/                 |            |
|    ep_len_mean           | 891        |
|    ep_rew_mean           | -499       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 36         |
|    time_elapsed          | 1086       |
|    total_timesteps       | 1277952    |
| train/                   |            |
|    approx_kl             | 0.00723749 |
|    clip_fraction         | 0.0423     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.72       |
|    cost_value_loss       | 11.1       |
|    cost_values           | 1.04       |
|    entropy               | -2.02      |
|    entropy_loss          | -2.02      |
|    explained_variance    | 0.962      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.93       |
|    n_updates             | 6230       |
|    policy_gradient_loss  | -0.00356   |
|    std                   | 0.663      |
|    value_loss            | 2.06       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5496177  |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -498        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1116        |
|    total_timesteps       | 1280000     |
| train/                   |             |
|    approx_kl             | 0.005779279 |
|    clip_fraction         | 0.0453      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 8.89        |
|    cost_values           | 1           |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.22        |
|    n_updates             | 6240        |
|    policy_gradient_loss  | -0.00585    |
|    std                   | 0.661       |
|    value_loss            | 3.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6995601   |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1147         |
|    total_timesteps       | 1282048      |
| train/                   |              |
|    approx_kl             | 0.0052492283 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.58         |
|    cost_value_loss       | 17.7         |
|    cost_values           | 1.06         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 6250         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.657        |
|    value_loss            | 2.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.52151775  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1177         |
|    total_timesteps       | 1284096      |
| train/                   |              |
|    approx_kl             | 0.0035979308 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 16.7         |
|    cost_values           | 1.04         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.78         |
|    n_updates             | 6260         |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 0.655        |
|    value_loss            | 1.5          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.36023852  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1208         |
|    total_timesteps       | 1286144      |
| train/                   |              |
|    approx_kl             | 0.0066854283 |
|    clip_fraction         | 0.0985       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.61         |
|    cost_value_loss       | 24.1         |
|    cost_values           | 1.08         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 6270         |
|    policy_gradient_loss  | -0.00793     |
|    std                   | 0.654        |
|    value_loss            | 3.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.44448417  |
| rollout/                 |              |
|    ep_len_mean           | 884          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1238         |
|    total_timesteps       | 1288192      |
| train/                   |              |
|    approx_kl             | 0.0060387007 |
|    clip_fraction         | 0.0664       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.52         |
|    cost_value_loss       | 25.3         |
|    cost_values           | 1.13         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 6280         |
|    policy_gradient_loss  | -0.00615     |
|    std                   | 0.654        |
|    value_loss            | 2.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.92505777 |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1268        |
|    total_timesteps       | 1290240     |
| train/                   |             |
|    approx_kl             | 0.006302964 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.76        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 0.979       |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.9        |
|    n_updates             | 6290        |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.654       |
|    value_loss            | 9.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4923399  |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -496        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1299        |
|    total_timesteps       | 1292288     |
| train/                   |             |
|    approx_kl             | 0.005696113 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 8.21        |
|    cost_values           | 0.96        |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 6300        |
|    policy_gradient_loss  | -0.00499    |
|    std                   | 0.655       |
|    value_loss            | 5.52        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.30013335  |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1330         |
|    total_timesteps       | 1294336      |
| train/                   |              |
|    approx_kl             | 0.0052451384 |
|    clip_fraction         | 0.0685       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 0.916        |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 6310         |
|    policy_gradient_loss  | -0.00512     |
|    std                   | 0.656        |
|    value_loss            | 7.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.5509587   |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1360         |
|    total_timesteps       | 1296384      |
| train/                   |              |
|    approx_kl             | 0.0058187484 |
|    clip_fraction         | 0.0676       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.23         |
|    cost_value_loss       | 25           |
|    cost_values           | 1.02         |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 6320         |
|    policy_gradient_loss  | -0.00708     |
|    std                   | 0.657        |
|    value_loss            | 6            |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55221707 |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -488        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1391        |
|    total_timesteps       | 1298432     |
| train/                   |             |
|    approx_kl             | 0.007214733 |
|    clip_fraction         | 0.0508      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.14        |
|    cost_value_loss       | 38.4        |
|    cost_values           | 1.05        |
|    entropy               | -1.99       |
|    entropy_loss          | -2          |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.2        |
|    n_updates             | 6330        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.655       |
|    value_loss            | 4.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.24379759  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1421         |
|    total_timesteps       | 1300480      |
| train/                   |              |
|    approx_kl             | 0.0036670503 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.79         |
|    cost_value_loss       | 19.9         |
|    cost_values           | 1.02         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 6340         |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 0.655        |
|    value_loss            | 7.5          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 1.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.86        |
| reward                   | -0.58244836 |
| rollout/                 |             |
|    ep_len_mean           | 879         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1452        |
|    total_timesteps       | 1302528     |
| train/                   |             |
|    approx_kl             | 0.006285036 |
|    clip_fraction         | 0.0586      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 0.987       |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.85        |
|    n_updates             | 6350        |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 0.657       |
|    value_loss            | 11.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.50630254 |
| rollout/                 |             |
|    ep_len_mean           | 879         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1482        |
|    total_timesteps       | 1304576     |
| train/                   |             |
|    approx_kl             | 0.006453773 |
|    clip_fraction         | 0.0755      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 0.994       |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.41        |
|    n_updates             | 6360        |
|    policy_gradient_loss  | -0.00832    |
|    std                   | 0.658       |
|    value_loss            | 9.67        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.65999573 |
| rollout/           |             |
|    ep_len_mean     | 872         |
|    ep_rew_mean     | -463        |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 1306624     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.57540774 |
| rollout/                 |             |
|    ep_len_mean           | 879         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 2           |
|    time_elapsed          | 50          |
|    total_timesteps       | 1308672     |
| train/                   |             |
|    approx_kl             | 0.003103129 |
|    clip_fraction         | 0.0357      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 4.62        |
|    cost_values           | 0.997       |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.14        |
|    n_updates             | 6380        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.658       |
|    value_loss            | 9.75        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.49584824  |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0041422597 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 1            |
|    entropy               | -1.99        |
|    entropy_loss          | -2           |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 6390         |
|    policy_gradient_loss  | -0.00562     |
|    std                   | 0.656        |
|    value_loss            | 4.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.51128334 |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1312768     |
| train/                   |             |
|    approx_kl             | 0.008443989 |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 14.4        |
|    cost_values           | 1           |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8           |
|    n_updates             | 6400        |
|    policy_gradient_loss  | -0.00792    |
|    std                   | 0.654       |
|    value_loss            | 2.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.70992094 |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 5           |
|    time_elapsed          | 141         |
|    total_timesteps       | 1314816     |
| train/                   |             |
|    approx_kl             | 0.008736687 |
|    clip_fraction         | 0.0547      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.27        |
|    cost_value_loss       | 7.57        |
|    cost_values           | 1.01        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.05        |
|    n_updates             | 6410        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.652       |
|    value_loss            | 2.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0880493  |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 1316864     |
| train/                   |             |
|    approx_kl             | 0.006295268 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 6.08        |
|    cost_values           | 0.996       |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.03        |
|    n_updates             | 6420        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.65        |
|    value_loss            | 2.65        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.84        |
| reward                   | -0.46221524 |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1318912     |
| train/                   |             |
|    approx_kl             | 0.006568881 |
|    clip_fraction         | 0.0882      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 7.18        |
|    cost_values           | 0.901       |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.59        |
|    n_updates             | 6430        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.648       |
|    value_loss            | 3.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.14591165  |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 8            |
|    time_elapsed          | 232          |
|    total_timesteps       | 1320960      |
| train/                   |              |
|    approx_kl             | 0.0066488357 |
|    clip_fraction         | 0.0566       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.09         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 1.01         |
|    entropy               | -1.96        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.79         |
|    n_updates             | 6440         |
|    policy_gradient_loss  | -0.00432     |
|    std                   | 0.646        |
|    value_loss            | 2.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.49442688 |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 263         |
|    total_timesteps       | 1323008     |
| train/                   |             |
|    approx_kl             | 0.008238561 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.64        |
|    cost_value_loss       | 9.05        |
|    cost_values           | 1.04        |
|    entropy               | -1.96       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.732       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.89        |
|    n_updates             | 6450        |
|    policy_gradient_loss  | -0.00542    |
|    std                   | 0.646       |
|    value_loss            | 9.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.878        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.878        |
| reward                   | -0.439734    |
| rollout/                 |              |
|    ep_len_mean           | 886          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 1325056      |
| train/                   |              |
|    approx_kl             | 0.0063518863 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 16.3         |
|    cost_values           | 1.07         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 6460         |
|    policy_gradient_loss  | -0.00492     |
|    std                   | 0.647        |
|    value_loss            | 6.25         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5763334   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 324          |
|    total_timesteps       | 1327104      |
| train/                   |              |
|    approx_kl             | 0.0076699927 |
|    clip_fraction         | 0.112        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 16.8         |
|    cost_values           | 1.01         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.92         |
|    n_updates             | 6470         |
|    policy_gradient_loss  | -0.00984     |
|    std                   | 0.647        |
|    value_loss            | 2.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.28573754  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 354          |
|    total_timesteps       | 1329152      |
| train/                   |              |
|    approx_kl             | 0.0064342665 |
|    clip_fraction         | 0.0822       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.33         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 1.07         |
|    entropy               | -1.96        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.96         |
|    n_updates             | 6480         |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 0.646        |
|    value_loss            | 5.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.39        |
| reward                   | -0.51888883 |
| rollout/                 |             |
|    ep_len_mean           | 882         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 385         |
|    total_timesteps       | 1331200     |
| train/                   |             |
|    approx_kl             | 0.009440877 |
|    clip_fraction         | 0.0819      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 7.23        |
|    cost_values           | 1.05        |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 6490        |
|    policy_gradient_loss  | -0.00629    |
|    std                   | 0.643       |
|    value_loss            | 2.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6567759   |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 415          |
|    total_timesteps       | 1333248      |
| train/                   |              |
|    approx_kl             | 0.0056921765 |
|    clip_fraction         | 0.0731       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 3.5          |
|    cost_values           | 0.991        |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.836        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.35         |
|    n_updates             | 6500         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.641        |
|    value_loss            | 10.9         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.2996328  |
| rollout/                 |             |
|    ep_len_mean           | 879         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 445         |
|    total_timesteps       | 1335296     |
| train/                   |             |
|    approx_kl             | 0.007141635 |
|    clip_fraction         | 0.0679      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 1.01        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.46        |
|    n_updates             | 6510        |
|    policy_gradient_loss  | -0.00552    |
|    std                   | 0.642       |
|    value_loss            | 5.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5982777   |
| rollout/                 |              |
|    ep_len_mean           | 879          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 476          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0046779104 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 1.01         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.21         |
|    n_updates             | 6520         |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 0.641        |
|    value_loss            | 2.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.7195571  |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 506         |
|    total_timesteps       | 1339392     |
| train/                   |             |
|    approx_kl             | 0.004075614 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.27        |
|    cost_value_loss       | 7.99        |
|    cost_values           | 1           |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.78        |
|    n_updates             | 6530        |
|    policy_gradient_loss  | -0.0071     |
|    std                   | 0.64        |
|    value_loss            | 2.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.33         |
| reward                   | -0.4288496   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 537          |
|    total_timesteps       | 1341440      |
| train/                   |              |
|    approx_kl             | 0.0107642785 |
|    clip_fraction         | 0.0868       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 2.89         |
|    cost_values           | 0.983        |
|    entropy               | -1.92        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.93         |
|    n_updates             | 6540         |
|    policy_gradient_loss  | -0.00621     |
|    std                   | 0.633        |
|    value_loss            | 1.05         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.62        |
| reward                   | -0.58225155 |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 567         |
|    total_timesteps       | 1343488     |
| train/                   |             |
|    approx_kl             | 0.004155694 |
|    clip_fraction         | 0.0543      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 29.7        |
|    cost_values           | 1.29        |
|    entropy               | -1.91       |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.6        |
|    n_updates             | 6550        |
|    policy_gradient_loss  | -0.00506    |
|    std                   | 0.628       |
|    value_loss            | 0.599       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.96         |
| reward                   | -0.25092044  |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 598          |
|    total_timesteps       | 1345536      |
| train/                   |              |
|    approx_kl             | 0.0061298213 |
|    clip_fraction         | 0.0726       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 15.1         |
|    cost_values           | 1.92         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.54         |
|    n_updates             | 6560         |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.626        |
|    value_loss            | 0.814        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47611576 |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 628         |
|    total_timesteps       | 1347584     |
| train/                   |             |
|    approx_kl             | 0.007522665 |
|    clip_fraction         | 0.0608      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 2.2         |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.17        |
|    n_updates             | 6570        |
|    policy_gradient_loss  | -0.00755    |
|    std                   | 0.627       |
|    value_loss            | 0.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4            |
| reward                   | -0.57423276  |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 659          |
|    total_timesteps       | 1349632      |
| train/                   |              |
|    approx_kl             | 0.0075816144 |
|    clip_fraction         | 0.0752       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.57         |
|    cost_value_loss       | 8.59         |
|    cost_values           | 2.08         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.61         |
|    n_updates             | 6580         |
|    policy_gradient_loss  | -0.00634     |
|    std                   | 0.627        |
|    value_loss            | 0.913        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 6.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.15        |
| reward                   | -0.51386297 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 689         |
|    total_timesteps       | 1351680     |
| train/                   |             |
|    approx_kl             | 0.007475947 |
|    clip_fraction         | 0.0916      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.84        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 1.73        |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.33        |
|    n_updates             | 6590        |
|    policy_gradient_loss  | -0.00874    |
|    std                   | 0.626       |
|    value_loss            | 1.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.47474042 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 720         |
|    total_timesteps       | 1353728     |
| train/                   |             |
|    approx_kl             | 0.007602784 |
|    clip_fraction         | 0.088       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 1.51        |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.81        |
|    n_updates             | 6600        |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.624       |
|    value_loss            | 7.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.21330316 |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 751         |
|    total_timesteps       | 1355776     |
| train/                   |             |
|    approx_kl             | 0.005263229 |
|    clip_fraction         | 0.037       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 20          |
|    cost_values           | 1.34        |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 6610        |
|    policy_gradient_loss  | -0.00327    |
|    std                   | 0.621       |
|    value_loss            | 1.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.14         |
| reward                   | -0.5065884   |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 781          |
|    total_timesteps       | 1357824      |
| train/                   |              |
|    approx_kl             | 0.0057600085 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.13         |
|    cost_value_loss       | 27.7         |
|    cost_values           | 1.49         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 6620         |
|    policy_gradient_loss  | -0.00446     |
|    std                   | 0.621        |
|    value_loss            | 3.01         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.27182686  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 812          |
|    total_timesteps       | 1359872      |
| train/                   |              |
|    approx_kl             | 0.0044379923 |
|    clip_fraction         | 0.0501       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 8.41         |
|    cost_values           | 1.48         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.92         |
|    n_updates             | 6630         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.621        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.28397986  |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 842          |
|    total_timesteps       | 1361920      |
| train/                   |              |
|    approx_kl             | 0.0039643585 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 1.27         |
|    entropy               | -1.88        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.05         |
|    n_updates             | 6640         |
|    policy_gradient_loss  | -0.0055      |
|    std                   | 0.621        |
|    value_loss            | 1.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.47        |
| reward                   | -0.5158513  |
| rollout/                 |             |
|    ep_len_mean           | 920         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 873         |
|    total_timesteps       | 1363968     |
| train/                   |             |
|    approx_kl             | 0.006842326 |
|    clip_fraction         | 0.0771      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 20          |
|    cost_values           | 1.11        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 6650        |
|    policy_gradient_loss  | -0.00739    |
|    std                   | 0.62        |
|    value_loss            | 1.82        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.41       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.41       |
| reward                   | -0.4742248 |
| rollout/                 |            |
|    ep_len_mean           | 920        |
|    ep_rew_mean           | -441       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 30         |
|    time_elapsed          | 903        |
|    total_timesteps       | 1366016    |
| train/                   |            |
|    approx_kl             | 0.00885224 |
|    clip_fraction         | 0.0778     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.51       |
|    cost_value_loss       | 12.5       |
|    cost_values           | 1          |
|    entropy               | -1.88      |
|    entropy_loss          | -1.88      |
|    explained_variance    | 0.976      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.93       |
|    n_updates             | 6660       |
|    policy_gradient_loss  | -0.00477   |
|    std                   | 0.619      |
|    value_loss            | 1.31       |
-----------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 4.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.22         |
| reward                   | -0.62206805  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 31           |
|    time_elapsed          | 934          |
|    total_timesteps       | 1368064      |
| train/                   |              |
|    approx_kl             | 0.0056984634 |
|    clip_fraction         | 0.0761       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 4.02         |
|    cost_values           | 0.998        |
|    entropy               | -1.87        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.08         |
|    n_updates             | 6670         |
|    policy_gradient_loss  | -0.00492     |
|    std                   | 0.618        |
|    value_loss            | 0.644        |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.82        |
| reward                   | -0.29323483 |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 964         |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.007714658 |
|    clip_fraction         | 0.0943      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 12          |
|    cost_values           | 1.01        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 6680        |
|    policy_gradient_loss  | -0.00311    |
|    std                   | 0.618       |
|    value_loss            | 4.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45735902 |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1372160     |
| train/                   |             |
|    approx_kl             | 0.009546028 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 0.997       |
|    entropy               | -1.87       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.07        |
|    n_updates             | 6690        |
|    policy_gradient_loss  | -0.00777    |
|    std                   | 0.618       |
|    value_loss            | 1.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4810533  |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1026        |
|    total_timesteps       | 1374208     |
| train/                   |             |
|    approx_kl             | 0.004176739 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.43        |
|    cost_value_loss       | 28          |
|    cost_values           | 1.05        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.7        |
|    n_updates             | 6700        |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.618       |
|    value_loss            | 4.5         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.28        |
| reward                   | -0.38735592 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1057        |
|    total_timesteps       | 1376256     |
| train/                   |             |
|    approx_kl             | 0.004185647 |
|    clip_fraction         | 0.0488      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.4         |
|    cost_value_loss       | 48.6        |
|    cost_values           | 1.27        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.8        |
|    n_updates             | 6710        |
|    policy_gradient_loss  | -0.00437    |
|    std                   | 0.618       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.09        |
| reward                   | -0.3197315  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1088        |
|    total_timesteps       | 1378304     |
| train/                   |             |
|    approx_kl             | 0.006821056 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.67        |
|    cost_value_loss       | 41.9        |
|    cost_values           | 1.67        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.7        |
|    n_updates             | 6720        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.617       |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.60929114 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1119        |
|    total_timesteps       | 1380352     |
| train/                   |             |
|    approx_kl             | 0.006538064 |
|    clip_fraction         | 0.0884      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 1.53        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.46        |
|    n_updates             | 6730        |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 0.617       |
|    value_loss            | 4.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.53         |
| reward                   | -0.23626266  |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1150         |
|    total_timesteps       | 1382400      |
| train/                   |              |
|    approx_kl             | 0.0068862247 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.98         |
|    cost_value_loss       | 38.9         |
|    cost_values           | 1.33         |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 6740         |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.616        |
|    value_loss            | 1.21         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 5.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.17        |
| reward                   | -0.6626836  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1181        |
|    total_timesteps       | 1384448     |
| train/                   |             |
|    approx_kl             | 0.007186788 |
|    clip_fraction         | 0.0711      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 25.8        |
|    cost_values           | 1.49        |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13          |
|    n_updates             | 6750        |
|    policy_gradient_loss  | -0.00509    |
|    std                   | 0.617       |
|    value_loss            | 0.669       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.12         |
| reward                   | -0.53673524  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1212         |
|    total_timesteps       | 1386496      |
| train/                   |              |
|    approx_kl             | 0.0049635516 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.33         |
|    cost_value_loss       | 50.6         |
|    cost_values           | 1.96         |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 6760         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.615        |
|    value_loss            | 1.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.33        |
| reward                   | -0.3260986  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1242        |
|    total_timesteps       | 1388544     |
| train/                   |             |
|    approx_kl             | 0.007191169 |
|    clip_fraction         | 0.0697      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.21        |
|    cost_value_loss       | 27.5        |
|    cost_values           | 2.55        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.46        |
|    n_updates             | 6770        |
|    policy_gradient_loss  | -0.00675    |
|    std                   | 0.61        |
|    value_loss            | 0.964       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.41102526  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 1390592      |
| train/                   |              |
|    approx_kl             | 0.0073093036 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 2.7          |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.72         |
|    n_updates             | 6780         |
|    policy_gradient_loss  | -0.00556     |
|    std                   | 0.609        |
|    value_loss            | 2.22         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.34376088  |
| rollout/                 |              |
|    ep_len_mean           | 925          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1303         |
|    total_timesteps       | 1392640      |
| train/                   |              |
|    approx_kl             | 0.0050999126 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 16.2         |
|    cost_values           | 2.32         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.02         |
|    n_updates             | 6790         |
|    policy_gradient_loss  | -0.00533     |
|    std                   | 0.608        |
|    value_loss            | 1.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.41874084  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1333         |
|    total_timesteps       | 1394688      |
| train/                   |              |
|    approx_kl             | 0.0070979847 |
|    clip_fraction         | 0.0533       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.67         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 1.89         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.17         |
|    n_updates             | 6800         |
|    policy_gradient_loss  | -0.00724     |
|    std                   | 0.608        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.86         |
| reward                   | -0.32647786  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1364         |
|    total_timesteps       | 1396736      |
| train/                   |              |
|    approx_kl             | 0.0031327717 |
|    clip_fraction         | 0.0286       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.05         |
|    cost_value_loss       | 26           |
|    cost_values           | 1.58         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 6810         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.607        |
|    value_loss            | 1.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.4649735  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1394        |
|    total_timesteps       | 1398784     |
| train/                   |             |
|    approx_kl             | 0.008093186 |
|    clip_fraction         | 0.0615      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.93        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 1.4         |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.07        |
|    n_updates             | 6820        |
|    policy_gradient_loss  | -0.00777    |
|    std                   | 0.606       |
|    value_loss            | 1.08        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.42162728 |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1425        |
|    total_timesteps       | 1400832     |
| train/                   |             |
|    approx_kl             | 0.003955028 |
|    clip_fraction         | 0.061       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 28.5        |
|    cost_values           | 1.22        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 6830        |
|    policy_gradient_loss  | -0.00543    |
|    std                   | 0.605       |
|    value_loss            | 1.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4870761  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1455        |
|    total_timesteps       | 1402880     |
| train/                   |             |
|    approx_kl             | 0.008156144 |
|    clip_fraction         | 0.0841      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 29.3        |
|    cost_values           | 1.2         |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 6840        |
|    policy_gradient_loss  | -0.0063     |
|    std                   | 0.605       |
|    value_loss            | 0.638       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.5884122   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1486         |
|    total_timesteps       | 1404928      |
| train/                   |              |
|    approx_kl             | 0.0048515648 |
|    clip_fraction         | 0.0569       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.8          |
|    cost_value_loss       | 25.8         |
|    cost_values           | 1.27         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 6850         |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 0.605        |
|    value_loss            | 0.629        |
-------------------------------------------
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.27195013 |
| rollout/           |             |
|    ep_len_mean     | 946         |
|    ep_rew_mean     | -441        |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 1406976     |
------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.846       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.846       |
| reward                   | -0.37156263 |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 2           |
|    time_elapsed          | 50          |
|    total_timesteps       | 1409024     |
| train/                   |             |
|    approx_kl             | 0.006901319 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 24.6        |
|    cost_values           | 1.4         |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 6870        |
|    policy_gradient_loss  | -0.00563    |
|    std                   | 0.604       |
|    value_loss            | 0.502       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.41959345  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 80           |
|    total_timesteps       | 1411072      |
| train/                   |              |
|    approx_kl             | 0.0051010065 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 6.1          |
|    cost_values           | 1.8          |
|    entropy               | -1.82        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.26         |
|    n_updates             | 6880         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.602        |
|    value_loss            | 0.765        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4831241  |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1413120     |
| train/                   |             |
|    approx_kl             | 0.007108004 |
|    clip_fraction         | 0.0814      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.6         |
|    cost_value_loss       | 10.2        |
|    cost_values           | 1.63        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.06        |
|    n_updates             | 6890        |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.6         |
|    value_loss            | 5.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.27362767  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 141          |
|    total_timesteps       | 1415168      |
| train/                   |              |
|    approx_kl             | 0.0062289727 |
|    clip_fraction         | 0.0665       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 5.56         |
|    cost_values           | 1.44         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0.773        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.78         |
|    n_updates             | 6900         |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.601        |
|    value_loss            | 5.11         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.52779174  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 1417216      |
| train/                   |              |
|    approx_kl             | 0.0044516223 |
|    clip_fraction         | 0.041        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.15         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 1.17         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.55         |
|    n_updates             | 6910         |
|    policy_gradient_loss  | -0.00515     |
|    std                   | 0.599        |
|    value_loss            | 2.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -0.38764307  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 202          |
|    total_timesteps       | 1419264      |
| train/                   |              |
|    approx_kl             | 0.0067577627 |
|    clip_fraction         | 0.0773       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 2.95         |
|    cost_values           | 0.928        |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.38         |
|    n_updates             | 6920         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.598        |
|    value_loss            | 4.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.37952846 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 1421312     |
| train/                   |             |
|    approx_kl             | 0.008980421 |
|    clip_fraction         | 0.0891      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.52        |
|    cost_value_loss       | 8           |
|    cost_values           | 1.01        |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 6930        |
|    policy_gradient_loss  | -0.00647    |
|    std                   | 0.597       |
|    value_loss            | 0.565       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.54097056 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 263         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.005943944 |
|    clip_fraction         | 0.0814      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.18        |
|    cost_value_loss       | 6.46        |
|    cost_values           | 1           |
|    entropy               | -1.8        |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.00229    |
|    std                   | 0.596       |
|    value_loss            | 0.857       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.27034745  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 293          |
|    total_timesteps       | 1425408      |
| train/                   |              |
|    approx_kl             | 0.0048494725 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.33         |
|    cost_value_loss       | 15           |
|    cost_values           | 1.01         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.61         |
|    n_updates             | 6950         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.595        |
|    value_loss            | 0.933        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.36         |
| reward                   | -0.46957514  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 324          |
|    total_timesteps       | 1427456      |
| train/                   |              |
|    approx_kl             | 0.0029793517 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 1.01         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.69         |
|    n_updates             | 6960         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 0.595        |
|    value_loss            | 5.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.52        |
| reward                   | -0.22338316 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 355         |
|    total_timesteps       | 1429504     |
| train/                   |             |
|    approx_kl             | 0.004429102 |
|    clip_fraction         | 0.0544      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 25.4        |
|    cost_values           | 1.03        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 6970        |
|    policy_gradient_loss  | -0.00538    |
|    std                   | 0.594       |
|    value_loss            | 0.976       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.28662676  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 385          |
|    total_timesteps       | 1431552      |
| train/                   |              |
|    approx_kl             | 0.0058898814 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.3          |
|    cost_value_loss       | 12.6         |
|    cost_values           | 1.03         |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 6980         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.595        |
|    value_loss            | 0.665        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.43128136 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 416         |
|    total_timesteps       | 1433600     |
| train/                   |             |
|    approx_kl             | 0.011581449 |
|    clip_fraction         | 0.0772      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 2.23        |
|    cost_values           | 0.993       |
|    entropy               | -1.79       |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.31        |
|    n_updates             | 6990        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.593       |
|    value_loss            | 0.526       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.68213826 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 446         |
|    total_timesteps       | 1435648     |
| train/                   |             |
|    approx_kl             | 0.00682731  |
|    clip_fraction         | 0.092       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 24.3        |
|    cost_values           | 1.03        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 7000        |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 0.593       |
|    value_loss            | 3.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.996       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.996       |
| reward                   | -0.33749518 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 477         |
|    total_timesteps       | 1437696     |
| train/                   |             |
|    approx_kl             | 0.007339685 |
|    clip_fraction         | 0.0584      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 9.24        |
|    cost_values           | 1.02        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 7010        |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.591       |
|    value_loss            | 0.583       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.54585665  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 507          |
|    total_timesteps       | 1439744      |
| train/                   |              |
|    approx_kl             | 0.0067356154 |
|    clip_fraction         | 0.109        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 1.07         |
|    entropy               | -1.79        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 7020         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.591        |
|    value_loss            | 4.6          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.55354446  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 538          |
|    total_timesteps       | 1441792      |
| train/                   |              |
|    approx_kl             | 0.0066367495 |
|    clip_fraction         | 0.0927       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 7.54         |
|    cost_values           | 1.01         |
|    entropy               | -1.78        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.32         |
|    n_updates             | 7030         |
|    policy_gradient_loss  | -0.00816     |
|    std                   | 0.591        |
|    value_loss            | 0.594        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40227088 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 568         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.007332772 |
|    clip_fraction         | 0.082       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 29.9        |
|    cost_values           | 1.15        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 7040        |
|    policy_gradient_loss  | -0.00555    |
|    std                   | 0.591       |
|    value_loss            | 0.814       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.5092664   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 599          |
|    total_timesteps       | 1445888      |
| train/                   |              |
|    approx_kl             | 0.0074336533 |
|    clip_fraction         | 0.0627       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.51         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 1.2          |
|    entropy               | -1.79        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0.906        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.9          |
|    n_updates             | 7050         |
|    policy_gradient_loss  | -0.00619     |
|    std                   | 0.592        |
|    value_loss            | 6.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.39        |
| reward                   | -0.22577837 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 629         |
|    total_timesteps       | 1447936     |
| train/                   |             |
|    approx_kl             | 0.005098178 |
|    clip_fraction         | 0.0544      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.93        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 1.08        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 7060        |
|    policy_gradient_loss  | -0.00513    |
|    std                   | 0.589       |
|    value_loss            | 1.14        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.49554572 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 659         |
|    total_timesteps       | 1449984     |
| train/                   |             |
|    approx_kl             | 0.006454914 |
|    clip_fraction         | 0.0483      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 14          |
|    cost_values           | 1.03        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.91        |
|    n_updates             | 7070        |
|    policy_gradient_loss  | -0.00595    |
|    std                   | 0.589       |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.52681464 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 689         |
|    total_timesteps       | 1452032     |
| train/                   |             |
|    approx_kl             | 0.004173519 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 0.988       |
|    entropy               | -1.77       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.26        |
|    n_updates             | 7080        |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 0.587       |
|    value_loss            | 3.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.4791857  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 720         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.009036975 |
|    clip_fraction         | 0.0568      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 8.32        |
|    cost_values           | 0.993       |
|    entropy               | -1.76       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 7090        |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.585       |
|    value_loss            | 1.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4461596   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 750          |
|    total_timesteps       | 1456128      |
| train/                   |              |
|    approx_kl             | 0.0087805595 |
|    clip_fraction         | 0.0965       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.74         |
|    cost_value_loss       | 23.9         |
|    cost_values           | 1.19         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 7100         |
|    policy_gradient_loss  | -0.00685     |
|    std                   | 0.584        |
|    value_loss            | 0.41         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.43072683 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 781         |
|    total_timesteps       | 1458176     |
| train/                   |             |
|    approx_kl             | 0.006201458 |
|    clip_fraction         | 0.0581      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 1.49        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.33        |
|    n_updates             | 7110        |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 0.582       |
|    value_loss            | 0.903       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.39         |
| reward                   | -0.47494286  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 811          |
|    total_timesteps       | 1460224      |
| train/                   |              |
|    approx_kl             | 0.0069238623 |
|    clip_fraction         | 0.0593       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.34         |
|    cost_value_loss       | 4.09         |
|    cost_values           | 1.33         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 7120         |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 0.58         |
|    value_loss            | 7            |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.77        |
| reward                   | -0.4482101  |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 842         |
|    total_timesteps       | 1462272     |
| train/                   |             |
|    approx_kl             | 0.005422337 |
|    clip_fraction         | 0.0482      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 1.03        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 7130        |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 0.582       |
|    value_loss            | 0.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47218665 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 872         |
|    total_timesteps       | 1464320     |
| train/                   |             |
|    approx_kl             | 0.007934969 |
|    clip_fraction         | 0.0936      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.36        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 1           |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 7140        |
|    policy_gradient_loss  | -0.00775    |
|    std                   | 0.582       |
|    value_loss            | 1.09        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.39267838 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 902         |
|    total_timesteps       | 1466368     |
| train/                   |             |
|    approx_kl             | 0.008133369 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.05        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1           |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.25        |
|    n_updates             | 7150        |
|    policy_gradient_loss  | -0.00638    |
|    std                   | 0.583       |
|    value_loss            | 0.606       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.5242595  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 933         |
|    total_timesteps       | 1468416     |
| train/                   |             |
|    approx_kl             | 0.005114678 |
|    clip_fraction         | 0.0716      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.24        |
|    cost_value_loss       | 0.786       |
|    cost_values           | 0.984       |
|    entropy               | -1.75       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 7160        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.582       |
|    value_loss            | 4.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.4371864  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 963         |
|    total_timesteps       | 1470464     |
| train/                   |             |
|    approx_kl             | 0.005662161 |
|    clip_fraction         | 0.0791      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 6.74        |
|    cost_values           | 0.994       |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 7170        |
|    policy_gradient_loss  | -0.00531    |
|    std                   | 0.582       |
|    value_loss            | 1.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.521111   |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 994         |
|    total_timesteps       | 1472512     |
| train/                   |             |
|    approx_kl             | 0.004122763 |
|    clip_fraction         | 0.0588      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 5.2         |
|    cost_values           | 0.999       |
|    entropy               | -1.77       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.23        |
|    n_updates             | 7180        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.585       |
|    value_loss            | 1.46        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.13        |
| reward                   | -0.42561376 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1024        |
|    total_timesteps       | 1474560     |
| train/                   |             |
|    approx_kl             | 0.004479547 |
|    clip_fraction         | 0.0706      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.28        |
|    cost_value_loss       | 30          |
|    cost_values           | 1.13        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 7190        |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 0.585       |
|    value_loss            | 0.831       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2955385  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1055        |
|    total_timesteps       | 1476608     |
| train/                   |             |
|    approx_kl             | 0.006350842 |
|    clip_fraction         | 0.0813      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.29        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 1.11        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 7200        |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.585       |
|    value_loss            | 4.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.48671153 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1085        |
|    total_timesteps       | 1478656     |
| train/                   |             |
|    approx_kl             | 0.004594494 |
|    clip_fraction         | 0.0631      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 22.6        |
|    cost_values           | 1.03        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.7        |
|    n_updates             | 7210        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.586       |
|    value_loss            | 4.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.44207755  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1115         |
|    total_timesteps       | 1480704      |
| train/                   |              |
|    approx_kl             | 0.0071952837 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 1            |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.99         |
|    n_updates             | 7220         |
|    policy_gradient_loss  | -0.00892     |
|    std                   | 0.584        |
|    value_loss            | 2.74         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 4.83         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.83         |
| reward                   | -0.43516484  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1146         |
|    total_timesteps       | 1482752      |
| train/                   |              |
|    approx_kl             | 0.0072342353 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 4.86         |
|    cost_values           | 0.991        |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 7230         |
|    policy_gradient_loss  | -0.00606     |
|    std                   | 0.584        |
|    value_loss            | 3.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.59         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.59         |
| reward                   | -0.4896843   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1177         |
|    total_timesteps       | 1484800      |
| train/                   |              |
|    approx_kl             | 0.0033654766 |
|    clip_fraction         | 0.0451       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 8.43         |
|    cost_values           | 1            |
|    entropy               | -1.77        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.955        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.72         |
|    n_updates             | 7240         |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 0.586        |
|    value_loss            | 1.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.42478037 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1207        |
|    total_timesteps       | 1486848     |
| train/                   |             |
|    approx_kl             | 0.006894374 |
|    clip_fraction         | 0.0578      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 1           |
|    entropy               | -1.76       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.35        |
|    n_updates             | 7250        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.584       |
|    value_loss            | 1.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.45524448 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1237        |
|    total_timesteps       | 1488896     |
| train/                   |             |
|    approx_kl             | 0.010471771 |
|    clip_fraction         | 0.073       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 1.02        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.85        |
|    n_updates             | 7260        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.586       |
|    value_loss            | 1.11        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.57945067 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1268        |
|    total_timesteps       | 1490944     |
| train/                   |             |
|    approx_kl             | 0.011210034 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.72        |
|    cost_value_loss       | 8.18        |
|    cost_values           | 1.03        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 7270        |
|    policy_gradient_loss  | -0.0102     |
|    std                   | 0.585       |
|    value_loss            | 1.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45088732  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1299         |
|    total_timesteps       | 1492992      |
| train/                   |              |
|    approx_kl             | 0.0048173824 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 1.06         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.04         |
|    n_updates             | 7280         |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 0.584        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.24642439  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1330         |
|    total_timesteps       | 1495040      |
| train/                   |              |
|    approx_kl             | 0.0033858183 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.75         |
|    cost_value_loss       | 42.7         |
|    cost_values           | 1.39         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 7290         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.585        |
|    value_loss            | 0.708        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.40939707  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1360         |
|    total_timesteps       | 1497088      |
| train/                   |              |
|    approx_kl             | 0.0040829936 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 20.3         |
|    cost_values           | 1.99         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0.000393     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.83         |
|    n_updates             | 7300         |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 0.583        |
|    value_loss            | 1.4          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3200977  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1390        |
|    total_timesteps       | 1499136     |
| train/                   |             |
|    approx_kl             | 0.004986827 |
|    clip_fraction         | 0.0447      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.78        |
|    cost_value_loss       | 0.865       |
|    cost_values           | 1.58        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.973       |
|    n_updates             | 7310        |
|    policy_gradient_loss  | -0.00509    |
|    std                   | 0.581       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2481501  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1421        |
|    total_timesteps       | 1501184     |
| train/                   |             |
|    approx_kl             | 0.004770371 |
|    clip_fraction         | 0.0653      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 2.75        |
|    cost_values           | 1.16        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.7         |
|    n_updates             | 7320        |
|    policy_gradient_loss  | -0.00203    |
|    std                   | 0.579       |
|    value_loss            | 0.768       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.38458076 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1451        |
|    total_timesteps       | 1503232     |
| train/                   |             |
|    approx_kl             | 0.010063814 |
|    clip_fraction         | 0.0845      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.01        |
|    cost_value_loss       | 6.94        |
|    cost_values           | 0.873       |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 7330        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.576       |
|    value_loss            | 0.668       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.5585457  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1481        |
|    total_timesteps       | 1505280     |
| train/                   |             |
|    approx_kl             | 0.009982893 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 5.96        |
|    cost_values           | 0.907       |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 7340        |
|    policy_gradient_loss  | -0.00864    |
|    std                   | 0.575       |
|    value_loss            | 4.78        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
------------------------------------
| avg_speed          | 5.39        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 5.39        |
| reward             | -0.48466653 |
| rollout/           |             |
|    ep_len_mean     | 962         |
|    ep_rew_mean     | -424        |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 1507328     |
------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6194847  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 1509376     |
| train/                   |             |
|    approx_kl             | 0.007203126 |
|    clip_fraction         | 0.0535      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 9.95        |
|    cost_values           | 0.953       |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 7360        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.571       |
|    value_loss            | 0.861       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.3608433   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1511424      |
| train/                   |              |
|    approx_kl             | 0.0035764228 |
|    clip_fraction         | 0.0681       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 25           |
|    cost_values           | 1.25         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 7370         |
|    policy_gradient_loss  | -0.00568     |
|    std                   | 0.57         |
|    value_loss            | 0.936        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.51955706  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 1513472      |
| train/                   |              |
|    approx_kl             | 0.0037139808 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 25           |
|    cost_values           | 1.57         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 7380         |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 0.57         |
|    value_loss            | 1.07         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.5123299   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 5            |
|    time_elapsed          | 142          |
|    total_timesteps       | 1515520      |
| train/                   |              |
|    approx_kl             | 0.0057907915 |
|    clip_fraction         | 0.0867       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 9.93         |
|    cost_values           | 1.67         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.87         |
|    n_updates             | 7390         |
|    policy_gradient_loss  | -0.00637     |
|    std                   | 0.569        |
|    value_loss            | 0.954        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.54353726 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 1517568     |
| train/                   |             |
|    approx_kl             | 0.009198111 |
|    clip_fraction         | 0.0914      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 1.33        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.13        |
|    n_updates             | 7400        |
|    policy_gradient_loss  | -0.00839    |
|    std                   | 0.567       |
|    value_loss            | 0.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.41197404  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 203          |
|    total_timesteps       | 1519616      |
| train/                   |              |
|    approx_kl             | 0.0067605004 |
|    clip_fraction         | 0.0866       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 10           |
|    cost_values           | 1.15         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.55         |
|    n_updates             | 7410         |
|    policy_gradient_loss  | -0.00434     |
|    std                   | 0.566        |
|    value_loss            | 0.692        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5391626   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 8            |
|    time_elapsed          | 234          |
|    total_timesteps       | 1521664      |
| train/                   |              |
|    approx_kl             | 0.0063366033 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 1.02         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.5          |
|    n_updates             | 7420         |
|    policy_gradient_loss  | -0.00509     |
|    std                   | 0.567        |
|    value_loss            | 0.634        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.56        |
| reward                   | -0.4727215  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 265         |
|    total_timesteps       | 1523712     |
| train/                   |             |
|    approx_kl             | 0.004574648 |
|    clip_fraction         | 0.0443      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 18          |
|    cost_values           | 1.24        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.81        |
|    n_updates             | 7430        |
|    policy_gradient_loss  | -0.00332    |
|    std                   | 0.565       |
|    value_loss            | 0.897       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.45727736  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 295          |
|    total_timesteps       | 1525760      |
| train/                   |              |
|    approx_kl             | 0.0061799632 |
|    clip_fraction         | 0.072        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.97         |
|    cost_value_loss       | 48.2         |
|    cost_values           | 1.95         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.828        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 7440         |
|    policy_gradient_loss  | -0.00652     |
|    std                   | 0.565        |
|    value_loss            | 0.334        |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.16        |
| reward                   | -0.5627858  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 326         |
|    total_timesteps       | 1527808     |
| train/                   |             |
|    approx_kl             | 0.008047115 |
|    clip_fraction         | 0.0767      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 18.9        |
|    cost_values           | 2.74        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.000261    |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 7450        |
|    policy_gradient_loss  | -0.00459    |
|    std                   | 0.564       |
|    value_loss            | 6.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.40201995  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 12           |
|    time_elapsed          | 357          |
|    total_timesteps       | 1529856      |
| train/                   |              |
|    approx_kl             | 0.0066516576 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.43         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 2.33         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0.000256     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.51         |
|    n_updates             | 7460         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.563        |
|    value_loss            | 1.57         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 3.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.94         |
| reward                   | -0.3882998   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 387          |
|    total_timesteps       | 1531904      |
| train/                   |              |
|    approx_kl             | 0.0047327583 |
|    clip_fraction         | 0.087        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 25.4         |
|    cost_values           | 2.2          |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 7470         |
|    policy_gradient_loss  | -0.00737     |
|    std                   | 0.563        |
|    value_loss            | 1.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47960111 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 418         |
|    total_timesteps       | 1533952     |
| train/                   |             |
|    approx_kl             | 0.003434563 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.05        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.000539    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 7480        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.562       |
|    value_loss            | 1.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.69140226  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 448          |
|    total_timesteps       | 1536000      |
| train/                   |              |
|    approx_kl             | 0.0049305856 |
|    clip_fraction         | 0.0402       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 1.9          |
|    cost_values           | 1.77         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.83         |
|    n_updates             | 7490         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.562        |
|    value_loss            | 1.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.6005355  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 479         |
|    total_timesteps       | 1538048     |
| train/                   |             |
|    approx_kl             | 0.004844013 |
|    clip_fraction         | 0.0639      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 1.4         |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.65        |
|    n_updates             | 7500        |
|    policy_gradient_loss  | -0.00657    |
|    std                   | 0.562       |
|    value_loss            | 0.931       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.44407728  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 509          |
|    total_timesteps       | 1540096      |
| train/                   |              |
|    approx_kl             | 0.0061507476 |
|    clip_fraction         | 0.0687       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.91         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 1.26         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.6          |
|    n_updates             | 7510         |
|    policy_gradient_loss  | -0.00708     |
|    std                   | 0.561        |
|    value_loss            | 0.963        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.589113    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 540          |
|    total_timesteps       | 1542144      |
| train/                   |              |
|    approx_kl             | 0.0068758237 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.64         |
|    cost_value_loss       | 8.41         |
|    cost_values           | 1.22         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.75         |
|    n_updates             | 7520         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.56         |
|    value_loss            | 1.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.29816315 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 570         |
|    total_timesteps       | 1544192     |
| train/                   |             |
|    approx_kl             | 0.004173243 |
|    clip_fraction         | 0.0709      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.04        |
|    cost_value_loss       | 19          |
|    cost_values           | 1.11        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 7530        |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 0.56        |
|    value_loss            | 5.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5581673  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 601         |
|    total_timesteps       | 1546240     |
| train/                   |             |
|    approx_kl             | 0.005171995 |
|    clip_fraction         | 0.0476      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 7.48        |
|    cost_values           | 1.14        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 7540        |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.56        |
|    value_loss            | 1.01        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6277596   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 631          |
|    total_timesteps       | 1548288      |
| train/                   |              |
|    approx_kl             | 0.0047943117 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.72         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 1            |
|    entropy               | -1.67        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 7550         |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 0.558        |
|    value_loss            | 1.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.18727088  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 662          |
|    total_timesteps       | 1550336      |
| train/                   |              |
|    approx_kl             | 0.0042060493 |
|    clip_fraction         | 0.0582       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 5.43         |
|    cost_values           | 1            |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.08         |
|    n_updates             | 7560         |
|    policy_gradient_loss  | -0.00599     |
|    std                   | 0.558        |
|    value_loss            | 1.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.94        |
| reward                   | -0.3946175  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 692         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.007141986 |
|    clip_fraction         | 0.0672      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.62        |
|    cost_value_loss       | 8.52        |
|    cost_values           | 1.04        |
|    entropy               | -1.66       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 7570        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.555       |
|    value_loss            | 0.834       |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.62         |
| reward                   | -0.30153048  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 723          |
|    total_timesteps       | 1554432      |
| train/                   |              |
|    approx_kl             | 0.0059642247 |
|    clip_fraction         | 0.071        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.65         |
|    cost_value_loss       | 16           |
|    cost_values           | 1.03         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.19         |
|    n_updates             | 7580         |
|    policy_gradient_loss  | -0.00813     |
|    std                   | 0.553        |
|    value_loss            | 0.909        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3606908   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 25           |
|    time_elapsed          | 753          |
|    total_timesteps       | 1556480      |
| train/                   |              |
|    approx_kl             | 0.0039474983 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 4.08         |
|    cost_values           | 1.06         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.08         |
|    n_updates             | 7590         |
|    policy_gradient_loss  | -0.00519     |
|    std                   | 0.555        |
|    value_loss            | 0.482        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3526906   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 784          |
|    total_timesteps       | 1558528      |
| train/                   |              |
|    approx_kl             | 0.0062319827 |
|    clip_fraction         | 0.0757       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.73         |
|    cost_value_loss       | 21.8         |
|    cost_values           | 1.19         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 7600         |
|    policy_gradient_loss  | -0.00735     |
|    std                   | 0.555        |
|    value_loss            | 1.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.97         |
| reward                   | -0.55592674  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 815          |
|    total_timesteps       | 1560576      |
| train/                   |              |
|    approx_kl             | 0.0070063383 |
|    clip_fraction         | 0.0788       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.39         |
|    cost_value_loss       | 26           |
|    cost_values           | 1.6          |
|    entropy               | -1.65        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 7610         |
|    policy_gradient_loss  | -0.00646     |
|    std                   | 0.552        |
|    value_loss            | 0.734        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.03         |
| reward                   | -0.63990337  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 845          |
|    total_timesteps       | 1562624      |
| train/                   |              |
|    approx_kl             | 0.0053291926 |
|    clip_fraction         | 0.0693       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 6.51         |
|    cost_values           | 1.82         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 7620         |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.554        |
|    value_loss            | 0.543        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3648029   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 876          |
|    total_timesteps       | 1564672      |
| train/                   |              |
|    approx_kl             | 0.0074191163 |
|    clip_fraction         | 0.107        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.06         |
|    cost_value_loss       | 9.15         |
|    cost_values           | 2.12         |
|    entropy               | -1.65        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0.00654      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.93         |
|    n_updates             | 7630         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.552        |
|    value_loss            | 0.225        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.35777587  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 30           |
|    time_elapsed          | 906          |
|    total_timesteps       | 1566720      |
| train/                   |              |
|    approx_kl             | 0.0024154093 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.76         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 2.48         |
|    entropy               | -1.64        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0.00339      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 7640         |
|    policy_gradient_loss  | -4.69e-05    |
|    std                   | 0.549        |
|    value_loss            | 0.498        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27870914 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 937         |
|    total_timesteps       | 1568768     |
| train/                   |             |
|    approx_kl             | 0.006554556 |
|    clip_fraction         | 0.0838      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 19.4        |
|    cost_values           | 2.71        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0.00294     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.72        |
|    n_updates             | 7650        |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 0.546       |
|    value_loss            | 0.441       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.66071254 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 967         |
|    total_timesteps       | 1570816     |
| train/                   |             |
|    approx_kl             | 0.009215182 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.28        |
|    cost_value_loss       | 18          |
|    cost_values           | 2.73        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0.00378     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 7660        |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.546       |
|    value_loss            | 0.558       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7021236  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 998         |
|    total_timesteps       | 1572864     |
| train/                   |             |
|    approx_kl             | 0.013306632 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 16.4        |
|    cost_values           | 2.62        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.23        |
|    n_updates             | 7670        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.546       |
|    value_loss            | 4.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.5638019   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 34           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 1574912      |
| train/                   |              |
|    approx_kl             | 0.0063349046 |
|    clip_fraction         | 0.0747       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.62         |
|    cost_value_loss       | 18.9         |
|    cost_values           | 2.51         |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.00178      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.12         |
|    n_updates             | 7680         |
|    policy_gradient_loss  | -0.008       |
|    std                   | 0.546        |
|    value_loss            | 0.825        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.55792004 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 1576960     |
| train/                   |             |
|    approx_kl             | 0.004537476 |
|    clip_fraction         | 0.0409      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.59        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0.000216    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.63        |
|    n_updates             | 7690        |
|    policy_gradient_loss  | -0.00479    |
|    std                   | 0.544       |
|    value_loss            | 0.746       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.48954153  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 1579008      |
| train/                   |              |
|    approx_kl             | 0.0052825976 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 6.29         |
|    cost_values           | 2.45         |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.41         |
|    n_updates             | 7700         |
|    policy_gradient_loss  | -0.00459     |
|    std                   | 0.543        |
|    value_loss            | 0.576        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.24972259 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1119        |
|    total_timesteps       | 1581056     |
| train/                   |             |
|    approx_kl             | 0.004234876 |
|    clip_fraction         | 0.064       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 5.99        |
|    cost_values           | 2.12        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.27        |
|    n_updates             | 7710        |
|    policy_gradient_loss  | -0.00552    |
|    std                   | 0.543       |
|    value_loss            | 0.604       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4710378  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1150        |
|    total_timesteps       | 1583104     |
| train/                   |             |
|    approx_kl             | 0.005304442 |
|    clip_fraction         | 0.0413      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.96        |
|    cost_value_loss       | 16.1        |
|    cost_values           | 1.83        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.12        |
|    n_updates             | 7720        |
|    policy_gradient_loss  | -0.00335    |
|    std                   | 0.541       |
|    value_loss            | 0.292       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.43558106  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1180         |
|    total_timesteps       | 1585152      |
| train/                   |              |
|    approx_kl             | 0.0047678566 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 4.92         |
|    cost_values           | 1.72         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.76         |
|    n_updates             | 7730         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.54         |
|    value_loss            | 0.677        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.214        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.214        |
| reward                   | -0.4337017   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1211         |
|    total_timesteps       | 1587200      |
| train/                   |              |
|    approx_kl             | 0.0073870867 |
|    clip_fraction         | 0.0523       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 16           |
|    cost_values           | 1.51         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.88         |
|    n_updates             | 7740         |
|    policy_gradient_loss  | -0.00552     |
|    std                   | 0.54         |
|    value_loss            | 0.881        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.34        |
| reward                   | -0.25508207 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1242        |
|    total_timesteps       | 1589248     |
| train/                   |             |
|    approx_kl             | 0.004794216 |
|    clip_fraction         | 0.0601      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.81        |
|    cost_value_loss       | 29          |
|    cost_values           | 1.83        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.2        |
|    n_updates             | 7750        |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.54        |
|    value_loss            | 0.403       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.844       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.844       |
| reward                   | -0.36804068 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1272        |
|    total_timesteps       | 1591296     |
| train/                   |             |
|    approx_kl             | 0.010832863 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 1.78        |
|    cost_values           | 1.98        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.32        |
|    n_updates             | 7760        |
|    policy_gradient_loss  | -0.00486    |
|    std                   | 0.541       |
|    value_loss            | 0.559       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.60011476  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1302         |
|    total_timesteps       | 1593344      |
| train/                   |              |
|    approx_kl             | 0.0076720696 |
|    clip_fraction         | 0.0609       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.9          |
|    cost_value_loss       | 18.3         |
|    cost_values           | 1.6          |
|    entropy               | -1.61        |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.83         |
|    n_updates             | 7770         |
|    policy_gradient_loss  | -0.00548     |
|    std                   | 0.541        |
|    value_loss            | 1            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.7365861   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1333         |
|    total_timesteps       | 1595392      |
| train/                   |              |
|    approx_kl             | 0.0041139442 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 7.64         |
|    cost_values           | 1.55         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.04         |
|    n_updates             | 7780         |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 0.539        |
|    value_loss            | 1.08         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.15        |
| reward                   | -0.221599   |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1363        |
|    total_timesteps       | 1597440     |
| train/                   |             |
|    approx_kl             | 0.004911502 |
|    clip_fraction         | 0.0679      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 9.88        |
|    cost_values           | 1.37        |
|    entropy               | -1.6        |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 7790        |
|    policy_gradient_loss  | -0.00588    |
|    std                   | 0.538       |
|    value_loss            | 0.811       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.96         |
| reward                   | -0.53782356  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1394         |
|    total_timesteps       | 1599488      |
| train/                   |              |
|    approx_kl             | 0.0062953457 |
|    clip_fraction         | 0.067        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.68         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 1.37         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.99         |
|    n_updates             | 7800         |
|    policy_gradient_loss  | -0.00576     |
|    std                   | 0.536        |
|    value_loss            | 2.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.25         |
| reward                   | -0.4318973   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1424         |
|    total_timesteps       | 1601536      |
| train/                   |              |
|    approx_kl             | 0.0054603647 |
|    clip_fraction         | 0.0518       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 1.28         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.3          |
|    n_updates             | 7810         |
|    policy_gradient_loss  | -0.00548     |
|    std                   | 0.536        |
|    value_loss            | 0.572        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.4800427   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1455         |
|    total_timesteps       | 1603584      |
| train/                   |              |
|    approx_kl             | 0.0071993577 |
|    clip_fraction         | 0.0648       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.54         |
|    cost_value_loss       | 20           |
|    cost_values           | 1.42         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 7820         |
|    policy_gradient_loss  | -0.00588     |
|    std                   | 0.535        |
|    value_loss            | 0.83         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24066636 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1486        |
|    total_timesteps       | 1605632     |
| train/                   |             |
|    approx_kl             | 0.007967342 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 1.81        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.15        |
|    n_updates             | 7830        |
|    policy_gradient_loss  | -0.00897    |
|    std                   | 0.533       |
|    value_loss            | 0.768       |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.35929438 |
| rollout/           |             |
|    ep_len_mean     | 991         |
|    ep_rew_mean     | -458        |
| time/              |             |
|    fps             | 100         |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 1607680     |
------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.52357084 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 2           |
|    time_elapsed          | 50          |
|    total_timesteps       | 1609728     |
| train/                   |             |
|    approx_kl             | 0.009586306 |
|    clip_fraction         | 0.0808      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.67        |
|    cost_value_loss       | 3.58        |
|    cost_values           | 1.76        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.96        |
|    n_updates             | 7850        |
|    policy_gradient_loss  | -0.00679    |
|    std                   | 0.529       |
|    value_loss            | 0.841       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.54095227  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1611776      |
| train/                   |              |
|    approx_kl             | 0.0071868636 |
|    clip_fraction         | 0.0666       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 1.66         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.68         |
|    n_updates             | 7860         |
|    policy_gradient_loss  | -0.007       |
|    std                   | 0.53         |
|    value_loss            | 0.734        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 1.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.59        |
| reward                   | -0.18649784 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.004883772 |
|    clip_fraction         | 0.0537      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 15.3        |
|    cost_values           | 1.74        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.48        |
|    n_updates             | 7870        |
|    policy_gradient_loss  | -0.00541    |
|    std                   | 0.53        |
|    value_loss            | 1.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.22061834 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1615872     |
| train/                   |             |
|    approx_kl             | 0.006083573 |
|    clip_fraction         | 0.0445      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.06        |
|    cost_value_loss       | 12          |
|    cost_values           | 1.79        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 7880        |
|    policy_gradient_loss  | -0.00486    |
|    std                   | 0.53        |
|    value_loss            | 0.175       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.93         |
| reward                   | -0.56881547  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 6            |
|    time_elapsed          | 173          |
|    total_timesteps       | 1617920      |
| train/                   |              |
|    approx_kl             | 0.0033078236 |
|    clip_fraction         | 0.0736       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.19         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 2.3          |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.09         |
|    n_updates             | 7890         |
|    policy_gradient_loss  | -0.00704     |
|    std                   | 0.532        |
|    value_loss            | 0.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.06        |
| reward                   | -0.50383157 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 204         |
|    total_timesteps       | 1619968     |
| train/                   |             |
|    approx_kl             | 0.007950547 |
|    clip_fraction         | 0.0559      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 0.401       |
|    cost_values           | 2.4         |
|    entropy               | -1.57       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.612       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 7900        |
|    policy_gradient_loss  | -0.00332    |
|    std                   | 0.532       |
|    value_loss            | 8.12        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.35        |
| reward                   | -0.5143058  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 234         |
|    total_timesteps       | 1622016     |
| train/                   |             |
|    approx_kl             | 0.005212326 |
|    clip_fraction         | 0.0387      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 4.13        |
|    cost_values           | 1.97        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 7910        |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 0.53        |
|    value_loss            | 1.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.74         |
| reward                   | -0.26774117  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 265          |
|    total_timesteps       | 1624064      |
| train/                   |              |
|    approx_kl             | 0.0073718783 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.568        |
|    cost_values           | 1.54         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.441        |
|    n_updates             | 7920         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.528        |
|    value_loss            | 0.705        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.93         |
| reward                   | -0.46518585  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 295          |
|    total_timesteps       | 1626112      |
| train/                   |              |
|    approx_kl             | 0.0051416205 |
|    clip_fraction         | 0.0976       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 6.6          |
|    cost_values           | 1.19         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 7930         |
|    policy_gradient_loss  | -0.000462    |
|    std                   | 0.528        |
|    value_loss            | 4.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.02        |
| reward                   | -0.47730875 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 326         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.008163869 |
|    clip_fraction         | 0.0905      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 6.49        |
|    cost_values           | 1.18        |
|    entropy               | -1.55       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.44        |
|    n_updates             | 7940        |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 0.526       |
|    value_loss            | 0.826       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5718545   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 12           |
|    time_elapsed          | 356          |
|    total_timesteps       | 1630208      |
| train/                   |              |
|    approx_kl             | 0.0060889805 |
|    clip_fraction         | 0.0697       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 3.79         |
|    cost_values           | 1.18         |
|    entropy               | -1.54        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.5          |
|    n_updates             | 7950         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.524        |
|    value_loss            | 0.804        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.93         |
| reward                   | -0.55353683  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 387          |
|    total_timesteps       | 1632256      |
| train/                   |              |
|    approx_kl             | 0.0042349603 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 8.15         |
|    cost_values           | 1.17         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.42         |
|    n_updates             | 7960         |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 0.526        |
|    value_loss            | 0.404        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.17         |
| reward                   | -0.4321724   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 417          |
|    total_timesteps       | 1634304      |
| train/                   |              |
|    approx_kl             | 0.0030809066 |
|    clip_fraction         | 0.0828       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 1.71         |
|    cost_values           | 1.32         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.801        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.47         |
|    n_updates             | 7970         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.531        |
|    value_loss            | 0.975        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5371953   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 448          |
|    total_timesteps       | 1636352      |
| train/                   |              |
|    approx_kl             | 0.0058769966 |
|    clip_fraction         | 0.0649       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.33         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 1.35         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.12         |
|    n_updates             | 7980         |
|    policy_gradient_loss  | -0.00796     |
|    std                   | 0.531        |
|    value_loss            | 0.903        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 5.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.28         |
| reward                   | -0.59976286  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 479          |
|    total_timesteps       | 1638400      |
| train/                   |              |
|    approx_kl             | 0.0051320987 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.3          |
|    cost_value_loss       | 43.8         |
|    cost_values           | 1.55         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.3         |
|    n_updates             | 7990         |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 0.53         |
|    value_loss            | 0.339        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3863154   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 510          |
|    total_timesteps       | 1640448      |
| train/                   |              |
|    approx_kl             | 0.0059398073 |
|    clip_fraction         | 0.0709       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 4.66         |
|    cost_values           | 1.86         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.4          |
|    n_updates             | 8000         |
|    policy_gradient_loss  | -0.00557     |
|    std                   | 0.53         |
|    value_loss            | 0.433        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5205295   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 540          |
|    total_timesteps       | 1642496      |
| train/                   |              |
|    approx_kl             | 0.0065094708 |
|    clip_fraction         | 0.0539       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.83         |
|    cost_value_loss       | 9.42         |
|    cost_values           | 2.03         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.24         |
|    n_updates             | 8010         |
|    policy_gradient_loss  | -0.0047      |
|    std                   | 0.53         |
|    value_loss            | 0.866        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.22270256  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 571          |
|    total_timesteps       | 1644544      |
| train/                   |              |
|    approx_kl             | 0.0058322093 |
|    clip_fraction         | 0.0546       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.73         |
|    cost_value_loss       | 29.2         |
|    cost_values           | 2.13         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0.00431      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 8020         |
|    policy_gradient_loss  | -0.00471     |
|    std                   | 0.53         |
|    value_loss            | 4.25         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -0.7513    |
| rollout/                 |            |
|    ep_len_mean           | 984        |
|    ep_rew_mean           | -441       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 20         |
|    time_elapsed          | 601        |
|    total_timesteps       | 1646592    |
| train/                   |            |
|    approx_kl             | 0.00585978 |
|    clip_fraction         | 0.0466     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.29       |
|    cost_value_loss       | 3.09       |
|    cost_values           | 1.83       |
|    entropy               | -1.57      |
|    entropy_loss          | -1.57      |
|    explained_variance    | 0.972      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.93       |
|    n_updates             | 8030       |
|    policy_gradient_loss  | -0.005     |
|    std                   | 0.531      |
|    value_loss            | 1.04       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.86        |
| reward                   | -0.42888126 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 632         |
|    total_timesteps       | 1648640     |
| train/                   |             |
|    approx_kl             | 0.004261445 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 19.3        |
|    cost_values           | 1.52        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 8040        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.529       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.66437876 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 662         |
|    total_timesteps       | 1650688     |
| train/                   |             |
|    approx_kl             | 0.009744507 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.29        |
|    cost_value_loss       | 6.99        |
|    cost_values           | 2           |
|    entropy               | -1.55       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 8050        |
|    policy_gradient_loss  | -0.00974    |
|    std                   | 0.526       |
|    value_loss            | 0.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.08        |
| reward                   | -0.5702031  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 23          |
|    time_elapsed          | 692         |
|    total_timesteps       | 1652736     |
| train/                   |             |
|    approx_kl             | 0.008040198 |
|    clip_fraction         | 0.0883      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 0.992       |
|    cost_values           | 1.78        |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.778       |
|    n_updates             | 8060        |
|    policy_gradient_loss  | -0.00588    |
|    std                   | 0.526       |
|    value_loss            | 0.527       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.3362482  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 723         |
|    total_timesteps       | 1654784     |
| train/                   |             |
|    approx_kl             | 0.004526805 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.29        |
|    cost_value_loss       | 7.98        |
|    cost_values           | 1.48        |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 8070        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.526       |
|    value_loss            | 0.913       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.49        |
| reward                   | -0.5279333  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 25          |
|    time_elapsed          | 753         |
|    total_timesteps       | 1656832     |
| train/                   |             |
|    approx_kl             | 0.008726084 |
|    clip_fraction         | 0.0722      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.0405      |
|    cost_values           | 0.976       |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.333       |
|    n_updates             | 8080        |
|    policy_gradient_loss  | -0.00439    |
|    std                   | 0.528       |
|    value_loss            | 0.572       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4477629   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 784          |
|    total_timesteps       | 1658880      |
| train/                   |              |
|    approx_kl             | 0.0059871594 |
|    clip_fraction         | 0.0709       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 17.7         |
|    cost_values           | 1.03         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.58         |
|    n_updates             | 8090         |
|    policy_gradient_loss  | -0.0065      |
|    std                   | 0.531        |
|    value_loss            | 0.395        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.31858575 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 814         |
|    total_timesteps       | 1660928     |
| train/                   |             |
|    approx_kl             | 0.009816298 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.36        |
|    cost_value_loss       | 9.6         |
|    cost_values           | 1.31        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 8100        |
|    policy_gradient_loss  | -0.00738    |
|    std                   | 0.53        |
|    value_loss            | 0.728       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.23        |
| reward                   | -0.3838226  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 845         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.008811053 |
|    clip_fraction         | 0.0831      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 1.02        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.95        |
|    n_updates             | 8110        |
|    policy_gradient_loss  | -0.00685    |
|    std                   | 0.528       |
|    value_loss            | 0.626       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.4018655   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 875          |
|    total_timesteps       | 1665024      |
| train/                   |              |
|    approx_kl             | 0.0035939072 |
|    clip_fraction         | 0.0708       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 9.87         |
|    cost_values           | 1.07         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.586        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.83         |
|    n_updates             | 8120         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.526        |
|    value_loss            | 5            |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.37613147 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 906         |
|    total_timesteps       | 1667072     |
| train/                   |             |
|    approx_kl             | 0.005651443 |
|    clip_fraction         | 0.0672      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.13        |
|    cost_value_loss       | 5.37        |
|    cost_values           | 1.01        |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 8130        |
|    policy_gradient_loss  | -0.00792    |
|    std                   | 0.525       |
|    value_loss            | 0.551       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.40630195  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 31           |
|    time_elapsed          | 936          |
|    total_timesteps       | 1669120      |
| train/                   |              |
|    approx_kl             | 0.0032308595 |
|    clip_fraction         | 0.0286       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.89         |
|    cost_value_loss       | 13           |
|    cost_values           | 1.01         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.79         |
|    n_updates             | 8140         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.525        |
|    value_loss            | 1.51         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.39659464  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 32           |
|    time_elapsed          | 967          |
|    total_timesteps       | 1671168      |
| train/                   |              |
|    approx_kl             | 0.0052490444 |
|    clip_fraction         | 0.074        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 0.722        |
|    cost_values           | 0.964        |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1            |
|    n_updates             | 8150         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.525        |
|    value_loss            | 1.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -0.43034098  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 33           |
|    time_elapsed          | 997          |
|    total_timesteps       | 1673216      |
| train/                   |              |
|    approx_kl             | 0.0044474183 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 1.06         |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 8160         |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 0.524        |
|    value_loss            | 0.409        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.56771153  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 34           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 1675264      |
| train/                   |              |
|    approx_kl             | 0.0053292955 |
|    clip_fraction         | 0.0671       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 14.2         |
|    cost_values           | 1.06         |
|    entropy               | -1.54        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.4          |
|    n_updates             | 8170         |
|    policy_gradient_loss  | -0.00579     |
|    std                   | 0.524        |
|    value_loss            | 0.646        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.5667485   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 35           |
|    time_elapsed          | 1058         |
|    total_timesteps       | 1677312      |
| train/                   |              |
|    approx_kl             | 0.0043686675 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 9.8          |
|    cost_values           | 0.994        |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 8180         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 0.523        |
|    value_loss            | 0.427        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.41672307  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1088         |
|    total_timesteps       | 1679360      |
| train/                   |              |
|    approx_kl             | 0.0045647575 |
|    clip_fraction         | 0.0611       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 7.18         |
|    cost_values           | 0.997        |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 8190         |
|    policy_gradient_loss  | -0.00721     |
|    std                   | 0.522        |
|    value_loss            | 0.772        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.49707848 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1119        |
|    total_timesteps       | 1681408     |
| train/                   |             |
|    approx_kl             | 0.004520379 |
|    clip_fraction         | 0.0559      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 1.16        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.25        |
|    n_updates             | 8200        |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 0.522       |
|    value_loss            | 0.444       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.3390405   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1149         |
|    total_timesteps       | 1683456      |
| train/                   |              |
|    approx_kl             | 0.0065172827 |
|    clip_fraction         | 0.0747       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 1.14         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.94         |
|    n_updates             | 8210         |
|    policy_gradient_loss  | -0.00787     |
|    std                   | 0.521        |
|    value_loss            | 1.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.6          |
| reward                   | -0.47855458  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1179         |
|    total_timesteps       | 1685504      |
| train/                   |              |
|    approx_kl             | 0.0107918875 |
|    clip_fraction         | 0.0851       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 2.43         |
|    cost_values           | 0.995        |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.55         |
|    n_updates             | 8220         |
|    policy_gradient_loss  | -0.00709     |
|    std                   | 0.521        |
|    value_loss            | 0.724        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 6.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.42        |
| reward                   | -0.63002807 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1209        |
|    total_timesteps       | 1687552     |
| train/                   |             |
|    approx_kl             | 0.010083083 |
|    clip_fraction         | 0.0846      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 1.17        |
|    cost_values           | 0.994       |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.885       |
|    n_updates             | 8230        |
|    policy_gradient_loss  | -0.00577    |
|    std                   | 0.521       |
|    value_loss            | 0.662       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.56610817  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1240         |
|    total_timesteps       | 1689600      |
| train/                   |              |
|    approx_kl             | 0.0040478026 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.12         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 1.14         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.85         |
|    n_updates             | 8240         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.519        |
|    value_loss            | 1.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.53942543  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1270         |
|    total_timesteps       | 1691648      |
| train/                   |              |
|    approx_kl             | 0.0066408906 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 4.26         |
|    cost_values           | 1.11         |
|    entropy               | -1.53        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.67         |
|    n_updates             | 8250         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.519        |
|    value_loss            | 0.628        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.44851702 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1300        |
|    total_timesteps       | 1693696     |
| train/                   |             |
|    approx_kl             | 0.009367046 |
|    clip_fraction         | 0.0839      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 4.93        |
|    cost_values           | 1.01        |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.8         |
|    n_updates             | 8260        |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.519       |
|    value_loss            | 0.371       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.34346882 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1330        |
|    total_timesteps       | 1695744     |
| train/                   |             |
|    approx_kl             | 0.01150696  |
|    clip_fraction         | 0.0686      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 2.17        |
|    cost_values           | 1           |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.47        |
|    n_updates             | 8270        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.52        |
|    value_loss            | 0.514       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.51        |
| reward                   | -0.48893782 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1361        |
|    total_timesteps       | 1697792     |
| train/                   |             |
|    approx_kl             | 0.012223347 |
|    clip_fraction         | 0.0884      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 7.99        |
|    cost_values           | 1.2         |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.81        |
|    n_updates             | 8280        |
|    policy_gradient_loss  | -0.00707    |
|    std                   | 0.521       |
|    value_loss            | 0.542       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.69        |
| reward                   | -0.45176902 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1392        |
|    total_timesteps       | 1699840     |
| train/                   |             |
|    approx_kl             | 0.00815288  |
|    clip_fraction         | 0.0646      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 18.4        |
|    cost_values           | 1.79        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.37        |
|    n_updates             | 8290        |
|    policy_gradient_loss  | -0.00403    |
|    std                   | 0.519       |
|    value_loss            | 0.955       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.444902    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1422         |
|    total_timesteps       | 1701888      |
| train/                   |              |
|    approx_kl             | 0.0090805665 |
|    clip_fraction         | 0.091        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 2.21         |
|    entropy               | -1.51        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 8300         |
|    policy_gradient_loss  | -0.00588     |
|    std                   | 0.516        |
|    value_loss            | 0.298        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 1.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.94         |
| reward                   | -0.40089712  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1453         |
|    total_timesteps       | 1703936      |
| train/                   |              |
|    approx_kl             | 0.0134834405 |
|    clip_fraction         | 0.141        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 7.24         |
|    cost_values           | 2.26         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0.00166      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.14         |
|    n_updates             | 8310         |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.517        |
|    value_loss            | 0.465        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3314348  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1483        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.012240045 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 0.467       |
|    cost_values           | 1.99        |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.509       |
|    n_updates             | 8320        |
|    policy_gradient_loss  | -0.000769   |
|    std                   | 0.518       |
|    value_loss            | 0.46        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.2672042 |
| rollout/           |            |
|    ep_len_mean     | 983        |
|    ep_rew_mean     | -433       |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 1708032    |
-----------------------------------
------------------------------------------
| avg_speed                | 3.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.82        |
| reward                   | -0.41006017 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 1710080     |
| train/                   |             |
|    approx_kl             | 0.006306451 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 3.15        |
|    cost_values           | 1.52        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.86        |
|    n_updates             | 8340        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.516       |
|    value_loss            | 0.721       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 3.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.41         |
| reward                   | -0.31613117  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1712128      |
| train/                   |              |
|    approx_kl             | 0.0056067393 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 0.937        |
|    cost_values           | 1.03         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.02         |
|    n_updates             | 8350         |
|    policy_gradient_loss  | -0.00533     |
|    std                   | 0.516        |
|    value_loss            | 0.869        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.5433817  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 1714176     |
| train/                   |             |
|    approx_kl             | 0.008580646 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.04        |
|    cost_values           | 0.99        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.645       |
|    n_updates             | 8360        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.516       |
|    value_loss            | 0.145       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.55541915 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1716224     |
| train/                   |             |
|    approx_kl             | 0.009062572 |
|    clip_fraction         | 0.0929      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.98        |
|    cost_value_loss       | 2.54        |
|    cost_values           | 1.02        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.22        |
|    n_updates             | 8370        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.514       |
|    value_loss            | 0.327       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5008429   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 1718272      |
| train/                   |              |
|    approx_kl             | 0.0069172787 |
|    clip_fraction         | 0.0788       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.928        |
|    cost_value_loss       | 0.115        |
|    cost_values           | 0.883        |
|    entropy               | -1.5         |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.212        |
|    n_updates             | 8380         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.513        |
|    value_loss            | 0.843        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24979879 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1720320     |
| train/                   |             |
|    approx_kl             | 0.00909501  |
|    clip_fraction         | 0.0805      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 20.5        |
|    cost_values           | 1.3         |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.49        |
|    n_updates             | 8390        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.512       |
|    value_loss            | 0.306       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.34214586  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 8            |
|    time_elapsed          | 233          |
|    total_timesteps       | 1722368      |
| train/                   |              |
|    approx_kl             | 0.0073687285 |
|    clip_fraction         | 0.0752       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 1.85         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.59         |
|    n_updates             | 8400         |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 0.513        |
|    value_loss            | 0.743        |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.94        |
| reward                   | -0.37793893 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 264         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.00664597  |
|    clip_fraction         | 0.0725      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 9.34        |
|    cost_values           | 1.61        |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.94        |
|    n_updates             | 8410        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.512       |
|    value_loss            | 0.692       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.358257    |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 294          |
|    total_timesteps       | 1726464      |
| train/                   |              |
|    approx_kl             | 0.0071581956 |
|    clip_fraction         | 0.0696       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 4.74         |
|    cost_values           | 1.6          |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.73         |
|    n_updates             | 8420         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.514        |
|    value_loss            | 0.213        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 0.0832       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0832       |
| reward                   | -0.42667308  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 325          |
|    total_timesteps       | 1728512      |
| train/                   |              |
|    approx_kl             | 0.0090266755 |
|    clip_fraction         | 0.115        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 1.6          |
|    cost_values           | 1.6          |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.984        |
|    n_updates             | 8430         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.513        |
|    value_loss            | 0.289        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.72         |
| reward                   | -0.37434387  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 355          |
|    total_timesteps       | 1730560      |
| train/                   |              |
|    approx_kl             | 0.0050264816 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 8.79         |
|    cost_values           | 1.76         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 8440         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.512        |
|    value_loss            | 0.263        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.1          |
| reward                   | -0.50615096  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 386          |
|    total_timesteps       | 1732608      |
| train/                   |              |
|    approx_kl             | 0.0076659387 |
|    clip_fraction         | 0.0715       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 5.63         |
|    cost_values           | 2.12         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.12         |
|    n_updates             | 8450         |
|    policy_gradient_loss  | -0.00808     |
|    std                   | 0.511        |
|    value_loss            | 1.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.33        |
| reward                   | -0.54932714 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 416         |
|    total_timesteps       | 1734656     |
| train/                   |             |
|    approx_kl             | 0.011640832 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 0.3         |
|    cost_values           | 1.78        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.321       |
|    n_updates             | 8460        |
|    policy_gradient_loss  | -0.00828    |
|    std                   | 0.51        |
|    value_loss            | 0.517       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 5.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.22         |
| reward                   | -0.33087844  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 447          |
|    total_timesteps       | 1736704      |
| train/                   |              |
|    approx_kl             | 0.0101722665 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 8.47         |
|    cost_values           | 1.5          |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 8470         |
|    policy_gradient_loss  | -0.00607     |
|    std                   | 0.51         |
|    value_loss            | 0.619        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.45732465 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 478         |
|    total_timesteps       | 1738752     |
| train/                   |             |
|    approx_kl             | 0.021347933 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 0.286       |
|    cost_values           | 1.43        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.386       |
|    n_updates             | 8480        |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 0.509       |
|    value_loss            | 0.842       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.08        |
| reward                   | -0.47308138 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 508         |
|    total_timesteps       | 1740800     |
| train/                   |             |
|    approx_kl             | 0.007586929 |
|    clip_fraction         | 0.0812      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 22.3        |
|    cost_values           | 1.23        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 8490        |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 0.509       |
|    value_loss            | 1.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.3         |
| reward                   | -0.27110636 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 539         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.010873454 |
|    clip_fraction         | 0.0907      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.01        |
|    cost_value_loss       | 3.47        |
|    cost_values           | 1.52        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 8500        |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 0.507       |
|    value_loss            | 1.21        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.46465445 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 569         |
|    total_timesteps       | 1744896     |
| train/                   |             |
|    approx_kl             | 0.00559016  |
|    clip_fraction         | 0.0822      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 1.31        |
|    cost_values           | 1.49        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.836       |
|    n_updates             | 8510        |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 0.506       |
|    value_loss            | 0.424       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.6042102   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 600          |
|    total_timesteps       | 1746944      |
| train/                   |              |
|    approx_kl             | 0.0053917672 |
|    clip_fraction         | 0.0729       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 1.33         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.55         |
|    n_updates             | 8520         |
|    policy_gradient_loss  | -0.00518     |
|    std                   | 0.506        |
|    value_loss            | 0.967        |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.05        |
| reward                   | -0.55172616 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 631         |
|    total_timesteps       | 1748992     |
| train/                   |             |
|    approx_kl             | 0.009110593 |
|    clip_fraction         | 0.0639      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 1.91        |
|    cost_values           | 1.39        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.15        |
|    n_updates             | 8530        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.505       |
|    value_loss            | 0.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.05         |
| reward                   | -0.23337834  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 661          |
|    total_timesteps       | 1751040      |
| train/                   |              |
|    approx_kl             | 0.0071261404 |
|    clip_fraction         | 0.103        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 8.87         |
|    cost_values           | 1.18         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 8540         |
|    policy_gradient_loss  | -0.00571     |
|    std                   | 0.504        |
|    value_loss            | 0.563        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.34        |
| reward                   | -0.4192833  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 692         |
|    total_timesteps       | 1753088     |
| train/                   |             |
|    approx_kl             | 0.007684104 |
|    clip_fraction         | 0.0621      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 1.98        |
|    cost_values           | 1.15        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.16        |
|    n_updates             | 8550        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.504       |
|    value_loss            | 5.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.04        |
| reward                   | -0.51139057 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 723         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.008181534 |
|    clip_fraction         | 0.0743      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 1.09        |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.63        |
|    n_updates             | 8560        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.502       |
|    value_loss            | 0.316       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.743      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.743      |
| reward                   | -0.3669736 |
| rollout/                 |            |
|    ep_len_mean           | 994        |
|    ep_rew_mean           | -439       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 25         |
|    time_elapsed          | 753        |
|    total_timesteps       | 1757184    |
| train/                   |            |
|    approx_kl             | 0.00994125 |
|    clip_fraction         | 0.118      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.17       |
|    cost_value_loss       | 19.8       |
|    cost_values           | 1.3        |
|    entropy               | -1.45      |
|    entropy_loss          | -1.46      |
|    explained_variance    | 0.995      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.2       |
|    n_updates             | 8570       |
|    policy_gradient_loss  | -0.0077    |
|    std                   | 0.501      |
|    value_loss            | 0.487      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 6.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.08         |
| reward                   | -0.57415164  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 784          |
|    total_timesteps       | 1759232      |
| train/                   |              |
|    approx_kl             | 0.0069934777 |
|    clip_fraction         | 0.0872       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.76         |
|    cost_value_loss       | 8.11         |
|    cost_values           | 1.15         |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.85         |
|    n_updates             | 8580         |
|    policy_gradient_loss  | -0.00536     |
|    std                   | 0.5          |
|    value_loss            | 4.2          |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.52573824  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 815          |
|    total_timesteps       | 1761280      |
| train/                   |              |
|    approx_kl             | 0.0059494385 |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.6          |
|    cost_value_loss       | 25.7         |
|    cost_values           | 1.12         |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 4.53e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 8590         |
|    policy_gradient_loss  | -0.00528     |
|    std                   | 0.5          |
|    value_loss            | 1.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.51166594  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 845          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 0.0074937963 |
|    clip_fraction         | 0.0678       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 1.66         |
|    cost_values           | 1.2          |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.28         |
|    n_updates             | 8600         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 0.499        |
|    value_loss            | 1.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.79         |
| reward                   | -0.38400647  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 875          |
|    total_timesteps       | 1765376      |
| train/                   |              |
|    approx_kl             | 0.0090178065 |
|    clip_fraction         | 0.125        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 3.12         |
|    cost_values           | 0.957        |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.72         |
|    n_updates             | 8610         |
|    policy_gradient_loss  | -0.00476     |
|    std                   | 0.497        |
|    value_loss            | 0.499        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.43333325  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 30           |
|    time_elapsed          | 906          |
|    total_timesteps       | 1767424      |
| train/                   |              |
|    approx_kl             | 0.0065523377 |
|    clip_fraction         | 0.0664       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 0.937        |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.73         |
|    n_updates             | 8620         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.496        |
|    value_loss            | 1.98         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.77        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.77        |
| reward                   | -0.41450027 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 936         |
|    total_timesteps       | 1769472     |
| train/                   |             |
|    approx_kl             | 0.007958893 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 28          |
|    cost_values           | 1.05        |
|    entropy               | -1.43       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.1        |
|    n_updates             | 8630        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.496       |
|    value_loss            | 4.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.64764786 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 967         |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.004130503 |
|    clip_fraction         | 0.0672      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.59        |
|    cost_value_loss       | 7.44        |
|    cost_values           | 1.05        |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 8640        |
|    policy_gradient_loss  | -0.00429    |
|    std                   | 0.495       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23097247 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 998         |
|    total_timesteps       | 1773568     |
| train/                   |             |
|    approx_kl             | 0.005170994 |
|    clip_fraction         | 0.0712      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 22.6        |
|    cost_values           | 0.998       |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 8650        |
|    policy_gradient_loss  | -0.00737    |
|    std                   | 0.494       |
|    value_loss            | 1.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.3899695  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1028        |
|    total_timesteps       | 1775616     |
| train/                   |             |
|    approx_kl             | 0.010846004 |
|    clip_fraction         | 0.0674      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.867       |
|    cost_value_loss       | 0.0575      |
|    cost_values           | 0.934       |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.123       |
|    n_updates             | 8660        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.494       |
|    value_loss            | 0.387       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.31        |
| reward                   | -0.33551067 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 1777664     |
| train/                   |             |
|    approx_kl             | 0.008495787 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.46        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 1.03        |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.04        |
|    n_updates             | 8670        |
|    policy_gradient_loss  | -0.000848   |
|    std                   | 0.494       |
|    value_loss            | 1.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.41         |
| reward                   | -0.67397034  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 1779712      |
| train/                   |              |
|    approx_kl             | 0.0040201526 |
|    clip_fraction         | 0.0719       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 2.2          |
|    cost_values           | 0.997        |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.835        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.34         |
|    n_updates             | 8680         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.494        |
|    value_loss            | 3.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.77        |
| reward                   | -0.4834421  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1120        |
|    total_timesteps       | 1781760     |
| train/                   |             |
|    approx_kl             | 0.004809933 |
|    clip_fraction         | 0.0593      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 1           |
|    entropy               | -1.42       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 8690        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 0.493       |
|    value_loss            | 0.654       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.43        |
| reward                   | -0.3340827  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1150        |
|    total_timesteps       | 1783808     |
| train/                   |             |
|    approx_kl             | 0.007242553 |
|    clip_fraction         | 0.094       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.37        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 1.26        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 8700        |
|    policy_gradient_loss  | -0.00712    |
|    std                   | 0.491       |
|    value_loss            | 0.226       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.81         |
| reward                   | -0.5068236   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1180         |
|    total_timesteps       | 1785856      |
| train/                   |              |
|    approx_kl             | 0.0053056055 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 3.98         |
|    cost_values           | 1.39         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.09         |
|    n_updates             | 8710         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.492        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4866092  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1211        |
|    total_timesteps       | 1787904     |
| train/                   |             |
|    approx_kl             | 0.010895573 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 3.01        |
|    cost_values           | 1.02        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 8720        |
|    policy_gradient_loss  | -0.00736    |
|    std                   | 0.493       |
|    value_loss            | 4.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.11         |
| reward                   | -0.5038032   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1242         |
|    total_timesteps       | 1789952      |
| train/                   |              |
|    approx_kl             | 0.0051525296 |
|    clip_fraction         | 0.0646       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 19.5         |
|    cost_values           | 1.07         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 8730         |
|    policy_gradient_loss  | -0.0067      |
|    std                   | 0.492        |
|    value_loss            | 1.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.34         |
| reward                   | -0.31965292  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 1792000      |
| train/                   |              |
|    approx_kl             | 0.0072371652 |
|    clip_fraction         | 0.0897       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.75         |
|    cost_value_loss       | 27.8         |
|    cost_values           | 1.46         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 8740         |
|    policy_gradient_loss  | -0.00721     |
|    std                   | 0.492        |
|    value_loss            | 0.472        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.49456295 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1303        |
|    total_timesteps       | 1794048     |
| train/                   |             |
|    approx_kl             | 0.012033148 |
|    clip_fraction         | 0.0803      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 4.11        |
|    cost_values           | 1.85        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 8750        |
|    policy_gradient_loss  | -0.00724    |
|    std                   | 0.491       |
|    value_loss            | 0.974       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.25935555  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1333         |
|    total_timesteps       | 1796096      |
| train/                   |              |
|    approx_kl             | 0.0074309446 |
|    clip_fraction         | 0.0802       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.4          |
|    cost_value_loss       | 19.5         |
|    cost_values           | 1.74         |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 8760         |
|    policy_gradient_loss  | -0.00358     |
|    std                   | 0.489        |
|    value_loss            | 0.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.91        |
| reward                   | -0.35159108 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1364        |
|    total_timesteps       | 1798144     |
| train/                   |             |
|    approx_kl             | 0.007442239 |
|    clip_fraction         | 0.08        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.02        |
|    cost_value_loss       | 21.1        |
|    cost_values           | 2.06        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 8770        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.488       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.08        |
| reward                   | -0.54604733 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1395        |
|    total_timesteps       | 1800192     |
| train/                   |             |
|    approx_kl             | 0.005839755 |
|    clip_fraction         | 0.0456      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.33        |
|    cost_value_loss       | 32.1        |
|    cost_values           | 2.2         |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.7        |
|    n_updates             | 8780        |
|    policy_gradient_loss  | -0.00524    |
|    std                   | 0.487       |
|    value_loss            | 0.7         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.3899414  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1425        |
|    total_timesteps       | 1802240     |
| train/                   |             |
|    approx_kl             | 0.007721353 |
|    clip_fraction         | 0.0967      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 4.53        |
|    cost_values           | 2.2         |
|    entropy               | -1.39       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.77        |
|    n_updates             | 8790        |
|    policy_gradient_loss  | -0.00643    |
|    std                   | 0.486       |
|    value_loss            | 0.457       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.19366352  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1456         |
|    total_timesteps       | 1804288      |
| train/                   |              |
|    approx_kl             | 0.0059011066 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.56         |
|    cost_value_loss       | 25           |
|    cost_values           | 2.12         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 8800         |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 0.485        |
|    value_loss            | 0.938        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.34394163  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1486         |
|    total_timesteps       | 1806336      |
| train/                   |              |
|    approx_kl             | 0.0031947785 |
|    clip_fraction         | 0.0817       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 8.22         |
|    cost_values           | 2.2          |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.14         |
|    n_updates             | 8810         |
|    policy_gradient_loss  | -0.00543     |
|    std                   | 0.485        |
|    value_loss            | 0.443        |
-------------------------------------------
------------------------------------
| avg_speed          | 2.57        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 2.57        |
| reward             | -0.38224936 |
| rollout/           |             |
|    ep_len_mean     | 991         |
|    ep_rew_mean     | -449        |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 1808384     |
------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.06        |
| reward                   | -0.55794466 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 1810432     |
| train/                   |             |
|    approx_kl             | 0.00875984  |
|    clip_fraction         | 0.0886      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 8.92        |
|    cost_values           | 1.76        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 8830        |
|    policy_gradient_loss  | -0.00527    |
|    std                   | 0.484       |
|    value_loss            | 0.844       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5857919   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1812480      |
| train/                   |              |
|    approx_kl             | 0.0048964927 |
|    clip_fraction         | 0.0645       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 24           |
|    cost_values           | 1.88         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0.000693     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.29         |
|    n_updates             | 8840         |
|    policy_gradient_loss  | -0.0045      |
|    std                   | 0.483        |
|    value_loss            | 1.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.32299373  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 1814528      |
| train/                   |              |
|    approx_kl             | 0.0077910074 |
|    clip_fraction         | 0.0657       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.11         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 2.13         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.000819     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.55         |
|    n_updates             | 8850         |
|    policy_gradient_loss  | -0.00816     |
|    std                   | 0.483        |
|    value_loss            | 1.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.72826177 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1816576     |
| train/                   |             |
|    approx_kl             | 0.007486539 |
|    clip_fraction         | 0.0653      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.35        |
|    cost_value_loss       | 21.3        |
|    cost_values           | 2.14        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 8860        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.482       |
|    value_loss            | 0.881       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.67        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.67        |
| reward                   | -0.45010763 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 173         |
|    total_timesteps       | 1818624     |
| train/                   |             |
|    approx_kl             | 0.011816129 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.25        |
|    cost_value_loss       | 20.8        |
|    cost_values           | 2.3         |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.9        |
|    n_updates             | 8870        |
|    policy_gradient_loss  | -0.0116     |
|    std                   | 0.482       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.45        |
| reward                   | -0.4219584  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 204         |
|    total_timesteps       | 1820672     |
| train/                   |             |
|    approx_kl             | 0.012550773 |
|    clip_fraction         | 0.0817      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.72        |
|    cost_value_loss       | 22.6        |
|    cost_values           | 2.1         |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.0036      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 8880        |
|    policy_gradient_loss  | -0.00747    |
|    std                   | 0.483       |
|    value_loss            | 0.667       |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 2.6        |
| reward                   | -0.3578059 |
| rollout/                 |            |
|    ep_len_mean           | 991        |
|    ep_rew_mean           | -450       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 8          |
|    time_elapsed          | 234        |
|    total_timesteps       | 1822720    |
| train/                   |            |
|    approx_kl             | 0.0121016  |
|    clip_fraction         | 0.144      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.48       |
|    cost_value_loss       | 2.25       |
|    cost_values           | 1.96       |
|    entropy               | -1.38      |
|    entropy_loss          | -1.38      |
|    explained_variance    | 0.996      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.31       |
|    n_updates             | 8890       |
|    policy_gradient_loss  | -0.00412   |
|    std                   | 0.483      |
|    value_loss            | 0.34       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.07        |
| reward                   | -0.47282684 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 265         |
|    total_timesteps       | 1824768     |
| train/                   |             |
|    approx_kl             | 0.00669793  |
|    clip_fraction         | 0.0722      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 10.7        |
|    cost_values           | 1.81        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.2         |
|    n_updates             | 8900        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.483       |
|    value_loss            | 0.406       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 3.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.69         |
| reward                   | -0.49518907  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 296          |
|    total_timesteps       | 1826816      |
| train/                   |              |
|    approx_kl             | 0.0075161858 |
|    clip_fraction         | 0.0729       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 2.17         |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0.00143      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.94         |
|    n_updates             | 8910         |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.479        |
|    value_loss            | 0.282        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.38920164 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 326         |
|    total_timesteps       | 1828864     |
| train/                   |             |
|    approx_kl             | 0.010753437 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.48        |
|    cost_value_loss       | 4.14        |
|    cost_values           | 2.23        |
|    entropy               | -1.37       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 9e-05       |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 8920        |
|    policy_gradient_loss  | -0.00339    |
|    std                   | 0.479       |
|    value_loss            | 0.511       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.48        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.48        |
| reward                   | -0.38490677 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 357         |
|    total_timesteps       | 1830912     |
| train/                   |             |
|    approx_kl             | 0.008732144 |
|    clip_fraction         | 0.0866      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 9.57        |
|    cost_values           | 2.34        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.76        |
|    n_updates             | 8930        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.479       |
|    value_loss            | 0.194       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41979843  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 388          |
|    total_timesteps       | 1832960      |
| train/                   |              |
|    approx_kl             | 0.0097989235 |
|    clip_fraction         | 0.0641       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.32         |
|    cost_value_loss       | 33.9         |
|    cost_values           | 2.57         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.00331      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.6          |
|    n_updates             | 8940         |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 0.477        |
|    value_loss            | 0.725        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.76        |
| reward                   | -0.598834   |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 419         |
|    total_timesteps       | 1835008     |
| train/                   |             |
|    approx_kl             | 0.007005753 |
|    clip_fraction         | 0.0822      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.88        |
|    cost_value_loss       | 19.9        |
|    cost_values           | 2.46        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00604     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 8950        |
|    policy_gradient_loss  | -0.00704    |
|    std                   | 0.477       |
|    value_loss            | 0.513       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.47         |
| reward                   | -0.4807569   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 450          |
|    total_timesteps       | 1837056      |
| train/                   |              |
|    approx_kl             | 0.0104388315 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.41         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 2.61         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0.00378      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.22         |
|    n_updates             | 8960         |
|    policy_gradient_loss  | -0.000246    |
|    std                   | 0.476        |
|    value_loss            | 0.431        |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.06        |
| reward                   | -0.46898776 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 480         |
|    total_timesteps       | 1839104     |
| train/                   |             |
|    approx_kl             | 0.007225564 |
|    clip_fraction         | 0.078       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 27          |
|    cost_values           | 2.66        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.00292     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.28        |
|    n_updates             | 8970        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.475       |
|    value_loss            | 0.548       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.20100965 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 511         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.011938976 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 7.19        |
|    cost_values           | 2.76        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.51        |
|    n_updates             | 8980        |
|    policy_gradient_loss  | -0.00332    |
|    std                   | 0.475       |
|    value_loss            | 0.845       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.33287984 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 541         |
|    total_timesteps       | 1843200     |
| train/                   |             |
|    approx_kl             | 0.010669988 |
|    clip_fraction         | 0.0799      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 0.106       |
|    cost_values           | 2.31        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.21        |
|    n_updates             | 8990        |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.473       |
|    value_loss            | 0.597       |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.47186774 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 572         |
|    total_timesteps       | 1845248     |
| train/                   |             |
|    approx_kl             | 0.010951292 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 17.6        |
|    cost_values           | 2.05        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0.00189     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.17        |
|    n_updates             | 9000        |
|    policy_gradient_loss  | -0.00504    |
|    std                   | 0.471       |
|    value_loss            | 4.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.39        |
| reward                   | -0.21666919 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 20          |
|    time_elapsed          | 603         |
|    total_timesteps       | 1847296     |
| train/                   |             |
|    approx_kl             | 0.005960655 |
|    clip_fraction         | 0.0785      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.93        |
|    cost_value_loss       | 33.6        |
|    cost_values           | 2.47        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00321     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.75        |
|    n_updates             | 9010        |
|    policy_gradient_loss  | -0.00601    |
|    std                   | 0.472       |
|    value_loss            | 0.413       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.35611627 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 634         |
|    total_timesteps       | 1849344     |
| train/                   |             |
|    approx_kl             | 0.014681131 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 31.5        |
|    cost_values           | 2.51        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 9020        |
|    policy_gradient_loss  | -0.00813    |
|    std                   | 0.472       |
|    value_loss            | 0.502       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 3.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.58        |
| reward                   | -0.65043694 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 22          |
|    time_elapsed          | 664         |
|    total_timesteps       | 1851392     |
| train/                   |             |
|    approx_kl             | 0.008016704 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 7.99        |
|    cost_values           | 2.59        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0.000942    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.57        |
|    n_updates             | 9030        |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.468       |
|    value_loss            | 0.351       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.99        |
| reward                   | -0.6595045  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 23          |
|    time_elapsed          | 695         |
|    total_timesteps       | 1853440     |
| train/                   |             |
|    approx_kl             | 0.008932934 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 2.16        |
|    cost_values           | 2.38        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.37        |
|    n_updates             | 9040        |
|    policy_gradient_loss  | -0.00623    |
|    std                   | 0.469       |
|    value_loss            | 0.419       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.51019615 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 725         |
|    total_timesteps       | 1855488     |
| train/                   |             |
|    approx_kl             | 0.010604865 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.19        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 9050        |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.469       |
|    value_loss            | 0.466       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.3980867   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 25           |
|    time_elapsed          | 756          |
|    total_timesteps       | 1857536      |
| train/                   |              |
|    approx_kl             | 0.0057976837 |
|    clip_fraction         | 0.0618       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 6.66         |
|    cost_values           | 2.03         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0.000228     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.52         |
|    n_updates             | 9060         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.469        |
|    value_loss            | 0.45         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4919467  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 786         |
|    total_timesteps       | 1859584     |
| train/                   |             |
|    approx_kl             | 0.004998155 |
|    clip_fraction         | 0.0672      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 20.8        |
|    cost_values           | 2.1         |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 9070        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.469       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.86        |
| reward                   | -0.42440373 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 817         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.009533392 |
|    clip_fraction         | 0.0715      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.73        |
|    cost_values           | 2.22        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.86        |
|    n_updates             | 9080        |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.468       |
|    value_loss            | 0.879       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.15        |
| reward                   | -0.47649536 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 847         |
|    total_timesteps       | 1863680     |
| train/                   |             |
|    approx_kl             | 0.012285892 |
|    clip_fraction         | 0.0921      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 0.608       |
|    cost_values           | 1.92        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.735       |
|    n_updates             | 9090        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.469       |
|    value_loss            | 0.822       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.45385826 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 878         |
|    total_timesteps       | 1865728     |
| train/                   |             |
|    approx_kl             | 0.037557535 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.95        |
|    cost_value_loss       | 1.86        |
|    cost_values           | 1.55        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.05        |
|    n_updates             | 9100        |
|    policy_gradient_loss  | 0.00637     |
|    std                   | 0.47        |
|    value_loss            | 0.225       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.54        |
| reward                   | -0.4112873  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 908         |
|    total_timesteps       | 1867776     |
| train/                   |             |
|    approx_kl             | 0.005699578 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 5.99        |
|    cost_values           | 1.27        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 9110        |
|    policy_gradient_loss  | 0.00663     |
|    std                   | 0.47        |
|    value_loss            | 0.663       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.08        |
| reward                   | -0.3309111  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 939         |
|    total_timesteps       | 1869824     |
| train/                   |             |
|    approx_kl             | 0.009778313 |
|    clip_fraction         | 0.0802      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 0.608       |
|    cost_values           | 1.06        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.424       |
|    n_updates             | 9120        |
|    policy_gradient_loss  | -0.00423    |
|    std                   | 0.471       |
|    value_loss            | 0.265       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.50620747  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 32           |
|    time_elapsed          | 969          |
|    total_timesteps       | 1871872      |
| train/                   |              |
|    approx_kl             | 0.0055455007 |
|    clip_fraction         | 0.0688       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.08         |
|    cost_value_loss       | 21.1         |
|    cost_values           | 1.29         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.2          |
|    n_updates             | 9130         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.471        |
|    value_loss            | 0.218        |
-------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.33848163 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 1000        |
|    total_timesteps       | 1873920     |
| train/                   |             |
|    approx_kl             | 0.017444933 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 0.92        |
|    cost_values           | 1.45        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.663       |
|    n_updates             | 9140        |
|    policy_gradient_loss  | 0.00191     |
|    std                   | 0.473       |
|    value_loss            | 0.324       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.4464828  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1030        |
|    total_timesteps       | 1875968     |
| train/                   |             |
|    approx_kl             | 0.007352273 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 21.5        |
|    cost_values           | 1.29        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 9150        |
|    policy_gradient_loss  | -0.00673    |
|    std                   | 0.473       |
|    value_loss            | 0.634       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.6415221  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1061        |
|    total_timesteps       | 1878016     |
| train/                   |             |
|    approx_kl             | 0.009149882 |
|    clip_fraction         | 0.0948      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.37        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 1.37        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 9160        |
|    policy_gradient_loss  | -0.00689    |
|    std                   | 0.472       |
|    value_loss            | 0.483       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.52        |
| reward                   | -0.43636748 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1091        |
|    total_timesteps       | 1880064     |
| train/                   |             |
|    approx_kl             | 0.008139895 |
|    clip_fraction         | 0.0576      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 23.4        |
|    cost_values           | 1.42        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 9170        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.471       |
|    value_loss            | 4.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.87        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.87        |
| reward                   | -0.35557967 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1122        |
|    total_timesteps       | 1882112     |
| train/                   |             |
|    approx_kl             | 0.005697797 |
|    clip_fraction         | 0.0523      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 6.39        |
|    cost_values           | 1.26        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.27        |
|    n_updates             | 9180        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.471       |
|    value_loss            | 0.607       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -0.5033918   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1153         |
|    total_timesteps       | 1884160      |
| train/                   |              |
|    approx_kl             | 0.0070511564 |
|    clip_fraction         | 0.0832       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 5.81         |
|    cost_values           | 1.33         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.96         |
|    n_updates             | 9190         |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.47         |
|    value_loss            | 0.959        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.07         |
| reward                   | -0.59539866  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1184         |
|    total_timesteps       | 1886208      |
| train/                   |              |
|    approx_kl             | 0.0066440236 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 23.6         |
|    cost_values           | 1.13         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 9200         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.469        |
|    value_loss            | 5.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.03         |
| reward                   | -0.54346895  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1215         |
|    total_timesteps       | 1888256      |
| train/                   |              |
|    approx_kl             | 0.0066377996 |
|    clip_fraction         | 0.0828       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 20.5         |
|    cost_values           | 1.16         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 9210         |
|    policy_gradient_loss  | -0.0067      |
|    std                   | 0.468        |
|    value_loss            | 1.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.42        |
| reward                   | -0.5190134  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1245        |
|    total_timesteps       | 1890304     |
| train/                   |             |
|    approx_kl             | 0.006607445 |
|    clip_fraction         | 0.0815      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 8.84        |
|    cost_values           | 1.5         |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 9220        |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 0.468       |
|    value_loss            | 0.838       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 3.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.73         |
| reward                   | -0.46207824  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1276         |
|    total_timesteps       | 1892352      |
| train/                   |              |
|    approx_kl             | 0.0058966884 |
|    clip_fraction         | 0.0612       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.99         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 1.68         |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.76         |
|    n_updates             | 9230         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.467        |
|    value_loss            | 0.615        |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.11        |
| reward                   | -0.49617925 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1307        |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.00859196  |
|    clip_fraction         | 0.0726      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.2         |
|    cost_value_loss       | 17.5        |
|    cost_values           | 2.1         |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.66        |
|    n_updates             | 9240        |
|    policy_gradient_loss  | -0.0056     |
|    std                   | 0.468       |
|    value_loss            | 1.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.69        |
| reward                   | -0.51221913 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1338        |
|    total_timesteps       | 1896448     |
| train/                   |             |
|    approx_kl             | 0.006523108 |
|    clip_fraction         | 0.0827      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 30.1        |
|    cost_values           | 2.46        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00825     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.92        |
|    n_updates             | 9250        |
|    policy_gradient_loss  | -0.00703    |
|    std                   | 0.467       |
|    value_loss            | 0.247       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42468056 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1368        |
|    total_timesteps       | 1898496     |
| train/                   |             |
|    approx_kl             | 0.007827094 |
|    clip_fraction         | 0.0716      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 8.04        |
|    cost_values           | 2.96        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.66        |
|    n_updates             | 9260        |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 0.465       |
|    value_loss            | 0.332       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.4349541   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1399         |
|    total_timesteps       | 1900544      |
| train/                   |              |
|    approx_kl             | 0.0083289975 |
|    clip_fraction         | 0.11         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.71         |
|    cost_value_loss       | 4.65         |
|    cost_values           | 2.8          |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.09         |
|    n_updates             | 9270         |
|    policy_gradient_loss  | -0.000995    |
|    std                   | 0.466        |
|    value_loss            | 1.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.38        |
| reward                   | -0.3317185  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1430        |
|    total_timesteps       | 1902592     |
| train/                   |             |
|    approx_kl             | 0.008943449 |
|    clip_fraction         | 0.086       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 2.64        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.00223     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 9280        |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 0.465       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24474646 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1460        |
|    total_timesteps       | 1904640     |
| train/                   |             |
|    approx_kl             | 0.007594153 |
|    clip_fraction         | 0.0872      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.5         |
|    cost_value_loss       | 19          |
|    cost_values           | 2.79        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.71        |
|    n_updates             | 9290        |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.464       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.08        |
| reward                   | -0.4743753  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1491        |
|    total_timesteps       | 1906688     |
| train/                   |             |
|    approx_kl             | 0.011411769 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.43        |
|    cost_value_loss       | 3.51        |
|    cost_values           | 2.78        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.99        |
|    n_updates             | 9300        |
|    policy_gradient_loss  | -0.00589    |
|    std                   | 0.463       |
|    value_loss            | 5.9         |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/gcskytqy
-----------------------------------
| avg_speed          | 7.92       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.92       |
| reward             | -0.7210689 |
| rollout/           |            |
|    ep_len_mean     | 993        |
|    ep_rew_mean     | -438       |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 1908736    |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2852422   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 1910784      |
| train/                   |              |
|    approx_kl             | 0.0069416566 |
|    clip_fraction         | 0.0701       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 21.8         |
|    cost_values           | 2.71         |
|    entropy               | -1.29        |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 3.28e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 9320         |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 0.461        |
|    value_loss            | 1.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.47325778  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 1912832      |
| train/                   |              |
|    approx_kl             | 0.0072772196 |
|    clip_fraction         | 0.0567       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.44         |
|    cost_value_loss       | 8.7          |
|    cost_values           | 2.79         |
|    entropy               | -1.3         |
|    entropy_loss          | -1.29        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0.000776     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.2          |
|    n_updates             | 9330         |
|    policy_gradient_loss  | -0.00512     |
|    std                   | 0.463        |
|    value_loss            | 0.832        |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.66        |
| reward                   | -0.33793515 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 1914880     |
| train/                   |             |
|    approx_kl             | 0.006700354 |
|    clip_fraction         | 0.0726      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 3.37        |
|    cost_values           | 2.69        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 9340        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.463       |
|    value_loss            | 4.36        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3189     |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1916928     |
| train/                   |             |
|    approx_kl             | 0.008344915 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 9.94        |
|    cost_values           | 2.55        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.000893    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 9350        |
|    policy_gradient_loss  | -0.0126     |
|    std                   | 0.461       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.75        |
| reward                   | -0.5239423  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 173         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.008363379 |
|    clip_fraction         | 0.0852      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 3.88        |
|    cost_values           | 2.51        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.000102    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 9360        |
|    policy_gradient_loss  | -0.0069     |
|    std                   | 0.461       |
|    value_loss            | 0.574       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.41505682 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 204         |
|    total_timesteps       | 1921024     |
| train/                   |             |
|    approx_kl             | 0.009899496 |
|    clip_fraction         | 0.0733      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 7.64        |
|    cost_values           | 2.58        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.0004      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.7         |
|    n_updates             | 9370        |
|    policy_gradient_loss  | -0.00575    |
|    std                   | 0.461       |
|    value_loss            | 0.866       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.75658005 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 234         |
|    total_timesteps       | 1923072     |
| train/                   |             |
|    approx_kl             | 0.006197028 |
|    clip_fraction         | 0.0827      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 8.62        |
|    cost_values           | 2.61        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.00075     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 9380        |
|    policy_gradient_loss  | -0.00556    |
|    std                   | 0.46        |
|    value_loss            | 0.765       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.75        |
| reward                   | -0.4357323  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 265         |
|    total_timesteps       | 1925120     |
| train/                   |             |
|    approx_kl             | 0.009105469 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 2.65        |
|    cost_values           | 2.51        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.38        |
|    n_updates             | 9390        |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.458       |
|    value_loss            | 0.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.43        |
| reward                   | -0.26549834 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 295         |
|    total_timesteps       | 1927168     |
| train/                   |             |
|    approx_kl             | 0.012604903 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 2.53        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.0117      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 9400        |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 0.458       |
|    value_loss            | 6.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.46        |
| reward                   | -0.49473476 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 326         |
|    total_timesteps       | 1929216     |
| train/                   |             |
|    approx_kl             | 0.011571007 |
|    clip_fraction         | 0.0848      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.95        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.57        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.00138     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.36        |
|    n_updates             | 9410        |
|    policy_gradient_loss  | -0.00439    |
|    std                   | 0.458       |
|    value_loss            | 4.06        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5408912 |
| rollout/                 |            |
|    ep_len_mean           | 985        |
|    ep_rew_mean           | -437       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 12         |
|    time_elapsed          | 357        |
|    total_timesteps       | 1931264    |
| train/                   |            |
|    approx_kl             | 0.01355576 |
|    clip_fraction         | 0.157      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.99       |
|    cost_value_loss       | 20         |
|    cost_values           | 2.49       |
|    entropy               | -1.26      |
|    entropy_loss          | -1.27      |
|    explained_variance    | 0.998      |
|    lagrangian_multiplier | 0.00609    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.38       |
|    n_updates             | 9420       |
|    policy_gradient_loss  | 0.0011     |
|    std                   | 0.455      |
|    value_loss            | 0.375      |
-----------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.36         |
| reward                   | -0.4479625   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 387          |
|    total_timesteps       | 1933312      |
| train/                   |              |
|    approx_kl             | 0.0040155374 |
|    clip_fraction         | 0.0616       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.29         |
|    cost_value_loss       | 21.9         |
|    cost_values           | 2.71         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0.00126      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.18         |
|    n_updates             | 9430         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.455        |
|    value_loss            | 0.527        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.4303667   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 418          |
|    total_timesteps       | 1935360      |
| train/                   |              |
|    approx_kl             | 0.0056313155 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.86         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 2.57         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.04         |
|    n_updates             | 9440         |
|    policy_gradient_loss  | -0.00351     |
|    std                   | 0.455        |
|    value_loss            | 2.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.35104278  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 448          |
|    total_timesteps       | 1937408      |
| train/                   |              |
|    approx_kl             | 0.0065653073 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.57         |
|    cost_value_loss       | 6.77         |
|    cost_values           | 2.26         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 9450         |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 0.454        |
|    value_loss            | 0.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.81        |
| reward                   | -0.4037284  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 479         |
|    total_timesteps       | 1939456     |
| train/                   |             |
|    approx_kl             | 0.006031844 |
|    clip_fraction         | 0.0364      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 2.13        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 9460        |
|    policy_gradient_loss  | -0.00382    |
|    std                   | 0.454       |
|    value_loss            | 6.63        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 4.24        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.24        |
| reward                   | -0.3817692  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 510         |
|    total_timesteps       | 1941504     |
| train/                   |             |
|    approx_kl             | 0.004326591 |
|    clip_fraction         | 0.0347      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 1.97        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 9470        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.455       |
|    value_loss            | 5.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.23         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.23         |
| reward                   | -0.29502705  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 540          |
|    total_timesteps       | 1943552      |
| train/                   |              |
|    approx_kl             | 0.0054659247 |
|    clip_fraction         | 0.0471       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.82         |
|    cost_value_loss       | 48.6         |
|    cost_values           | 2.21         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.0101       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 9480         |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.454        |
|    value_loss            | 0.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.3981492   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 571          |
|    total_timesteps       | 1945600      |
| train/                   |              |
|    approx_kl             | 0.0071494295 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.11         |
|    cost_value_loss       | 24.1         |
|    cost_values           | 2.35         |
|    entropy               | -1.26        |
|    entropy_loss          | -1.26        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0.00366      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.99         |
|    n_updates             | 9490         |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 0.454        |
|    value_loss            | 0.884        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5324152  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 602         |
|    total_timesteps       | 1947648     |
| train/                   |             |
|    approx_kl             | 0.009112689 |
|    clip_fraction         | 0.0926      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.24        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 2.18        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 9500        |
|    policy_gradient_loss  | -0.00758    |
|    std                   | 0.454       |
|    value_loss            | 5.31        |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5148735  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 632         |
|    total_timesteps       | 1949696     |
| train/                   |             |
|    approx_kl             | 0.010342255 |
|    clip_fraction         | 0.0663      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 9.4         |
|    cost_values           | 2.3         |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.45        |
|    n_updates             | 9510        |
|    policy_gradient_loss  | -0.00895    |
|    std                   | 0.453       |
|    value_loss            | 2.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.99        |
| reward                   | -0.32654938 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 22          |
|    time_elapsed          | 663         |
|    total_timesteps       | 1951744     |
| train/                   |             |
|    approx_kl             | 0.008520446 |
|    clip_fraction         | 0.0849      |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.22        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.08        |
|    n_updates             | 9520        |
|    policy_gradient_loss  | -0.00821    |
|    std                   | 0.452       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.09        |
| reward                   | -0.3526257  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 23          |
|    time_elapsed          | 694         |
|    total_timesteps       | 1953792     |
| train/                   |             |
|    approx_kl             | 0.008665116 |
|    clip_fraction         | 0.0719      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.55        |
|    cost_value_loss       | 24.7        |
|    cost_values           | 2.54        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0.00537     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 9530        |
|    policy_gradient_loss  | -0.00563    |
|    std                   | 0.452       |
|    value_loss            | 1.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -0.23645517  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 724          |
|    total_timesteps       | 1955840      |
| train/                   |              |
|    approx_kl             | 0.0062906328 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.19         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 2.84         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0.000312     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.23         |
|    n_updates             | 9540         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.451        |
|    value_loss            | 3.48         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.76198626 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 25          |
|    time_elapsed          | 755         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.013474652 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.61        |
|    cost_value_loss       | 47.1        |
|    cost_values           | 2.77        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00543     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.59        |
|    n_updates             | 9550        |
|    policy_gradient_loss  | -0.00589    |
|    std                   | 0.449       |
|    value_loss            | 3.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.06         |
| reward                   | -0.52109647  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 786          |
|    total_timesteps       | 1959936      |
| train/                   |              |
|    approx_kl             | 0.0053045535 |
|    clip_fraction         | 0.0635       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.67         |
|    cost_value_loss       | 24.1         |
|    cost_values           | 2.84         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0.00574      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 9560         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.449        |
|    value_loss            | 0.543        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.51582867 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 817         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.01047093  |
|    clip_fraction         | 0.0729      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 2.54        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 9570        |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 0.45        |
|    value_loss            | 1.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.52         |
| reward                   | -0.2915731   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 847          |
|    total_timesteps       | 1964032      |
| train/                   |              |
|    approx_kl             | 0.0075803525 |
|    clip_fraction         | 0.0953       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.49         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.93         |
|    n_updates             | 9580         |
|    policy_gradient_loss  | -0.00873     |
|    std                   | 0.449        |
|    value_loss            | 0.304        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-----------------------------------------
| avg_speed                | 1.91       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.91       |
| reward                   | -0.3920518 |
| rollout/                 |            |
|    ep_len_mean           | 957        |
|    ep_rew_mean           | -422       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 29         |
|    time_elapsed          | 878        |
|    total_timesteps       | 1966080    |
| train/                   |            |
|    approx_kl             | 0.00895436 |
|    clip_fraction         | 0.0775     |
|    clip_range            | 0.2        |
|    cost_returns          | 4.62       |
|    cost_value_loss       | 8.35       |
|    cost_values           | 2.68       |
|    entropy               | -1.24      |
|    entropy_loss          | -1.24      |
|    explained_variance    | 0.997      |
|    lagrangian_multiplier | 0.00325    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.42       |
|    n_updates             | 9590       |
|    policy_gradient_loss  | -0.00649   |
|    std                   | 0.451      |
|    value_loss            | 0.228      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.07        |
| reward                   | -0.42922217 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 908         |
|    total_timesteps       | 1968128     |
| train/                   |             |
|    approx_kl             | 0.007697078 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 7.8         |
|    cost_values           | 2.61        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000929    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 9600        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.451       |
|    value_loss            | 0.641       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.32899752 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 939         |
|    total_timesteps       | 1970176     |
| train/                   |             |
|    approx_kl             | 0.011843393 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 2.99        |
|    cost_values           | 2.48        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.76        |
|    n_updates             | 9610        |
|    policy_gradient_loss  | -0.00608    |
|    std                   | 0.451       |
|    value_loss            | 3.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5941626  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 970         |
|    total_timesteps       | 1972224     |
| train/                   |             |
|    approx_kl             | 0.013010139 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 1.71        |
|    cost_values           | 2.14        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.31        |
|    n_updates             | 9620        |
|    policy_gradient_loss  | -0.00723    |
|    std                   | 0.451       |
|    value_loss            | 0.505       |
------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 2.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.43         |
| reward                   | -0.38559574  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 33           |
|    time_elapsed          | 1000         |
|    total_timesteps       | 1974272      |
| train/                   |              |
|    approx_kl             | 0.0058464743 |
|    clip_fraction         | 0.0721       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.38         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 1.81         |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.27         |
|    n_updates             | 9630         |
|    policy_gradient_loss  | -0.00508     |
|    std                   | 0.452        |
|    value_loss            | 2.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.51        |
| reward                   | -0.3166888  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1031        |
|    total_timesteps       | 1976320     |
| train/                   |             |
|    approx_kl             | 0.005697997 |
|    clip_fraction         | 0.0647      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.06        |
|    cost_value_loss       | 19.4        |
|    cost_values           | 1.68        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.68        |
|    n_updates             | 9640        |
|    policy_gradient_loss  | -0.00589    |
|    std                   | 0.452       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.96        |
| reward                   | -0.50152534 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1061        |
|    total_timesteps       | 1978368     |
| train/                   |             |
|    approx_kl             | 0.00937386  |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.96        |
|    cost_value_loss       | 0.464       |
|    cost_values           | 1.71        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.363       |
|    n_updates             | 9650        |
|    policy_gradient_loss  | 0.00248     |
|    std                   | 0.45        |
|    value_loss            | 0.644       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.75         |
| reward                   | -0.4335496   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1092         |
|    total_timesteps       | 1980416      |
| train/                   |              |
|    approx_kl             | 0.0055305343 |
|    clip_fraction         | 0.162        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 4.08         |
|    cost_values           | 1.44         |
|    entropy               | -1.24        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.765        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.07         |
|    n_updates             | 9660         |
|    policy_gradient_loss  | 0.00158      |
|    std                   | 0.45         |
|    value_loss            | 1.34         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.50338554  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1122         |
|    total_timesteps       | 1982464      |
| train/                   |              |
|    approx_kl             | 0.0042346683 |
|    clip_fraction         | 0.0954       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 0.604        |
|    cost_values           | 1.12         |
|    entropy               | -1.25        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.472        |
|    n_updates             | 9670         |
|    policy_gradient_loss  | 0.00192      |
|    std                   | 0.451        |
|    value_loss            | 0.717        |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.37        |
| reward                   | -0.26514488 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1153        |
|    total_timesteps       | 1984512     |
| train/                   |             |
|    approx_kl             | 0.006821919 |
|    clip_fraction         | 0.0937      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1.02        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 9680        |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 0.451       |
|    value_loss            | 0.819       |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.77         |
| reward                   | -0.5016223   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1183         |
|    total_timesteps       | 1986560      |
| train/                   |              |
|    approx_kl             | 0.0071450267 |
|    clip_fraction         | 0.0649       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 0.952        |
|    cost_values           | 0.88         |
|    entropy               | -1.25        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.619        |
|    n_updates             | 9690         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 0.451        |
|    value_loss            | 0.742        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.59541416  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1214         |
|    total_timesteps       | 1988608      |
| train/                   |              |
|    approx_kl             | 0.0128471395 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.845        |
|    cost_value_loss       | 0.0559       |
|    cost_values           | 0.887        |
|    entropy               | -1.23        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.119        |
|    n_updates             | 9700         |
|    policy_gradient_loss  | -0.00502     |
|    std                   | 0.447        |
|    value_loss            | 0.24         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 2.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.97        |
| reward                   | -0.4392244  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1244        |
|    total_timesteps       | 1990656     |
| train/                   |             |
|    approx_kl             | 0.008458111 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 0.971       |
|    entropy               | -1.22       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 9710        |
|    policy_gradient_loss  | -0.000518   |
|    std                   | 0.446       |
|    value_loss            | 0.844       |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.23         |
| reward                   | -0.55795366  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1275         |
|    total_timesteps       | 1992704      |
| train/                   |              |
|    approx_kl             | 0.0061079483 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 4.92         |
|    cost_values           | 0.909        |
|    entropy               | -1.22        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0.868        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.63         |
|    n_updates             | 9720         |
|    policy_gradient_loss  | -0.00534     |
|    std                   | 0.446        |
|    value_loss            | 3.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.1          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.1          |
| reward                   | -0.4925484   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1306         |
|    total_timesteps       | 1994752      |
| train/                   |              |
|    approx_kl             | 0.0091613615 |
|    clip_fraction         | 0.0867       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 1.27         |
|    cost_values           | 0.931        |
|    entropy               | -1.21        |
|    entropy_loss          | -1.22        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.816        |
|    n_updates             | 9730         |
|    policy_gradient_loss  | -0.0071      |
|    std                   | 0.444        |
|    value_loss            | 0.594        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.40479195  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1336         |
|    total_timesteps       | 1996800      |
| train/                   |              |
|    approx_kl             | 0.0063607236 |
|    clip_fraction         | 0.059        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.21         |
|    cost_value_loss       | 41.6         |
|    cost_values           | 1.27         |
|    entropy               | -1.21        |
|    entropy_loss          | -1.21        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 9740         |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 0.442        |
|    value_loss            | 0.615        |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.48074672  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1367         |
|    total_timesteps       | 1998848      |
| train/                   |              |
|    approx_kl             | 0.0055440203 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.81         |
|    cost_value_loss       | 42.2         |
|    cost_values           | 2.01         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 9750         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.442        |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.31955817 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1398        |
|    total_timesteps       | 2000896     |
| train/                   |             |
|    approx_kl             | 0.008015218 |
|    clip_fraction         | 0.0972      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.44        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 9760        |
|    policy_gradient_loss  | -0.00549    |
|    std                   | 0.441       |
|    value_loss            | 4.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.03         |
| reward                   | -0.5246912   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1428         |
|    total_timesteps       | 2002944      |
| train/                   |              |
|    approx_kl             | 0.0040737228 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.9          |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.36         |
|    entropy               | -1.2         |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 9770         |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 0.441        |
|    value_loss            | 0.976        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.41506085  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1459         |
|    total_timesteps       | 2004992      |
| train/                   |              |
|    approx_kl             | 0.0064971377 |
|    clip_fraction         | 0.071        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 8.03         |
|    cost_values           | 2.3          |
|    entropy               | -1.19        |
|    entropy_loss          | -1.2         |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.13         |
|    n_updates             | 9780         |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 0.44         |
|    value_loss            | 0.51         |
-------------------------------------------
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.5955641  |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1489        |
|    total_timesteps       | 2007040     |
| train/                   |             |
|    approx_kl             | 0.008059774 |
|    clip_fraction         | 0.0869      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.24        |
|    cost_values           | 2.24        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 9790        |
|    policy_gradient_loss  | -0.0064     |
|    std                   | 0.441       |
|    value_loss            | 1.42        |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5501651763916016
Final reward: -0.5521951913833618
Final reward: -0.5551517605781555
Final reward: -0.559630811214447
Final reward: -0.5651235580444336
Final reward: -0.57084721326828
Final reward: -0.5757091045379639
Final reward: -0.5783031582832336
Final reward: -0.5769640803337097
Final reward: -0.5699368119239807
Final reward: -0.5557004809379578
Final reward: -0.5335150361061096
Final reward: -0.5042625665664673
Final reward: -0.4716032147407532
Final reward: -0.46203044056892395
Final reward: -0.46598049998283386
Final reward: -0.48187172412872314
Final reward: -0.505291759967804
Final reward: -0.5292221307754517
Final reward: -0.5479775071144104
Final reward: -0.5725839138031006
Final reward: -0.5767478942871094
Final reward: -0.5574992299079895
Final reward: -0.5165672898292542
Final reward: -0.4684987962245941
Final reward: -0.46264782547950745
Final reward: -0.4803716242313385
Final reward: -0.5120148062705994
Final reward: -0.5404137969017029
Final reward: -0.572347104549408
Final reward: -0.5733182430267334
Final reward: -0.5372092127799988
Final reward: -0.47776445746421814
Final reward: -0.4623512029647827
Final reward: -0.48445287346839905
Final reward: -0.5232216119766235
Final reward: -0.5610676407814026
Final reward: -0.5762746334075928
Final reward: -0.5362319946289062
Final reward: -0.46932175755500793
Final reward: -0.4671213626861572
Final reward: -0.5044770836830139
Final reward: -0.5429097414016724
Final reward: -0.5771063566207886
Final reward: -0.550281822681427
Final reward: -0.4807257354259491
Final reward: -0.45952939987182617
Final reward: -0.4916553199291229
Final reward: -0.5343714952468872
Final reward: -0.5741809606552124
Final reward: -0.5456772446632385
Final reward: -0.46790751814842224
Final reward: -0.45261865854263306
Final reward: -0.4937109053134918
Final reward: -0.5410003662109375
Final reward: -0.565217137336731
Final reward: -0.5098673701286316
Final reward: -0.4496448338031769
Final reward: -0.47146210074424744
Final reward: -0.5221761465072632
Final reward: -0.5669466853141785
Final reward: -0.5277778506278992
Final reward: -0.451973021030426
Final reward: -0.46777355670928955
Final reward: -0.5215303301811218
Final reward: -0.5672217011451721
Final reward: -0.5147002935409546
Final reward: -0.44889771938323975
Final reward: -0.4844960570335388
Final reward: -0.5473317503929138
Final reward: -0.5532084703445435
Final reward: -0.45919081568717957
Final reward: -0.4628943204879761
Final reward: -0.5207383036613464
Final reward: -0.5668541789054871
Final reward: -0.4996322989463806
Final reward: -0.44983595609664917
Final reward: -0.4977341890335083
Final reward: -0.5595688223838806
Final reward: -0.5377492904663086
Final reward: -0.4521310329437256
Final reward: -0.47311052680015564
Final reward: -0.5328667759895325
Final reward: -0.5616146922111511
Final reward: -0.47578147053718567
Final reward: -0.453611820936203
Final reward: -0.5092412233352661
Final reward: -0.5651322603225708
Final reward: -0.5174223780632019
Final reward: -0.4479043185710907
Final reward: -0.4854673743247986
Final reward: -0.5487166047096252
Final reward: -0.5502374172210693
Final reward: -0.45738059282302856
Final reward: -0.46153658628463745
Final reward: -0.5198075175285339
Final reward: -0.5659267902374268
Final reward: -0.49619707465171814
Final reward: -0.44935452938079834
Final reward: -0.49854716658592224
Final reward: -0.5600118041038513
Final reward: -0.5344860553741455
Final reward: -0.4503834545612335
Final reward: -0.47458064556121826
Final reward: -0.5351446270942688
Final reward: -0.5597979426383972
Final reward: -0.4714605510234833
Final reward: -0.45495298504829407
Final reward: -0.5111343264579773
Final reward: -0.5651317834854126
Final reward: -0.5183202624320984
Final reward: -0.4475110173225403
Final reward: -0.48337703943252563
Final reward: -0.546663761138916
Final reward: -0.551139235496521
Final reward: -0.4571523368358612
Final reward: -0.4609556794166565
Final reward: -0.5191715955734253
Final reward: -0.5652352571487427
Final reward: -0.4961111545562744
Final reward: -0.44827011227607727
Final reward: -0.4971279203891754
Final reward: -0.5586001873016357
Final reward: -0.535184919834137
Final reward: -0.44961628317832947
Final reward: -0.47252458333969116
Final reward: -0.5329009294509888
Final reward: -0.5594809651374817
Final reward: -0.4726893901824951
Final reward: -0.4528849720954895
Final reward: -0.5087812542915344
Final reward: -0.5643200874328613
Final reward: -0.515883207321167
Final reward: -0.44673505425453186
Final reward: -0.484699547290802
Final reward: -0.5480657815933228
Final reward: -0.5489722490310669
Final reward: -0.45547881722450256
Final reward: -0.4616488814353943
Final reward: -0.519923985004425
Final reward: -0.5643863081932068
Final reward: -0.49501198530197144
Final reward: -0.44732341170310974
Final reward: -0.4960194528102875
Final reward: -0.5578465461730957
Final reward: -0.5342548489570618
Final reward: -0.4489017128944397
Final reward: -0.4720210134983063
Final reward: -0.5323491096496582
Final reward: -0.5590559244155884
Final reward: -0.4722050726413727
Final reward: -0.45227980613708496
Final reward: -0.5147596001625061
Final reward: -0.5741602778434753
Final reward: -0.549993097782135
Final reward: -0.46630457043647766
Final reward: -0.4859394431114197
Final reward: -0.5436429381370544
Final reward: -0.5734659433364868
Final reward: -0.48951277136802673
Final reward: -0.46856096386909485
Final reward: -0.5226057171821594
Final reward: -0.5770976543426514
Final reward: -0.5305407047271729
Final reward: -0.46289026737213135
Final reward: -0.49955233931541443
Final reward: -0.5613226294517517
Final reward: -0.5618543028831482
Final reward: -0.4709590971469879
Final reward: -0.47792530059814453
Final reward: -0.5344077348709106
Final reward: -0.5772364139556885
Final reward: -0.5060683488845825
Final reward: -0.4645518660545349
Final reward: -0.5135244727134705
Final reward: -0.5720152854919434
Final reward: -0.547349750995636
Final reward: -0.46499595046043396
Final reward: -0.4861189126968384
Final reward: -0.5443441867828369
Final reward: -0.5726674795150757
Final reward: -0.487485408782959
Final reward: -0.46870216727256775
Final reward: -0.5231476426124573
Final reward: -0.5768538117408752
Final reward: -0.5288145542144775
Final reward: -0.46234437823295593
Final reward: -0.4996662437915802
Final reward: -0.5614750385284424
Final reward: -0.5609644055366516
Final reward: -0.4702540636062622
Final reward: -0.47767212986946106
Final reward: -0.534152626991272
Final reward: -0.5767929553985596
Final reward: -0.5060103535652161
Final reward: -0.46387979388237
Final reward: -0.5126614570617676
Final reward: -0.5720775127410889
Final reward: -0.5449223518371582
Final reward: -0.4516724646091461
Final reward: -0.44717684388160706
Final reward: -0.5056137442588806
Final reward: -0.5567799806594849
Final reward: -0.5036904811859131
Final reward: -0.4357660710811615
Final reward: -0.47468703985214233
Final reward: -0.5395334959030151
Final reward: -0.539455771446228
Final reward: -0.44421106576919556
Final reward: -0.4522395730018616
Final reward: -0.5116011500358582
Final reward: -0.5557007193565369
Final reward: -0.4804551899433136
Final reward: -0.43792447447776794
Final reward: -0.48992398381233215
Final reward: -0.5512062311172485
Final reward: -0.5226601362228394
Final reward: -0.43747735023498535
Final reward: -0.4641062915325165
Final reward: -0.526872992515564
Final reward: -0.5485004782676697
Final reward: -0.4562447667121887
Final reward: -0.441988080739975
Final reward: -0.4969356060028076
Final reward: -0.555773913860321
Final reward: -0.5153189897537231
Final reward: -0.43828561902046204
Final reward: -0.47225242853164673
Final reward: -0.5362851023674011
Final reward: -0.5454942584037781
Final reward: -0.4493635892868042
Final reward: -0.45008066296577454
Final reward: -0.5091582536697388
Final reward: -0.5580378770828247
Final reward: -0.49301236867904663
Final reward: -0.4379870593547821
Final reward: -0.48480284214019775
Final reward: -0.5471475124359131
Final reward: -0.5340403318405151
Final reward: -0.4421554505825043
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.4581739008426666
Final reward: -0.5169512033462524
Final reward: -0.5543009042739868
Final reward: -0.47036200761795044
Final reward: -0.44144371151924133
Final reward: -0.4969247877597809
Final reward: -0.555306077003479
Final reward: -0.5132158398628235
Final reward: -0.4371543526649475
Final reward: -0.4721226394176483
Final reward: -0.5363926291465759
Final reward: -0.5439483523368835
Final reward: -0.4479769170284271
Final reward: -0.449463427066803
Final reward: -0.5087400078773499
Final reward: -0.5573424100875854
Final reward: -0.48996543884277344
Final reward: -0.43760213255882263
Final reward: -0.4860236346721649
Final reward: -0.5492888689041138
Final reward: -0.5286131501197815
Final reward: -0.4402032196521759
Final reward: -0.46145087480545044
Final reward: -0.5219394564628601
Final reward: -0.5525097250938416
Final reward: -0.4647049307823181
Final reward: -0.44282180070877075
Final reward: -0.4995359480381012
Final reward: -0.5562210083007812
Final reward: -0.5084946751594543
Final reward: -0.43675798177719116
Final reward: -0.47511306405067444
Final reward: -0.5397292375564575
Final reward: -0.5407019853591919
Final reward: -0.4454096257686615
Final reward: -0.45251455903053284
Final reward: -0.5117999315261841
Final reward: -0.5565397143363953
Final reward: -0.4835582971572876
Final reward: -0.4381444752216339
Final reward: -0.48920607566833496
Final reward: -0.551402747631073
Final reward: -0.5236867666244507
Final reward: -0.43863484263420105
Final reward: -0.4643941819667816
Final reward: -0.5264550447463989
Final reward: -0.5502641201019287
Final reward: -0.4602709114551544
Final reward: -0.4435255229473114
Final reward: -0.5012126564979553
Final reward: -0.5564491152763367
Final reward: -0.5033676028251648
Final reward: -0.4361661970615387
Final reward: -0.4774804413318634
Final reward: -0.5418720841407776
Final reward: -0.5379726886749268
Final reward: -0.443485826253891
Final reward: -0.4535540044307709
Final reward: -0.5127825736999512
Final reward: -0.5553444623947144
Final reward: -0.47884705662727356
Final reward: -0.4381837844848633
Final reward: -0.49079209566116333
Final reward: -0.55219966173172
Final reward: -0.5199897885322571
Final reward: -0.43148526549339294
Final reward: -0.4488951563835144
Final reward: -0.508785605430603
Final reward: -0.5462322235107422
Final reward: -0.46357300877571106
Final reward: -0.43004101514816284
Final reward: -0.485883891582489
Final reward: -0.5464788675308228
Final reward: -0.5066037178039551
Final reward: -0.426897794008255
Final reward: -0.4606676399707794
Final reward: -0.5257272720336914
Final reward: -0.537441611289978
Final reward: -0.4399121105670929
Final reward: -0.43727484345436096
Final reward: -0.4975697100162506
Final reward: -0.5489075183868408
Final reward: -0.48653170466423035
Final reward: -0.42578354477882385
Final reward: -0.47234827280044556
Final reward: -0.537530779838562
Final reward: -0.5238837003707886
Final reward: -0.4305770993232727
Final reward: -0.44742974638938904
Final reward: -0.5071852207183838
Final reward: -0.5455453991889954
Final reward: -0.4627492427825928
Final reward: -0.42895054817199707
Final reward: -0.4850456416606903
Final reward: -0.5456879138946533
Final reward: -0.5049746036529541
Final reward: -0.42567896842956543
Final reward: -0.45999011397361755
Final reward: -0.5252283811569214
Final reward: -0.5361121892929077
Final reward: -0.4377075731754303
Final reward: -0.4370301365852356
Final reward: -0.4977315664291382
Final reward: -0.5480090975761414
Final reward: -0.4823358654975891
Final reward: -0.42498743534088135
Final reward: -0.4737296998500824
Final reward: -0.538835346698761
Final reward: -0.5192919373512268
Final reward: -0.42813724279403687
Final reward: -0.4494250416755676
Final reward: -0.5112945437431335
Final reward: -0.5429623126983643
Final reward: -0.4545961916446686
Final reward: -0.42992424964904785
Final reward: -0.48790594935417175
Final reward: -0.5461388230323792
Final reward: -0.49999532103538513
Final reward: -0.4239915907382965
Final reward: -0.4616439640522003
Final reward: -0.5276962518692017
Final reward: -0.531919538974762
Final reward: -0.43379849195480347
Final reward: -0.43865564465522766
Final reward: -0.4996253550052643
Final reward: -0.5466087460517883
Final reward: -0.473541259765625
Final reward: -0.424915075302124
Final reward: -0.47687697410583496
Final reward: -0.5407370328903198
Final reward: -0.5136062502861023
Final reward: -0.42581111192703247
Final reward: -0.45172980427742004
Final reward: -0.515151858329773
Final reward: -0.5400818586349487
Final reward: -0.4471648931503296
Final reward: -0.43118563294410706
Final reward: -0.49090760946273804
Final reward: -0.546644389629364
Final reward: -0.4898947775363922
Final reward: -0.4232958257198334
Final reward: -0.4671330153942108
Final reward: -0.5331096649169922
Final reward: -0.5255716443061829
Final reward: -0.4298848509788513
Final reward: -0.4428859055042267
Final reward: -0.5032712817192078
Final reward: -0.5447331666946411
Final reward: -0.4626157283782959
Final reward: -0.42663925886154175
Final reward: -0.4824676215648651
Final reward: -0.5433201789855957
Final reward: -0.5061455368995667
Final reward: -0.42367711663246155
Final reward: -0.4560057818889618
Final reward: -0.5213125348091125
Final reward: -0.5356124639511108
Final reward: -0.4380655586719513
Final reward: -0.4333172142505646
Final reward: -0.4940964877605438
Final reward: -0.5462501049041748
Final reward: -0.48160508275032043
Final reward: -0.4227769076824188
Final reward: -0.47067564725875854
Final reward: -0.5359542965888977
Final reward: -0.5198433995246887
Final reward: -0.42682522535324097
Final reward: -0.4457497298717499
Final reward: -0.506881594657898
Final reward: -0.5422517657279968
Final reward: -0.45527946949005127
Final reward: -0.4272007942199707
Final reward: -0.4850761294364929
Final reward: -0.5443716049194336
Final reward: -0.4977060854434967
Final reward: -0.42213669419288635
Final reward: -0.46061810851097107
Final reward: -0.5268879532814026
Final reward: -0.5301110148429871
Final reward: -0.432294636964798
Final reward: -0.43646249175071716
Final reward: -0.49745529890060425
Final reward: -0.5453261137008667
Final reward: -0.4760783016681671
Final reward: -0.4221939146518707
Final reward: -0.47168204188346863
Final reward: -0.5362052321434021
Final reward: -0.5179619789123535
Final reward: -0.42530718445777893
Final reward: -0.4455319046974182
Final reward: -0.5074279308319092
Final reward: -0.5407942533493042
Final reward: -0.45229217410087585
Final reward: -0.42659270763397217
Final reward: -0.484798789024353
Final reward: -0.5434046387672424
Final reward: -0.49693116545677185
Final reward: -0.42084112763404846
Final reward: -0.4588990807533264
Final reward: -0.5251592397689819
Final reward: -0.529516339302063
Final reward: -0.4364122450351715
Final reward: -0.3708741366863251
Final reward: -0.4247089922428131
Final reward: -0.49638286232948303
Final reward: -0.4779307544231415
Final reward: -0.375313401222229
Final reward: -0.3974795937538147
Final reward: -0.46535149216651917
Final reward: -0.5026410818099976
Final reward: -0.40697839856147766
Final reward: -0.3761332035064697
Final reward: -0.4405782222747803
Final reward: -0.5051897764205933
Final reward: -0.4555457532405853
Final reward: -0.3705180585384369
Final reward: -0.41250282526016235
Final reward: -0.48482730984687805
Final reward: -0.4914499521255493
Final reward: -0.3825938403606415
Final reward: -0.3860546946525574
Final reward: -0.45400190353393555
Final reward: -0.5064733028411865
Final reward: -0.42805662751197815
Final reward: -0.37143123149871826
Final reward: -0.4291069805622101
Final reward: -0.49930882453918457
Final reward: -0.4720248281955719
Final reward: -0.3731301724910736
Final reward: -0.40095946192741394
Final reward: -0.4706318974494934
Final reward: -0.5000312924385071
Final reward: -0.3986131548881531
Final reward: -0.3782782256603241
Final reward: -0.4441318213939667
Final reward: -0.5055190324783325
Final reward: -0.4522823691368103
Final reward: -0.36921942234039307
Final reward: -0.41367241740226746
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.48664382100105286
Final reward: -0.48786717653274536
Final reward: -0.379808634519577
Final reward: -0.3869563937187195
Final reward: -0.4548589289188385
Final reward: -0.5053954124450684
Final reward: -0.42372995615005493
Final reward: -0.37098509073257446
Final reward: -0.4301014244556427
Final reward: -0.4997189939022064
Final reward: -0.4689006507396698
Final reward: -0.37155377864837646
Final reward: -0.4016992151737213
Final reward: -0.4721086919307709
Final reward: -0.49826714396476746
Final reward: -0.39488205313682556
Final reward: -0.3782345652580261
Final reward: -0.4447115361690521
Final reward: -0.5050821304321289
Final reward: -0.44918185472488403
Final reward: -0.3681435286998749
Final reward: -0.4135008156299591
Final reward: -0.48648327589035034
Final reward: -0.48639917373657227
Final reward: -0.3780234158039093
Final reward: -0.38719940185546875
Final reward: -0.45508962869644165
Final reward: -0.504364550113678
Final reward: -0.4232487082481384
Final reward: -0.36943331360816956
Final reward: -0.42848390340805054
Final reward: -0.4984256625175476
Final reward: -0.4682808518409729
Final reward: -0.37024855613708496
Final reward: -0.39998769760131836
Final reward: -0.4704485833644867
Final reward: -0.49756038188934326
Final reward: -0.396371066570282
Final reward: -0.3755071461200714
Final reward: -0.4417126178741455
Final reward: -0.5042194128036499
Final reward: -0.447228342294693
Final reward: -0.36754167079925537
Final reward: -0.41434529423713684
Final reward: -0.4872572124004364
Final reward: -0.48492440581321716
Final reward: -0.37715551257133484
Final reward: -0.38706907629966736
Final reward: -0.4551777243614197
Final reward: -0.5038770437240601
Final reward: -0.41968128085136414
Final reward: -0.3698696196079254
Final reward: -0.4300755560398102
Final reward: -0.4984453320503235
Final reward: -0.46803000569343567
Final reward: -0.36965593695640564
Final reward: -0.39919570088386536
Final reward: -0.4699409306049347
Final reward: -0.4969840943813324
Final reward: -0.39634618163108826
Final reward: -0.37443089485168457
Final reward: -0.4407420754432678
Final reward: -0.5035460591316223
Final reward: -0.4473109245300293
Final reward: -0.366655558347702
Final reward: -0.41303303837776184
Final reward: -0.4860832989215851
Final reward: -0.48472291231155396
Final reward: -0.3763425946235657
Final reward: -0.3861468434333801
Final reward: -0.4541451632976532
Final reward: -0.5032950043678284
Final reward: -0.41901057958602905
Final reward: -0.3690546154975891
Final reward: -0.42941024899482727
Final reward: -0.4987383782863617
Final reward: -0.46524307131767273
Final reward: -0.36877354979515076
Final reward: -0.4007225036621094
Final reward: -0.4718470871448517
Final reward: -0.49576425552368164
Final reward: -0.39135342836380005
Final reward: -0.37617844343185425
Final reward: -0.44345638155937195
Final reward: -0.5038550496101379
Final reward: -0.4417712092399597
Final reward: -0.36616575717926025
Final reward: -0.4161681830883026
Final reward: -0.4884878993034363
Final reward: -0.48188766837120056
Final reward: -0.37485525012016296
Final reward: -0.3861842751502991
Final reward: -0.45424598455429077
Final reward: -0.5022702813148499
Final reward: -0.41852155327796936
Final reward: -0.36756283044815063
Final reward: -0.4279671013355255
Final reward: -0.49749094247817993
Final reward: -0.464702308177948
Final reward: -0.3673906624317169
Final reward: -0.39899706840515137
Final reward: -0.4702927768230438
Final reward: -0.4946967661380768
Final reward: -0.38938793540000916
Final reward: -0.37507110834121704
Final reward: -0.4503381848335266
Final reward: -0.5164286494255066
Final reward: -0.4827325642108917
Final reward: -0.39144134521484375
Final reward: -0.42260420322418213
Final reward: -0.4909977912902832
Final reward: -0.5122062563896179
Final reward: -0.410215824842453
Final reward: -0.3998907208442688
Final reward: -0.4716484546661377
Final reward: -0.5344269871711731
Final reward: -0.49802935123443604
Final reward: -0.4131321310997009
Final reward: -0.44512245059013367
Final reward: -0.5112614631652832
Final reward: -0.5282362103462219
Final reward: -0.43079379200935364
Final reward: -0.4214975833892822
Final reward: -0.48311173915863037
Final reward: -0.5378856062889099
Final reward: -0.4764670729637146
Final reward: -0.41167885065078735
Final reward: -0.45858123898506165
Final reward: -0.5256779789924622
Final reward: -0.513646125793457
Final reward: -0.41722196340560913
Final reward: -0.43359607458114624
Final reward: -0.49482613801956177
Final reward: -0.5350450277328491
Final reward: -0.45145002007484436
Final reward: -0.4147498905658722
Final reward: -0.47187691926956177
Final reward: -0.5342456698417664
Final reward: -0.49577760696411133
Final reward: -0.40425005555152893
Final reward: -0.42304590344429016
Final reward: -0.48639026284217834
Final reward: -0.5248291492462158
Final reward: -0.4356042444705963
Final reward: -0.4037797749042511
Final reward: -0.46403616666793823
Final reward: -0.5262045860290527
Final reward: -0.4804283082485199
Final reward: -0.39911243319511414
Final reward: -0.4372889995574951
Final reward: -0.5058777928352356
Final reward: -0.5140417218208313
Final reward: -0.41116294264793396
Final reward: -0.4123328626155853
Final reward: -0.47631677985191345
Final reward: -0.5280514359474182
Final reward: -0.45753276348114014
Final reward: -0.3993057310581207
Final reward: -0.45136594772338867
Final reward: -0.5186275243759155
Final reward: -0.49840205907821655
Final reward: -0.40239018201828003
Final reward: -0.42514678835868835
Final reward: -0.49034348130226135
Final reward: -0.5227275490760803
Final reward: -0.4306851923465729
Final reward: -0.40417423844337463
Final reward: -0.4654083251953125
Final reward: -0.5262885689735413
Final reward: -0.47675347328186035
Final reward: -0.3981165885925293
Final reward: -0.43915435671806335
Final reward: -0.5082646012306213
Final reward: -0.5105783343315125
Final reward: -0.4079270660877228
Final reward: -0.4148089289665222
Final reward: -0.4787658452987671
Final reward: -0.5268427729606628
Final reward: -0.4501914381980896
Final reward: -0.39931386709213257
Final reward: -0.4540797770023346
Final reward: -0.5199930667877197
Final reward: -0.4952440559864044
Final reward: -0.40111467242240906
Final reward: -0.42396843433380127
Final reward: -0.48926642537117004
Final reward: -0.5220876336097717
Final reward: -0.4300957918167114
Final reward: -0.40309715270996094
Final reward: -0.4644384980201721
Final reward: -0.5255891680717468
Final reward: -0.4753858149051666
Final reward: -0.38033047318458557
Final reward: -0.39174747467041016
Final reward: -0.45880594849586487
Final reward: -0.505864143371582
Final reward: -0.4239678680896759
Final reward: -0.37175241112709045
Final reward: -0.4432000517845154
Final reward: -0.4999215602874756
Final reward: -0.47104543447494507
Final reward: -0.37244266271591187
Final reward: -0.4106529653072357
Final reward: -0.47042056918144226
Final reward: -0.4992789328098297
Final reward: -0.3973280191421509
Final reward: -0.3777100741863251
Final reward: -0.4526723027229309
Final reward: -0.504690945148468
Final reward: -0.45299044251441956
Final reward: -0.36837276816368103
Final reward: -0.423939049243927
Final reward: -0.4836064279079437
Final reward: -0.48933401703834534
Final reward: -0.3802511990070343
Final reward: -0.38730400800704956
Final reward: -0.457183301448822
Final reward: -0.505190372467041
Final reward: -0.42714163661003113
Final reward: -0.3695141673088074
Final reward: -0.4400268495082855
Final reward: -0.49753662943840027
Final reward: -0.47158122062683105
Final reward: -0.3716418445110321
Final reward: -0.4086865186691284
Final reward: -0.46806082129478455
Final reward: -0.49922195076942444
Final reward: -0.3981877267360687
Final reward: -0.37618488073349
Final reward: -0.45175278186798096
Final reward: -0.5046148896217346
Final reward: -0.4478951096534729
Final reward: -0.36809471249580383
Final reward: -0.4278431236743927
Final reward: -0.48734161257743835
Final reward: -0.4856942892074585
Final reward: -0.37767571210861206
Final reward: -0.3926055431365967
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.4580821990966797
Final reward: -0.5043134093284607
Final reward: -0.4205819070339203
Final reward: -0.3702591359615326
Final reward: -0.44323983788490295
Final reward: -0.49979594349861145
Final reward: -0.4655907154083252
Final reward: -0.3696768581867218
Final reward: -0.4133804440498352
Final reward: -0.4730645716190338
Final reward: -0.496301531791687
Final reward: -0.3932850658893585
Final reward: -0.3764950633049011
Final reward: -0.4524306356906891
Final reward: -0.5046694874763489
Final reward: -0.4453684985637665
Final reward: -0.3677121698856354
Final reward: -0.42959508299827576
Final reward: -0.488707035779953
Final reward: -0.48354867100715637
Final reward: -0.37619730830192566
Final reward: -0.3952289819717407
Final reward: -0.45848485827445984
Final reward: -0.5034887790679932
Final reward: -0.4185391068458557
Final reward: -0.36993056535720825
Final reward: -0.4435570538043976
Final reward: -0.499584436416626
Final reward: -0.4646826982498169
Final reward: -0.3691513240337372
Final reward: -0.4140581786632538
Final reward: -0.473369836807251
Final reward: -0.4954845905303955
Final reward: -0.38868948817253113
Final reward: -0.37825894355773926
Final reward: -0.4539254307746887
Final reward: -0.5043018460273743
Final reward: -0.44226524233818054
Final reward: -0.3630230724811554
Final reward: -0.42508944869041443
Final reward: -0.4794830083847046
Final reward: -0.4854615330696106
Final reward: -0.37502819299697876
Final reward: -0.38868749141693115
Final reward: -0.4582230746746063
Final reward: -0.5011246800422668
Final reward: -0.42231911420822144
Final reward: -0.3638569116592407
Final reward: -0.4415249228477478
Final reward: -0.49402040243148804
Final reward: -0.46516358852386475
Final reward: -0.3652925491333008
Final reward: -0.41181886196136475
Final reward: -0.4664110541343689
Final reward: -0.49377819895744324
Final reward: -0.3907276391983032
Final reward: -0.373241662979126
Final reward: -0.4533200263977051
Final reward: -0.500556468963623
Final reward: -0.4404595196247101
Final reward: -0.3620595932006836
Final reward: -0.43034234642982483
Final reward: -0.48429226875305176
Final reward: -0.4795568883419037
Final reward: -0.37087178230285645
Final reward: -0.395652174949646
Final reward: -0.45920732617378235
Final reward: -0.4995054006576538
Final reward: -0.41371411085128784
Final reward: -0.36443936824798584
Final reward: -0.44434279203414917
Final reward: -0.49513131380081177
Final reward: -0.4613882303237915
Final reward: -0.36368414759635925
Final reward: -0.4140380024909973
Final reward: -0.46826133131980896
Final reward: -0.49183300137519836
Final reward: -0.3875061869621277
Final reward: -0.37416285276412964
Final reward: -0.4577624201774597
Final reward: -0.5077217817306519
Final reward: -0.4630098044872284
Final reward: -0.3748973608016968
Final reward: -0.4306891858577728
Final reward: -0.4858083128929138
Final reward: -0.4958195984363556
Final reward: -0.38735947012901306
Final reward: -0.39571210741996765
Final reward: -0.4655262231826782
Final reward: -0.5097355842590332
Final reward: -0.43507400155067444
Final reward: -0.375044584274292
Final reward: -0.4477061927318573
Final reward: -0.500881552696228
Final reward: -0.4777262806892395
Final reward: -0.3777889609336853
Final reward: -0.4179006516933441
Final reward: -0.4727191925048828
Final reward: -0.5034101009368896
Final reward: -0.4029083847999573
Final reward: -0.38225439190864563
Final reward: -0.4607267379760742
Final reward: -0.5088168978691101
Final reward: -0.4536135196685791
Final reward: -0.37370380759239197
Final reward: -0.4361328184604645
Final reward: -0.4909493327140808
Final reward: -0.4907410442829132
Final reward: -0.3838546872138977
Final reward: -0.4006838798522949
Final reward: -0.4662226140499115
Final reward: -0.5086365342140198
Final reward: -0.42801377177238464
Final reward: -0.3752146065235138
Final reward: -0.4501868784427643
Final reward: -0.5012645721435547
Final reward: -0.47720572352409363
Final reward: -0.3770071864128113
Final reward: -0.41263988614082336
Final reward: -0.46932128071784973
Final reward: -0.5041615962982178
Final reward: -0.4087503254413605
Final reward: -0.3783559501171112
Final reward: -0.4573453962802887
Final reward: -0.506537914276123
Final reward: -0.4576485753059387
Final reward: -0.37253618240356445
Final reward: -0.43203821778297424
Final reward: -0.48689723014831543
Final reward: -0.4923020899295807
Final reward: -0.38400378823280334
Final reward: -0.3968336582183838
Final reward: -0.4648529887199402
Final reward: -0.5078383088111877
Final reward: -0.4296235144138336
Final reward: -0.37324684858322144
Final reward: -0.4605990946292877
Final reward: -0.5152109861373901
Final reward: -0.5445961952209473
Final reward: -0.4648361802101135
Final reward: -0.4139098823070526
Final reward: -0.4797179400920868
Final reward: -0.5288150906562805
Final reward: -0.527887761592865
Final reward: -0.4399991035461426
Final reward: -0.446062296628952
Final reward: -0.517715573310852
Final reward: -0.5398270487785339
Final reward: -0.48459699749946594
Final reward: -0.42122772336006165
Final reward: -0.4954037368297577
Final reward: -0.5376772284507751
Final reward: -0.5169821381568909
Final reward: -0.4146318733692169
Final reward: -0.4652215540409088
Final reward: -0.5250597596168518
Final reward: -0.5318413972854614
Final reward: -0.46017441153526306
Final reward: -0.43322864174842834
Final reward: -0.5166536569595337
Final reward: -0.5609458684921265
Final reward: -0.5489326119422913
Final reward: -0.4569777548313141
Final reward: -0.487150102853775
Final reward: -0.5502984523773193
Final reward: -0.5645584464073181
Final reward: -0.4999905526638031
Final reward: -0.46125084161758423
Final reward: -0.531968891620636
Final reward: -0.5676165223121643
Final reward: -0.5354368090629578
Final reward: -0.44775182008743286
Final reward: -0.5044018626213074
Final reward: -0.5547037124633789
Final reward: -0.5549052357673645
Final reward: -0.4761078655719757
Final reward: -0.47455012798309326
Final reward: -0.5435848832130432
Final reward: -0.5680607557296753
Final reward: -0.5169045329093933
Final reward: -0.4531567692756653
Final reward: -0.5206834077835083
Final reward: -0.5630418062210083
Final reward: -0.5457166433334351
Final reward: -0.45162448287010193
Final reward: -0.4897022247314453
Final reward: -0.5510455369949341
Final reward: -0.5633282661437988
Final reward: -0.4972037076950073
Final reward: -0.4620470106601715
Final reward: -0.5332295298576355
Final reward: -0.5676551461219788
Final reward: -0.5319238305091858
Final reward: -0.4477859139442444
Final reward: -0.5070148706436157
Final reward: -0.5545474886894226
Final reward: -0.5523437261581421
Final reward: -0.471774697303772
Final reward: -0.47590744495391846
Final reward: -0.5443511009216309
Final reward: -0.5673583149909973
Final reward: -0.5155194401741028
Final reward: -0.4522787630558014
Final reward: -0.5195210576057434
Final reward: -0.5621649026870728
Final reward: -0.5449296832084656
Final reward: -0.44981715083122253
Final reward: -0.48957815766334534
Final reward: -0.5507229566574097
Final reward: -0.5624160766601562
Final reward: -0.493447482585907
Final reward: -0.46297410130500793
Final reward: -0.5341606736183167
Final reward: -0.5675262212753296
Final reward: -0.5295515060424805
Final reward: -0.4476762115955353
Final reward: -0.5079740881919861
Final reward: -0.5549129247665405
Final reward: -0.5510207414627075
Final reward: -0.4684251844882965
Final reward: -0.4771731197834015
Final reward: -0.5450929999351501
Final reward: -0.5665335059165955
Final reward: -0.5095615983009338
Final reward: -0.454598605632782
Final reward: -0.5238627195358276
Final reward: -0.5642075538635254
Final reward: -0.5406705737113953
Final reward: -0.44608274102211
Final reward: -0.49316510558128357
Final reward: -0.5518531799316406
Final reward: -0.560758650302887
Final reward: -0.4894709289073944
Final reward: -0.46472153067588806
Final reward: -0.5359539985656738
Final reward: -0.5676652193069458
Final reward: -0.5266484022140503
Final reward: -0.4480973482131958
Final reward: -0.5104404091835022
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5567746758460999
Final reward: -0.5488717555999756
Final reward: -0.46166613698005676
Final reward: -0.48056966066360474
Final reward: -0.5464093685150146
Final reward: -0.5656396150588989
Final reward: -0.5096108317375183
Final reward: -0.4528062045574188
Final reward: -0.52178955078125
Final reward: -0.5629453659057617
Final reward: -0.540050745010376
Final reward: -0.44500333070755005
Final reward: -0.493310809135437
Final reward: -0.5510998964309692
Final reward: -0.5595384836196899
Final reward: -0.49005070328712463
Final reward: -0.46094128489494324
Final reward: -0.5316707491874695
Final reward: -0.5659002661705017
Final reward: -0.5322185158729553
Final reward: -0.4449823200702667
Final reward: -0.4966183602809906
Final reward: -0.5521140694618225
Final reward: -0.5579193234443665
Final reward: -0.4828335642814636
Final reward: -0.46625298261642456
Final reward: -0.5366963148117065
Final reward: -0.566875159740448
Final reward: -0.52398282289505
Final reward: -0.44727879762649536
Final reward: -0.5102571845054626
Final reward: -0.556460440158844
Final reward: -0.5467084050178528
Final reward: -0.45760491490364075
Final reward: -0.48099973797798157
Final reward: -0.5467512607574463
Final reward: -0.564797043800354
Final reward: -0.5021923780441284
Final reward: -0.4564056992530823
Final reward: -0.5266700983047485
Final reward: -0.564985454082489
Final reward: -0.5359827876091003
Final reward: -0.4453553259372711
Final reward: -0.49755120277404785
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                   avg_speed ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñá‚ñÉ‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñà
wandb:                        cost ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  is_success ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   max_speed ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñá‚ñÉ‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñà
wandb:                      reward ‚ñÜ‚ñá‚ñÖ‚ñá‚ñÉ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñá‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb:             train/approx_kl ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñÉ‚ñÜ
wandb:         train/clip_fraction ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÜ
wandb:            train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/cost_returns ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÖ‚ñÇ‚ñà‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÉ
wandb:       train/cost_value_loss ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñá‚ñÉ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÅ
wandb:           train/cost_values ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÉ‚ñá‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñá‚ñÉ‚ñÑ‚ñÖ
wandb:               train/entropy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:          train/entropy_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:    train/explained_variance ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÖ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/lagrangian_multiplier ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:         train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss ‚ñÑ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  train/policy_gradient_loss ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÇ
wandb:                   train/std ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/value_loss ‚ñÖ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                   avg_speed 7.92641
wandb:                        cost 0
wandb:                  is_success 0
wandb:                   max_speed 7.92641
wandb:                      reward -0.59556
wandb:             train/approx_kl 0.00806
wandb:         train/clip_fraction 0.08691
wandb:            train/clip_range 0.2
wandb:          train/cost_returns 2.91006
wandb:       train/cost_value_loss 3.23743
wandb:           train/cost_values 2.23607
wandb:               train/entropy -1.19922
wandb:          train/entropy_loss -1.19604
wandb:    train/explained_variance 0.98917
wandb: train/lagrangian_multiplier 0.0
wandb:         train/learning_rate 0.0003
wandb:                  train/loss 2.3211
wandb:             train/n_updates 9790
wandb:  train/policy_gradient_loss -0.0064
wandb:                   train/std 0.44084
wandb:            train/value_loss 1.41603
wandb: 
wandb: üöÄ View run fresh-sun-29 at: https://wandb.ai/ecrl/ppol-extra-obs/runs/gcskytqy
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240307_032750-gcskytqy/logs
srun: Job 148608 step creation still disabled, retrying (Requested nodes are busy)
srun: Step created for StepId=148608.1
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240307_114624-46po4mwk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-darkness-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/46po4mwk
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
Using cpu device
-----------------------------------
| avg_speed          | 0.496      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.496      |
| reward             | -0.4377388 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -870       |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 2048       |
-----------------------------------
-------------------------------------------
| avg_speed                | 1.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.58         |
| reward                   | -0.9477178   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 51           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0039845463 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 16.8         |
|    cost_values           | 0.366        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 9.61e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.1         |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 1            |
|    value_loss            | 187          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.858       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.858       |
| reward                   | -0.89600617 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 3           |
|    time_elapsed          | 81          |
|    total_timesteps       | 6144        |
| train/                   |             |
|    approx_kl             | 0.001001138 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 5.45        |
|    cost_values           | 0.973       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -0.0312     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 176         |
|    n_updates             | 20          |
|    policy_gradient_loss  | -0.000725   |
|    std                   | 1           |
|    value_loss            | 380         |
------------------------------------------
--------------------------------------------
| avg_speed                | 4.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.03          |
| reward                   | -1.6745083    |
| rollout/                 |               |
|    ep_len_mean           | 930           |
|    ep_rew_mean           | -963          |
| time/                    |               |
|    fps                   | 73            |
|    iterations            | 4             |
|    time_elapsed          | 111           |
|    total_timesteps       | 8192          |
| train/                   |               |
|    approx_kl             | 0.00014553126 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.21          |
|    cost_value_loss       | 2.74          |
|    cost_values           | 0.981         |
|    entropy               | -2.83         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -0.000543     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 108           |
|    n_updates             | 30            |
|    policy_gradient_loss  | -0.000195     |
|    std                   | 0.998         |
|    value_loss            | 241           |
--------------------------------------------
--------------------------------------------
| avg_speed                | 4.48          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.48          |
| reward                   | -1.4147346    |
| rollout/                 |               |
|    ep_len_mean           | 944           |
|    ep_rew_mean           | -1e+03        |
| time/                    |               |
|    fps                   | 71            |
|    iterations            | 5             |
|    time_elapsed          | 142           |
|    total_timesteps       | 10240         |
| train/                   |               |
|    approx_kl             | 0.00017418619 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.5           |
|    cost_value_loss       | 6.01          |
|    cost_values           | 0.977         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.83         |
|    explained_variance    | -0.000199     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 152           |
|    n_updates             | 40            |
|    policy_gradient_loss  | -0.000228     |
|    std                   | 0.999         |
|    value_loss            | 331           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.9279333   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0002519204 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 1.31         |
|    cost_values           | 0.931        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 5.63e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 142          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.000244    |
|    std                   | 1            |
|    value_loss            | 306          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 1.75          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.75          |
| reward                   | -2.0371327    |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -1.05e+03     |
| time/                    |               |
|    fps                   | 70            |
|    iterations            | 7             |
|    time_elapsed          | 203           |
|    total_timesteps       | 14336         |
| train/                   |               |
|    approx_kl             | 0.00026211835 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.964         |
|    cost_value_loss       | 1.27          |
|    cost_values           | 0.953         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -7.26e-05     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 94.2          |
|    n_updates             | 60            |
|    policy_gradient_loss  | -0.00059      |
|    std                   | 1             |
|    value_loss            | 223           |
--------------------------------------------
-----------------------------------------
| avg_speed                | 7.94       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.94       |
| reward                   | -2.73753   |
| rollout/                 |            |
|    ep_len_mean           | 964        |
|    ep_rew_mean           | -1.12e+03  |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 8          |
|    time_elapsed          | 233        |
|    total_timesteps       | 16384      |
| train/                   |            |
|    approx_kl             | 0.00331131 |
|    clip_fraction         | 0.00288    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.21       |
|    cost_value_loss       | 2.53       |
|    cost_values           | 0.988      |
|    entropy               | -2.85      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 1.79e-05   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 288        |
|    n_updates             | 70         |
|    policy_gradient_loss  | -0.00327   |
|    std                   | 1          |
|    value_loss            | 617        |
-----------------------------------------
--------------------------------------------
| avg_speed                | 0.0286        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0286        |
| reward                   | -0.4277787    |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -1.19e+03     |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 9             |
|    time_elapsed          | 263           |
|    total_timesteps       | 18432         |
| train/                   |               |
|    approx_kl             | 0.00039180837 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.04          |
|    cost_value_loss       | 1.62          |
|    cost_values           | 0.98          |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -2.3e-05      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 349           |
|    n_updates             | 80            |
|    policy_gradient_loss  | -0.000343     |
|    std                   | 1             |
|    value_loss            | 713           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.911        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.911        |
| reward                   | -0.50878024  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 294          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0007339264 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 1.34         |
|    cost_values           | 0.967        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -5.96e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 216          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.000897    |
|    std                   | 1            |
|    value_loss            | 456          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.81         |
| reward                   | -0.9624261   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 324          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0016417882 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.72         |
|    cost_values           | 0.983        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -5.22e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 298          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00148     |
|    std                   | 1            |
|    value_loss            | 671          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 1.06          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 1.06          |
| reward                   | -0.597756     |
| rollout/                 |               |
|    ep_len_mean           | 977           |
|    ep_rew_mean           | -1.24e+03     |
| time/                    |               |
|    fps                   | 69            |
|    iterations            | 12            |
|    time_elapsed          | 355           |
|    total_timesteps       | 24576         |
| train/                   |               |
|    approx_kl             | 0.00025372108 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.21          |
|    cost_value_loss       | 2.24          |
|    cost_values           | 0.973         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -0.00143      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 206           |
|    n_updates             | 110           |
|    policy_gradient_loss  | -0.000492     |
|    std                   | 1.01          |
|    value_loss            | 444           |
--------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.86284363 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 385         |
|    total_timesteps       | 26624       |
| train/                   |             |
|    approx_kl             | 0.004011405 |
|    clip_fraction         | 0.00703     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 1.49        |
|    cost_values           | 0.906       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 2.65e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 129         |
|    n_updates             | 120         |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 1.01        |
|    value_loss            | 300         |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.04          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.04          |
| reward                   | -1.4527696    |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -1.24e+03     |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 14            |
|    time_elapsed          | 416           |
|    total_timesteps       | 28672         |
| train/                   |               |
|    approx_kl             | 0.00036552743 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.09          |
|    cost_value_loss       | 1.46          |
|    cost_values           | 0.927         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -0.015        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 141           |
|    n_updates             | 130           |
|    policy_gradient_loss  | -0.00053      |
|    std                   | 1.01          |
|    value_loss            | 297           |
--------------------------------------------
------------------------------------------
| avg_speed                | 4.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.05        |
| reward                   | -1.4965256  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 446         |
|    total_timesteps       | 30720       |
| train/                   |             |
|    approx_kl             | 0.004990398 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 1.82        |
|    cost_values           | 0.931       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.000813   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 122         |
|    n_updates             | 140         |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 1.01        |
|    value_loss            | 261         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.09         |
| reward                   | -1.5180061   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 476          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0009875458 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.31         |
|    cost_values           | 0.958        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -5.75e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 189          |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.000872    |
|    std                   | 1.01         |
|    value_loss            | 400          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 6.8           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.8           |
| reward                   | -1.8266486    |
| rollout/                 |               |
|    ep_len_mean           | 984           |
|    ep_rew_mean           | -1.29e+03     |
| time/                    |               |
|    fps                   | 68            |
|    iterations            | 17            |
|    time_elapsed          | 507           |
|    total_timesteps       | 34816         |
| train/                   |               |
|    approx_kl             | 0.00067836547 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.01          |
|    cost_value_loss       | 1.02          |
|    cost_values           | 0.882         |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -3.8e-05      |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 270           |
|    n_updates             | 160           |
|    policy_gradient_loss  | -0.000741     |
|    std                   | 1             |
|    value_loss            | 563           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 3.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.65         |
| reward                   | -0.89936614  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 537          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0013868022 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.549        |
|    cost_values           | 0.908        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -5.95e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 265          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 1            |
|    value_loss            | 552          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.36        |
| reward                   | -1.5904073  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 568         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.001380981 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 1.18        |
|    cost_values           | 0.95        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -2.4e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 167         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.000878   |
|    std                   | 1           |
|    value_loss            | 362         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -1.9467098   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 598          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0012203511 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 12           |
|    cost_values           | 0.974        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -2.66e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 147          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.000964    |
|    std                   | 1            |
|    value_loss            | 292          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.880058    |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 629          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0019171296 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 2.33         |
|    cost_values           | 0.927        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -2.91e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 183          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.996        |
|    value_loss            | 384          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.57        |
| reward                   | -1.3275352  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 659         |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.005388875 |
|    clip_fraction         | 0.0129      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 4.84        |
|    cost_values           | 0.95        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -1.79e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 112         |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.994       |
|    value_loss            | 243         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.81         |
| reward                   | -1.5169567   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 690          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0045442423 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.995        |
|    cost_value_loss       | 0.387        |
|    cost_values           | 0.928        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -1.67e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 110          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.993        |
|    value_loss            | 224          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.44         |
| reward                   | -0.87962484  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 720          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0043022255 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.49         |
|    cost_values           | 0.955        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -7.75e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.3         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.994        |
|    value_loss            | 146          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.87         |
| reward                   | -0.8654763   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 751          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0014887878 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.957        |
|    cost_values           | 0.903        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -6.79e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.8         |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.997        |
|    value_loss            | 181          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.06         |
| reward                   | -1.9458015   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 781          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0043397453 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 8.73         |
|    cost_values           | 0.977        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -3.58e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.7         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.993        |
|    value_loss            | 134          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.564435   |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 811         |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.006312354 |
|    clip_fraction         | 0.0192      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.971       |
|    cost_value_loss       | 1.19        |
|    cost_values           | 0.945       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.82       |
|    explained_variance    | -6.79e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 98.5        |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.994       |
|    value_loss            | 212         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -2.0589716   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 28           |
|    time_elapsed          | 842          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0018472492 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 0.977        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.53e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 389          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.995        |
|    value_loss            | 840          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.4567044   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 872          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0027418341 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 5.95         |
|    cost_values           | 0.962        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -3.17e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 237          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.996        |
|    value_loss            | 479          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.1          |
| reward                   | -2.1916294   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 902          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0015659648 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 1.27         |
|    cost_values           | 0.905        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -9.18e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 241          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.998        |
|    value_loss            | 497          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.9423033  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 933         |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.003051912 |
|    clip_fraction         | 0.00371     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.927       |
|    cost_value_loss       | 1.36        |
|    cost_values           | 0.894       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -6.68e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 288         |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.997       |
|    value_loss            | 602         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.5493388   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 963          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0050770408 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 2.08         |
|    cost_values           | 0.951        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1e-05       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 95.3         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.998        |
|    value_loss            | 227          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.3         |
| reward                   | -0.23773491 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 994         |
|    total_timesteps       | 67584       |
| train/                   |             |
|    approx_kl             | 0.004320061 |
|    clip_fraction         | 0.0123      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.971       |
|    cost_value_loss       | 1.38        |
|    cost_values           | 0.939       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -3.1e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 147         |
|    n_updates             | 320         |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.999       |
|    value_loss            | 320         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.01         |
| reward                   | -0.7225341   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 34           |
|    time_elapsed          | 1024         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0009742997 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 1.49         |
|    cost_values           | 0.939        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -2.98e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.6         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.000469    |
|    std                   | 0.998        |
|    value_loss            | 137          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.39         |
| reward                   | -0.88991374  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 35           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0029297327 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 6.93         |
|    cost_values           | 0.98         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.79e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.2         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 1            |
|    value_loss            | 117          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.3           |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.3           |
| reward                   | -1.2264211    |
| rollout/                 |               |
|    ep_len_mean           | 981           |
|    ep_rew_mean           | -1.31e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 36            |
|    time_elapsed          | 1085          |
|    total_timesteps       | 73728         |
| train/                   |               |
|    approx_kl             | 0.00071131566 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.15          |
|    cost_value_loss       | 2.16          |
|    cost_values           | 0.927         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -4.77e-06     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 145           |
|    n_updates             | 350           |
|    policy_gradient_loss  | -0.000418     |
|    std                   | 1             |
|    value_loss            | 318           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.7424575   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1116         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0048674257 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.61         |
|    cost_values           | 0.953        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -5.13e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.6         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 1            |
|    value_loss            | 88.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -1.2264538  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1146        |
|    total_timesteps       | 77824       |
| train/                   |             |
|    approx_kl             | 0.003696171 |
|    clip_fraction         | 0.0109      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.885       |
|    cost_value_loss       | 0.577       |
|    cost_values           | 0.94        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -2.38e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 208         |
|    n_updates             | 370         |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 1           |
|    value_loss            | 452         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -1.5538191   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1176         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0019283642 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.993        |
|    cost_value_loss       | 1.79         |
|    cost_values           | 0.942        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -4.05e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.9         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.000989    |
|    std                   | 1            |
|    value_loss            | 186          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1544851   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1207         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0047809174 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 1.46         |
|    cost_values           | 0.98         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -4.65e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 233          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 1            |
|    value_loss            | 492          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.28          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.28          |
| reward                   | -1.2730764    |
| rollout/                 |               |
|    ep_len_mean           | 983           |
|    ep_rew_mean           | -1.36e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 41            |
|    time_elapsed          | 1237          |
|    total_timesteps       | 83968         |
| train/                   |               |
|    approx_kl             | 0.00085133035 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.983         |
|    cost_value_loss       | 0.821         |
|    cost_values           | 0.991         |
|    entropy               | -2.84         |
|    entropy_loss          | -2.84         |
|    explained_variance    | -4.77e-06     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 222           |
|    n_updates             | 400           |
|    policy_gradient_loss  | -0.000777     |
|    std                   | 1             |
|    value_loss            | 452           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.2074069   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1267         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0036076226 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.98         |
|    cost_values           | 0.94         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -1.91e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 255          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 1            |
|    value_loss            | 533          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -2.2781222 |
| rollout/                 |            |
|    ep_len_mean           | 984        |
|    ep_rew_mean           | -1.37e+03  |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 43         |
|    time_elapsed          | 1298       |
|    total_timesteps       | 88064      |
| train/                   |            |
|    approx_kl             | 0.00503938 |
|    clip_fraction         | 0.0156     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.913      |
|    cost_value_loss       | 0.776      |
|    cost_values           | 0.944      |
|    entropy               | -2.83      |
|    entropy_loss          | -2.83      |
|    explained_variance    | -2.38e-06  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 89.1       |
|    n_updates             | 420        |
|    policy_gradient_loss  | -0.00197   |
|    std                   | 0.996      |
|    value_loss            | 193        |
-----------------------------------------
-----------------------------------------
| avg_speed                | 7.38       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.38       |
| reward                   | -1.4409609 |
| rollout/                 |            |
|    ep_len_mean           | 984        |
|    ep_rew_mean           | -1.38e+03  |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 44         |
|    time_elapsed          | 1328       |
|    total_timesteps       | 90112      |
| train/                   |            |
|    approx_kl             | 0.00422193 |
|    clip_fraction         | 0.00762    |
|    clip_range            | 0.2        |
|    cost_returns          | 0.961      |
|    cost_value_loss       | 1.27       |
|    cost_values           | 0.937      |
|    entropy               | -2.83      |
|    entropy_loss          | -2.83      |
|    explained_variance    | -2.38e-06  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 148        |
|    n_updates             | 430        |
|    policy_gradient_loss  | -0.00218   |
|    std                   | 0.997      |
|    value_loss            | 336        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.69046235 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1359        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.004658226 |
|    clip_fraction         | 0.0177      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.926       |
|    cost_value_loss       | 0.956       |
|    cost_values           | 0.944       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -2.5e-06    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 232         |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 0.998       |
|    value_loss            | 506         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.11         |
| reward                   | -1.8168613   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1389         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0035283454 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.04         |
|    cost_values           | 0.975        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.6         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.992        |
|    value_loss            | 81.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.7857883   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1419         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0039024684 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 1.12         |
|    cost_values           | 0.9          |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -2.98e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 57.8         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.988        |
|    value_loss            | 128          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -2.3056083   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1450         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0059443386 |
|    clip_fraction         | 0.0531       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.921        |
|    cost_value_loss       | 0.797        |
|    cost_values           | 0.953        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.86e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 89.5         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 0.986        |
|    value_loss            | 187          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -1.9268101  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.4e+03    |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1480        |
|    total_timesteps       | 100352      |
| train/                   |             |
|    approx_kl             | 0.004157846 |
|    clip_fraction         | 0.0139      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.913       |
|    cost_value_loss       | 0.925       |
|    cost_values           | 0.93        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -1.79e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 226         |
|    n_updates             | 480         |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 0.987       |
|    value_loss            | 483         |
------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/46po4mwk
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -1.3713096 |
| rollout/           |            |
|    ep_len_mean     | 986        |
|    ep_rew_mean     | -1.41e+03  |
| time/              |            |
|    fps             | 100        |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 6.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.71         |
| reward                   | -2.0163236   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0042748055 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.906        |
|    cost_value_loss       | 0.577        |
|    cost_values           | 0.95         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -2.5e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 139          |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.984        |
|    value_loss            | 303          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -2.505137   |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.44e+03   |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 3           |
|    time_elapsed          | 81          |
|    total_timesteps       | 106496      |
| train/                   |             |
|    approx_kl             | 0.007848063 |
|    clip_fraction         | 0.0705      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 2.05        |
|    cost_values           | 0.953       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 71.5        |
|    n_updates             | 510         |
|    policy_gradient_loss  | -0.0058     |
|    std                   | 0.984       |
|    value_loss            | 153         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -2.4361172  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.45e+03   |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 111         |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.003961273 |
|    clip_fraction         | 0.0364      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.918       |
|    cost_value_loss       | 1.18        |
|    cost_values           | 0.795       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 172         |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 0.986       |
|    value_loss            | 372         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -3.5453691  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 5           |
|    time_elapsed          | 141         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.004054145 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.972       |
|    cost_value_loss       | 2.48        |
|    cost_values           | 0.886       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | -2.66e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 221         |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.987       |
|    value_loss            | 467         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.07         |
| reward                   | -0.6173157   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.49e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0034338776 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.93         |
|    cost_value_loss       | 0.762        |
|    cost_values           | 0.937        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -9.42e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 293          |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.989        |
|    value_loss            | 607          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.44         |
| reward                   | -0.70446736  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.49e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 202          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0022637288 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.914        |
|    cost_value_loss       | 0.582        |
|    cost_values           | 0.929        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -2.03e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 149          |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.99         |
|    value_loss            | 307          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.48        |
| reward                   | -1.454032   |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.49e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 233         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.002458386 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.882       |
|    cost_value_loss       | 0.746       |
|    cost_values           | 0.898       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 48.7        |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.981       |
|    value_loss            | 108         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.94         |
| reward                   | -0.6127603   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.49e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 263          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0039134934 |
|    clip_fraction         | 0.0435       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.905        |
|    cost_value_loss       | 1.18         |
|    cost_values           | 0.887        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 169          |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 0.98         |
|    value_loss            | 366          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.45        |
| reward                   | -0.94204885 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.49e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 293         |
|    total_timesteps       | 120832      |
| train/                   |             |
|    approx_kl             | 0.004822171 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.96        |
|    cost_value_loss       | 0.862       |
|    cost_values           | 0.925       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.8        |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 110         |
|    n_updates             | 580         |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 0.977       |
|    value_loss            | 238         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.42         |
| reward                   | -1.7107242   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.51e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 324          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0042610653 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.915        |
|    cost_value_loss       | 0.699        |
|    cost_values           | 0.931        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -1.55e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.7         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 0.973        |
|    value_loss            | 76.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.9565585   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.52e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 12           |
|    time_elapsed          | 354          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0025029057 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.906        |
|    cost_value_loss       | 1.22         |
|    cost_values           | 0.91         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -1.19e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 187          |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.97         |
|    value_loss            | 420          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.0666976  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.53e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 384         |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.004359806 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.876       |
|    cost_value_loss       | 0.597       |
|    cost_values           | 0.892       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | -1.43e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 71.4        |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.97        |
|    value_loss            | 153         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.0988259   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.52e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 415          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0027824703 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 2.35         |
|    cost_values           | 0.94         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.7         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.968        |
|    value_loss            | 201          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -2.0549874   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.52e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 445          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0063439375 |
|    clip_fraction         | 0.0517       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.9          |
|    cost_value_loss       | 0.929        |
|    cost_values           | 0.872        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 0.968        |
|    value_loss            | 24.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.06        |
| reward                   | -1.1036886  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.53e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.003866708 |
|    clip_fraction         | 0.0347      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.891       |
|    cost_value_loss       | 0.676       |
|    cost_values           | 0.897       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -1.91e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 46.2        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 0.963       |
|    value_loss            | 96.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.1513351   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.52e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 506          |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0044712564 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 3.77         |
|    cost_values           | 0.921        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -1.79e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 100          |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.96         |
|    value_loss            | 213          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -2.0215259  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.53e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 537         |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.006850955 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.944       |
|    cost_value_loss       | 0.893       |
|    cost_values           | 0.959       |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 46.6        |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.959       |
|    value_loss            | 96.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.73         |
| reward                   | -2.4675648   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.53e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 567          |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0032815882 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 2.22         |
|    cost_values           | 0.958        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 82.4         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.96         |
|    value_loss            | 177          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.469       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.469       |
| reward                   | -2.2110972  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.55e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 597         |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.004755857 |
|    clip_fraction         | 0.0336      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.875       |
|    cost_value_loss       | 0.482       |
|    cost_values           | 0.911       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | -1.43e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 80.9        |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.963       |
|    value_loss            | 179         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.14         |
| reward                   | -1.9721498   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.55e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 628          |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0035445145 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.877        |
|    cost_value_loss       | 0.602        |
|    cost_values           | 0.874        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 0.965        |
|    value_loss            | 233          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.9665834   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.55e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 658          |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0056870184 |
|    clip_fraction         | 0.046        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.763        |
|    cost_values           | 0.875        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.4         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.967        |
|    value_loss            | 111          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.64         |
| reward                   | -1.4432987   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.56e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 688          |
|    total_timesteps       | 147456       |
| train/                   |              |
|    approx_kl             | 0.0025349564 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.866        |
|    cost_value_loss       | 0.983        |
|    cost_values           | 0.869        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 710          |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.968        |
|    value_loss            | 197          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.65        |
| reward                   | -2.2601237  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.57e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 719         |
|    total_timesteps       | 149504      |
| train/                   |             |
|    approx_kl             | 0.004958275 |
|    clip_fraction         | 0.053       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.95        |
|    cost_value_loss       | 1.78        |
|    cost_values           | 0.932       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.8        |
|    n_updates             | 720         |
|    policy_gradient_loss  | -0.00462    |
|    std                   | 0.965       |
|    value_loss            | 77.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.35        |
| reward                   | -1.2939583  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.58e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 749         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.008173907 |
|    clip_fraction         | 0.0687      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 1.71        |
|    cost_values           | 0.935       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.4        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00664    |
|    std                   | 0.968       |
|    value_loss            | 71.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.417       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.417       |
| reward                   | -1.9204085  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.57e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 779         |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.004983095 |
|    clip_fraction         | 0.0326      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 1.13        |
|    cost_values           | 0.911       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -7.15e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 84.6        |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 0.967       |
|    value_loss            | 178         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.42         |
| reward                   | -2.0689278   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.57e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 27           |
|    time_elapsed          | 810          |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0035100766 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 3.94         |
|    cost_values           | 0.897        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 83.3         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.969        |
|    value_loss            | 173          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.159       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.159       |
| reward                   | -0.47363085 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.58e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 840         |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.007390668 |
|    clip_fraction         | 0.051       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.962       |
|    cost_value_loss       | 1.12        |
|    cost_values           | 0.941       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49.9        |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.00423    |
|    std                   | 0.97        |
|    value_loss            | 108         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.66        |
| reward                   | -0.4273366  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.57e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 871         |
|    total_timesteps       | 159744      |
| train/                   |             |
|    approx_kl             | 0.005144382 |
|    clip_fraction         | 0.0374      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.52        |
|    cost_values           | 0.971       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.6        |
|    n_updates             | 770         |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.965       |
|    value_loss            | 68.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.217        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.217        |
| reward                   | -0.79630816  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.56e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 901          |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0036600519 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.93         |
|    cost_values           | 0.968        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 2.98e-07     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.971        |
|    value_loss            | 25.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.81        |
| reward                   | -0.99846745 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.57e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 931         |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.005190393 |
|    clip_fraction         | 0.0503      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 1.98        |
|    cost_values           | 0.984       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.97        |
|    value_loss            | 29.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.38         |
| reward                   | -0.7119825   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.56e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 962          |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0054597426 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.49         |
|    cost_values           | 0.959        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.2         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.972        |
|    value_loss            | 113          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0211097  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.56e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 992         |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.005699156 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 3.17        |
|    cost_values           | 1.06        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.2        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.000194   |
|    std                   | 0.975       |
|    value_loss            | 58.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.58         |
| reward                   | -1.1693573   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.56e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 34           |
|    time_elapsed          | 1023         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0024477611 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 0.915        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.974        |
|    value_loss            | 33.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.38         |
| reward                   | -0.73659533  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.56e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 35           |
|    time_elapsed          | 1053         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0043125954 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 2.32         |
|    cost_values           | 0.988        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16           |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 0.967        |
|    value_loss            | 30.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.5414033  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.55e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1084        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.004997799 |
|    clip_fraction         | 0.0112      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 1           |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 61.4        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.964       |
|    value_loss            | 116         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.3005071   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.54e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1114         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0033083844 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 11           |
|    cost_values           | 1.02         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.9         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.96         |
|    value_loss            | 69.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.09        |
| reward                   | -1.3776466  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.53e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1144        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.005939631 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.29        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 1.68        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 52.4        |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.00385    |
|    std                   | 0.957       |
|    value_loss            | 96.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.62         |
| reward                   | -1.2847555   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.5e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1175         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0048852786 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 4.92         |
|    cost_values           | 1.94         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29           |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.959        |
|    value_loss            | 53.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0481       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0481       |
| reward                   | -0.9108857   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.49e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1205         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0009873016 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.06         |
|    cost_values           | 1.12         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.3         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.96         |
|    value_loss            | 49.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.23        |
| reward                   | -1.5287871  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.48e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1236        |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.003907704 |
|    clip_fraction         | 0.0165      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 1.75        |
|    cost_values           | 0.981       |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24          |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.96        |
|    value_loss            | 50.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.293       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.293       |
| reward                   | -0.8932578  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.48e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1266        |
|    total_timesteps       | 186368      |
| train/                   |             |
|    approx_kl             | 0.008360695 |
|    clip_fraction         | 0.0599      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 2.65        |
|    cost_values           | 1.04        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.2        |
|    n_updates             | 900         |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.964       |
|    value_loss            | 60.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.372        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.372        |
| reward                   | -0.48871148  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.46e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1296         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0036876798 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 1.03         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.1         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.000335    |
|    std                   | 0.964        |
|    value_loss            | 132          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.623        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.623        |
| reward                   | -0.78987414  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.45e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1327         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0057170256 |
|    clip_fraction         | 0.0466       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 4.23         |
|    cost_values           | 0.999        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.8         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.00452     |
|    std                   | 0.97         |
|    value_loss            | 87           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.77        |
| reward                   | -0.85144544 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.44e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1357        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.002636229 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 9.07        |
|    cost_values           | 1.01        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30          |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.00216    |
|    std                   | 0.972       |
|    value_loss            | 56.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.303        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.303        |
| reward                   | -1.0496669   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.43e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1388         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0051951027 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 2.61         |
|    cost_values           | 0.995        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.971        |
|    value_loss            | 60.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.922        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.922        |
| reward                   | -0.80011356  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1419         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0042773215 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 7.73         |
|    cost_values           | 0.996        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.3         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.971        |
|    value_loss            | 54.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.167        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.167        |
| reward                   | -1.360327    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1449         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0015408341 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.23         |
|    cost_value_loss       | 33.4         |
|    cost_values           | 1.06         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.2         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.971        |
|    value_loss            | 80.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 5.24          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.24          |
| reward                   | -1.3512648    |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -1.38e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 49            |
|    time_elapsed          | 1480          |
|    total_timesteps       | 200704        |
| train/                   |               |
|    approx_kl             | 0.00072152744 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.11          |
|    cost_value_loss       | 30.9          |
|    cost_values           | 1.12          |
|    entropy               | -2.77         |
|    entropy_loss          | -2.77         |
|    explained_variance    | -2.38e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 39.7          |
|    n_updates             | 970           |
|    policy_gradient_loss  | -0.000896     |
|    std                   | 0.971         |
|    value_loss            | 54.8          |
--------------------------------------------
------------------------------------
| avg_speed          | 0.562       |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.562       |
| reward             | -0.49769783 |
| rollout/           |             |
|    ep_len_mean     | 991         |
|    ep_rew_mean     | -1.36e+03   |
| time/              |             |
|    fps             | 99          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 202752      |
------------------------------------
------------------------------------------
| avg_speed                | 0.199       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.199       |
| reward                   | -0.2987691  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.34e+03   |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 204800      |
| train/                   |             |
|    approx_kl             | 0.002599625 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 3.69        |
|    cost_values           | 1.24        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.79       |
|    explained_variance    | -1.07e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.6        |
|    n_updates             | 990         |
|    policy_gradient_loss  | -0.000724   |
|    std                   | 0.983       |
|    value_loss            | 33.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -2.2707105  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 3           |
|    time_elapsed          | 81          |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.005974819 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.39        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 1.63        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 96.9        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.986       |
|    value_loss            | 170         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -2.3298573   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0033910344 |
|    clip_fraction         | 0.107        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 17.1         |
|    cost_values           | 2.35         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -4.77e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 75.1         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.985        |
|    value_loss            | 140          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.05         |
| reward                   | -0.79257435  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 5            |
|    time_elapsed          | 142          |
|    total_timesteps       | 210944       |
| train/                   |              |
|    approx_kl             | 0.0031876792 |
|    clip_fraction         | 0.0041       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 2.64         |
|    cost_values           | 2.14         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.2         |
|    n_updates             | 1020         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.985        |
|    value_loss            | 175          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.769        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.769        |
| reward                   | -0.4492511   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 6            |
|    time_elapsed          | 173          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0052464427 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.55         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 1.71         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -1.19e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.6         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00444     |
|    std                   | 0.985        |
|    value_loss            | 101          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0507       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0507       |
| reward                   | -2.956458    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 204          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0044100913 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.86         |
|    cost_value_loss       | 60.4         |
|    cost_values           | 2.25         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 136          |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.985        |
|    value_loss            | 211          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -2.7649074   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 8            |
|    time_elapsed          | 234          |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0046878206 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.78         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 2.91         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -1.43e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 98.2         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.985        |
|    value_loss            | 190          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.52         |
| reward                   | -1.8682523   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 265          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0029639725 |
|    clip_fraction         | 0.00762      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 4.8          |
|    cost_values           | 2.43         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.984        |
|    value_loss            | 317          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.44        |
| reward                   | -0.86250997 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 296         |
|    total_timesteps       | 221184      |
| train/                   |             |
|    approx_kl             | 0.005894686 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 31.2        |
|    cost_values           | 2.31        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | -1.07e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 91.6        |
|    n_updates             | 1070        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 0.983       |
|    value_loss            | 151         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.48         |
| reward                   | -1.771742    |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 326          |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0034296561 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.42         |
|    cost_value_loss       | 19.8         |
|    cost_values           | 2.98         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -9.54e-07    |
|    lagrangian_multiplier | 0.0191       |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.98         |
|    value_loss            | 250          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.64        |
| reward                   | -1.7614301  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 356         |
|    total_timesteps       | 225280      |
| train/                   |             |
|    approx_kl             | 0.004496566 |
|    clip_fraction         | 0.0508      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 3.61        |
|    cost_values           | 2.88        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 5.96e-08    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.7        |
|    n_updates             | 1090        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.979       |
|    value_loss            | 54.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.96         |
| reward                   | -1.5778722   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 387          |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0026414795 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 3.63         |
|    cost_values           | 2.6          |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.7         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.000481    |
|    std                   | 0.978        |
|    value_loss            | 106          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.28        |
| reward                   | -0.7720164  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 417         |
|    total_timesteps       | 229376      |
| train/                   |             |
|    approx_kl             | 0.003167216 |
|    clip_fraction         | 0.0315      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 3.89        |
|    cost_values           | 2.08        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | -2.38e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.6        |
|    n_updates             | 1110        |
|    policy_gradient_loss  | -0.00239    |
|    std                   | 0.979       |
|    value_loss            | 68.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.94        |
| reward                   | -1.8132803  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 448         |
|    total_timesteps       | 231424      |
| train/                   |             |
|    approx_kl             | 0.004906902 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.52        |
|    cost_value_loss       | 5.59        |
|    cost_values           | 1.87        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 73.7        |
|    n_updates             | 1120        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.979       |
|    value_loss            | 148         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.21        |
| reward                   | -1.6876092  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 478         |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.007190819 |
|    clip_fraction         | 0.0578      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 1.33        |
|    cost_values           | 1.66        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49.1        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00508    |
|    std                   | 0.978       |
|    value_loss            | 96.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.42        |
| reward                   | -1.4406637  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 509         |
|    total_timesteps       | 235520      |
| train/                   |             |
|    approx_kl             | 0.003905192 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 8.43        |
|    cost_values           | 1.48        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | -4.77e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41.8        |
|    n_updates             | 1140        |
|    policy_gradient_loss  | -0.000437   |
|    std                   | 0.977       |
|    value_loss            | 82.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.71         |
| reward                   | -2.3646348   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 539          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0055296654 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 2.3          |
|    cost_values           | 1.35         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.5         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.979        |
|    value_loss            | 48           |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -1.6889035  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 570         |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.004667475 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 2.55        |
|    cost_values           | 1.08        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | -3.58e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 52.4        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 0.979       |
|    value_loss            | 101         |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.21       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.21       |
| reward                   | -1.9937005 |
| rollout/                 |            |
|    ep_len_mean           | 981        |
|    ep_rew_mean           | -1.18e+03  |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 20         |
|    time_elapsed          | 601        |
|    total_timesteps       | 241664     |
| train/                   |            |
|    approx_kl             | 0.01132692 |
|    clip_fraction         | 0.0718     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.5        |
|    cost_value_loss       | 4.71       |
|    cost_values           | 1.12       |
|    entropy               | -2.78      |
|    entropy_loss          | -2.79      |
|    explained_variance    | -4.77e-07  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 33.6       |
|    n_updates             | 1170       |
|    policy_gradient_loss  | -0.0042    |
|    std                   | 0.976      |
|    value_loss            | 62.4       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.741        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.741        |
| reward                   | -0.4017028   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 631          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0067922366 |
|    clip_fraction         | 0.0757       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 4.15         |
|    cost_values           | 1.37         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -1.43e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28           |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.972        |
|    value_loss            | 53.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00748      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00748      |
| reward                   | -0.485235    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 661          |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0044362266 |
|    clip_fraction         | 0.209        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 9.04         |
|    cost_values           | 1.78         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 80.6         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | 0.015        |
|    std                   | 0.968        |
|    value_loss            | 147          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.83        |
| reward                   | -0.58532244 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 692         |
|    total_timesteps       | 247808      |
| train/                   |             |
|    approx_kl             | 0.007008557 |
|    clip_fraction         | 0.0635      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 5.55        |
|    cost_values           | 2.07        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | -7.15e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.2        |
|    n_updates             | 1200        |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.965       |
|    value_loss            | 45.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.03         |
| reward                   | -0.8637536   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 722          |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0066856476 |
|    clip_fraction         | 0.0552       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 8.34         |
|    cost_values           | 2.42         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.8         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 0.961        |
|    value_loss            | 63.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.98        |
| reward                   | -0.88607746 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 25          |
|    time_elapsed          | 753         |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.003226174 |
|    clip_fraction         | 0.0594      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 4.66        |
|    cost_values           | 2.58        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 86.2        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 0.96        |
|    value_loss            | 180         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.9434313   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 783          |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0042389063 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 5.09         |
|    cost_values           | 2.13         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.9         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00365     |
|    std                   | 0.961        |
|    value_loss            | 101          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.15         |
| reward                   | -0.3073966   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 814          |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0036832523 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 3.64         |
|    cost_values           | 1.76         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.3         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.96         |
|    value_loss            | 129          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.31         |
| reward                   | -0.76596475  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 845          |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0056610806 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 1.87         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -7.15e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.4         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 0.959        |
|    value_loss            | 163          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.24         |
| reward                   | -0.7235517   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 875          |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0015779949 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.69         |
|    cost_value_loss       | 3.02         |
|    cost_values           | 2.31         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.6         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | 4.31e-06     |
|    std                   | 0.958        |
|    value_loss            | 56.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.66        |
| reward                   | -0.99316305 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 906         |
|    total_timesteps       | 262144      |
| train/                   |             |
|    approx_kl             | 0.004728752 |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.37        |
|    cost_value_loss       | 6.05        |
|    cost_values           | 1.88        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | -8.34e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.8        |
|    n_updates             | 1270        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.958       |
|    value_loss            | 39.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.21         |
| reward                   | -0.55329025  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 31           |
|    time_elapsed          | 936          |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0041587763 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.94         |
|    cost_value_loss       | 8.61         |
|    cost_values           | 1.63         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -8.34e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.3         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.00508     |
|    std                   | 0.957        |
|    value_loss            | 57.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.0749636   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 32           |
|    time_elapsed          | 967          |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0035791397 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 5.44         |
|    cost_values           | 1.5          |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -5.96e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.3         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.957        |
|    value_loss            | 55.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.3         |
| reward                   | -1.5237046  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 997         |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.005060161 |
|    clip_fraction         | 0.0613      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.53        |
|    cost_value_loss       | 2.99        |
|    cost_values           | 1.14        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | -5.96e-07   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.4        |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.00527    |
|    std                   | 0.957       |
|    value_loss            | 46.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.8          |
| reward                   | -0.57939386  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 34           |
|    time_elapsed          | 1028         |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0031650823 |
|    clip_fraction         | 0.0447       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 8.24         |
|    cost_values           | 1.13         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.8         |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 0.954        |
|    value_loss            | 82.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0162       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0162       |
| reward                   | -0.43300712  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 35           |
|    time_elapsed          | 1059         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0021507791 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.71         |
|    cost_value_loss       | 24.4         |
|    cost_values           | 1.47         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.3         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | 0.000572     |
|    std                   | 0.951        |
|    value_loss            | 114          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.86        |
| reward                   | -0.7312857  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1090        |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.002228186 |
|    clip_fraction         | 0.0061      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 38          |
|    cost_values           | 1.48        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -1.31e-06   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67          |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.951       |
|    value_loss            | 109         |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.00944       |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.00944       |
| reward                   | -0.5477812    |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -1.07e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 37            |
|    time_elapsed          | 1121          |
|    total_timesteps       | 276480        |
| train/                   |               |
|    approx_kl             | 0.00048731634 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 5.76          |
|    cost_value_loss       | 56.8          |
|    cost_values           | 1.53          |
|    entropy               | -2.73         |
|    entropy_loss          | -2.73         |
|    explained_variance    | -1.19e-07     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 59.6          |
|    n_updates             | 1340          |
|    policy_gradient_loss  | -0.000653     |
|    std                   | 0.951         |
|    value_loss            | 80            |
--------------------------------------------
--------------------------------------------
| avg_speed                | 0.0695        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0695        |
| reward                   | -0.5983142    |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -1.07e+03     |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 38            |
|    time_elapsed          | 1152          |
|    total_timesteps       | 278528        |
| train/                   |               |
|    approx_kl             | 0.00083348935 |
|    clip_fraction         | 0.000928      |
|    clip_range            | 0.2           |
|    cost_returns          | 8.38          |
|    cost_value_loss       | 95.5          |
|    cost_values           | 1.83          |
|    entropy               | -2.73         |
|    entropy_loss          | -2.73         |
|    explained_variance    | -3.22e-06     |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 89.5          |
|    n_updates             | 1350          |
|    policy_gradient_loss  | -0.000927     |
|    std                   | 0.951         |
|    value_loss            | 90.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.154        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.154        |
| reward                   | -0.5618815   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1182         |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0028688759 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.74         |
|    cost_value_loss       | 60.3         |
|    cost_values           | 2.29         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.31e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 57.2         |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 0.951        |
|    value_loss            | 62.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.583        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.583        |
| reward                   | -0.2802014   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1213         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0038410865 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.91         |
|    cost_value_loss       | 43.5         |
|    cost_values           | 2.6          |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -2.38e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.7         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.951        |
|    value_loss            | 60.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0694       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0694       |
| reward                   | -0.35190275  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1244         |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0026967307 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.98         |
|    cost_value_loss       | 51.7         |
|    cost_values           | 2.73         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.3         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.000964    |
|    std                   | 0.951        |
|    value_loss            | 70           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.346        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.346        |
| reward                   | -0.46701533  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1275         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0043805474 |
|    clip_fraction         | 0.00713      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.78         |
|    cost_value_loss       | 75           |
|    cost_values           | 2.9          |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.3         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.951        |
|    value_loss            | 105          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.298        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.298        |
| reward                   | -0.29129988  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1306         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0017354498 |
|    clip_fraction         | 0.00156      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.14         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 2.86         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.19e-07    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 86.9         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.000874    |
|    std                   | 0.951        |
|    value_loss            | 132          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.498        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.498        |
| reward                   | -0.377218    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -999         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0019304475 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 108          |
|    cost_values           | 2.84         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.07e-06    |
|    lagrangian_multiplier | 0.0148       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.951        |
|    value_loss            | 82.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.384        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.384        |
| reward                   | -0.4928455   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -996         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1368         |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0057508233 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.83         |
|    cost_value_loss       | 51.9         |
|    cost_values           | 2.98         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -3.58e-07    |
|    lagrangian_multiplier | 0.00989      |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.951        |
|    value_loss            | 79           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.38378382  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1398         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0012927873 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.6          |
|    cost_value_loss       | 85.6         |
|    cost_values           | 3            |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -2.62e-06    |
|    lagrangian_multiplier | 0.02         |
|    learning_rate         | 0.0003       |
|    loss                  | 7.69         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.95         |
|    value_loss            | 37.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.138        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.138        |
| reward                   | -0.46901548  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1429         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0023374278 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.69         |
|    cost_value_loss       | 44           |
|    cost_values           | 2.99         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -2.86e-06    |
|    lagrangian_multiplier | 0.00403      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.949        |
|    value_loss            | 79.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.342         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.342         |
| reward                   | -0.36601105   |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -989          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 48            |
|    time_elapsed          | 1461          |
|    total_timesteps       | 299008        |
| train/                   |               |
|    approx_kl             | 0.00024390413 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 9.53          |
|    cost_value_loss       | 82.8          |
|    cost_values           | 3             |
|    entropy               | -2.72         |
|    entropy_loss          | -2.72         |
|    explained_variance    | 2.38e-07      |
|    lagrangian_multiplier | 0.000557      |
|    learning_rate         | 0.0003        |
|    loss                  | 57.3          |
|    n_updates             | 1450          |
|    policy_gradient_loss  | 0.000361      |
|    std                   | 0.948         |
|    value_loss            | 70.7          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.055        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.055        |
| reward                   | -0.40466332  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -982         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1492         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0047262684 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 119          |
|    cost_values           | 3            |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -3.34e-06    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.2         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.948        |
|    value_loss            | 47           |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/46po4mwk
-----------------------------------
| avg_speed          | 0.315      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.315      |
| reward             | -0.4702294 |
| rollout/           |            |
|    ep_len_mean     | 990        |
|    ep_rew_mean     | -975       |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 303104     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.3          |
| reward                   | -0.5947112   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -959         |
| time/                    |              |
|    fps                   | 77           |
|    iterations            | 2            |
|    time_elapsed          | 52           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0062433816 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 12           |
|    cost_value_loss       | 124          |
|    cost_values           | 2.94         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.000154     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.7         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.949        |
|    value_loss            | 25.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0848       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0848       |
| reward                   | -0.26796255  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -947         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 3            |
|    time_elapsed          | 84           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0035973988 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.7         |
|    cost_value_loss       | 151          |
|    cost_values           | 2.99         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.000239     |
|    lagrangian_multiplier | 0.0037       |
|    learning_rate         | 0.0003       |
|    loss                  | 29.8         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.949        |
|    value_loss            | 5            |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.12        |
| reward                   | -0.22659919 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -926        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 4           |
|    time_elapsed          | 116         |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.004277028 |
|    clip_fraction         | 0.00493     |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 125         |
|    cost_values           | 2.93        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.000438    |
|    lagrangian_multiplier | 0.00369     |
|    learning_rate         | 0.0003      |
|    loss                  | 23.8        |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.000797   |
|    std                   | 0.948       |
|    value_loss            | 11.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.102        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.102        |
| reward                   | -0.31331947  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -918         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 5            |
|    time_elapsed          | 147          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0023137685 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 103          |
|    cost_values           | 2.92         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.000251     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.1         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.00047     |
|    std                   | 0.948        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0457       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0457       |
| reward                   | -1.9350575   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -903         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 6            |
|    time_elapsed          | 178          |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0058401385 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.55         |
|    cost_value_loss       | 45.7         |
|    cost_values           | 2.99         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.00283      |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.948        |
|    value_loss            | 4.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.99         |
| reward                   | -1.7838402   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -887         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 7            |
|    time_elapsed          | 209          |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0019752383 |
|    clip_fraction         | 0.00718      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 28.9         |
|    cost_values           | 2.16         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0534       |
|    lagrangian_multiplier | 0.000413     |
|    learning_rate         | 0.0003       |
|    loss                  | 33.9         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.95         |
|    value_loss            | 124          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.205        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.205        |
| reward                   | -0.38851288  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -867         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 8            |
|    time_elapsed          | 240          |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0024677082 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 36           |
|    cost_values           | 1.54         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0427       |
|    lagrangian_multiplier | 0.0117       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.63         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.951        |
|    value_loss            | 111          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.53         |
| reward                   | -1.140706    |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -835         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 9            |
|    time_elapsed          | 271          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0016926684 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 144          |
|    cost_values           | 1.52         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.206        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 74.5         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.951        |
|    value_loss            | 28.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.71         |
| reward                   | -0.5373729   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 10           |
|    time_elapsed          | 302          |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0062360168 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.2          |
|    cost_value_loss       | 94.9         |
|    cost_values           | 1.58         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.726        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.8         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.951        |
|    value_loss            | 25.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.235        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.235        |
| reward                   | -0.5192554   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 11           |
|    time_elapsed          | 334          |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0023483923 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.64         |
|    cost_value_loss       | 83           |
|    cost_values           | 1.54         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.7         |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.952        |
|    value_loss            | 11.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.551        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.551        |
| reward                   | -0.4953117   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -802         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 12           |
|    time_elapsed          | 365          |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0042429427 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.25         |
|    cost_value_loss       | 93.3         |
|    cost_values           | 1.38         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.897        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.2         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.951        |
|    value_loss            | 9.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.116       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.116       |
| reward                   | -0.49268767 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -788        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 397         |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.00509663  |
|    clip_fraction         | 0.0426      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.78        |
|    cost_value_loss       | 107         |
|    cost_values           | 1.5         |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 51          |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.951       |
|    value_loss            | 3.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0125       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0125       |
| reward                   | -0.50575787  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -774         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 14           |
|    time_elapsed          | 428          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0046994174 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 116          |
|    cost_values           | 2.23         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.0189       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.51         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.95         |
|    value_loss            | 1.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.316       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.316       |
| reward                   | -0.4949876  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -754        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 15          |
|    time_elapsed          | 459         |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.007748951 |
|    clip_fraction         | 0.0612      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.71        |
|    cost_value_loss       | 46.1        |
|    cost_values           | 2.73        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.643       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.8        |
|    n_updates             | 1610        |
|    policy_gradient_loss  | -0.00637    |
|    std                   | 0.949       |
|    value_loss            | 2.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.295       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.295       |
| reward                   | -0.4925682  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -742        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 16          |
|    time_elapsed          | 490         |
|    total_timesteps       | 333824      |
| train/                   |             |
|    approx_kl             | 0.003459232 |
|    clip_fraction         | 0.0186      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.96        |
|    cost_value_loss       | 64.1        |
|    cost_values           | 2.74        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0.0145      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.04        |
|    n_updates             | 1620        |
|    policy_gradient_loss  | -0.000475   |
|    std                   | 0.949       |
|    value_loss            | 2.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.254       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.254       |
| reward                   | -0.32830766 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 17          |
|    time_elapsed          | 521         |
|    total_timesteps       | 335872      |
| train/                   |             |
|    approx_kl             | 0.002283802 |
|    clip_fraction         | 0.00591     |
|    clip_range            | 0.2         |
|    cost_returns          | 8.44        |
|    cost_value_loss       | 80.9        |
|    cost_values           | 2.72        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.673       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.7        |
|    n_updates             | 1630        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.947       |
|    value_loss            | 1.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.321        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.321        |
| reward                   | -0.44891053  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 18           |
|    time_elapsed          | 551          |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0027682388 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.4          |
|    cost_value_loss       | 50.7         |
|    cost_values           | 2.88         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.725        |
|    lagrangian_multiplier | 0.00486      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.57         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.000903    |
|    std                   | 0.945        |
|    value_loss            | 2.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00754     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00754     |
| reward                   | -0.5170636  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 19          |
|    time_elapsed          | 582         |
|    total_timesteps       | 339968      |
| train/                   |             |
|    approx_kl             | 0.005477312 |
|    clip_fraction         | 0.0344      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.71        |
|    cost_value_loss       | 48.8        |
|    cost_values           | 2.95        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.302       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.1        |
|    n_updates             | 1650        |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 0.945       |
|    value_loss            | 1.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.5194247   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 20           |
|    time_elapsed          | 613          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0052432143 |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.19         |
|    cost_value_loss       | 72.9         |
|    cost_values           | 2.88         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.667        |
|    lagrangian_multiplier | 0.0351       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.948        |
|    value_loss            | 1.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.376       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.376       |
| reward                   | -0.5289961  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -659        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 21          |
|    time_elapsed          | 644         |
|    total_timesteps       | 344064      |
| train/                   |             |
|    approx_kl             | 0.008118512 |
|    clip_fraction         | 0.0629      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 55.5        |
|    cost_values           | 2.96        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.138       |
|    lagrangian_multiplier | 0.0302      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 1670        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.946       |
|    value_loss            | 2.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.108        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.108        |
| reward                   | -0.5773446   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -647         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 22           |
|    time_elapsed          | 675          |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0026580282 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.94         |
|    cost_value_loss       | 52.7         |
|    cost_values           | 2.98         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.218        |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 0.946        |
|    value_loss            | 1.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.208        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.208        |
| reward                   | -0.38058478  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -625         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 23           |
|    time_elapsed          | 706          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0024105664 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.9          |
|    cost_value_loss       | 69.5         |
|    cost_values           | 2.93         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.67         |
|    lagrangian_multiplier | 0.0164       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.35         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.947        |
|    value_loss            | 1.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.305       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.305       |
| reward                   | -0.42620707 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -605        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 24          |
|    time_elapsed          | 737         |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.003138253 |
|    clip_fraction         | 0.0578      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 46.1        |
|    cost_values           | 2.99        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | -0.0499     |
|    lagrangian_multiplier | 0.00582     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00451    |
|    std                   | 0.947       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.177       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.177       |
| reward                   | -0.49249047 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -587        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 25          |
|    time_elapsed          | 768         |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.007617332 |
|    clip_fraction         | 0.0577      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 2.89        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.0957      |
|    lagrangian_multiplier | 0.000121    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.01        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.00423    |
|    std                   | 0.949       |
|    value_loss            | 0.893       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.398       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.398       |
| reward                   | -0.6086273  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -563        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 26          |
|    time_elapsed          | 799         |
|    total_timesteps       | 354304      |
| train/                   |             |
|    approx_kl             | 0.005921257 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.65        |
|    cost_value_loss       | 67.3        |
|    cost_values           | 2.9         |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.424       |
|    lagrangian_multiplier | 0.00437     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 1720        |
|    policy_gradient_loss  | -0.000286   |
|    std                   | 0.951       |
|    value_loss            | 1.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.48657215  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -559         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 27           |
|    time_elapsed          | 831          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0018000352 |
|    clip_fraction         | 0.002        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.31         |
|    cost_value_loss       | 96           |
|    cost_values           | 2.91         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.278        |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.95         |
|    value_loss            | 4.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.873       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.873       |
| reward                   | -0.39474356 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -547        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 28          |
|    time_elapsed          | 861         |
|    total_timesteps       | 358400      |
| train/                   |             |
|    approx_kl             | 0.006824618 |
|    clip_fraction         | 0.0138      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 134         |
|    cost_values           | 2.95        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.604       |
|    lagrangian_multiplier | 0.0228      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.08        |
|    n_updates             | 1740        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.949       |
|    value_loss            | 1.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.309        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.309        |
| reward                   | -0.24703155  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 29           |
|    time_elapsed          | 892          |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0043238956 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 31           |
|    cost_values           | 2.93         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.448        |
|    lagrangian_multiplier | 0.00262      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.952        |
|    value_loss            | 1.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.444       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.444       |
| reward                   | -0.47032696 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -529        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 30          |
|    time_elapsed          | 923         |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.010231581 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 23.4        |
|    cost_values           | 2.87        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.605       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 1760        |
|    policy_gradient_loss  | 0.00324     |
|    std                   | 0.948       |
|    value_loss            | 1.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.577        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.577        |
| reward                   | -0.5018614   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -514         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 31           |
|    time_elapsed          | 954          |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0075104646 |
|    clip_fraction         | 0.069        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.56         |
|    cost_value_loss       | 25.2         |
|    cost_values           | 2.81         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.537        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00359     |
|    std                   | 0.947        |
|    value_loss            | 2.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.524       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.524       |
| reward                   | -0.36183748 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 985         |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.004902545 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.23        |
|    cost_value_loss       | 73.4        |
|    cost_values           | 2.88        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.275       |
|    lagrangian_multiplier | 0.00569     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.949       |
|    value_loss            | 8.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -1.0416026   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 33           |
|    time_elapsed          | 1016         |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0077642277 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.72         |
|    cost_value_loss       | 38.5         |
|    cost_values           | 2.38         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0.000161     |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.95         |
|    value_loss            | 3.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.033        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.033        |
| reward                   | -0.85930353  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 34           |
|    time_elapsed          | 1047         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0011414795 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 11.3         |
|    cost_values           | 1.45         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.621        |
|    lagrangian_multiplier | 0.0007       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.18         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.000107    |
|    std                   | 0.95         |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.08         |
| reward                   | -1.5839515   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 35           |
|    time_elapsed          | 1077         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0023275192 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 17.5         |
|    cost_values           | 0.581        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.438        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.75         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.000946    |
|    std                   | 0.951        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.273       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.273       |
| reward                   | -0.38215718 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -508        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 36          |
|    time_elapsed          | 1108        |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.005126551 |
|    clip_fraction         | 0.0179      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.963       |
|    cost_value_loss       | 6.22        |
|    cost_values           | 0.729       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | -8.74       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.83        |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.95        |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.27         |
| reward                   | -1.0113655   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 37           |
|    time_elapsed          | 1138         |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0033176546 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 32.3         |
|    cost_values           | 0.944        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.144        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.95         |
|    value_loss            | 17.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.635       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.635       |
| reward                   | -0.5538323  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -506        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1169        |
|    total_timesteps       | 378880      |
| train/                   |             |
|    approx_kl             | 0.004620229 |
|    clip_fraction         | 0.0745      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 16.5        |
|    cost_values           | 1.02        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.75        |
|    n_updates             | 1840        |
|    policy_gradient_loss  | -0.007      |
|    std                   | 0.952       |
|    value_loss            | 5.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.06        |
| reward                   | -0.6786468  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -498        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 39          |
|    time_elapsed          | 1200        |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.005195379 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 41.9        |
|    cost_values           | 1.09        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.7        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.954       |
|    value_loss            | 2.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.664        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.664        |
| reward                   | -0.44640166  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 40           |
|    time_elapsed          | 1231         |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0064472696 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.37         |
|    cost_value_loss       | 80.6         |
|    cost_values           | 1.57         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.368        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.8         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 0.953        |
|    value_loss            | 7.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.741        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.741        |
| reward                   | -0.307798    |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 41           |
|    time_elapsed          | 1262         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0023404246 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.49         |
|    cost_value_loss       | 26.8         |
|    cost_values           | 2.01         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0.00285      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.94         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.952        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.844        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.844        |
| reward                   | -0.5303286   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 42           |
|    time_elapsed          | 1293         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0021778825 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 28.3         |
|    cost_values           | 2.06         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.403        |
|    lagrangian_multiplier | 0.00105      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.953        |
|    value_loss            | 1.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.38        |
| reward                   | -0.45216215 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 43          |
|    time_elapsed          | 1324        |
|    total_timesteps       | 389120      |
| train/                   |             |
|    approx_kl             | 0.010384852 |
|    clip_fraction         | 0.0707      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.81        |
|    cost_value_loss       | 64.4        |
|    cost_values           | 2.65        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.34        |
|    lagrangian_multiplier | 0.00737     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.84        |
|    n_updates             | 1890        |
|    policy_gradient_loss  | -0.00745    |
|    std                   | 0.95        |
|    value_loss            | 0.853       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.58         |
| reward                   | -0.16156086  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 44           |
|    time_elapsed          | 1355         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0044692727 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 24.1         |
|    cost_values           | 2.72         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.157        |
|    lagrangian_multiplier | 0.000164     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.6         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.947        |
|    value_loss            | 3.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0529      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0529      |
| reward                   | -0.39034784 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 45          |
|    time_elapsed          | 1386        |
|    total_timesteps       | 393216      |
| train/                   |             |
|    approx_kl             | 0.008521661 |
|    clip_fraction         | 0.0843      |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 109         |
|    cost_values           | 2.73        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.449       |
|    lagrangian_multiplier | 0.0143      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.71        |
|    n_updates             | 1910        |
|    policy_gradient_loss  | -0.00818    |
|    std                   | 0.95        |
|    value_loss            | 1.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -0.5717953   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 46           |
|    time_elapsed          | 1416         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0024953173 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.2          |
|    cost_value_loss       | 24.6         |
|    cost_values           | 2.45         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0656       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.1         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.951        |
|    value_loss            | 85.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0032       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0032       |
| reward                   | -0.6199219   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 47           |
|    time_elapsed          | 1447         |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0039259307 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.87         |
|    cost_value_loss       | 39.6         |
|    cost_values           | 2.31         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.572        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 0.951        |
|    value_loss            | 5.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.158       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.158       |
| reward                   | -0.542703   |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -496        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 48          |
|    time_elapsed          | 1478        |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.005579639 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.75        |
|    cost_value_loss       | 59.8        |
|    cost_values           | 2.41        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.747       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.1        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 0.952       |
|    value_loss            | 3.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0349       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0349       |
| reward                   | -0.53068423  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1509         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0034751196 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.96         |
|    cost_value_loss       | 58.1         |
|    cost_values           | 2.51         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.593        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.3         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.954        |
|    value_loss            | 33.1         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.243      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.243      |
| reward             | -0.3158815 |
| rollout/           |            |
|    ep_len_mean     | 965        |
|    ep_rew_mean     | -502       |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 403456     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.407        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.407        |
| reward                   | -0.5682789   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 2            |
|    time_elapsed          | 52           |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0007768021 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 9            |
|    cost_value_loss       | 97.2         |
|    cost_values           | 2.46         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.543        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.6         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.000875    |
|    std                   | 0.955        |
|    value_loss            | 4.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0712      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0712      |
| reward                   | -0.5151069  |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -506        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 3           |
|    time_elapsed          | 83          |
|    total_timesteps       | 407552      |
| train/                   |             |
|    approx_kl             | 0.004124712 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.01        |
|    cost_value_loss       | 53.8        |
|    cost_values           | 2.54        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -0.0777     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.9        |
|    n_updates             | 1980        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.955       |
|    value_loss            | 4.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.118        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.118        |
| reward                   | -0.4812437   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 4            |
|    time_elapsed          | 114          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0072850278 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.98         |
|    cost_value_loss       | 75.4         |
|    cost_values           | 2.86         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0.00671      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 0.955        |
|    value_loss            | 3.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.165        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.165        |
| reward                   | -0.36267117  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -497         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 5            |
|    time_elapsed          | 145          |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0013815723 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.64         |
|    cost_value_loss       | 66.7         |
|    cost_values           | 2.96         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.15         |
|    lagrangian_multiplier | 0.0125       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.09         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 0.957        |
|    value_loss            | 1.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.46392387  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 6            |
|    time_elapsed          | 176          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0037639928 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.61         |
|    cost_value_loss       | 86.4         |
|    cost_values           | 2.99         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.373        |
|    lagrangian_multiplier | 0.00845      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.956        |
|    value_loss            | 1.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.459       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.459       |
| reward                   | -0.51147807 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 207         |
|    total_timesteps       | 415744      |
| train/                   |             |
|    approx_kl             | 0.005714411 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.45        |
|    cost_value_loss       | 64.7        |
|    cost_values           | 2.94        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -0.0467     |
|    lagrangian_multiplier | 0.00675     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.96        |
|    n_updates             | 2020        |
|    policy_gradient_loss  | -0.00235    |
|    std                   | 0.952       |
|    value_loss            | 2.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.291       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.291       |
| reward                   | -0.60356677 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 238         |
|    total_timesteps       | 417792      |
| train/                   |             |
|    approx_kl             | 0.004683567 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.02        |
|    cost_value_loss       | 60.1        |
|    cost_values           | 2.96        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0.00636     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.67        |
|    n_updates             | 2030        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.95        |
|    value_loss            | 1.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.479       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.479       |
| reward                   | -0.34147903 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 268         |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.00317923  |
|    clip_fraction         | 0.00908     |
|    clip_range            | 0.2         |
|    cost_returns          | 8.02        |
|    cost_value_loss       | 71.3        |
|    cost_values           | 2.98        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | -0.031      |
|    lagrangian_multiplier | 0.00167     |
|    learning_rate         | 0.0003      |
|    loss                  | 21.4        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.951       |
|    value_loss            | 2.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0996      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0996      |
| reward                   | -0.46443138 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 10          |
|    time_elapsed          | 300         |
|    total_timesteps       | 421888      |
| train/                   |             |
|    approx_kl             | 0.005960079 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.89        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | -4.26       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 2050        |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.948       |
|    value_loss            | 1.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.5329592   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 11           |
|    time_elapsed          | 331          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0041269157 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 12           |
|    cost_value_loss       | 126          |
|    cost_values           | 2.98         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -0.246       |
|    lagrangian_multiplier | 0.02         |
|    learning_rate         | 0.0003       |
|    loss                  | 8.68         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.000545    |
|    std                   | 0.944        |
|    value_loss            | 2.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.5070444   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 12           |
|    time_elapsed          | 362          |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0017554059 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.1          |
|    cost_value_loss       | 70.1         |
|    cost_values           | 2.99         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.142       |
|    lagrangian_multiplier | 0.0019       |
|    learning_rate         | 0.0003       |
|    loss                  | 19.2         |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.944        |
|    value_loss            | 1.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.5073199   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 13           |
|    time_elapsed          | 393          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0028976635 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 117          |
|    cost_values           | 2.99         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.3          |
|    lagrangian_multiplier | 0.0519       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 0.944        |
|    value_loss            | 0.902        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.627        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.627        |
| reward                   | -0.5994376   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 14           |
|    time_elapsed          | 424          |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0069888467 |
|    clip_fraction         | 0.0912       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.59         |
|    cost_value_loss       | 36.8         |
|    cost_values           | 2.98         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.0935      |
|    lagrangian_multiplier | 0.00443      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.1          |
|    n_updates             | 2090         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.943        |
|    value_loss            | 1.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0717       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0717       |
| reward                   | -0.50216895  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 15           |
|    time_elapsed          | 454          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0027977317 |
|    clip_fraction         | 0.0457       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 26           |
|    cost_values           | 2.6          |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -2.01        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.7         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00017     |
|    std                   | 0.943        |
|    value_loss            | 87.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.297        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.297        |
| reward                   | -0.49144012  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 16           |
|    time_elapsed          | 486          |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0038191006 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.04         |
|    cost_value_loss       | 34.5         |
|    cost_values           | 2.81         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.514        |
|    lagrangian_multiplier | 0.00357      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.76         |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.944        |
|    value_loss            | 1.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.584       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.584       |
| reward                   | -0.46320024 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -537        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 17          |
|    time_elapsed          | 516         |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.005591884 |
|    clip_fraction         | 0.0696      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.18        |
|    cost_value_loss       | 72.9        |
|    cost_values           | 2.99        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 24.1        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | -0.00573    |
|    std                   | 0.942       |
|    value_loss            | 0.547       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.435        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.435        |
| reward                   | -0.5573578   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -536         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 18           |
|    time_elapsed          | 547          |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0053866385 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 6.56         |
|    cost_values           | 2.45         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.43         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.941        |
|    value_loss            | 136          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.216        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.216        |
| reward                   | -0.60172564  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -551         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 19           |
|    time_elapsed          | 577          |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0038510435 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.08         |
|    cost_value_loss       | 29.2         |
|    cost_values           | 2.21         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.0446       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.00359     |
|    std                   | 0.941        |
|    value_loss            | 2.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0651       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0651       |
| reward                   | -0.5814265   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -556         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 20           |
|    time_elapsed          | 608          |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0062598237 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 2.01         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.56         |
|    lagrangian_multiplier | 0.00415      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.941        |
|    value_loss            | 29.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.05        |
| reward                   | -0.6616249  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -557        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 639         |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.007898493 |
|    clip_fraction         | 0.0688      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 12          |
|    cost_values           | 1.71        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.826       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.78        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00839    |
|    std                   | 0.94        |
|    value_loss            | 7.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.163       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.163       |
| reward                   | -0.38605013 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -560        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 22          |
|    time_elapsed          | 669         |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.006284658 |
|    clip_fraction         | 0.0314      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.95        |
|    cost_value_loss       | 25.3        |
|    cost_values           | 1.83        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.7        |
|    explained_variance    | -0.926      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.943       |
|    value_loss            | 4.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.51         |
| reward                   | -0.7741808   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -565         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 23           |
|    time_elapsed          | 700          |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0076381154 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 1.56         |
|    cost_values           | 2.1          |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.169       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.974        |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.944        |
|    value_loss            | 1.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0958      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0958      |
| reward                   | -0.43058774 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -578        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 731         |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.008815317 |
|    clip_fraction         | 0.093       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 56.3        |
|    cost_values           | 1.75        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.422       |
|    lagrangian_multiplier | 0.00327     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.945       |
|    value_loss            | 29.5        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.215         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.215         |
| reward                   | -0.30982405   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -582          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 25            |
|    time_elapsed          | 762           |
|    total_timesteps       | 452608        |
| train/                   |               |
|    approx_kl             | 0.00067449396 |
|    clip_fraction         | 4.88e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 0.911         |
|    cost_value_loss       | 5.26          |
|    cost_values           | 0.766         |
|    entropy               | -2.71         |
|    entropy_loss          | -2.71         |
|    explained_variance    | 0.399         |
|    lagrangian_multiplier | 0.034         |
|    learning_rate         | 0.0003        |
|    loss                  | 3.2           |
|    n_updates             | 2200          |
|    policy_gradient_loss  | 5.35e-06      |
|    std                   | 0.946         |
|    value_loss            | 106           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.122        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.122        |
| reward                   | -0.28357258  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -590         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 793          |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0020288185 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.6          |
|    cost_value_loss       | 59.8         |
|    cost_values           | 0.995        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -6.87        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.9         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.947        |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.245       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.245       |
| reward                   | -0.21537967 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -612        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 824         |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.008153366 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.77        |
|    cost_value_loss       | 56.2        |
|    cost_values           | 1.15        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -0.874      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.1        |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.00293    |
|    std                   | 0.947       |
|    value_loss            | 15.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.339        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.339        |
| reward                   | -0.38238406  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 854          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0029966442 |
|    clip_fraction         | 0.00869      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 3.03         |
|    cost_values           | 0.878        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.611        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.24         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.948        |
|    value_loss            | 67.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.26         |
| reward                   | -1.1545118   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -623         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 885          |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0020929545 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.19         |
|    cost_value_loss       | 80           |
|    cost_values           | 1.01         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.7         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.000183    |
|    std                   | 0.948        |
|    value_loss            | 20.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.331       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.331       |
| reward                   | -0.46863097 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -628        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 916         |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.003941646 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 42.6        |
|    cost_values           | 1.25        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.643       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.1        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.948       |
|    value_loss            | 29.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.5655657  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -645        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 947         |
|    total_timesteps       | 464896      |
| train/                   |             |
|    approx_kl             | 0.008648511 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.76        |
|    cost_value_loss       | 30.5        |
|    cost_values           | 1.35        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.9        |
|    n_updates             | 2260        |
|    policy_gradient_loss  | -0.00802    |
|    std                   | 0.947       |
|    value_loss            | 5.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.332        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.332        |
| reward                   | -0.2713456   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -642         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 32           |
|    time_elapsed          | 977          |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0004437442 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 24.3         |
|    cost_values           | 1.06         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.0951      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.4         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.000678    |
|    std                   | 0.947        |
|    value_loss            | 160          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.08         |
| reward                   | -0.3980314   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -654         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 33           |
|    time_elapsed          | 1008         |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0031343377 |
|    clip_fraction         | 0.00869      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 21.3         |
|    cost_values           | 0.825        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.718        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.000955    |
|    std                   | 0.947        |
|    value_loss            | 3.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.128       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.128       |
| reward                   | -0.5606284  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -658        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1039        |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.005347632 |
|    clip_fraction         | 0.0145      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 0.755       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -0.394      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.946       |
|    value_loss            | 69.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.46503696  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 35           |
|    time_elapsed          | 1069         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0008266232 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 0.769        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.491        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46           |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.000607    |
|    std                   | 0.946        |
|    value_loss            | 139          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.0948547   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1099         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0032022782 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 23.9         |
|    cost_values           | 0.867        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 0.946        |
|    value_loss            | 52.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -0.18685117  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1130         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0056404234 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 0.941        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.3         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.946        |
|    value_loss            | 93.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.31         |
| reward                   | -1.2566916   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1161         |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0050997525 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.52         |
|    cost_value_loss       | 68.9         |
|    cost_values           | 1.06         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.5         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.946        |
|    value_loss            | 63.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.303       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.303       |
| reward                   | -0.3527401  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1192        |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.003467569 |
|    clip_fraction         | 0.00962     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 0.804       |
|    cost_values           | 0.923       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.8         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.5         |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.946       |
|    value_loss            | 13.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.145        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.145        |
| reward                   | -0.7237288   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 40           |
|    time_elapsed          | 1223         |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0071916506 |
|    clip_fraction         | 0.051        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 36.4         |
|    cost_values           | 0.969        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00803     |
|    std                   | 0.945        |
|    value_loss            | 5.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.259       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.259       |
| reward                   | -0.58741987 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 41          |
|    time_elapsed          | 1253        |
|    total_timesteps       | 485376      |
| train/                   |             |
|    approx_kl             | 0.005840604 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.55        |
|    cost_value_loss       | 125         |
|    cost_values           | 1.24        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 57.9        |
|    n_updates             | 2360        |
|    policy_gradient_loss  | -0.0054     |
|    std                   | 0.945       |
|    value_loss            | 4.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -3.4541092  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 42          |
|    time_elapsed          | 1284        |
|    total_timesteps       | 487424      |
| train/                   |             |
|    approx_kl             | 0.009147851 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.82        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 1.26        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.102       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.53        |
|    n_updates             | 2370        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.946       |
|    value_loss            | 12          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.3656216   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 43           |
|    time_elapsed          | 1315         |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0022418085 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 22.5         |
|    cost_values           | 0.838        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -2.33        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.000551    |
|    std                   | 0.945        |
|    value_loss            | 59.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.33         |
| reward                   | -2.6265745   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -756         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 44           |
|    time_elapsed          | 1346         |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0043789432 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 56.8         |
|    cost_values           | 0.824        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -3.32        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.7         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.945        |
|    value_loss            | 170          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.4872525   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 45           |
|    time_elapsed          | 1376         |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0010786125 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 52.5         |
|    cost_values           | 1.03         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.558        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40           |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.000468    |
|    std                   | 0.945        |
|    value_loss            | 103          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.165        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.165        |
| reward                   | -0.49218053  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 46           |
|    time_elapsed          | 1407         |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0020397254 |
|    clip_fraction         | 0.00532      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.29         |
|    cost_value_loss       | 32.2         |
|    cost_values           | 0.999        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 87.6         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.946        |
|    value_loss            | 160          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -3.4815526   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 47           |
|    time_elapsed          | 1438         |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0029551345 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.2          |
|    cost_value_loss       | 31.8         |
|    cost_values           | 0.992        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.2         |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.949        |
|    value_loss            | 28.6         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.32       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.32       |
| reward                   | -4.3329363 |
| rollout/                 |            |
|    ep_len_mean           | 987        |
|    ep_rew_mean           | -759       |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 48         |
|    time_elapsed          | 1469       |
|    total_timesteps       | 499712     |
| train/                   |            |
|    approx_kl             | 0.00326139 |
|    clip_fraction         | 0.0169     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.68       |
|    cost_value_loss       | 37.7       |
|    cost_values           | 1.04       |
|    entropy               | -2.72      |
|    entropy_loss          | -2.72      |
|    explained_variance    | 0.914      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 75.2       |
|    n_updates             | 2430       |
|    policy_gradient_loss  | -0.00299   |
|    std                   | 0.95       |
|    value_loss            | 100        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.214        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.214        |
| reward                   | -0.50497735  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -781         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1500         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0040250057 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.84         |
|    cost_value_loss       | 91.2         |
|    cost_values           | 1.02         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 264          |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.951        |
|    value_loss            | 493          |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/46po4mwk
-----------------------------------
| avg_speed          | 0.322      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.322      |
| reward             | -0.6281861 |
| rollout/           |            |
|    ep_len_mean     | 987        |
|    ep_rew_mean     | -780       |
| time/              |            |
|    fps             | 97         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 503808     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.045       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.045       |
| reward                   | -0.5470304  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -778        |
| time/                    |             |
|    fps                   | 78          |
|    iterations            | 2           |
|    time_elapsed          | 52          |
|    total_timesteps       | 505856      |
| train/                   |             |
|    approx_kl             | 0.006228485 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 57.6        |
|    cost_values           | 0.992       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.7        |
|    n_updates             | 2460        |
|    policy_gradient_loss  | -0.00636    |
|    std                   | 0.951       |
|    value_loss            | 6.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.52        |
| reward                   | -0.34493884 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 3           |
|    time_elapsed          | 83          |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.008154249 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 70.4        |
|    cost_values           | 1.02        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38.3        |
|    n_updates             | 2470        |
|    policy_gradient_loss  | -0.0143     |
|    std                   | 0.951       |
|    value_loss            | 4.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.144       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.144       |
| reward                   | -0.45840532 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 115         |
|    total_timesteps       | 509952      |
| train/                   |             |
|    approx_kl             | 0.003876905 |
|    clip_fraction         | 0.00322     |
|    clip_range            | 0.2         |
|    cost_returns          | 9.34        |
|    cost_value_loss       | 122         |
|    cost_values           | 1.23        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.274       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67.8        |
|    n_updates             | 2480        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.95        |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.244       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.244       |
| reward                   | -0.30965972 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -775        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 145         |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.005300007 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.32        |
|    cost_value_loss       | 111         |
|    cost_values           | 1.56        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | -0.78       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 53          |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00203    |
|    std                   | 0.95        |
|    value_loss            | 2.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.201        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.201        |
| reward                   | -0.3686923   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 6            |
|    time_elapsed          | 176          |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0006353691 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 29.7         |
|    cost_values           | 1.96         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -0.208       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.949        |
|    value_loss            | 4.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0823       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0823       |
| reward                   | -0.30624422  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 7            |
|    time_elapsed          | 207          |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0029125237 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.18         |
|    cost_value_loss       | 54.5         |
|    cost_values           | 2.2          |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.744        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27           |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.951        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0556       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0556       |
| reward                   | -0.37302363  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 8            |
|    time_elapsed          | 238          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0069494676 |
|    clip_fraction         | 0.0527       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.51         |
|    cost_value_loss       | 77.9         |
|    cost_values           | 2.71         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.679        |
|    lagrangian_multiplier | 0.0168       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.49         |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00478     |
|    std                   | 0.953        |
|    value_loss            | 1.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.29444283  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -773         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 9            |
|    time_elapsed          | 269          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0040850798 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 2.91         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.37        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00453     |
|    std                   | 0.954        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0647       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0647       |
| reward                   | -0.5034985   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -771         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 10           |
|    time_elapsed          | 299          |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0041360147 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.04         |
|    cost_value_loss       | 46.2         |
|    cost_values           | 2.97         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.816       |
|    lagrangian_multiplier | 0.000486     |
|    learning_rate         | 0.0003       |
|    loss                  | 20.3         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.959        |
|    value_loss            | 0.431        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.21         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.21         |
| reward                   | -0.3082282   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -770         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 11           |
|    time_elapsed          | 331          |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0041334014 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.9          |
|    cost_value_loss       | 59.7         |
|    cost_values           | 2.99         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.048        |
|    lagrangian_multiplier | 0.00569      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.958        |
|    value_loss            | 6.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.46        |
| reward                   | -0.4464705  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 12          |
|    time_elapsed          | 362         |
|    total_timesteps       | 526336      |
| train/                   |             |
|    approx_kl             | 0.005121143 |
|    clip_fraction         | 0.0524      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.23        |
|    cost_value_loss       | 81.8        |
|    cost_values           | 3           |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.061       |
|    lagrangian_multiplier | 0.00185     |
|    learning_rate         | 0.0003      |
|    loss                  | 24.3        |
|    n_updates             | 2560        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 0.957       |
|    value_loss            | 4.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0662      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0662      |
| reward                   | -0.54400414 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -755        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 393         |
|    total_timesteps       | 528384      |
| train/                   |             |
|    approx_kl             | 0.008304008 |
|    clip_fraction         | 0.0508      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.27        |
|    cost_value_loss       | 88.8        |
|    cost_values           | 3           |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -0.116      |
|    lagrangian_multiplier | 6.31e-06    |
|    learning_rate         | 0.0003      |
|    loss                  | 47.3        |
|    n_updates             | 2570        |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.957       |
|    value_loss            | 3.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.601        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.601        |
| reward                   | -0.41344446  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 14           |
|    time_elapsed          | 423          |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0040424084 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 27.3         |
|    cost_values           | 2.97         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.91        |
|    lagrangian_multiplier | 0.00158      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.96         |
|    value_loss            | 6.23         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.143      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.143      |
| reward                   | -0.5477766 |
| rollout/                 |            |
|    ep_len_mean           | 977        |
|    ep_rew_mean           | -758       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 15         |
|    time_elapsed          | 454        |
|    total_timesteps       | 532480     |
| train/                   |            |
|    approx_kl             | 0.02277374 |
|    clip_fraction         | 0.0701     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.27       |
|    cost_value_loss       | 6.58       |
|    cost_values           | 2.95       |
|    entropy               | -2.74      |
|    entropy_loss          | -2.74      |
|    explained_variance    | -0.5       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 6.3        |
|    n_updates             | 2590       |
|    policy_gradient_loss  | -0.000398  |
|    std                   | 0.963      |
|    value_loss            | 8.06       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.97        |
| reward                   | -0.8857076  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -735        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 16          |
|    time_elapsed          | 484         |
|    total_timesteps       | 534528      |
| train/                   |             |
|    approx_kl             | 0.029254256 |
|    clip_fraction         | 0.337       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.27        |
|    cost_value_loss       | 44.4        |
|    cost_values           | 2.99        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -0.00282    |
|    lagrangian_multiplier | 0.00938     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.44        |
|    n_updates             | 2600        |
|    policy_gradient_loss  | 0.0299      |
|    std                   | 0.964       |
|    value_loss            | 3.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.41         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.41         |
| reward                   | -0.6349553   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 17           |
|    time_elapsed          | 515          |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0011517915 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.05         |
|    cost_value_loss       | 14.4         |
|    cost_values           | 2.3          |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0179      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.2         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.000435    |
|    std                   | 0.963        |
|    value_loss            | 68.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.5          |
| reward                   | -1.8361481   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -728         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 18           |
|    time_elapsed          | 545          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0011468758 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.31         |
|    cost_value_loss       | 21.1         |
|    cost_values           | 1.18         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0572      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00069     |
|    std                   | 0.963        |
|    value_loss            | 57.7         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.822         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.822         |
| reward                   | -0.51000684   |
| rollout/                 |               |
|    ep_len_mean           | 967           |
|    ep_rew_mean           | -736          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 19            |
|    time_elapsed          | 576           |
|    total_timesteps       | 540672        |
| train/                   |               |
|    approx_kl             | 0.00029652135 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 2.76          |
|    cost_value_loss       | 15.5          |
|    cost_values           | 0.982         |
|    entropy               | -2.74         |
|    entropy_loss          | -2.75         |
|    explained_variance    | 0.695         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 21            |
|    n_updates             | 2630          |
|    policy_gradient_loss  | -9.19e-05     |
|    std                   | 0.963         |
|    value_loss            | 41.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.935        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.935        |
| reward                   | -0.46791533  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 20           |
|    time_elapsed          | 607          |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0028373771 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 0.916        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.962        |
|    value_loss            | 15.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.527       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.527       |
| reward                   | -0.30353153 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -728        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 638         |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.00155742  |
|    clip_fraction         | 0.00269     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.32        |
|    cost_value_loss       | 26.7        |
|    cost_values           | 1.27        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.781       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.962       |
|    value_loss            | 3.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.83         |
| reward                   | -1.2981329   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 22           |
|    time_elapsed          | 668          |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0035514878 |
|    clip_fraction         | 0.00605      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.88         |
|    cost_value_loss       | 47.6         |
|    cost_values           | 1.78         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.342        |
|    lagrangian_multiplier | 0.000137     |
|    learning_rate         | 0.0003       |
|    loss                  | 27.1         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.961        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.5149274   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 23           |
|    time_elapsed          | 699          |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0021489994 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.72         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 1.63         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.831        |
|    lagrangian_multiplier | 0.000764     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.961        |
|    value_loss            | 26.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -1.9329104  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -728        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 729         |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.003750875 |
|    clip_fraction         | 0.00693     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 0.707       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.58        |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.961       |
|    value_loss            | 30.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.81         |
| reward                   | -1.4284087   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 25           |
|    time_elapsed          | 760          |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0018702638 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.26         |
|    cost_value_loss       | 28.9         |
|    cost_values           | 0.61         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.782        |
|    lagrangian_multiplier | 0.000217     |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.96         |
|    value_loss            | 27.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.7         |
| reward                   | -1.6186364  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -727        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 791         |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.004359428 |
|    clip_fraction         | 0.00698     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.43        |
|    cost_value_loss       | 19.6        |
|    cost_values           | 0.44        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.95        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.959       |
|    value_loss            | 17          |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.91         |
| reward                   | -0.5521721   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -726         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 821          |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0008388189 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 3.09         |
|    cost_value_loss       | 23.5         |
|    cost_values           | 0.726        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.888        |
|    lagrangian_multiplier | 0.000243     |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.959        |
|    value_loss            | 12.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.1673579  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -728        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 852         |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.000927467 |
|    clip_fraction         | 0.000146    |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 23.6        |
|    cost_values           | 0.648       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.1        |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.96        |
|    value_loss            | 7.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -0.75378835  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 883          |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0014624668 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 42.9         |
|    cost_values           | 0.928        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0.00173      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.958        |
|    value_loss            | 6.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.93         |
| reward                   | -0.4744507   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 30           |
|    time_elapsed          | 914          |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0056662657 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.82         |
|    cost_value_loss       | 49.5         |
|    cost_values           | 1.27         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.775        |
|    lagrangian_multiplier | 0.00407      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.957        |
|    value_loss            | 30.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1927818   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 31           |
|    time_elapsed          | 945          |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0052292896 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.51         |
|    cost_value_loss       | 25.5         |
|    cost_values           | 1.48         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -1.01        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.954        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.07         |
| reward                   | -0.71394044  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 32           |
|    time_elapsed          | 975          |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0010814569 |
|    clip_fraction         | 0.00415      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 9.58         |
|    cost_values           | 1.88         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.495       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.000842    |
|    std                   | 0.953        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.12        |
| reward                   | -0.73925996 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 1006        |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.003017099 |
|    clip_fraction         | 0.00718     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.57        |
|    cost_value_loss       | 6.89        |
|    cost_values           | 1.46        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.632       |
|    lagrangian_multiplier | 3.96e-06    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.72        |
|    n_updates             | 2770        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.955       |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.819        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.819        |
| reward                   | -0.3867498   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 34           |
|    time_elapsed          | 1036         |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0044345404 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.14         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 1.36         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.466        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.954        |
|    value_loss            | 16.4         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 4.08          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 4.08          |
| reward                   | -1.569325     |
| rollout/                 |               |
|    ep_len_mean           | 949           |
|    ep_rew_mean           | -662          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 35            |
|    time_elapsed          | 1067          |
|    total_timesteps       | 573440        |
| train/                   |               |
|    approx_kl             | 0.00068964233 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.12          |
|    cost_value_loss       | 23.7          |
|    cost_values           | 1.45          |
|    entropy               | -2.73         |
|    entropy_loss          | -2.73         |
|    explained_variance    | 0.743         |
|    lagrangian_multiplier | 0.00289       |
|    learning_rate         | 0.0003        |
|    loss                  | 5.9           |
|    n_updates             | 2790          |
|    policy_gradient_loss  | -0.000133     |
|    std                   | 0.953         |
|    value_loss            | 8.2           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 5.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.58         |
| reward                   | -0.9878226   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1098         |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0047604674 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.47         |
|    cost_value_loss       | 23.6         |
|    cost_values           | 1.25         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0.000362     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.952        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.68        |
| reward                   | -0.35878894 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1129        |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.005073554 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 5           |
|    cost_values           | 0.818       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.00214    |
|    std                   | 0.952       |
|    value_loss            | 15          |
------------------------------------------
--------------------------------------------
| avg_speed                | 2.92          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.92          |
| reward                   | -0.54550266   |
| rollout/                 |               |
|    ep_len_mean           | 949           |
|    ep_rew_mean           | -675          |
| time/                    |               |
|    fps                   | 67            |
|    iterations            | 38            |
|    time_elapsed          | 1159          |
|    total_timesteps       | 579584        |
| train/                   |               |
|    approx_kl             | 0.00091444224 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 4.44          |
|    cost_value_loss       | 34.1          |
|    cost_values           | 0.865         |
|    entropy               | -2.72         |
|    entropy_loss          | -2.72         |
|    explained_variance    | 0.898         |
|    lagrangian_multiplier | 2.89e-06      |
|    learning_rate         | 0.0003        |
|    loss                  | 17.2          |
|    n_updates             | 2820          |
|    policy_gradient_loss  | -0.000632     |
|    std                   | 0.951         |
|    value_loss            | 9.19          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.6582684   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -680         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1190         |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0036444627 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 5.21         |
|    cost_values           | 0.864        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.951        |
|    value_loss            | 7.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.18        |
| reward                   | -1.2830775  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -658        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1221        |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.004087135 |
|    clip_fraction         | 0.0169      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 5.29        |
|    cost_values           | 0.832       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.712       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.952       |
|    value_loss            | 8.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.87         |
| reward                   | -1.0582067   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -641         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1251         |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0033648307 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 0.857        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.5          |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.953        |
|    value_loss            | 7.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.42         |
| reward                   | -1.4203534   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -625         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1282         |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0043783495 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.97         |
|    cost_value_loss       | 29.1         |
|    cost_values           | 1.03         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0.0033       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.34         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00561     |
|    std                   | 0.951        |
|    value_loss            | 3.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.42         |
| reward                   | -0.59786403  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -621         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1313         |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0073411795 |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 1.1          |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.951        |
|    value_loss            | 15.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.9         |
| reward                   | -0.49312684 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -617        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1344        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.004295795 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.03        |
|    cost_value_loss       | 61.9        |
|    cost_values           | 1.37        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0.00086     |
|    learning_rate         | 0.0003      |
|    loss                  | 24          |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.95        |
|    value_loss            | 11.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.01        |
| reward                   | -0.39237767 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -609        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1375        |
|    total_timesteps       | 593920      |
| train/                   |             |
|    approx_kl             | 0.004987746 |
|    clip_fraction         | 0.01        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 1.13        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.548       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 2890        |
|    policy_gradient_loss  | -0.000652   |
|    std                   | 0.95        |
|    value_loss            | 31.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.55         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.55         |
| reward                   | -0.67457205  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -613         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1405         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0065270625 |
|    clip_fraction         | 0.0674       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 0.818        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.0049      |
|    std                   | 0.95         |
|    value_loss            | 17           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.522       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.522       |
| reward                   | -0.6529833  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -618        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1436        |
|    total_timesteps       | 598016      |
| train/                   |             |
|    approx_kl             | 0.002989559 |
|    clip_fraction         | 0.00864     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.56        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 0.793       |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 2910        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.952       |
|    value_loss            | 22.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.31         |
| reward                   | -0.9962329   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -620         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 48           |
|    time_elapsed          | 1467         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0020513036 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 0.837        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.954        |
|    value_loss            | 3.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.292        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.292        |
| reward                   | -0.46905798  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -631         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1498         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0059383092 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.22         |
|    cost_value_loss       | 22.4         |
|    cost_values           | 1.08         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.766        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.954        |
|    value_loss            | 12           |
-------------------------------------------
----------------------------------
| avg_speed          | 5.55      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 5.55      |
| reward             | -1.304553 |
| rollout/           |           |
|    ep_len_mean     | 933       |
|    ep_rew_mean     | -627      |
| time/              |           |
|    fps             | 98        |
|    iterations      | 1         |
|    time_elapsed    | 20        |
|    total_timesteps | 604160    |
----------------------------------
------------------------------------------
| avg_speed                | 6.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.51        |
| reward                   | -0.61541474 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -631        |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.007305878 |
|    clip_fraction         | 0.0486      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 22.8        |
|    cost_values           | 1.09        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.8        |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 0.954       |
|    value_loss            | 18.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.69        |
| reward                   | -1.2364419  |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -637        |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 3           |
|    time_elapsed          | 81          |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.006239444 |
|    clip_fraction         | 0.0276      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 19.8        |
|    cost_values           | 1.24        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00513    |
|    std                   | 0.954       |
|    value_loss            | 7.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.492        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.492        |
| reward                   | -0.3664736   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -647         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0031799362 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 8.97         |
|    cost_values           | 1            |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.831        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.65         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.956        |
|    value_loss            | 7.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.657        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.657        |
| reward                   | -0.38595346  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -663         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 5            |
|    time_elapsed          | 143          |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0012271064 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 45.3         |
|    cost_values           | 0.973        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.7         |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.000228    |
|    std                   | 0.956        |
|    value_loss            | 5.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.07        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.07        |
| reward                   | -0.48701456 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -666        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 173         |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.001187496 |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 5.94        |
|    cost_values           | 0.961       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.37        |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.957       |
|    value_loss            | 27.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.67        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.67        |
| reward                   | -0.55991787 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -674        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 204         |
|    total_timesteps       | 616448      |
| train/                   |             |
|    approx_kl             | 0.005001722 |
|    clip_fraction         | 0.0219      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 39          |
|    cost_values           | 1.09        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.3        |
|    n_updates             | 3000        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.957       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.23         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.23         |
| reward                   | -0.5137072   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 8            |
|    time_elapsed          | 235          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0035243095 |
|    clip_fraction         | 0.00801      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.78         |
|    cost_value_loss       | 24.7         |
|    cost_values           | 1.25         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.956        |
|    value_loss            | 7.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.17         |
| reward                   | -0.44822913  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 265          |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0031787371 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 9.76         |
|    cost_values           | 1.15         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.956        |
|    value_loss            | 17.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0833       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0833       |
| reward                   | -0.5693056   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 296          |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0029056664 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 17.5         |
|    cost_values           | 0.779        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.956        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.49        |
| reward                   | -0.5048005  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 326         |
|    total_timesteps       | 624640      |
| train/                   |             |
|    approx_kl             | 0.003995218 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 0.922       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 3040        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.956       |
|    value_loss            | 13          |
------------------------------------------
------------------------------------------
| avg_speed                | 2.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.51        |
| reward                   | -0.44423565 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 357         |
|    total_timesteps       | 626688      |
| train/                   |             |
|    approx_kl             | 0.003666507 |
|    clip_fraction         | 0.0155      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 14          |
|    cost_values           | 1.07        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.02        |
|    n_updates             | 3050        |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 0.955       |
|    value_loss            | 1.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.63         |
| reward                   | -1.0011891   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 388          |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0077421013 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.78         |
|    cost_value_loss       | 22.7         |
|    cost_values           | 1.11         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.953        |
|    value_loss            | 4.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0108       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0108       |
| reward                   | -0.5618633   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 419          |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0038267444 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 0.949        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.43         |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.952        |
|    value_loss            | 9.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.69         |
| reward                   | -0.9371582   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 449          |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0026011574 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 22.7         |
|    cost_values           | 1.04         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.95         |
|    value_loss            | 2.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.73        |
| reward                   | -0.5881123  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 480         |
|    total_timesteps       | 634880      |
| train/                   |             |
|    approx_kl             | 0.006154729 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 12          |
|    cost_values           | 1.22        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.41        |
|    n_updates             | 3090        |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.948       |
|    value_loss            | 7.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.01        |
| reward                   | -0.45173416 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 511         |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.002177562 |
|    clip_fraction         | 0.0136      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 42          |
|    cost_values           | 1.15        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.6        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.949       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.51         |
| reward                   | -0.3891696   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -687         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 18           |
|    time_elapsed          | 542          |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0046006995 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.34         |
|    cost_value_loss       | 23.2         |
|    cost_values           | 1.53         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0.000434     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 0.949        |
|    value_loss            | 5            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.99         |
| reward                   | -0.70600545  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 19           |
|    time_elapsed          | 573          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0046881437 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.45         |
|    cost_value_loss       | 36           |
|    cost_values           | 2.24         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.00583      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.34         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00478     |
|    std                   | 0.947        |
|    value_loss            | 2.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.4869633   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 20           |
|    time_elapsed          | 603          |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0047913347 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.6          |
|    cost_value_loss       | 38.4         |
|    cost_values           | 2.69         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.629        |
|    lagrangian_multiplier | 0.00839      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.96         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 0.945        |
|    value_loss            | 4.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.34        |
| reward                   | -0.43724284 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -662        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 634         |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.005977153 |
|    clip_fraction         | 0.0179      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.84        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.05        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.773       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.943       |
|    value_loss            | 17.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.09         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.09         |
| reward                   | -0.51172954  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 22           |
|    time_elapsed          | 664          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0039537335 |
|    clip_fraction         | 0.00615      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.08         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 1.35         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.89         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.000775    |
|    std                   | 0.944        |
|    value_loss            | 7.57         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.71        |
| reward                   | -0.6717301  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -659        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 23          |
|    time_elapsed          | 695         |
|    total_timesteps       | 649216      |
| train/                   |             |
|    approx_kl             | 0.005905594 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.69        |
|    cost_value_loss       | 26.1        |
|    cost_values           | 1.11        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.4        |
|    n_updates             | 3160        |
|    policy_gradient_loss  | -0.00645    |
|    std                   | 0.946       |
|    value_loss            | 9.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.86         |
| reward                   | -0.5350835   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -655         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 725          |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0042723697 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29         |
|    cost_value_loss       | 32.4         |
|    cost_values           | 1.02         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.946        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -1.0933485  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -657        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 25          |
|    time_elapsed          | 756         |
|    total_timesteps       | 653312      |
| train/                   |             |
|    approx_kl             | 0.005965005 |
|    clip_fraction         | 0.0471      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 9.91        |
|    cost_values           | 1.22        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.2         |
|    n_updates             | 3180        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.941       |
|    value_loss            | 2.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.486        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.486        |
| reward                   | -0.38120583  |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 786          |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0046892744 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 3.26         |
|    cost_values           | 0.817        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.939        |
|    value_loss            | 8.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.13        |
| reward                   | -0.42862055 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -653        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 817         |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.004891297 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.57        |
|    cost_value_loss       | 11          |
|    cost_values           | 0.921       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.41        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 0.937       |
|    value_loss            | 8.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.34         |
| reward                   | -0.4343147   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -648         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 848          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0044437326 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 28           |
|    cost_values           | 1.17         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.684        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.935        |
|    value_loss            | 15.1         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2.57       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.57       |
| reward                   | -0.4890343 |
| rollout/                 |            |
|    ep_len_mean           | 931        |
|    ep_rew_mean           | -641       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 29         |
|    time_elapsed          | 878        |
|    total_timesteps       | 661504     |
| train/                   |            |
|    approx_kl             | 0.00647308 |
|    clip_fraction         | 0.0244     |
|    clip_range            | 0.2        |
|    cost_returns          | 4.93       |
|    cost_value_loss       | 28.1       |
|    cost_values           | 1.51       |
|    entropy               | -2.68      |
|    entropy_loss          | -2.69      |
|    explained_variance    | 0.859      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 13.5       |
|    n_updates             | 3220       |
|    policy_gradient_loss  | -0.00332   |
|    std                   | 0.931      |
|    value_loss            | 4.22       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.938       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.938       |
| reward                   | -0.41261113 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -639        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 909         |
|    total_timesteps       | 663552      |
| train/                   |             |
|    approx_kl             | 0.004393982 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 19.3        |
|    cost_values           | 2.19        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.454       |
|    lagrangian_multiplier | 0.00393     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.56        |
|    n_updates             | 3230        |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.932       |
|    value_loss            | 11.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.13         |
| reward                   | -0.5320931   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -637         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 31           |
|    time_elapsed          | 940          |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0052926517 |
|    clip_fraction         | 0.0517       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.27         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 2.63         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0.0019       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.81         |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00547     |
|    std                   | 0.926        |
|    value_loss            | 8.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.849       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.849       |
| reward                   | -0.53767794 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -631        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 970         |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.003711757 |
|    clip_fraction         | 0.00972     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 15.5        |
|    cost_values           | 1.82        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.922       |
|    value_loss            | 7.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.48         |
| reward                   | -0.3376798   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -632         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 33           |
|    time_elapsed          | 1001         |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0058231507 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.13         |
|    cost_value_loss       | 15           |
|    cost_values           | 1.35         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.45         |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.919        |
|    value_loss            | 5.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.52         |
| reward                   | -0.7478188   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -625         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 34           |
|    time_elapsed          | 1032         |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0048765005 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 14.8         |
|    cost_values           | 0.939        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.05         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 0.917        |
|    value_loss            | 8.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.38         |
| reward                   | -0.8831009   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -625         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 35           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0054519977 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 27.5         |
|    cost_values           | 1.27         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19           |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.916        |
|    value_loss            | 10.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.273        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.273        |
| reward                   | -0.35770327  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -622         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1093         |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0020804345 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.49         |
|    cost_value_loss       | 17.8         |
|    cost_values           | 1.17         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.000789    |
|    std                   | 0.914        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.499        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.499        |
| reward                   | -0.6055274   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -618         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1124         |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0057888026 |
|    clip_fraction         | 0.0532       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.51         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 1.16         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.888        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | -0.00659     |
|    std                   | 0.913        |
|    value_loss            | 8.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.945       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.945       |
| reward                   | -0.5804829  |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -622        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1155        |
|    total_timesteps       | 679936      |
| train/                   |             |
|    approx_kl             | 0.004794044 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.98        |
|    cost_value_loss       | 55.6        |
|    cost_values           | 1.67        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24          |
|    n_updates             | 3310        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 0.91        |
|    value_loss            | 0.813       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.23         |
| reward                   | -0.521249    |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -617         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 39           |
|    time_elapsed          | 1186         |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0029849578 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.45         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 1.6          |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.911        |
|    value_loss            | 6.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.71         |
| reward                   | -1.0361017   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1217         |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0048279096 |
|    clip_fraction         | 0.0567       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.22         |
|    cost_value_loss       | 20.5         |
|    cost_values           | 1.6          |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.508        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.91         |
|    value_loss            | 7.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.73        |
| reward                   | -0.54045814 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -616        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1248        |
|    total_timesteps       | 686080      |
| train/                   |             |
|    approx_kl             | 0.004473861 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 45.7        |
|    cost_values           | 1.46        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0.000325    |
|    learning_rate         | 0.0003      |
|    loss                  | 22.5        |
|    n_updates             | 3340        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.909       |
|    value_loss            | 7.59        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.68       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.68       |
| reward                   | -1.6170357 |
| rollout/                 |            |
|    ep_len_mean           | 937        |
|    ep_rew_mean           | -601       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 42         |
|    time_elapsed          | 1278       |
|    total_timesteps       | 688128     |
| train/                   |            |
|    approx_kl             | 0.00486736 |
|    clip_fraction         | 0.023      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.76       |
|    cost_value_loss       | 11.3       |
|    cost_values           | 1.14       |
|    entropy               | -2.63      |
|    entropy_loss          | -2.64      |
|    explained_variance    | 0.969      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.35       |
|    n_updates             | 3350       |
|    policy_gradient_loss  | -0.00329   |
|    std                   | 0.907      |
|    value_loss            | 5.82       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.53131616  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -601         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 43           |
|    time_elapsed          | 1309         |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0059136488 |
|    clip_fraction         | 0.0539       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.43         |
|    cost_value_loss       | 29           |
|    cost_values           | 1.09         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 0.907        |
|    value_loss            | 5.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.342        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.342        |
| reward                   | -0.2812957   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -596         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1339         |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0042810626 |
|    clip_fraction         | 0.0626       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 13.2         |
|    cost_values           | 1.33         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 0.906        |
|    value_loss            | 3.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.04         |
| reward                   | -0.3862255   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -593         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1370         |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0059914375 |
|    clip_fraction         | 0.0785       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 8.28         |
|    cost_values           | 0.936        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.00846     |
|    std                   | 0.902        |
|    value_loss            | 3.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.254        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.254        |
| reward                   | -0.5201314   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -588         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1401         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0058787917 |
|    clip_fraction         | 0.0751       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.46         |
|    cost_value_loss       | 29.5         |
|    cost_values           | 1.17         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.00608     |
|    std                   | 0.9          |
|    value_loss            | 3.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0961      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0961      |
| reward                   | -0.3360903  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -590        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1432        |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.008723686 |
|    clip_fraction         | 0.0517      |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 25.9        |
|    cost_values           | 1.63        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00519    |
|    std                   | 0.9         |
|    value_loss            | 4.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.1         |
| reward                   | -0.5862361  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -585        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1463        |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.007370875 |
|    clip_fraction         | 0.0539      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 22.5        |
|    cost_values           | 1.5         |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.0079     |
|    std                   | 0.9         |
|    value_loss            | 9.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.949        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.949        |
| reward                   | -0.33160296  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -579         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1494         |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0067147445 |
|    clip_fraction         | 0.0825       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 34.3         |
|    cost_values           | 1.87         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.926        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.00942     |
|    std                   | 0.902        |
|    value_loss            | 1.4          |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/46po4mwk
-----------------------------------
| avg_speed          | 0.193      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.193      |
| reward             | -0.2559175 |
| rollout/           |            |
|    ep_len_mean     | 943        |
|    ep_rew_mean     | -579       |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 704512     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.562       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.562       |
| reward                   | -0.5399094  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -567        |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.005517903 |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.49        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 1.8         |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -3.43e-05   |
|    std                   | 0.896       |
|    value_loss            | 7.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.16         |
| reward                   | -0.5328425   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -559         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 3            |
|    time_elapsed          | 81           |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0068415636 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 1.23         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.902        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.00638     |
|    std                   | 0.896        |
|    value_loss            | 3.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.18         |
| reward                   | -0.3866661   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -555         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0049900347 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.69         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 0.979        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 0.897        |
|    value_loss            | 14.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.52         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.52         |
| reward                   | -0.48259878  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 5            |
|    time_elapsed          | 143          |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0031786617 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.58         |
|    cost_value_loss       | 29.6         |
|    cost_values           | 0.985        |
|    entropy               | -2.6         |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.893        |
|    value_loss            | 4.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.695       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.695       |
| reward                   | -0.41955584 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -532        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 174         |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.008746123 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.66        |
|    cost_value_loss       | 76.3        |
|    cost_values           | 1.55        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 36.1        |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.0141     |
|    std                   | 0.891       |
|    value_loss            | 2.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.2492337  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -526        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 205         |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.005246022 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 29.2        |
|    cost_values           | 1.89        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 2.63e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 15.9        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.00437    |
|    std                   | 0.89        |
|    value_loss            | 5.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.329       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.329       |
| reward                   | -0.37539092 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -521        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 235         |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.008632004 |
|    clip_fraction         | 0.0883      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.98        |
|    cost_value_loss       | 40.7        |
|    cost_values           | 1.81        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.1        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.0102     |
|    std                   | 0.889       |
|    value_loss            | 1.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.272       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.272       |
| reward                   | -0.4765763  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -517        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 266         |
|    total_timesteps       | 720896      |
| train/                   |             |
|    approx_kl             | 0.004723591 |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 12.1        |
|    cost_values           | 1.74        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.95        |
|    n_updates             | 3510        |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.886       |
|    value_loss            | 0.674       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0786      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0786      |
| reward                   | -0.3144227  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -508        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 296         |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.006549702 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 28.6        |
|    cost_values           | 1.64        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.883       |
|    value_loss            | 0.861       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.423        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.423        |
| reward                   | -0.33568007  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 11           |
|    time_elapsed          | 326          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0057765665 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 0.181        |
|    cost_values           | 1.52         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.159        |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -3.33e-05    |
|    std                   | 0.881        |
|    value_loss            | 1.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0107       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0107       |
| reward                   | -0.31993487  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 12           |
|    time_elapsed          | 357          |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0061459923 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 1.15         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.51         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00515     |
|    std                   | 0.878        |
|    value_loss            | 0.513        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0322      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0322      |
| reward                   | -0.5450597  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -497        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 387         |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.005078244 |
|    clip_fraction         | 0.0509      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 2.62        |
|    cost_values           | 1.01        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.41        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.88        |
|    value_loss            | 0.432       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0285       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0285       |
| reward                   | -0.36664116  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -495         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 418          |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0052912775 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.959        |
|    cost_value_loss       | 0.563        |
|    cost_values           | 0.913        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.622        |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.886        |
|    value_loss            | 2.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0994       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0994       |
| reward                   | -0.52627766  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 448          |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0052970643 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 4.98         |
|    cost_values           | 0.945        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.69         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 0.881        |
|    value_loss            | 0.819        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0523       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0523       |
| reward                   | -0.40424332  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 479          |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0059574125 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 15.7         |
|    cost_values           | 1            |
|    entropy               | -2.56        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.85         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.876        |
|    value_loss            | 1.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.246        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.246        |
| reward                   | -0.5347926   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 17           |
|    time_elapsed          | 509          |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0035758915 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1.01         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.55         |
|    n_updates             | 3590         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.87         |
|    value_loss            | 0.355        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.193       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.193       |
| reward                   | -0.33172563 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -492        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 539         |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.009180796 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.918       |
|    cost_value_loss       | 0.353       |
|    cost_values           | 0.94        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.189       |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 0.862       |
|    value_loss            | 0.297       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.156       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.156       |
| reward                   | -0.42455807 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -482        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 570         |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.003369248 |
|    clip_fraction         | 0.0712      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.738       |
|    cost_value_loss       | 0.0142      |
|    cost_values           | 0.821       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0443      |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.857       |
|    value_loss            | 0.155       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.465       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.465       |
| reward                   | -0.5649733  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 600         |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.017150793 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.653       |
|    cost_value_loss       | 0.101       |
|    cost_values           | 0.687       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.501       |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00475    |
|    std                   | 0.849       |
|    value_loss            | 0.567       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.212       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.212       |
| reward                   | -0.3530122  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 631         |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.010712925 |
|    clip_fraction         | 0.052       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 4.4         |
|    cost_values           | 0.795       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.68        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 0.851       |
|    value_loss            | 0.613       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.109       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.109       |
| reward                   | -0.57511675 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 662         |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.004501282 |
|    clip_fraction         | 0.054       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 1.71        |
|    cost_values           | 0.931       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.23        |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.847       |
|    value_loss            | 2.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.274       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.274       |
| reward                   | -0.48873562 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 692         |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.008030576 |
|    clip_fraction         | 0.0491      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.96        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 1           |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.9         |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.844       |
|    value_loss            | 1.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.823        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.823        |
| reward                   | -0.31845528  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 724          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0041173548 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 36.1         |
|    cost_values           | 1.12         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.844        |
|    value_loss            | 0.653        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.294        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.294        |
| reward                   | -0.38879195  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 25           |
|    time_elapsed          | 754          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0034449867 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.49         |
|    cost_value_loss       | 77.2         |
|    cost_values           | 1.8          |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.8         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.845        |
|    value_loss            | 0.407        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0202      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0202      |
| reward                   | -0.48565644 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 785         |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.004438048 |
|    clip_fraction         | 0.0346      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 2.16        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.72        |
|    n_updates             | 3680        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.845       |
|    value_loss            | 0.477       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.154       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.154       |
| reward                   | -0.34052306 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 815         |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.009245196 |
|    clip_fraction         | 0.0815      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 6.74        |
|    cost_values           | 1.91        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.0109     |
|    std                   | 0.842       |
|    value_loss            | 0.622       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0278045   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 846          |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0074651064 |
|    clip_fraction         | 0.0714       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 7.53         |
|    cost_values           | 1.59         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.76         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 0.839        |
|    value_loss            | 0.418        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.227       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.227       |
| reward                   | -0.45928428 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 876         |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.005270495 |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 4.83        |
|    cost_values           | 1.2         |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.32        |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.839       |
|    value_loss            | 4.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.252       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.252       |
| reward                   | -0.42652893 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 906         |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.009544917 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.802       |
|    cost_value_loss       | 0.0142      |
|    cost_values           | 0.882       |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.538       |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.00841    |
|    std                   | 0.839       |
|    value_loss            | 0.738       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.37317643 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 937         |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.005373221 |
|    clip_fraction         | 0.0586      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 5.29        |
|    cost_values           | 0.713       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.81        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00655    |
|    std                   | 0.84        |
|    value_loss            | 3.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0412      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0412      |
| reward                   | -0.507905   |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 967         |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.003891518 |
|    clip_fraction         | 0.0583      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.836       |
|    cost_value_loss       | 0.0139      |
|    cost_values           | 0.889       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.211       |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.841       |
|    value_loss            | 0.689       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0921      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0921      |
| reward                   | -0.3943838  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 997         |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.005379243 |
|    clip_fraction         | 0.0676      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 7.49        |
|    cost_values           | 0.744       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 3750        |
|    policy_gradient_loss  | -0.00557    |
|    std                   | 0.841       |
|    value_loss            | 9.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.196       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.196       |
| reward                   | -0.41497958 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1028        |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.017139088 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.785       |
|    cost_value_loss       | 0.0218      |
|    cost_values           | 0.898       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0725      |
|    n_updates             | 3760        |
|    policy_gradient_loss  | 0.00294     |
|    std                   | 0.832       |
|    value_loss            | 0.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0633      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0633      |
| reward                   | -0.32366037 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.019035546 |
|    clip_fraction         | 0.29        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 5.66        |
|    cost_values           | 0.784       |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | 0.00835     |
|    std                   | 0.828       |
|    value_loss            | 3.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.40061948  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0074902885 |
|    clip_fraction         | 0.0931       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.9          |
|    cost_value_loss       | 0.0745       |
|    cost_values           | 0.918        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0625       |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.831        |
|    value_loss            | 0.166        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.27         |
| reward                   | -0.40839     |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1119         |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0039781095 |
|    clip_fraction         | 0.0711       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.702        |
|    cost_value_loss       | 0.0162       |
|    cost_values           | 0.802        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0439       |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.827        |
|    value_loss            | 0.167        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.165       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.165       |
| reward                   | -0.3215037  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1149        |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.006026943 |
|    clip_fraction         | 0.0779      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 8.9         |
|    cost_values           | 1.03        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.83        |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.00734    |
|    std                   | 0.831       |
|    value_loss            | 0.183       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.122       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.122       |
| reward                   | -0.46755594 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1180        |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.005610509 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.87        |
|    cost_value_loss       | 0.0118      |
|    cost_values           | 0.89        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0402      |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.833       |
|    value_loss            | 0.169       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.97         |
| reward                   | -0.7398047   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1211         |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0057925773 |
|    clip_fraction         | 0.0618       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 0.784        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.22         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.834        |
|    value_loss            | 7.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.45        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.45        |
| reward                   | -0.5193985  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1241        |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.010685269 |
|    clip_fraction         | 0.0897      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 13.4        |
|    cost_values           | 1.09        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.38        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.00627    |
|    std                   | 0.834       |
|    value_loss            | 1.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0889       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0889       |
| reward                   | -0.56815225  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1272         |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0059479363 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 2.68         |
|    cost_values           | 1.17         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.834        |
|    value_loss            | 9.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5043102  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1302        |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.003394844 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 2.43        |
|    cost_values           | 0.742       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.834       |
|    value_loss            | 5.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0671       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0671       |
| reward                   | -0.31945184  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1333         |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0063133165 |
|    clip_fraction         | 0.0493       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 7.87         |
|    cost_values           | 0.853        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.75         |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.00542     |
|    std                   | 0.833        |
|    value_loss            | 1.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.49324927  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1363         |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0076306323 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.784        |
|    cost_value_loss       | 0.142        |
|    cost_values           | 0.838        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.944        |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.833        |
|    value_loss            | 3.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00926      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00926      |
| reward                   | -0.2990915   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1394         |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0041048354 |
|    clip_fraction         | 0.0567       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 2.16         |
|    cost_values           | 0.81         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.794        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.96         |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.832        |
|    value_loss            | 9.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.75146604 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1424        |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.008068452 |
|    clip_fraction         | 0.0504      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 6.15        |
|    cost_values           | 0.894       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00649    |
|    std                   | 0.832       |
|    value_loss            | 8.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -1.0691093   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1455         |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0032368903 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.49         |
|    cost_value_loss       | 5.06         |
|    cost_values           | 0.918        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.832        |
|    value_loss            | 4.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7971218   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1485         |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0073416308 |
|    clip_fraction         | 0.0544       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 3.18         |
|    cost_values           | 0.868        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.926        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.57         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 0.833        |
|    value_loss            | 4.7          |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.95       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.95       |
| reward             | -1.2441367 |
| rollout/           |            |
|    ep_len_mean     | 986        |
|    ep_rew_mean     | -476       |
| time/              |            |
|    fps             | 99         |
|    iterations      | 1          |
|    time_elapsed    | 20         |
|    total_timesteps | 804864     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.0381      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0381      |
| reward                   | -0.42277342 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.005127212 |
|    clip_fraction         | 0.0445      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.24        |
|    cost_value_loss       | 3.95        |
|    cost_values           | 0.816       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.87        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 0.833       |
|    value_loss            | 3.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0134      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0134      |
| reward                   | -0.4658579  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 3           |
|    time_elapsed          | 81          |
|    total_timesteps       | 808960      |
| train/                   |             |
|    approx_kl             | 0.010072792 |
|    clip_fraction         | 0.0847      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.724       |
|    cost_value_loss       | 0.0193      |
|    cost_values           | 0.818       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.14        |
|    n_updates             | 3940        |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.835       |
|    value_loss            | 0.955       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0963       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0963       |
| reward                   | -0.4435658   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0042462396 |
|    clip_fraction         | 0.145        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.711        |
|    cost_value_loss       | 0.0146       |
|    cost_values           | 0.804        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.842        |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 0.837        |
|    value_loss            | 0.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.26833984 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -481        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 143         |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.014942565 |
|    clip_fraction         | 0.0721      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.766       |
|    cost_value_loss       | 0.482       |
|    cost_values           | 0.763       |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.325       |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.833       |
|    value_loss            | 0.296       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0336      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0336      |
| reward                   | -0.31886426 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 173         |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.006161727 |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 50.4        |
|    cost_values           | 1.31        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.4        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.00794    |
|    std                   | 0.833       |
|    value_loss            | 2.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00347     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00347     |
| reward                   | -0.5007394  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 204         |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.008748895 |
|    clip_fraction         | 0.0773      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.82        |
|    cost_value_loss       | 0.484       |
|    cost_values           | 1.75        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.65        |
|    n_updates             | 3980        |
|    policy_gradient_loss  | -0.0059     |
|    std                   | 0.832       |
|    value_loss            | 0.845       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0371      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0371      |
| reward                   | -0.3255425  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 234         |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.010256104 |
|    clip_fraction         | 0.0824      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 8.26        |
|    cost_values           | 1.1         |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.832       |
|    value_loss            | 0.659       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.221        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.221        |
| reward                   | -0.50070405  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 265          |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0074245892 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 1.07         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.831        |
|    value_loss            | 0.208        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.183       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.183       |
| reward                   | -0.4170945  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 296         |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.006723994 |
|    clip_fraction         | 0.0575      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 8.15        |
|    cost_values           | 1.21        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.15        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.827       |
|    value_loss            | 0.0797      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0513       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0513       |
| reward                   | -0.54641604  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 11           |
|    time_elapsed          | 327          |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0034866263 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 7            |
|    cost_value_loss       | 83.4         |
|    cost_values           | 1.77         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0.00161      |
|    learning_rate         | 0.0003       |
|    loss                  | 23           |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.000303    |
|    std                   | 0.825        |
|    value_loss            | 0.165        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.159       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.159       |
| reward                   | -0.4261689  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 358         |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.004190648 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.75        |
|    cost_value_loss       | 108         |
|    cost_values           | 1.93        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.00791     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00766    |
|    std                   | 0.826       |
|    value_loss            | 0.543       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.095       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.095       |
| reward                   | -0.25434354 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 389         |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.0037269   |
|    clip_fraction         | 0.0507      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 149         |
|    cost_values           | 2.71        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0.0188      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.65        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00505    |
|    std                   | 0.824       |
|    value_loss            | 0.579       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.195        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.195        |
| reward                   | -0.4989323   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 420          |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0043560932 |
|    clip_fraction         | 0.0392       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.92         |
|    cost_value_loss       | 110          |
|    cost_values           | 2.71         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.0115       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.97         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | -0.000823    |
|    std                   | 0.823        |
|    value_loss            | 0.938        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.102       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.102       |
| reward                   | -0.32534048 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -482        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 15          |
|    time_elapsed          | 451         |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.013591718 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 156         |
|    cost_values           | 2.95        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0.021       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.26        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 0.823       |
|    value_loss            | 0.203       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00577      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00577      |
| reward                   | -0.5313959   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 16           |
|    time_elapsed          | 483          |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0035104756 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.89         |
|    cost_value_loss       | 88.1         |
|    cost_values           | 2.9          |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0.0122       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.57         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.824        |
|    value_loss            | 0.162        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0274       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0274       |
| reward                   | -0.5894916   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 17           |
|    time_elapsed          | 513          |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0073887734 |
|    clip_fraction         | 0.0681       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 25.9         |
|    cost_values           | 2.82         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.911        |
|    lagrangian_multiplier | 0.00198      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.95         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.826        |
|    value_loss            | 4.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.156       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.156       |
| reward                   | -0.54307353 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 18          |
|    time_elapsed          | 544         |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.004799925 |
|    clip_fraction         | 0.0392      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.71        |
|    cost_value_loss       | 73.3        |
|    cost_values           | 2.92        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0.0059      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 0.826       |
|    value_loss            | 0.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.50406265  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 19           |
|    time_elapsed          | 575          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0039899237 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.34         |
|    cost_value_loss       | 59.6         |
|    cost_values           | 2.95         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0.0032       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.827        |
|    value_loss            | 2.02         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.187      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.187      |
| reward                   | -0.3879229 |
| rollout/                 |            |
|    ep_len_mean           | 994        |
|    ep_rew_mean           | -484       |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 20         |
|    time_elapsed          | 605        |
|    total_timesteps       | 843776     |
| train/                   |            |
|    approx_kl             | 0.00397516 |
|    clip_fraction         | 0.00728    |
|    clip_range            | 0.2        |
|    cost_returns          | 3.55       |
|    cost_value_loss       | 13.8       |
|    cost_values           | 2.77       |
|    entropy               | -2.44      |
|    entropy_loss          | -2.44      |
|    explained_variance    | 0.991      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.09       |
|    n_updates             | 4110       |
|    policy_gradient_loss  | -0.000633  |
|    std                   | 0.827      |
|    value_loss            | 0.84       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.49330604  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 21           |
|    time_elapsed          | 636          |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0043543857 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 22.9         |
|    cost_values           | 2.52         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.706        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.829        |
|    value_loss            | 1.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0142       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0142       |
| reward                   | -0.4587038   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 22           |
|    time_elapsed          | 667          |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0093460735 |
|    clip_fraction         | 0.053        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 25.6         |
|    cost_values           | 2.41         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.829        |
|    value_loss            | 0.892        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.135        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.135        |
| reward                   | -0.29151824  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 23           |
|    time_elapsed          | 697          |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0058129774 |
|    clip_fraction         | 0.0485       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 3.99         |
|    cost_values           | 2.2          |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.878        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.92         |
|    n_updates             | 4140         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.828        |
|    value_loss            | 1.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.342        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.342        |
| reward                   | -0.41053393  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 728          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0033971146 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.7          |
|    cost_value_loss       | 83.5         |
|    cost_values           | 2.23         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43           |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.828        |
|    value_loss            | 0.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.50845736  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 25           |
|    time_elapsed          | 759          |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0012537937 |
|    clip_fraction         | 0.0713       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 38.5         |
|    cost_values           | 2.87         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0.00174      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 4160         |
|    policy_gradient_loss  | 0.000884     |
|    std                   | 0.826        |
|    value_loss            | 0.433        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.075       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.075       |
| reward                   | -0.4504535  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 790         |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.005923489 |
|    clip_fraction         | 0.052       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.98        |
|    cost_value_loss       | 87.2        |
|    cost_values           | 2.75        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.0118      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.74        |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.826       |
|    value_loss            | 0.573       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0615      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0615      |
| reward                   | -0.3565845  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 821         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.003442695 |
|    clip_fraction         | 0.0084      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.77        |
|    cost_value_loss       | 61.9        |
|    cost_values           | 2.73        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.0016      |
|    learning_rate         | 0.0003      |
|    loss                  | 18.6        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.826       |
|    value_loss            | 0.431       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.078        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.078        |
| reward                   | -0.28482294  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 853          |
|    total_timesteps       | 860160       |
| train/                   |              |
|    approx_kl             | 0.0065828157 |
|    clip_fraction         | 0.0609       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.88         |
|    cost_value_loss       | 57.2         |
|    cost_values           | 2.83         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0.00376      |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 4190         |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 0.826        |
|    value_loss            | 0.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.104       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.104       |
| reward                   | -0.49189433 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 884         |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.006150904 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.4        |
|    cost_value_loss       | 162         |
|    cost_values           | 2.98        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.474       |
|    lagrangian_multiplier | 0.00134     |
|    learning_rate         | 0.0003      |
|    loss                  | 48.2        |
|    n_updates             | 4200        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.828       |
|    value_loss            | 0.839       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0318      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0318      |
| reward                   | -0.475014   |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 916         |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.003538978 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.65        |
|    cost_value_loss       | 99.7        |
|    cost_values           | 2.98        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.0207      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.15        |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.829       |
|    value_loss            | 0.668       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0732       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0732       |
| reward                   | -0.45380256  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 31           |
|    time_elapsed          | 947          |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0032204897 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.31         |
|    cost_value_loss       | 97           |
|    cost_values           | 2.96         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.799        |
|    lagrangian_multiplier | 0.00649      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.83         |
|    value_loss            | 5.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.21        |
| reward                   | -0.4380296  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 978         |
|    total_timesteps       | 868352      |
| train/                   |             |
|    approx_kl             | 0.005575416 |
|    clip_fraction         | 0.0446      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.86        |
|    cost_value_loss       | 111         |
|    cost_values           | 2.97        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.0181      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.95        |
|    n_updates             | 4230        |
|    policy_gradient_loss  | -0.00463    |
|    std                   | 0.83        |
|    value_loss            | 0.564       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0141      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0141      |
| reward                   | -0.4852417  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1010        |
|    total_timesteps       | 870400      |
| train/                   |             |
|    approx_kl             | 0.011210448 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.52        |
|    cost_value_loss       | 101         |
|    cost_values           | 2.98        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49.3        |
|    n_updates             | 4240        |
|    policy_gradient_loss  | -0.00917    |
|    std                   | 0.831       |
|    value_loss            | 0.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.11        |
| reward                   | -0.3627539  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 872448      |
| train/                   |             |
|    approx_kl             | 0.013282374 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.99        |
|    cost_value_loss       | 95.9        |
|    cost_values           | 2.99        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.0044      |
|    learning_rate         | 0.0003      |
|    loss                  | 16.9        |
|    n_updates             | 4250        |
|    policy_gradient_loss  | -0.0179     |
|    std                   | 0.83        |
|    value_loss            | 0.378       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.259        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.259        |
| reward                   | -0.37845674  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 35           |
|    time_elapsed          | 1072         |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0042140856 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.22         |
|    cost_value_loss       | 66           |
|    cost_values           | 2.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0.00398      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 4260         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.83         |
|    value_loss            | 0.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0971      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0971      |
| reward                   | -0.35462174 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 36          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 876544      |
| train/                   |             |
|    approx_kl             | 0.007566485 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.07        |
|    cost_value_loss       | 50.7        |
|    cost_values           | 2.98        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.656       |
|    lagrangian_multiplier | 0.00668     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.61        |
|    n_updates             | 4270        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.83        |
|    value_loss            | 0.917       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.059      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.059      |
| reward                   | -0.4995105 |
| rollout/                 |            |
|    ep_len_mean           | 991        |
|    ep_rew_mean           | -461       |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 37         |
|    time_elapsed          | 1133       |
|    total_timesteps       | 878592     |
| train/                   |            |
|    approx_kl             | 0.0218209  |
|    clip_fraction         | 0.0701     |
|    clip_range            | 0.2        |
|    cost_returns          | 7.2        |
|    cost_value_loss       | 67.8       |
|    cost_values           | 2.99       |
|    entropy               | -2.46      |
|    entropy_loss          | -2.45      |
|    explained_variance    | 0.943      |
|    lagrangian_multiplier | 0.00771    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.94       |
|    n_updates             | 4280       |
|    policy_gradient_loss  | 0.00143    |
|    std                   | 0.835      |
|    value_loss            | 0.322      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.066        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.066        |
| reward                   | -0.41764334  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 38           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0065172594 |
|    clip_fraction         | 0.0908       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.31         |
|    cost_value_loss       | 30.3         |
|    cost_values           | 2.97         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.821        |
|    lagrangian_multiplier | 0.0042       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.02         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.838        |
|    value_loss            | 1.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.279        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.279        |
| reward                   | -0.42546389  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 39           |
|    time_elapsed          | 1195         |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0036190664 |
|    clip_fraction         | 0.0278       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.67         |
|    cost_value_loss       | 44.4         |
|    cost_values           | 2.97         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0.0034       |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.835        |
|    value_loss            | 0.572        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0506      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0506      |
| reward                   | -0.48432964 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 40          |
|    time_elapsed          | 1225        |
|    total_timesteps       | 884736      |
| train/                   |             |
|    approx_kl             | 0.005039024 |
|    clip_fraction         | 0.048       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 37.5        |
|    cost_values           | 2.97        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0.00469     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.44        |
|    n_updates             | 4310        |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.831       |
|    value_loss            | 0.549       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.158        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.158        |
| reward                   | -0.4597101   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 41           |
|    time_elapsed          | 1256         |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0067081843 |
|    clip_fraction         | 0.0607       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.71         |
|    cost_value_loss       | 17.5         |
|    cost_values           | 2.84         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.81         |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.83         |
|    value_loss            | 0.815        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.326        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.326        |
| reward                   | -0.54147136  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 42           |
|    time_elapsed          | 1286         |
|    total_timesteps       | 888832       |
| train/                   |              |
|    approx_kl             | 0.0057452107 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.67         |
|    cost_value_loss       | 35.5         |
|    cost_values           | 2.88         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0.00227      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 4330         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.826        |
|    value_loss            | 0.719        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.288       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.288       |
| reward                   | -0.36783296 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 43          |
|    time_elapsed          | 1317        |
|    total_timesteps       | 890880      |
| train/                   |             |
|    approx_kl             | 0.00489752  |
|    clip_fraction         | 0.0531      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 18.6        |
|    cost_values           | 2.78        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.000653    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.3         |
|    n_updates             | 4340        |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.824       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.111       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.111       |
| reward                   | -0.38411373 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 44          |
|    time_elapsed          | 1348        |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.004724264 |
|    clip_fraction         | 0.0992      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 43.5        |
|    cost_values           | 2.73        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.00231     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.0056     |
|    std                   | 0.825       |
|    value_loss            | 0.751       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.061       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.061       |
| reward                   | -0.4303165  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 45          |
|    time_elapsed          | 1379        |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.006732843 |
|    clip_fraction         | 0.0522      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.37        |
|    cost_value_loss       | 74.3        |
|    cost_values           | 2.84        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0.0127      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.87        |
|    n_updates             | 4360        |
|    policy_gradient_loss  | -0.00303    |
|    std                   | 0.824       |
|    value_loss            | 0.264       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.284      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.284      |
| reward                   | -0.3532771 |
| rollout/                 |            |
|    ep_len_mean           | 997        |
|    ep_rew_mean           | -447       |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 46         |
|    time_elapsed          | 1410       |
|    total_timesteps       | 897024     |
| train/                   |            |
|    approx_kl             | 0.00825712 |
|    clip_fraction         | 0.0659     |
|    clip_range            | 0.2        |
|    cost_returns          | 11.1       |
|    cost_value_loss       | 129        |
|    cost_values           | 2.95       |
|    entropy               | -2.44      |
|    entropy_loss          | -2.44      |
|    explained_variance    | 0.881      |
|    lagrangian_multiplier | 0.0192     |
|    learning_rate         | 0.0003     |
|    loss                  | 9.12       |
|    n_updates             | 4370       |
|    policy_gradient_loss  | -0.00146   |
|    std                   | 0.823      |
|    value_loss            | 0.662      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.00853      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00853      |
| reward                   | -0.54335225  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 47           |
|    time_elapsed          | 1441         |
|    total_timesteps       | 899072       |
| train/                   |              |
|    approx_kl             | 0.0048109842 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.97         |
|    cost_value_loss       | 96.9         |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.0216       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.95         |
|    n_updates             | 4380         |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.823        |
|    value_loss            | 0.323        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.286        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.286        |
| reward                   | -0.36422768  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 48           |
|    time_elapsed          | 1472         |
|    total_timesteps       | 901120       |
| train/                   |              |
|    approx_kl             | 0.0054595903 |
|    clip_fraction         | 0.0617       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.37         |
|    cost_value_loss       | 85.1         |
|    cost_values           | 2.98         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0.00551      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 4390         |
|    policy_gradient_loss  | -0.00599     |
|    std                   | 0.822        |
|    value_loss            | 0.447        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.084        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.084        |
| reward                   | -0.38400707  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1503         |
|    total_timesteps       | 903168       |
| train/                   |              |
|    approx_kl             | 0.0032341059 |
|    clip_fraction         | 0.0692       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.94         |
|    cost_value_loss       | 82.8         |
|    cost_values           | 2.97         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0.00523      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 4400         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.82         |
|    value_loss            | 0.374        |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/46po4mwk
-----------------------------------
| avg_speed          | 0.00509    |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.00509    |
| reward             | -0.3450473 |
| rollout/           |            |
|    ep_len_mean     | 997        |
|    ep_rew_mean     | -417       |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 905216     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.287        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.287        |
| reward                   | -0.32970607  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 2            |
|    time_elapsed          | 52           |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0026767203 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.91         |
|    cost_value_loss       | 101          |
|    cost_values           | 3            |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.0167       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.87         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 0.818        |
|    value_loss            | 0.347        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0892      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0892      |
| reward                   | -0.79994524 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 3           |
|    time_elapsed          | 83          |
|    total_timesteps       | 909312      |
| train/                   |             |
|    approx_kl             | 0.006857424 |
|    clip_fraction         | 0.0768      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 55.3        |
|    cost_values           | 2.99        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00391     |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 4430        |
|    policy_gradient_loss  | -0.00686    |
|    std                   | 0.818       |
|    value_loss            | 0.564       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.51593906 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 113         |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.005585154 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.55        |
|    cost_value_loss       | 89.9        |
|    cost_values           | 2.67        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.0156      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.59        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.816       |
|    value_loss            | 0.725       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.337       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.337       |
| reward                   | -0.24283744 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 145         |
|    total_timesteps       | 913408      |
| train/                   |             |
|    approx_kl             | 0.007081734 |
|    clip_fraction         | 0.0645      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 43.5        |
|    cost_values           | 1.78        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.8        |
|    n_updates             | 4450        |
|    policy_gradient_loss  | -0.00335    |
|    std                   | 0.815       |
|    value_loss            | 5.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0441       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0441       |
| reward                   | -0.31498852  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 6            |
|    time_elapsed          | 176          |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0066871094 |
|    clip_fraction         | 0.0865       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.42         |
|    cost_value_loss       | 87.5         |
|    cost_values           | 1.67         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.4         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.00635     |
|    std                   | 0.814        |
|    value_loss            | 0.943        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0621       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0621       |
| reward                   | -0.50552547  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 7            |
|    time_elapsed          | 207          |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0075496887 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 1.88         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.19         |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.817        |
|    value_loss            | 0.899        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0152      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0152      |
| reward                   | -0.51374793 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 238         |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.004470351 |
|    clip_fraction         | 0.0491      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.33        |
|    cost_value_loss       | 83.3        |
|    cost_values           | 2.08        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 40.9        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.818       |
|    value_loss            | 0.568       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.087       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.087       |
| reward                   | -0.43599987 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 269         |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.022680234 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.58        |
|    cost_value_loss       | 75.7        |
|    cost_values           | 2.8         |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0.000976    |
|    learning_rate         | 0.0003      |
|    loss                  | 26.5        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.0071     |
|    std                   | 0.817       |
|    value_loss            | 0.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0109       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0109       |
| reward                   | -0.44281235  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 10           |
|    time_elapsed          | 300          |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0039004378 |
|    clip_fraction         | 0.0493       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.02         |
|    cost_value_loss       | 56.2         |
|    cost_values           | 2.26         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.00061      |
|    learning_rate         | 0.0003       |
|    loss                  | 20.8         |
|    n_updates             | 4500         |
|    policy_gradient_loss  | 5.88e-05     |
|    std                   | 0.817        |
|    value_loss            | 1.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.3673292   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 11           |
|    time_elapsed          | 331          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0033816188 |
|    clip_fraction         | 0.0471       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.64         |
|    cost_value_loss       | 72.5         |
|    cost_values           | 2.15         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0.00826      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.39         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.817        |
|    value_loss            | 0.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0826       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0826       |
| reward                   | -0.38082105  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 12           |
|    time_elapsed          | 362          |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0046745976 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 118          |
|    cost_values           | 2.52         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0.0231       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.92         |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.818        |
|    value_loss            | 0.306        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.52        |
| reward                   | -0.4234363  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 393         |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.005054901 |
|    clip_fraction         | 0.0526      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.58        |
|    cost_value_loss       | 98.8        |
|    cost_values           | 2.97        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.00745     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00422    |
|    std                   | 0.816       |
|    value_loss            | 0.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.59         |
| reward                   | -0.41041824  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 14           |
|    time_elapsed          | 424          |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0062629855 |
|    clip_fraction         | 0.0542       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.85         |
|    cost_value_loss       | 92.1         |
|    cost_values           | 2.94         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.00747      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.813        |
|    value_loss            | 0.685        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.4708277  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 15          |
|    time_elapsed          | 455         |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.006598787 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.14        |
|    cost_value_loss       | 66.3        |
|    cost_values           | 2.95        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0.00718     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.57        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.813       |
|    value_loss            | 1.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0352       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0352       |
| reward                   | -0.4109269   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 16           |
|    time_elapsed          | 486          |
|    total_timesteps       | 935936       |
| train/                   |              |
|    approx_kl             | 0.0068341787 |
|    clip_fraction         | 0.0761       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.75         |
|    cost_value_loss       | 76.9         |
|    cost_values           | 2.96         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.00631      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 4560         |
|    policy_gradient_loss  | -0.00548     |
|    std                   | 0.81         |
|    value_loss            | 0.509        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.25         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.25         |
| reward                   | -0.25083318  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 17           |
|    time_elapsed          | 517          |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0069761653 |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.33         |
|    cost_value_loss       | 51.8         |
|    cost_values           | 2.76         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0.0082       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.4          |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.00562     |
|    std                   | 0.807        |
|    value_loss            | 0.864        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00646      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00646      |
| reward                   | -0.27181992  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 18           |
|    time_elapsed          | 548          |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0077095805 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.47         |
|    cost_value_loss       | 102          |
|    cost_values           | 2.9          |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.00942      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.808        |
|    value_loss            | 0.412        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.32         |
| reward                   | -0.28192732  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 19           |
|    time_elapsed          | 578          |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0069314907 |
|    clip_fraction         | 0.069        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.53         |
|    cost_value_loss       | 56.5         |
|    cost_values           | 2.87         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0.00461      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.85         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 0.81         |
|    value_loss            | 0.647        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0876       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0876       |
| reward                   | -0.35358724  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 20           |
|    time_elapsed          | 609          |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0054264287 |
|    clip_fraction         | 0.142        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 36.6         |
|    cost_values           | 2.85         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.00489      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.27         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.00323     |
|    std                   | 0.814        |
|    value_loss            | 0.555        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.457       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.457       |
| reward                   | -0.288991   |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 639         |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.015200701 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 33.7        |
|    cost_values           | 2.9         |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00146     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.811       |
|    value_loss            | 0.388       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.233        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.233        |
| reward                   | -0.48202437  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 22           |
|    time_elapsed          | 670          |
|    total_timesteps       | 948224       |
| train/                   |              |
|    approx_kl             | 0.0083296485 |
|    clip_fraction         | 0.0865       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.18         |
|    cost_value_loss       | 103          |
|    cost_values           | 2.88         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0.0114       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.82         |
|    n_updates             | 4620         |
|    policy_gradient_loss  | -0.00647     |
|    std                   | 0.81         |
|    value_loss            | 0.736        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.47         |
| reward                   | -0.442918    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 23           |
|    time_elapsed          | 701          |
|    total_timesteps       | 950272       |
| train/                   |              |
|    approx_kl             | 0.0055125523 |
|    clip_fraction         | 0.0771       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.8          |
|    cost_value_loss       | 48.9         |
|    cost_values           | 2.72         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0.0034       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.9          |
|    n_updates             | 4630         |
|    policy_gradient_loss  | -0.00725     |
|    std                   | 0.81         |
|    value_loss            | 0.439        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.051       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.051       |
| reward                   | -0.38854933 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 732         |
|    total_timesteps       | 952320      |
| train/                   |             |
|    approx_kl             | 0.004204236 |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.87        |
|    cost_value_loss       | 41.6        |
|    cost_values           | 2.84        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.0039      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.06        |
|    n_updates             | 4640        |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 0.81        |
|    value_loss            | 0.273       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.372        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.372        |
| reward                   | -0.423542    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 25           |
|    time_elapsed          | 762          |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0074291304 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 6.72         |
|    cost_value_loss       | 65.5         |
|    cost_values           | 2.91         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0.00524      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00593     |
|    std                   | 0.81         |
|    value_loss            | 0.337        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.143        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.143        |
| reward                   | -0.32714716  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 793          |
|    total_timesteps       | 956416       |
| train/                   |              |
|    approx_kl             | 0.0069832434 |
|    clip_fraction         | 0.0636       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.05         |
|    cost_value_loss       | 27.8         |
|    cost_values           | 2.41         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0.0029       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 4660         |
|    policy_gradient_loss  | -0.00536     |
|    std                   | 0.811        |
|    value_loss            | 1.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.128       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.128       |
| reward                   | -0.41746792 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 824         |
|    total_timesteps       | 958464      |
| train/                   |             |
|    approx_kl             | 0.013324529 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 109         |
|    cost_values           | 2.7         |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.0146      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.86        |
|    n_updates             | 4670        |
|    policy_gradient_loss  | -0.0118     |
|    std                   | 0.81        |
|    value_loss            | 0.305       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0442      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0442      |
| reward                   | -0.2507714  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 855         |
|    total_timesteps       | 960512      |
| train/                   |             |
|    approx_kl             | 0.004960046 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.09        |
|    cost_value_loss       | 62.4        |
|    cost_values           | 2.8         |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0.00324     |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 4680        |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 0.81        |
|    value_loss            | 0.223       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.118       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.118       |
| reward                   | -0.36485198 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 885         |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.004073268 |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.45        |
|    cost_value_loss       | 69.4        |
|    cost_values           | 2.95        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00656     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.811       |
|    value_loss            | 0.87        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0433       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0433       |
| reward                   | -0.45055652  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 30           |
|    time_elapsed          | 916          |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0059320014 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.23         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 2.6          |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.09         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.809        |
|    value_loss            | 0.629        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0411      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0411      |
| reward                   | -0.34046343 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 947         |
|    total_timesteps       | 966656      |
| train/                   |             |
|    approx_kl             | 0.006494599 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.33        |
|    cost_value_loss       | 29.3        |
|    cost_values           | 2.57        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 4.37e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 4710        |
|    policy_gradient_loss  | -0.00106    |
|    std                   | 0.807       |
|    value_loss            | 2.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.44493654  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 32           |
|    time_elapsed          | 978          |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0067121815 |
|    clip_fraction         | 0.0743       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.56         |
|    cost_value_loss       | 61.5         |
|    cost_values           | 2.57         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0.00603      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.75         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.806        |
|    value_loss            | 2.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0214       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0214       |
| reward                   | -0.23824236  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 33           |
|    time_elapsed          | 1009         |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0048215026 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.7          |
|    cost_value_loss       | 95.1         |
|    cost_values           | 2.56         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.83         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.806        |
|    value_loss            | 1.29         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.174      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.174      |
| reward                   | -0.3310056 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -391       |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 34         |
|    time_elapsed          | 1040       |
|    total_timesteps       | 972800     |
| train/                   |            |
|    approx_kl             | 0.01057839 |
|    clip_fraction         | 0.174      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.94       |
|    cost_value_loss       | 20.8       |
|    cost_values           | 2.45       |
|    entropy               | -2.39      |
|    entropy_loss          | -2.39      |
|    explained_variance    | 0.998      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.9       |
|    n_updates             | 4740       |
|    policy_gradient_loss  | -0.00702   |
|    std                   | 0.805      |
|    value_loss            | 0.561      |
-----------------------------------------
-----------------------------------------
| avg_speed                | 0.0936     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0936     |
| reward                   | -0.266757  |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -389       |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 35         |
|    time_elapsed          | 1071       |
|    total_timesteps       | 974848     |
| train/                   |            |
|    approx_kl             | 0.01038624 |
|    clip_fraction         | 0.0842     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.68       |
|    cost_value_loss       | 53.6       |
|    cost_values           | 2.56       |
|    entropy               | -2.39      |
|    entropy_loss          | -2.39      |
|    explained_variance    | 0.984      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 26.3       |
|    n_updates             | 4750       |
|    policy_gradient_loss  | -0.00628   |
|    std                   | 0.805      |
|    value_loss            | 0.334      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0839       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0839       |
| reward                   | -0.158093    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 36           |
|    time_elapsed          | 1102         |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0060161045 |
|    clip_fraction         | 0.0831       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.43         |
|    cost_value_loss       | 74.9         |
|    cost_values           | 2.88         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.00157      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.9         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00546     |
|    std                   | 0.805        |
|    value_loss            | 0.694        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0101     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0101     |
| reward                   | -0.5188456 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -384       |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 37         |
|    time_elapsed          | 1133       |
|    total_timesteps       | 978944     |
| train/                   |            |
|    approx_kl             | 0.00442551 |
|    clip_fraction         | 0.0732     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.99       |
|    cost_value_loss       | 46.6       |
|    cost_values           | 2.88       |
|    entropy               | -2.39      |
|    entropy_loss          | -2.39      |
|    explained_variance    | 0.992      |
|    lagrangian_multiplier | 0.00404    |
|    learning_rate         | 0.0003     |
|    loss                  | 9.81       |
|    n_updates             | 4770       |
|    policy_gradient_loss  | -0.00792   |
|    std                   | 0.805      |
|    value_loss            | 0.716      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0873      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0873      |
| reward                   | -0.46693587 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -383        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1164        |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.003320591 |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 2.75        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.08        |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.806       |
|    value_loss            | 0.602       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.217        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.217        |
| reward                   | -0.45272794  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 39           |
|    time_elapsed          | 1195         |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0076520904 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 7.84         |
|    cost_value_loss       | 69.1         |
|    cost_values           | 2.71         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0.00469      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 0.805        |
|    value_loss            | 0.877        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00115      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00115      |
| reward                   | -0.19736958  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 40           |
|    time_elapsed          | 1226         |
|    total_timesteps       | 985088       |
| train/                   |              |
|    approx_kl             | 0.0041074473 |
|    clip_fraction         | 0.128        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.3          |
|    cost_value_loss       | 92.1         |
|    cost_values           | 2.73         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0.0181       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.83         |
|    n_updates             | 4800         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.806        |
|    value_loss            | 0.338        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0855      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0855      |
| reward                   | -0.30915326 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -380        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 41          |
|    time_elapsed          | 1257        |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.007543071 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 32.2        |
|    cost_values           | 2.58        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.2        |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00795    |
|    std                   | 0.806       |
|    value_loss            | 0.867       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.233       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.233       |
| reward                   | -0.39730757 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 42          |
|    time_elapsed          | 1288        |
|    total_timesteps       | 989184      |
| train/                   |             |
|    approx_kl             | 0.004491074 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 124         |
|    cost_values           | 2.76        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.0165      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.64        |
|    n_updates             | 4820        |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.806       |
|    value_loss            | 0.374       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.42158282  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 43           |
|    time_elapsed          | 1319         |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0077212797 |
|    clip_fraction         | 0.0327       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 117          |
|    cost_values           | 2.86         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0.00468      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.804        |
|    value_loss            | 1.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0952       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0952       |
| reward                   | -0.50917685  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 44           |
|    time_elapsed          | 1350         |
|    total_timesteps       | 993280       |
| train/                   |              |
|    approx_kl             | 0.0077252695 |
|    clip_fraction         | 0.0713       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.02         |
|    cost_value_loss       | 9.35         |
|    cost_values           | 2.38         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 4840         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.804        |
|    value_loss            | 0.855        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.37637806  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 45           |
|    time_elapsed          | 1381         |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0050248513 |
|    clip_fraction         | 0.084        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.76         |
|    cost_value_loss       | 62.6         |
|    cost_values           | 2.35         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0.0101       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.89         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.00709     |
|    std                   | 0.802        |
|    value_loss            | 0.219        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.221       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.221       |
| reward                   | -0.27438632 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 46          |
|    time_elapsed          | 1412        |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.009863552 |
|    clip_fraction         | 0.0667      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.7         |
|    cost_value_loss       | 54          |
|    cost_values           | 2.47        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.005       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.38        |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.00506    |
|    std                   | 0.8         |
|    value_loss            | 0.294       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.215       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.215       |
| reward                   | -0.45746124 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1443        |
|    total_timesteps       | 999424      |
| train/                   |             |
|    approx_kl             | 0.006242114 |
|    clip_fraction         | 0.0336      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.85        |
|    cost_value_loss       | 83.8        |
|    cost_values           | 2.62        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.00726     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 4870        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.802       |
|    value_loss            | 0.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0219      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0219      |
| reward                   | -0.42009166 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 48          |
|    time_elapsed          | 1474        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.010064231 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.47        |
|    cost_value_loss       | 78.2        |
|    cost_values           | 2.59        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.00383     |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -9.22e-05   |
|    std                   | 0.801       |
|    value_loss            | 0.428       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.44248828  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1505         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0057348963 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.15         |
|    cost_value_loss       | 28.7         |
|    cost_values           | 2.67         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.661        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 0.798        |
|    value_loss            | 0.498        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.261       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.261       |
| reward             | -0.41781363 |
| rollout/           |             |
|    ep_len_mean     | 983         |
|    ep_rew_mean     | -384        |
| time/              |             |
|    fps             | 98          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 1005568     |
------------------------------------
-----------------------------------------
| avg_speed                | 0.0841     |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.0841     |
| reward                   | -0.2886954 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -383       |
| time/                    |            |
|    fps                   | 78         |
|    iterations            | 2          |
|    time_elapsed          | 52         |
|    total_timesteps       | 1007616    |
| train/                   |            |
|    approx_kl             | 0.01315511 |
|    clip_fraction         | 0.132      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.54       |
|    cost_value_loss       | 40.6       |
|    cost_values           | 2.96       |
|    entropy               | -2.36      |
|    entropy_loss          | -2.37      |
|    explained_variance    | 0.956      |
|    lagrangian_multiplier | 0.00237    |
|    learning_rate         | 0.0003     |
|    loss                  | 11.1       |
|    n_updates             | 4910       |
|    policy_gradient_loss  | -0.005     |
|    std                   | 0.795      |
|    value_loss            | 0.393      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.048       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.048       |
| reward                   | -0.49821833 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -383        |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 3           |
|    time_elapsed          | 82          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.005188534 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.63        |
|    cost_value_loss       | 99.5        |
|    cost_values           | 2.99        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.0138      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.82        |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.0103     |
|    std                   | 0.796       |
|    value_loss            | 0.352       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0265       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0265       |
| reward                   | -0.30129373  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 4            |
|    time_elapsed          | 113          |
|    total_timesteps       | 1011712      |
| train/                   |              |
|    approx_kl             | 0.0073926058 |
|    clip_fraction         | 0.0937       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.36         |
|    cost_value_loss       | 32.4         |
|    cost_values           | 2.79         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.707        |
|    lagrangian_multiplier | 0.00214      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.73         |
|    n_updates             | 4930         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.799        |
|    value_loss            | 1.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.208       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.208       |
| reward                   | -0.4395614  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 143         |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.009981809 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 4.77        |
|    cost_values           | 2.48        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.25        |
|    n_updates             | 4940        |
|    policy_gradient_loss  | 9.52e-05    |
|    std                   | 0.793       |
|    value_loss            | 0.423       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.243       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.243       |
| reward                   | -0.2841563  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -383        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 174         |
|    total_timesteps       | 1015808     |
| train/                   |             |
|    approx_kl             | 0.022087349 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 0.0866      |
|    cost_values           | 2.05        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.289       |
|    n_updates             | 4950        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.792       |
|    value_loss            | 0.411       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.24         |
| reward                   | -0.34765768  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 7            |
|    time_elapsed          | 205          |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0036197263 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.74         |
|    cost_value_loss       | 47.9         |
|    cost_values           | 2            |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.9         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.000442    |
|    std                   | 0.791        |
|    value_loss            | 0.121        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.049       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.049       |
| reward                   | -0.45020273 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -380        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 235         |
|    total_timesteps       | 1019904     |
| train/                   |             |
|    approx_kl             | 0.013105755 |
|    clip_fraction         | 0.0759      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.47        |
|    cost_value_loss       | 70.4        |
|    cost_values           | 2.76        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00623     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 4970        |
|    policy_gradient_loss  | -0.000405   |
|    std                   | 0.789       |
|    value_loss            | 0.453       |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.14       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.14       |
| reward                   | -1.1537704 |
| rollout/                 |            |
|    ep_len_mean           | 989        |
|    ep_rew_mean           | -379       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 9          |
|    time_elapsed          | 266        |
|    total_timesteps       | 1021952    |
| train/                   |            |
|    approx_kl             | 0.04055071 |
|    clip_fraction         | 0.295      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.22       |
|    cost_value_loss       | 0.125      |
|    cost_values           | 2.25       |
|    entropy               | -2.34      |
|    entropy_loss          | -2.34      |
|    explained_variance    | 0.985      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.962      |
|    n_updates             | 4980       |
|    policy_gradient_loss  | 0.0219     |
|    std                   | 0.788      |
|    value_loss            | 0.56       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0767      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0767      |
| reward                   | -0.23370661 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 296         |
|    total_timesteps       | 1024000     |
| train/                   |             |
|    approx_kl             | 0.004073392 |
|    clip_fraction         | 0.0627      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 4.67        |
|    cost_values           | 1.17        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0.00087     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 4990        |
|    policy_gradient_loss  | 0.000784    |
|    std                   | 0.788       |
|    value_loss            | 5.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0804      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0804      |
| reward                   | -0.3821189  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 326         |
|    total_timesteps       | 1026048     |
| train/                   |             |
|    approx_kl             | 0.008427935 |
|    clip_fraction         | 0.0562      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 20.1        |
|    cost_values           | 0.616       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00366     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.2         |
|    n_updates             | 5000        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.786       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.24169198 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 357         |
|    total_timesteps       | 1028096     |
| train/                   |             |
|    approx_kl             | 0.012498824 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.799       |
|    cost_value_loss       | 1.73        |
|    cost_values           | 0.707       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.801       |
|    n_updates             | 5010        |
|    policy_gradient_loss  | -0.00897    |
|    std                   | 0.784       |
|    value_loss            | 0.214       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.301       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.301       |
| reward                   | -0.4280294  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -379        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 388         |
|    total_timesteps       | 1030144     |
| train/                   |             |
|    approx_kl             | 0.010274422 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.65        |
|    cost_value_loss       | 58.4        |
|    cost_values           | 1.28        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.2        |
|    n_updates             | 5020        |
|    policy_gradient_loss  | -0.0109     |
|    std                   | 0.784       |
|    value_loss            | 0.0938      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.517        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.517        |
| reward                   | -0.27565876  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 419          |
|    total_timesteps       | 1032192      |
| train/                   |              |
|    approx_kl             | 0.0043768743 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 28.3         |
|    cost_values           | 2            |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 5030         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.784        |
|    value_loss            | 0.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0105      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0105      |
| reward                   | -0.4491797  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -379        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 450         |
|    total_timesteps       | 1034240     |
| train/                   |             |
|    approx_kl             | 0.012283621 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.18        |
|    cost_value_loss       | 82.2        |
|    cost_values           | 2.32        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41          |
|    n_updates             | 5040        |
|    policy_gradient_loss  | -0.0233     |
|    std                   | 0.784       |
|    value_loss            | 1.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.3244938   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 16           |
|    time_elapsed          | 481          |
|    total_timesteps       | 1036288      |
| train/                   |              |
|    approx_kl             | 0.0035464605 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.67         |
|    cost_value_loss       | 99.9         |
|    cost_values           | 2.29         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0.0075       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 5050         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.782        |
|    value_loss            | 0.659        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0348       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0348       |
| reward                   | -0.46923062  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 17           |
|    time_elapsed          | 512          |
|    total_timesteps       | 1038336      |
| train/                   |              |
|    approx_kl             | 0.0026485673 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 27.7         |
|    cost_values           | 2.55         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.00479      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.88         |
|    n_updates             | 5060         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.783        |
|    value_loss            | 0.475        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.135       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.135       |
| reward                   | -0.32020012 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 18          |
|    time_elapsed          | 542         |
|    total_timesteps       | 1040384     |
| train/                   |             |
|    approx_kl             | 0.008667775 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.31        |
|    cost_value_loss       | 51.6        |
|    cost_values           | 2.7         |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.773       |
|    lagrangian_multiplier | 0.00559     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.86        |
|    n_updates             | 5070        |
|    policy_gradient_loss  | -0.014      |
|    std                   | 0.785       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0173      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0173      |
| reward                   | -0.54817015 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -386        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 573         |
|    total_timesteps       | 1042432     |
| train/                   |             |
|    approx_kl             | 0.008176159 |
|    clip_fraction         | 0.0733      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 18.9        |
|    cost_values           | 0.75        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.665       |
|    lagrangian_multiplier | 0.238       |
|    learning_rate         | 0.0003      |
|    loss                  | 1.44        |
|    n_updates             | 5080        |
|    policy_gradient_loss  | 0.00279     |
|    std                   | 0.786       |
|    value_loss            | 335         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0182      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0182      |
| reward                   | -0.59568524 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 20          |
|    time_elapsed          | 604         |
|    total_timesteps       | 1044480     |
| train/                   |             |
|    approx_kl             | 0.010584734 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.9         |
|    cost_value_loss       | 115         |
|    cost_values           | 1.04        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49.8        |
|    n_updates             | 5090        |
|    policy_gradient_loss  | -0.0164     |
|    std                   | 0.785       |
|    value_loss            | 0.541       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.179       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.179       |
| reward                   | -0.30379543 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 635         |
|    total_timesteps       | 1046528     |
| train/                   |             |
|    approx_kl             | 0.000481906 |
|    clip_fraction         | 9.77e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 22.9        |
|    cost_values           | -0.185      |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.37        |
|    lagrangian_multiplier | 0.0365      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.81        |
|    n_updates             | 5100        |
|    policy_gradient_loss  | -0.000377   |
|    std                   | 0.785       |
|    value_loss            | 101         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0726       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0726       |
| reward                   | -0.32125324  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 22           |
|    time_elapsed          | 665          |
|    total_timesteps       | 1048576      |
| train/                   |              |
|    approx_kl             | 0.0076306444 |
|    clip_fraction         | 0.11         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 7.29         |
|    cost_values           | 0.42         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0.00561      |
|    learning_rate         | 0.0003       |
|    loss                  | 1.67         |
|    n_updates             | 5110         |
|    policy_gradient_loss  | -0.00819     |
|    std                   | 0.786        |
|    value_loss            | 0.311        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0221       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0221       |
| reward                   | -0.25952777  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 23           |
|    time_elapsed          | 696          |
|    total_timesteps       | 1050624      |
| train/                   |              |
|    approx_kl             | 0.0091240965 |
|    clip_fraction         | 0.0594       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.327        |
|    cost_value_loss       | 0.0113       |
|    cost_values           | 0.373        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.045        |
|    n_updates             | 5120         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.787        |
|    value_loss            | 0.166        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00328      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00328      |
| reward                   | -0.35259986  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 24           |
|    time_elapsed          | 727          |
|    total_timesteps       | 1052672      |
| train/                   |              |
|    approx_kl             | 0.0057094498 |
|    clip_fraction         | 0.086        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 46.1         |
|    cost_values           | 0.423        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0.00592      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.1          |
|    n_updates             | 5130         |
|    policy_gradient_loss  | -0.00486     |
|    std                   | 0.787        |
|    value_loss            | 6.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.035       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.035       |
| reward                   | -0.27246562 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 25          |
|    time_elapsed          | 758         |
|    total_timesteps       | 1054720     |
| train/                   |             |
|    approx_kl             | 0.009197379 |
|    clip_fraction         | 0.0692      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.95        |
|    cost_value_loss       | 72.4        |
|    cost_values           | 1.29        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.2        |
|    n_updates             | 5140        |
|    policy_gradient_loss  | -0.00854    |
|    std                   | 0.786       |
|    value_loss            | 0.377       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0226       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0226       |
| reward                   | -0.33050823  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 790          |
|    total_timesteps       | 1056768      |
| train/                   |              |
|    approx_kl             | 0.0077625434 |
|    clip_fraction         | 0.0941       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.85         |
|    cost_value_loss       | 90           |
|    cost_values           | 2.18         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.913        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.3         |
|    n_updates             | 5150         |
|    policy_gradient_loss  | -0.0082      |
|    std                   | 0.785        |
|    value_loss            | 0.501        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0423      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0423      |
| reward                   | -0.27312806 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 821         |
|    total_timesteps       | 1058816     |
| train/                   |             |
|    approx_kl             | 0.008814931 |
|    clip_fraction         | 0.0732      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.35        |
|    cost_value_loss       | 90          |
|    cost_values           | 2.91        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.74        |
|    lagrangian_multiplier | 0.013       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.52        |
|    n_updates             | 5160        |
|    policy_gradient_loss  | -0.00504    |
|    std                   | 0.784       |
|    value_loss            | 4.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.028        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.028        |
| reward                   | -0.35490257  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 851          |
|    total_timesteps       | 1060864      |
| train/                   |              |
|    approx_kl             | 0.0062630856 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 32           |
|    cost_values           | 2.43         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0.00064      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 5170         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.784        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0134       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0134       |
| reward                   | -0.21664308  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 882          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0023357612 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 0.25         |
|    cost_values           | 1.91         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.357        |
|    n_updates             | 5180         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.783        |
|    value_loss            | 0.778        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0793      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0793      |
| reward                   | -0.27269018 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 912         |
|    total_timesteps       | 1064960     |
| train/                   |             |
|    approx_kl             | 0.005471641 |
|    clip_fraction         | 0.0677      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 7.27        |
|    cost_values           | 1.52        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.66        |
|    n_updates             | 5190        |
|    policy_gradient_loss  | -0.00832    |
|    std                   | 0.785       |
|    value_loss            | 0.401       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.058484   |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 943         |
|    total_timesteps       | 1067008     |
| train/                   |             |
|    approx_kl             | 0.009379987 |
|    clip_fraction         | 0.0644      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 0.0441      |
|    cost_values           | 1.36        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.254       |
|    n_updates             | 5200        |
|    policy_gradient_loss  | -0.00313    |
|    std                   | 0.785       |
|    value_loss            | 0.887       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.7962173  |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 973         |
|    total_timesteps       | 1069056     |
| train/                   |             |
|    approx_kl             | 0.004178836 |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 20.6        |
|    cost_values           | 0.276       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.681       |
|    lagrangian_multiplier | 0.00226     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.6         |
|    n_updates             | 5210        |
|    policy_gradient_loss  | -0.00065    |
|    std                   | 0.784       |
|    value_loss            | 58.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0779      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0779      |
| reward                   | -0.46808317 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 1004        |
|    total_timesteps       | 1071104     |
| train/                   |             |
|    approx_kl             | 0.005886346 |
|    clip_fraction         | 0.0692      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.544       |
|    cost_value_loss       | 0.0937      |
|    cost_values           | 0.632       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.927       |
|    n_updates             | 5220        |
|    policy_gradient_loss  | -0.0108     |
|    std                   | 0.787       |
|    value_loss            | 4.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.216       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.216       |
| reward                   | -0.28273776 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1034        |
|    total_timesteps       | 1073152     |
| train/                   |             |
|    approx_kl             | 0.009681398 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.618       |
|    cost_value_loss       | 0.0102      |
|    cost_values           | 0.685       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.3         |
|    n_updates             | 5230        |
|    policy_gradient_loss  | -0.0101     |
|    std                   | 0.792       |
|    value_loss            | 0.427       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.5022857  |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1065        |
|    total_timesteps       | 1075200     |
| train/                   |             |
|    approx_kl             | 0.007867259 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.897       |
|    cost_value_loss       | 7.27        |
|    cost_values           | 0.504       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.22        |
|    n_updates             | 5240        |
|    policy_gradient_loss  | -0.00768    |
|    std                   | 0.787       |
|    value_loss            | 0.451       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.3435156   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 36           |
|    time_elapsed          | 1096         |
|    total_timesteps       | 1077248      |
| train/                   |              |
|    approx_kl             | 0.0045864014 |
|    clip_fraction         | 0.146        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.74         |
|    cost_value_loss       | 72.8         |
|    cost_values           | 1.3          |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.9         |
|    n_updates             | 5250         |
|    policy_gradient_loss  | 0.00521      |
|    std                   | 0.784        |
|    value_loss            | 0.728        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.102        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.102        |
| reward                   | -0.29394996  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 37           |
|    time_elapsed          | 1127         |
|    total_timesteps       | 1079296      |
| train/                   |              |
|    approx_kl             | 0.0067612054 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.51         |
|    cost_value_loss       | 90.4         |
|    cost_values           | 2.24         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.00585      |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 5260         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.783        |
|    value_loss            | 0.569        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.163        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.163        |
| reward                   | -0.5460143   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 38           |
|    time_elapsed          | 1158         |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 0.0076726973 |
|    clip_fraction         | 0.0687       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.36         |
|    cost_value_loss       | 57.7         |
|    cost_values           | 2.61         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.00402      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -0.00568     |
|    std                   | 0.784        |
|    value_loss            | 0.378        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.40312412 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1189        |
|    total_timesteps       | 1083392     |
| train/                   |             |
|    approx_kl             | 0.002806357 |
|    clip_fraction         | 0.00874     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 24          |
|    cost_values           | 2.2         |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 5280        |
|    policy_gradient_loss  | -0.0015     |
|    std                   | 0.785       |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.081       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.081       |
| reward                   | -0.41552484 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1221        |
|    total_timesteps       | 1085440     |
| train/                   |             |
|    approx_kl             | 0.007310182 |
|    clip_fraction         | 0.0468      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 120         |
|    cost_values           | 2.35        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0.0144      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.45        |
|    n_updates             | 5290        |
|    policy_gradient_loss  | -0.00743    |
|    std                   | 0.784       |
|    value_loss            | 0.282       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0223      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0223      |
| reward                   | -0.32164207 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1251        |
|    total_timesteps       | 1087488     |
| train/                   |             |
|    approx_kl             | 0.006750974 |
|    clip_fraction         | 0.083       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.35        |
|    cost_value_loss       | 92.2        |
|    cost_values           | 2.64        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.00456     |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 5300        |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 0.784       |
|    value_loss            | 0.471       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.163        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.163        |
| reward                   | -0.35955843  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1282         |
|    total_timesteps       | 1089536      |
| train/                   |              |
|    approx_kl             | 0.0018475591 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.44         |
|    cost_value_loss       | 28.3         |
|    cost_values           | 2.29         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0.00147      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.75         |
|    n_updates             | 5310         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.785        |
|    value_loss            | 0.675        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.178       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.178       |
| reward                   | -0.34837615 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 43          |
|    time_elapsed          | 1314        |
|    total_timesteps       | 1091584     |
| train/                   |             |
|    approx_kl             | 0.007876263 |
|    clip_fraction         | 0.0722      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.32        |
|    cost_value_loss       | 38          |
|    cost_values           | 2.46        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00453     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.86        |
|    n_updates             | 5320        |
|    policy_gradient_loss  | -0.00748    |
|    std                   | 0.78        |
|    value_loss            | 0.238       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.337       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.337       |
| reward                   | -0.5010988  |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 44          |
|    time_elapsed          | 1345        |
|    total_timesteps       | 1093632     |
| train/                   |             |
|    approx_kl             | 0.006541226 |
|    clip_fraction         | 0.0491      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.5        |
|    cost_value_loss       | 166         |
|    cost_values           | 2.82        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0.0194      |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 5330        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.776       |
|    value_loss            | 0.496       |
------------------------------------------
slurmstepd: error: *** STEP 148608.1 ON airl.ist.berkeley.edu CANCELLED AT 2024-03-07T16:20:04 ***
slurmstepd: error: *** JOB 148608 ON airl.ist.berkeley.edu CANCELLED AT 2024-03-07T16:20:04 ***
